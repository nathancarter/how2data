{"0": {
    "doc": "About",
    "title": "About How to Data",
    "content": " ",
    "url": "/about/#about-how-to-data",
    "relUrl": "/about/#about-how-to-data"
  },"1": {
    "doc": "About",
    "title": "Purpose",
    "content": "How to Data is a free, online reference site targeted primarily at analytics and data science students. It’s organized around statistical and data-related tasks and shows their implementation in a wide variety of software packages. ",
    "url": "/about/#purpose",
    "relUrl": "/about/#purpose"
  },"2": {
    "doc": "About",
    "title": "Scope",
    "content": "The website began at Bentley University and is initially targeted at the needs of students and faculty at that institution. It includes pages that organize the content around Bentley’s curriculum. But new content from other schools and businesses is always welcome, including new ways to organize existing content to better suit your organization’s needs. We aim for this resource to be as broadly useful as possible. We aim for the site to cover all the tasks useful to students in the data-related courses of study at Bentley (e.g., the Data Analytics major), and show how to accomplish those tasks in several common software packages and programming languages. But the site is just beginning, and does not yet cover every data-related course at Bentley. ",
    "url": "/about/#scope",
    "relUrl": "/about/#scope"
  },"3": {
    "doc": "About",
    "title": "History",
    "content": "The website was begun in Summer 2021 by Nathan Carter (a faculty member in Bentley’s Mathematical Sciences Department), with help from some other faculty and students. ",
    "url": "/about/#history",
    "relUrl": "/about/#history"
  },"4": {
    "doc": "About",
    "title": "Aren’t there websites like this already?",
    "content": "Not really. Here’s what I’ve seen, and why it’s not exactly what How to Data is designed to accomplish. | Software documentation . | Example: the pandas manual | Documentation is specific to one piece of software; How to Data aims to show how each task is solved in many different pieces of software. | Software documentation is not organized around the courses students are taking. | . | Q&amp;A sites . | Example: Stack Overflow | While an invaluable resource, such sites can have overly specific questions that don’t always teach a general lesson in a didactic way. | They are also not organized around a student’s coursework. | . | Interactive online lessons . | Example: DataCamp | These are excellent tools for a flipped classroom or individual study, but are not excellent references; they expect you to take your own notes. | They also typically have paywalls to support their business model. | . | Existing academic references . | Example: UCLA’s data analysis examples and annotated output | That website has very similar goals to How to Data, with one major exception—the lessons on that website are lengthy, while ours aim to be very bite-sized, answering one specific question with a short snippet of code that it’s easy to take and re-use. They’re aiming more to teach, while we’re aiming to get you the code or steps you need to do a task. | . | . ",
    "url": "/about/#arent-there-websites-like-this-already",
    "relUrl": "/about/#arent-there-websites-like-this-already"
  },"5": {
    "doc": "About",
    "title": "Why the funny name?",
    "content": "The Internet spawns many strange and amusing new ways to speak and write. One example innovation is using the words “how to” followed by a noun. Examples include online images of dogs, captioned with the phrase “I forgot how to dog”, or the book How to College. How to Data follows this pattern. ",
    "url": "/about/#why-the-funny-name",
    "relUrl": "/about/#why-the-funny-name"
  },"6": {
    "doc": "About",
    "title": "About",
    "content": " ",
    "url": "/about/",
    "relUrl": "/about/"
  },"7": {
    "doc": "Acknowledgments",
    "title": "Acknowledgments",
    "content": " ",
    "url": "/acknowledgments/",
    "relUrl": "/acknowledgments/"
  },"8": {
    "doc": "Acknowledgments",
    "title": "Content Contributors",
    "content": "Any solution on this website lists the author(s) at the bottom of the page. Here’s an example. Scroll to the bottom of it to see the authors. A complete list of authors who have contributed solutions so far appears below. Want to become one of them? Here’s how! . | Author | Solutions contributed | . | Nathan Carter (ncarter@bentley.edu) | 96 | . | Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) | 74 | . | Krtin Juneja (KJUNEJA@falcon.bentley.edu) | 30 | . | Ni Shi (shi_ni@bentley.edu) | 5 | . | Debayan Sen (DSEN@bentley.edu) | 3 | . | Andrew Quagliaroli (aquagliaroli@falcon.bentley.edu) | 3 | . ",
    "url": "/acknowledgments/#content-contributors",
    "relUrl": "/acknowledgments/#content-contributors"
  },"9": {
    "doc": "Acknowledgments",
    "title": "Advisors",
    "content": "The following faculty members have proofread student work or given advice on website structure or content. | Moinak Bhaduri | Nathan Carter | Reagan Mozer | Gregory Vaughan | . ",
    "url": "/acknowledgments/#advisors",
    "relUrl": "/acknowledgments/#advisors"
  },"10": {
    "doc": "Acknowledgments",
    "title": "Supporters",
    "content": "Bentley University supported the creation of this website in 2021 with the following resources. | a grant supporting Prof. Carter’s work creating the site infrastructure | a research assistantship for a student to add site content | . ",
    "url": "/acknowledgments/#supporters",
    "relUrl": "/acknowledgments/#supporters"
  },"11": {
    "doc": "Bentley University GB213",
    "title": "Topic - Bentley University GB213",
    "content": "GB213 is an undergraduate Business Statistics course at Bentley University. The description from the course catalog can be found here. Topics included in the course are listed as tasks below. Mathematical topics include random variables, discrete and continuous probability distributions, confidence intervals, hypothesis testing, single-variable linear models, and optionally ANOVA and/or $\\chi^2$ tests, time permitting. ",
    "url": "/bentley-university-gb213/#topic---bentley-university-gb213",
    "relUrl": "/bentley-university-gb213/#topic---bentley-university-gb213"
  },"12": {
    "doc": "Bentley University GB213",
    "title": "Basics",
    "content": ". | How to do basic mathematical computations | How to quickly load some sample data | How to compute summary statistics | . ",
    "url": "/bentley-university-gb213/#basics",
    "relUrl": "/bentley-university-gb213/#basics"
  },"13": {
    "doc": "Bentley University GB213",
    "title": "Random variables and probability distributions",
    "content": ". | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/bentley-university-gb213/#random-variables-and-probability-distributions",
    "relUrl": "/bentley-university-gb213/#random-variables-and-probability-distributions"
  },"14": {
    "doc": "Bentley University GB213",
    "title": "Confidence intervals and hypothesis testing",
    "content": ". | How to find critical values and p-values from the t-distribution | How to find critical values and p-values from the normal distribution | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/bentley-university-gb213/#confidence-intervals-and-hypothesis-testing",
    "relUrl": "/bentley-university-gb213/#confidence-intervals-and-hypothesis-testing"
  },"15": {
    "doc": "Bentley University GB213",
    "title": "Linear modeling, time permitting",
    "content": ". | How to fit a linear model to two columns of data | How to compute R-squared for a simple linear model | . Content last modified on 07 December 2021. Contributed by Nathan Carter (ncarter@bentley.edu) . Downloads . | Solutions in Python using SciPy (download PDF) | Solutions in pure R (download PDF) | Solutions in pure Julia (download PDF) | . ",
    "url": "/bentley-university-gb213/#linear-modeling-time-permitting",
    "relUrl": "/bentley-university-gb213/#linear-modeling-time-permitting"
  },"16": {
    "doc": "Bentley University GB213",
    "title": "Bentley University GB213",
    "content": " ",
    "url": "/bentley-university-gb213/",
    "relUrl": "/bentley-university-gb213/"
  },"17": {
    "doc": "Bentley University GR521",
    "title": "Topic - Bentley University GR521",
    "content": "GR521 is a graduate Managerial Statistics course at Bentley University. The description from the course catalog can be found here. Mathematical topics include random variables, discrete and continuous probability distributions, confidence intervals, hypothesis testing, single-variable linear models, and optionally advanced topics such as data mining, time permitting. ",
    "url": "/bentley-university-gr521/#topic---bentley-university-gr521",
    "relUrl": "/bentley-university-gr521/#topic---bentley-university-gr521"
  },"18": {
    "doc": "Bentley University GR521",
    "title": "Basics",
    "content": ". | How to do basic mathematical computations | How to quickly load some sample data | How to compute summary statistics | . ",
    "url": "/bentley-university-gr521/#basics",
    "relUrl": "/bentley-university-gr521/#basics"
  },"19": {
    "doc": "Bentley University GR521",
    "title": "Random variables and probability distributions",
    "content": ". | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/bentley-university-gr521/#random-variables-and-probability-distributions",
    "relUrl": "/bentley-university-gr521/#random-variables-and-probability-distributions"
  },"20": {
    "doc": "Bentley University GR521",
    "title": "Confidence intervals and hypothesis testing",
    "content": ". | How to find critical values and p-values from the t-distribution | How to find critical values and p-values from the normal distribution | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/bentley-university-gr521/#confidence-intervals-and-hypothesis-testing",
    "relUrl": "/bentley-university-gr521/#confidence-intervals-and-hypothesis-testing"
  },"21": {
    "doc": "Bentley University GR521",
    "title": "Linear modeling",
    "content": ". | How to fit a linear model to two columns of data | How to compute R-squared for a simple linear model | . ",
    "url": "/bentley-university-gr521/#linear-modeling",
    "relUrl": "/bentley-university-gr521/#linear-modeling"
  },"22": {
    "doc": "Bentley University GR521",
    "title": "Other end-of-semester topics, time permitting",
    "content": ". | How to do a one-way analysis of variance (ANOVA) | How to perform a chi-squared test on a contingency table | . Content last modified on 07 December 2021. Contributed by Nathan Carter (ncarter@bentley.edu) . Downloads . | Solutions in Python using SciPy (download PDF) | Solutions in pure R (download PDF) | Solutions in pure Julia (download PDF) | . ",
    "url": "/bentley-university-gr521/#other-end-of-semester-topics-time-permitting",
    "relUrl": "/bentley-university-gr521/#other-end-of-semester-topics-time-permitting"
  },"23": {
    "doc": "Bentley University GR521",
    "title": "Bentley University GR521",
    "content": " ",
    "url": "/bentley-university-gr521/",
    "relUrl": "/bentley-university-gr521/"
  },"24": {
    "doc": "Bentley University GR526",
    "title": "Topic - Bentley University GR526",
    "content": "GR526 is a graduate course at Bentley University that gives an overview of Calculus from a computational viewpoint, for students who plan to study quantitative finance. The description from the course catalog can be found here. Topics include limits, derivatives, integrals, differential equations, implicit differentiation, Taylor series, and continuous probability. By-hand computation is minimized and the use of a computer algebra system is required, such as Maxima or SymPy. ",
    "url": "/bentley-university-gr526/#topic---bentley-university-gr526",
    "relUrl": "/bentley-university-gr526/#topic---bentley-university-gr526"
  },"25": {
    "doc": "Bentley University GR526",
    "title": "Basic Symbolic Mathematics",
    "content": ". | How to do basic mathematical computations | How to create symbolic variables | How to substitute a value for a symbolic variable | . ",
    "url": "/bentley-university-gr526/#basic-symbolic-mathematics",
    "relUrl": "/bentley-university-gr526/#basic-symbolic-mathematics"
  },"26": {
    "doc": "Bentley University GR526",
    "title": "Functions and Graphs",
    "content": ". | How to compute the domain of a function | How to graph mathematical functions | How to graph curves that are not functions | How to write a piecewise-defined function | How to graph a two-variable function as a surface | . ",
    "url": "/bentley-university-gr526/#functions-and-graphs",
    "relUrl": "/bentley-university-gr526/#functions-and-graphs"
  },"27": {
    "doc": "Bentley University GR526",
    "title": "Equations and Systems",
    "content": ". | How to write symbolic equations | How to solve symbolic equations | How to isolate one variable in an equation | . ",
    "url": "/bentley-university-gr526/#equations-and-systems",
    "relUrl": "/bentley-university-gr526/#equations-and-systems"
  },"28": {
    "doc": "Bentley University GR526",
    "title": "Limits, Sequences, and Series",
    "content": ". | How to compute the limit of a function | How to define a mathematical sequence | How to graph mathematical sequences | How to define a mathematical series (and evaluate it) | . ",
    "url": "/bentley-university-gr526/#limits-sequences-and-series",
    "relUrl": "/bentley-university-gr526/#limits-sequences-and-series"
  },"29": {
    "doc": "Bentley University GR526",
    "title": "Differentiation",
    "content": ". | How to compute the derivative of a function | How to compute the Taylor series for a function | How to compute the error bounds on a Taylor approximation | How to do implicit differentiation | How to find the critical numbers of a function | . ",
    "url": "/bentley-university-gr526/#differentiation",
    "relUrl": "/bentley-university-gr526/#differentiation"
  },"30": {
    "doc": "Bentley University GR526",
    "title": "Antidifferentiation",
    "content": ". | How to write and evaluate indefinite integrals | How to write and evaluate definite integrals | . ",
    "url": "/bentley-university-gr526/#antidifferentiation",
    "relUrl": "/bentley-university-gr526/#antidifferentiation"
  },"31": {
    "doc": "Bentley University GR526",
    "title": "Differential Equations",
    "content": ". | How to write an ordinary differential equation | How to solve an ordinary differential equation | . Content last modified on 07 June 2021. Contributed by Nathan Carter (ncarter@bentley.edu) . Downloads . | Solutions in Python using SymPy (download PDF) | . ",
    "url": "/bentley-university-gr526/#differential-equations",
    "relUrl": "/bentley-university-gr526/#differential-equations"
  },"32": {
    "doc": "Bentley University GR526",
    "title": "Bentley University GR526",
    "content": " ",
    "url": "/bentley-university-gr526/",
    "relUrl": "/bentley-university-gr526/"
  },"33": {
    "doc": "Bentley University MA214",
    "title": "Topic - Bentley University MA214",
    "content": "MA214 is an undergraduate statistics course at Bentley University that builds on the basic managerial statistics course taken by all students. The description from the course catalog can be found here. It covers hypothesis tests, analysis of variance, multiple regression, and contingency tables. ",
    "url": "/bentley-university-ma214/#topic---bentley-university-ma214",
    "relUrl": "/bentley-university-ma214/#topic---bentley-university-ma214"
  },"34": {
    "doc": "Bentley University MA214",
    "title": "Review of statistical inference",
    "content": ". | How to compute a confidence interval for a population mean | How to compute a confidence interval for a population mean using z-scores | How to compute a confidence interval for the population proportion | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the mean with known standard deviation | . ",
    "url": "/bentley-university-ma214/#review-of-statistical-inference",
    "relUrl": "/bentley-university-ma214/#review-of-statistical-inference"
  },"35": {
    "doc": "Bentley University MA214",
    "title": "Two populations",
    "content": ". | How to compute a confidence interval for a mean difference (matched pairs) | How to choose the sample size in a study with two population means | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the ratio of two population variances | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the ratio of two population variances | How to do a Kruskal-Wallis test | How to do a one-sided hypothesis test for two sample means | How to do a Wilcoxon rank-sum test | How to do a Wilcoxon signed-rank test | How to do a Wilcoxon signed-rank test for matched pairs | . ",
    "url": "/bentley-university-ma214/#two-populations",
    "relUrl": "/bentley-university-ma214/#two-populations"
  },"36": {
    "doc": "Bentley University MA214",
    "title": "Variance inference",
    "content": ". | How to compute a confidence interval for a single population variance | . ",
    "url": "/bentley-university-ma214/#variance-inference",
    "relUrl": "/bentley-university-ma214/#variance-inference"
  },"37": {
    "doc": "Bentley University MA214",
    "title": "Chi-squares tests",
    "content": ". | How to perform a chi-squared test on a contingency table | How to do a goodness of fit test for a multinomial experiment | . ",
    "url": "/bentley-university-ma214/#chi-squares-tests",
    "relUrl": "/bentley-university-ma214/#chi-squares-tests"
  },"38": {
    "doc": "Bentley University MA214",
    "title": "ANOVA",
    "content": ". | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compute Fisher’s confidence intervals | How to perform an analysis of covariance (ANCOVA) | How to perform post-hoc analysis with Tukey’s HSD test | How to use Bonferroni’s Correction method | . ",
    "url": "/bentley-university-ma214/#anova",
    "relUrl": "/bentley-university-ma214/#anova"
  },"39": {
    "doc": "Bentley University MA214",
    "title": "Regression",
    "content": ". | How to fit a linear model to two columns of data | How to compute a confidence interval for the expected value of a response variable | How to compute R-squared for a simple linear model | How to predict the response variable in a linear model | . ",
    "url": "/bentley-university-ma214/#regression",
    "relUrl": "/bentley-university-ma214/#regression"
  },"40": {
    "doc": "Bentley University MA214",
    "title": "Nonparametric tests",
    "content": ". | How to create a QQ-plot | How to test data for normality with Pearson’s chi-squared test | How to test data for normality with the D’Agostino-Pearson test | How to test data for normality with the Jarque-Bera test | . Content last modified on 07 December 2021. Contributed by Nathan Carter (ncarter@bentley.edu) . Downloads . | Solutions in Python using SciPy (download PDF) | Solutions in pure R (download PDF) | . ",
    "url": "/bentley-university-ma214/#nonparametric-tests",
    "relUrl": "/bentley-university-ma214/#nonparametric-tests"
  },"41": {
    "doc": "Bentley University MA214",
    "title": "Bentley University MA214",
    "content": " ",
    "url": "/bentley-university-ma214/",
    "relUrl": "/bentley-university-ma214/"
  },"42": {
    "doc": "Bentley University MA252",
    "title": "Topic - Bentley University MA252",
    "content": "MA252 is an undergraduate statistics course at Bentley University that focuses on model building using regression. The description from the course catalog can be found here. It covers simple linear regression, multivariate linear regression, logistic linear regression, model building, transformations, and interactions. ",
    "url": "/bentley-university-ma252/#topic---bentley-university-ma252",
    "relUrl": "/bentley-university-ma252/#topic---bentley-university-ma252"
  },"43": {
    "doc": "Bentley University MA252",
    "title": "Simple Linear Regression",
    "content": ". | How to fit a linear model to two columns of data | How to compute a confidence interval for the expected value of a response variable | How to compute R-squared for a simple linear model | How to predict the response variable in a linear model | . ",
    "url": "/bentley-university-ma252/#simple-linear-regression",
    "relUrl": "/bentley-university-ma252/#simple-linear-regression"
  },"44": {
    "doc": "Bentley University MA252",
    "title": "Multivariate Linear Regression",
    "content": ". | How to fit a multivariate linear model | How to add an interaction term to a model | How to add a polynomial term to a model | How to add a transformed term to a model | How to compute a confidence interval for a regression coefficient | How to compute adjusted R-squared | . ",
    "url": "/bentley-university-ma252/#multivariate-linear-regression",
    "relUrl": "/bentley-university-ma252/#multivariate-linear-regression"
  },"45": {
    "doc": "Bentley University MA252",
    "title": "Model Building",
    "content": ". | How to compute covariance and correlation coefficients | How to compute the standard error of the estimate for a model | How to do a hypothesis test of a coefficient’s significance | How to do a test of joint significance | How to do a Spearman rank correlation test | . ",
    "url": "/bentley-university-ma252/#model-building",
    "relUrl": "/bentley-university-ma252/#model-building"
  },"46": {
    "doc": "Bentley University MA252",
    "title": "Residual Analysis",
    "content": ". | How to compute the residuals of a linear model | . Content last modified on 07 December 2021. Contributed by Nathan Carter (ncarter@bentley.edu) . Downloads . | Solutions in pure R (download PDF) | . ",
    "url": "/bentley-university-ma252/#residual-analysis",
    "relUrl": "/bentley-university-ma252/#residual-analysis"
  },"47": {
    "doc": "Bentley University MA252",
    "title": "Bentley University MA252",
    "content": " ",
    "url": "/bentley-university-ma252/",
    "relUrl": "/bentley-university-ma252/"
  },"48": {
    "doc": "Bentley University MA255",
    "title": "Topic - Bentley University MA255",
    "content": "MA255 is an undergraduate statistics course at Bentley University on the Design of Experiments. The description from the course catalog can be found here. The course covers various experimental designs including factorial and fractional factorial designs, interaction among factors, and applications in management (including cost savings and policy making) as well as in marketing. The sequence of topics below is not necessarily the final version; this topic page is under construction. ",
    "url": "/bentley-university-ma255/#topic---bentley-university-ma255",
    "relUrl": "/bentley-university-ma255/#topic---bentley-university-ma255"
  },"49": {
    "doc": "Bentley University MA255",
    "title": "Summarizing data and exploratory analysis",
    "content": ". | How to summarize a column | How to compute summary statistics | How to summarize and compare data by groups | How to create bivariate plots to compare groups | . ",
    "url": "/bentley-university-ma255/#summarizing-data-and-exploratory-analysis",
    "relUrl": "/bentley-university-ma255/#summarizing-data-and-exploratory-analysis"
  },"50": {
    "doc": "Bentley University MA255",
    "title": "Experiments with one treatment factor",
    "content": ". | How to check the assumptions of a linear model | How to compute the power of a test comparing two population means | How to perform an analysis of covariance (ANCOVA) | How to perform pairwise comparisons | How to perform post-hoc analysis with Tukey’s HSD test | How to test for a treatment effect in a single factor design | . ",
    "url": "/bentley-university-ma255/#experiments-with-one-treatment-factor",
    "relUrl": "/bentley-university-ma255/#experiments-with-one-treatment-factor"
  },"51": {
    "doc": "Bentley University MA255",
    "title": "Analyzing data from a larger design",
    "content": ". | How to plot interaction effects of treatments | How to analyze the sample means of different treatment conditions | How to compare two nested linear models | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform a planned comparison test | . Content last modified on 07 December 2021. Contributed by Nathan Carter (ncarter@bentley.edu) . Downloads . | Solutions in pure R (download PDF) | . ",
    "url": "/bentley-university-ma255/#analyzing-data-from-a-larger-design",
    "relUrl": "/bentley-university-ma255/#analyzing-data-from-a-larger-design"
  },"52": {
    "doc": "Bentley University MA255",
    "title": "Bentley University MA255",
    "content": " ",
    "url": "/bentley-university-ma255/",
    "relUrl": "/bentley-university-ma255/"
  },"53": {
    "doc": "Bentley University MA346",
    "title": "Topic - Bentley University MA346",
    "content": "MA346 is an undergraduate data science course at Bentley University. The description from the course catalog can be found here. Topics included in the course are listed as tasks below. Mathematical topics include functions and relations, a review of basic statistics, and (time permitting) networks, matrices, and an introduction to supervised learning. Computing topics include Jupyter notebooks (locally and in the cloud), Python and pandas, abstraction, concatenation and merging, map-reduce, split-apply-combine, data munging, version control, and dashboards. Communication topics include best practices for writing reports, documenting code and computational notebooks, and data visualization. ",
    "url": "/bentley-university-ma346/#topic---bentley-university-ma346",
    "relUrl": "/bentley-university-ma346/#topic---bentley-university-ma346"
  },"54": {
    "doc": "Bentley University MA346",
    "title": "Basics",
    "content": ". | How to do basic mathematical computations | How to quickly load some sample data | How to compute summary statistics | . ",
    "url": "/bentley-university-ma346/#basics",
    "relUrl": "/bentley-university-ma346/#basics"
  },"55": {
    "doc": "Bentley University MA346",
    "title": "Data manipulation",
    "content": ". | How to convert a text column into dates | How to create a data frame from scratch | . ",
    "url": "/bentley-university-ma346/#data-manipulation",
    "relUrl": "/bentley-university-ma346/#data-manipulation"
  },"56": {
    "doc": "Bentley University MA346",
    "title": "Statistics in Python",
    "content": ". | How to compute covariance and correlation coefficients | . ",
    "url": "/bentley-university-ma346/#statistics-in-python",
    "relUrl": "/bentley-university-ma346/#statistics-in-python"
  },"57": {
    "doc": "Bentley University MA346",
    "title": "Plotting",
    "content": ". | How to create basic plots | How to add details to a plot | How to change axes, ticks, and scale in a plot | How to create a histogram | How to create a box (and whisker) plot | How to create a QQ-plot | . This page is not yet complete. More content will be added here over time. Content last modified on 07 December 2021. Contributed by Nathan Carter (ncarter@bentley.edu) . Downloads . | Solutions in pure R (download PDF) | . ",
    "url": "/bentley-university-ma346/#plotting",
    "relUrl": "/bentley-university-ma346/#plotting"
  },"58": {
    "doc": "Bentley University MA346",
    "title": "Bentley University MA346",
    "content": " ",
    "url": "/bentley-university-ma346/",
    "relUrl": "/bentley-university-ma346/"
  },"59": {
    "doc": "Contributing",
    "title": "Contributing to How to Data",
    "content": "By contributing to How to Data, you’re permitting your work to be used under the same license as the rest of the site. See licensing information in the README of our GitHub repository. ",
    "url": "/contributing/#contributing-to-how-to-data",
    "relUrl": "/contributing/#contributing-to-how-to-data"
  },"60": {
    "doc": "Contributing",
    "title": "If you’ve come to this page because you have a question…",
    "content": "You probably want to be browsing our Tasks page. If your question isn’t there, this site may not be the right place for you. It’s a reference for common questions, not a place to ask individual questions. We highly recommend the following websites that answer custom/individual questions. | For programming questions: Stack Overflow | For statistics questions: Cross Validated | For mathematics questions: Math Stack Exchange | . ",
    "url": "/contributing/#if-youve-come-to-this-page-because-you-have-a-question",
    "relUrl": "/contributing/#if-youve-come-to-this-page-because-you-have-a-question"
  },"61": {
    "doc": "Contributing",
    "title": "If you’ve come to this page because there’s a mistake on our site…",
    "content": "Please tell us! The best way to do so is to file a new issue in our source code repository. ",
    "url": "/contributing/#if-youve-come-to-this-page-because-theres-a-mistake-on-our-site",
    "relUrl": "/contributing/#if-youve-come-to-this-page-because-theres-a-mistake-on-our-site"
  },"62": {
    "doc": "Contributing",
    "title": "If you’ve come to this page because you have a suggested improvement…",
    "content": "Great! You can make the edit yourself, and we’ll review it for inclusion. Here’s how: . | View whichever solution you’d like to improve. | At the bottom of the page, click the link that says “edit the source.” | Click the pencil icon on the right above the page content to start editing. | Under the “Commit changes” heading, write a short phrase to explain what you’re submitting, such as “Fixing incorrect RMSE formula.” | Make sure you’re creating a new branch and a pull request. (A “pull request” is a request for the How to Data maintainers to review and accept your submission.) | Click “Commit changes.” | . ",
    "url": "/contributing/#if-youve-come-to-this-page-because-you-have-a-suggested-improvement",
    "relUrl": "/contributing/#if-youve-come-to-this-page-because-you-have-a-suggested-improvement"
  },"63": {
    "doc": "Contributing",
    "title": "If you’ve come to this page because you want to create new content…",
    "content": "Excellent! Download this zipped folder and read the document inside it to see how to get started. The download contains example content you can edit to create new tasks and/or solutions that are then ready to upload, following the instructions in the document. When writing new content, please follow these guidelines: . | Write plenty of explanations. Comments in code are great. Comments between code cells are great. Explain everything you’re doing in your code. | Break your work into bite-sized pieces. Really large chunks of complex code are not helpful to learners. If you have many nested function calls, consider breaking them down into small assignment statements instead. | Use helpful names for variables and functions. Do not call a variable t when you could call it seconds_elapsed. Do not call a function convert when you could call it inches_to_cm. | . ",
    "url": "/contributing/#if-youve-come-to-this-page-because-you-want-to-create-new-content",
    "relUrl": "/contributing/#if-youve-come-to-this-page-because-you-want-to-create-new-content"
  },"64": {
    "doc": "Contributing",
    "title": "Contributing",
    "content": " ",
    "url": "/contributing/",
    "relUrl": "/contributing/"
  },"65": {
    "doc": "How to add a polynomial term to a model (in Python, using sklearn)",
    "title": "How to add a polynomial term to a model (in Python, using sklearn)",
    "content": "See all solutions. ",
    "url": "/how-to-add-a-polynomial-term-to-a-model-in-python-using-sklearn/",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model-in-python-using-sklearn/"
  },"66": {
    "doc": "How to add a polynomial term to a model (in Python, using sklearn)",
    "title": "Task",
    "content": "Sometimes, a simple linear model isn’t sufficient to describe the data. How can we include a higher-order term in a regression model, such as the square or cube of one of the predictors? . Related tasks: . | How to add a transformed term to a model | How to add an interaction term to a model | . ",
    "url": "/how-to-add-a-polynomial-term-to-a-model-in-python-using-sklearn/#task",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model-in-python-using-sklearn/#task"
  },"67": {
    "doc": "How to add a polynomial term to a model (in Python, using sklearn)",
    "title": "Solution",
    "content": "We begin with a fabricated dataset of 20 points. You can replace the code below with your own, real, data. | 1 2 3 4 5 . | import numpy as np import pandas as pd x = np.arange(0,20) # List of integers from 0 to 19 y = [3,4,5,7,9,20,31,50,70,75,80,91,101,120,135,160,179,181,190,193] # List of 20 integers . | . We extend our dataset with a new column (or “feature”), containing $x^2$. | 1 2 3 4 . | from sklearn.preprocessing import PolynomialFeatures poly = PolynomialFeatures( degree=2, include_bias=False ) x_matrix = x.reshape( -1, 1 ) # make x a matrix so that we can add columns poly_features = poly.fit_transform( x_matrix ) # add a second column, so we now have x and x^2 . | . Next, fit a regression model to the new features, which are $x$ and $x^2$. | 1 2 3 4 . | from sklearn.linear_model import LinearRegression poly_reg_model = LinearRegression() # Our model will be linear in the features x and x^2 poly_reg_model.fit( poly_features, y ) # Use regression to create the model . | . | 1 . | LinearRegression() . | . Finally, get the coefficients and intercept of the model. | 1 . | poly_reg_model.intercept_, poly_reg_model.coef_ . | . | 1 . | (-8.384415584415635, array([6.28628389, 0.27420825])) . | . Thus the equation for our model of degree two is $\\widehat{y} = -8.38 + 6.28x + 0.27x^2$ . Content last modified on 21 June 2022. See a problem? Tell us or edit the source. Contributed by Debayan Sen (DSEN@bentley.edu) . ",
    "url": "/how-to-add-a-polynomial-term-to-a-model-in-python-using-sklearn/#solution",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model-in-python-using-sklearn/#solution"
  },"68": {
    "doc": "How to add a polynomial term to a model (in R)",
    "title": "How to add a polynomial term to a model (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-add-a-polynomial-term-to-a-model-in-r/",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model-in-r/"
  },"69": {
    "doc": "How to add a polynomial term to a model (in R)",
    "title": "Task",
    "content": "Sometimes, a simple linear model isn’t sufficient to describe the data. How can we include a higher-order term in a regression model, such as the square or cube of one of the predictors? . Related tasks: . | How to add a transformed term to a model | How to add an interaction term to a model | . ",
    "url": "/how-to-add-a-polynomial-term-to-a-model-in-r/#task",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model-in-r/#task"
  },"70": {
    "doc": "How to add a polynomial term to a model (in R)",
    "title": "Solution",
    "content": "We’re going to use the Pressure dataset in R’s ggplot library as example data. It contains observations of pressure and temperature. You would use your own data instead. | 1 2 3 . | # install.packages( \"ggplot2\" ) # if you haven't done this already library(ggplot2) data(\"pressure\") . | . Let’s model temperature as the dependent variable with pressure squared as the independent variable. To place the “pressure squared” term in the model, we use R’s poly function, as shown below. It automatically includes a pressure term as well (not squared). | 1 2 3 . | # Build the model model &lt;- lm(temperature ~ poly(pressure, 2), data = pressure) summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 . | Call: lm(formula = temperature ~ poly(pressure, 2), data = pressure) Residuals: Min 1Q Median 3Q Max -113.095 -44.543 6.157 50.459 75.791 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 180.00 14.31 12.581 1.03e-09 *** poly(pressure, 2)1 361.84 62.36 5.802 2.70e-05 *** poly(pressure, 2)2 -186.66 62.36 -2.993 0.0086 ** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 62.36 on 16 degrees of freedom Multiple R-squared: 0.7271, Adjusted R-squared: 0.693 F-statistic: 21.31 on 2 and 16 DF, p-value: 3.079e-05 . | . Now we have a model of the form $\\hat t = 180 + 361.84p - 186.66p^2$, where $t$ stands for temperature and $p$ for pressure. You can change the number in the poly function. For example, if we wanted to create a third-degree polynomial term then we would have specified poly(pressure, 3), and it would have included pressure, pressure squared, and pressure cubed. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-add-a-polynomial-term-to-a-model-in-r/#solution",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model-in-r/#solution"
  },"71": {
    "doc": "How to add a polynomial term to a model",
    "title": "How to add a polynomial term to a model",
    "content": " ",
    "url": "/how-to-add-a-polynomial-term-to-a-model/",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model/"
  },"72": {
    "doc": "How to add a polynomial term to a model",
    "title": "Description",
    "content": "Sometimes, a simple linear model isn’t sufficient to describe the data. How can we include a higher-order term in a regression model, such as the square or cube of one of the predictors? . Related tasks: . | How to add a transformed term to a model | How to add an interaction term to a model | . ",
    "url": "/how-to-add-a-polynomial-term-to-a-model/#description",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model/#description"
  },"73": {
    "doc": "How to add a polynomial term to a model",
    "title": "Using sklearn, in Python",
    "content": "View this solution alone. We begin with a fabricated dataset of 20 points. You can replace the code below with your own, real, data. | 1 2 3 4 5 . | import numpy as np import pandas as pd x = np.arange(0,20) # List of integers from 0 to 19 y = [3,4,5,7,9,20,31,50,70,75,80,91,101,120,135,160,179,181,190,193] # List of 20 integers . | . We extend our dataset with a new column (or “feature”), containing $x^2$. | 1 2 3 4 . | from sklearn.preprocessing import PolynomialFeatures poly = PolynomialFeatures( degree=2, include_bias=False ) x_matrix = x.reshape( -1, 1 ) # make x a matrix so that we can add columns poly_features = poly.fit_transform( x_matrix ) # add a second column, so we now have x and x^2 . | . Next, fit a regression model to the new features, which are $x$ and $x^2$. | 1 2 3 4 . | from sklearn.linear_model import LinearRegression poly_reg_model = LinearRegression() # Our model will be linear in the features x and x^2 poly_reg_model.fit( poly_features, y ) # Use regression to create the model . | . | 1 . | LinearRegression() . | . Finally, get the coefficients and intercept of the model. | 1 . | poly_reg_model.intercept_, poly_reg_model.coef_ . | . | 1 . | (-8.384415584415635, array([6.28628389, 0.27420825])) . | . Thus the equation for our model of degree two is $\\widehat{y} = -8.38 + 6.28x + 0.27x^2$ . Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-add-a-polynomial-term-to-a-model/#using-sklearn-in-python",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model/#using-sklearn-in-python"
  },"74": {
    "doc": "How to add a polynomial term to a model",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use the Pressure dataset in R’s ggplot library as example data. It contains observations of pressure and temperature. You would use your own data instead. | 1 2 3 . | # install.packages( \"ggplot2\" ) # if you haven't done this already library(ggplot2) data(\"pressure\") . | . Let’s model temperature as the dependent variable with pressure squared as the independent variable. To place the “pressure squared” term in the model, we use R’s poly function, as shown below. It automatically includes a pressure term as well (not squared). | 1 2 3 . | # Build the model model &lt;- lm(temperature ~ poly(pressure, 2), data = pressure) summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 . | Call: lm(formula = temperature ~ poly(pressure, 2), data = pressure) Residuals: Min 1Q Median 3Q Max -113.095 -44.543 6.157 50.459 75.791 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 180.00 14.31 12.581 1.03e-09 *** poly(pressure, 2)1 361.84 62.36 5.802 2.70e-05 *** poly(pressure, 2)2 -186.66 62.36 -2.993 0.0086 ** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 62.36 on 16 degrees of freedom Multiple R-squared: 0.7271, Adjusted R-squared: 0.693 F-statistic: 21.31 on 2 and 16 DF, p-value: 3.079e-05 . | . Now we have a model of the form $\\hat t = 180 + 361.84p - 186.66p^2$, where $t$ stands for temperature and $p$ for pressure. You can change the number in the poly function. For example, if we wanted to create a third-degree polynomial term then we would have specified poly(pressure, 3), and it would have included pressure, pressure squared, and pressure cubed. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-add-a-polynomial-term-to-a-model/#solution-in-r",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model/#solution-in-r"
  },"75": {
    "doc": "How to add a polynomial term to a model",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-add-a-polynomial-term-to-a-model/#topics-that-include-this-task",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model/#topics-that-include-this-task"
  },"76": {
    "doc": "How to add a polynomial term to a model",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-add-a-polynomial-term-to-a-model/#opportunities",
    "relUrl": "/how-to-add-a-polynomial-term-to-a-model/#opportunities"
  },"77": {
    "doc": "How to add a transformed term to a model (in Python, using NumPy and sklearn)",
    "title": "How to add a transformed term to a model (in Python, using NumPy and sklearn)",
    "content": "See all solutions. ",
    "url": "/how-to-add-a-transformed-term-to-a-model-in-python-using-numpy-and-sklearn/",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model-in-python-using-numpy-and-sklearn/"
  },"78": {
    "doc": "How to add a transformed term to a model (in Python, using NumPy and sklearn)",
    "title": "Task",
    "content": "Sometimes, a simple linear model isn’t sufficient for our data, and we need more complex terms or transformed variables in the model to make adequate predictions. How do we include these complex and transformed terms in a regression model? . Related tasks: . | How to add a polynomial term to a model | How to add an interaction term to a model | . ",
    "url": "/how-to-add-a-transformed-term-to-a-model-in-python-using-numpy-and-sklearn/#task",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model-in-python-using-numpy-and-sklearn/#task"
  },"79": {
    "doc": "How to add a transformed term to a model (in Python, using NumPy and sklearn)",
    "title": "Solution",
    "content": "We’re going to create the Pressure dataset as example data. It contains observations of pressure and temperature. You would use your own data instead. | 1 2 3 4 5 6 7 8 9 . | import pandas as pd pressure = pd.DataFrame( { 'temperature': [0,20,40,60,80,100,120,140,160,180,200, 220,240,260,280,300,320,340,360], 'pressure': [0.0002,0.0012,0.0060,0.0300,0.0900,0.2700,0.7500, 1.8500,4.2000,8.8000,17.3000,32.1000,57.0000,96.0000, 157.0000,247.0000,376.0000,558.0000,806.0000] } ) pressure . | . | | temperature | pressure | . | 0 | 0 | 0.0002 | . | 1 | 20 | 0.0012 | . | 2 | 40 | 0.0060 | . | 3 | 60 | 0.0300 | . | 4 | 80 | 0.0900 | . | 5 | 100 | 0.2700 | . | 6 | 120 | 0.7500 | . | 7 | 140 | 1.8500 | . | 8 | 160 | 4.2000 | . | 9 | 180 | 8.8000 | . | 10 | 200 | 17.3000 | . | 11 | 220 | 32.1000 | . | 12 | 240 | 57.0000 | . | 13 | 260 | 96.0000 | . | 14 | 280 | 157.0000 | . | 15 | 300 | 247.0000 | . | 16 | 320 | 376.0000 | . | 17 | 340 | 558.0000 | . | 18 | 360 | 806.0000 | . Let’s model temperature as the dependent variable with the logarithm of pressure as the independent variable. To transform the independent variable pressure, we use NumPy’s np.log function, as shown below. It uses the natural logarithm (base $e$). | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 . | import numpy as np # Compute the logarithm of pressure X = pressure[['pressure']] log_X = np.log(X) # Build the linear model using Scikit-Learn from sklearn.linear_model import LinearRegression y = pressure['temperature'] log_model = LinearRegression() log_model.fit(log_X, y) # Display regression coefficients and R-squared value of the model log_model.intercept_, log_model.coef_, log_model.score(log_X, y) . | . | 1 . | (153.97045660511063, array([23.78440995]), 0.9464264282083346) . | . The model is $\\hat t = 153.97 + 23.784\\log p$, where $t$ stands for temperature and $p$ for pressure. Another example transformation is the square root transformation. As with np.log, just apply the np.sqrt function to the appropriate term when defining the model. | 1 2 3 4 5 6 7 8 9 10 11 12 . | # Compute the square root of pressure X = pressure[['pressure']] sqrt_X = np.sqrt(X) # Build the linear model using Scikit-Learn from sklearn.linear_model import LinearRegression y = pressure['temperature'] sqrt_model = LinearRegression() sqrt_model.fit(sqrt_X, y) # Display regression coefficients and R-squared value of the model sqrt_model.intercept_, sqrt_model.coef_, sqrt_model.score( log_X, y ) . | . | 1 . | (98.56139249917803, array([11.44621468]), 0.29600246256782614) . | . The model is $\\hat t = 98.561 + 11.446\\sqrt{p}$, with $t$ and $p$ having the same meanings as above. Content last modified on 18 October 2022. See a problem? Tell us or edit the source. Contributed by Ni Shi (shi_ni@bentley.edu) . ",
    "url": "/how-to-add-a-transformed-term-to-a-model-in-python-using-numpy-and-sklearn/#solution",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model-in-python-using-numpy-and-sklearn/#solution"
  },"80": {
    "doc": "How to add a transformed term to a model (in R)",
    "title": "How to add a transformed term to a model (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-add-a-transformed-term-to-a-model-in-r/",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model-in-r/"
  },"81": {
    "doc": "How to add a transformed term to a model (in R)",
    "title": "Task",
    "content": "Sometimes, a simple linear model isn’t sufficient for our data, and we need more complex terms or transformed variables in the model to make adequate predictions. How do we include these complex and transformed terms in a regression model? . Related tasks: . | How to add a polynomial term to a model | How to add an interaction term to a model | . ",
    "url": "/how-to-add-a-transformed-term-to-a-model-in-r/#task",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model-in-r/#task"
  },"82": {
    "doc": "How to add a transformed term to a model (in R)",
    "title": "Solution",
    "content": "We’re going to use the Pressure dataset in R’s ggplot library as example data. It contains observations of pressure and temperature. You would use your own data instead. | 1 2 3 . | # install.packages( \"ggplot2\" ) # if you haven't done this already library(ggplot2) data(\"pressure\") . | . Let’s model temperature as the dependent variable with the logarithm of pressure as the independent variable. To place the “log of pressure” term in the model, we use R’s log function, as shown below. It uses the naturarl logarithm (base $e$). | 1 2 3 . | # Build the model model.log &lt;- lm(temperature ~ log(pressure), data = pressure) summary(model.log) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | Call: lm(formula = temperature ~ log(pressure), data = pressure) Residuals: Min 1Q Median 3Q Max -28.60 -22.30 -10.13 20.00 48.61 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 153.970 6.330 24.32 1.20e-14 *** log(pressure) 23.784 1.372 17.33 3.07e-12 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 26.81 on 17 degrees of freedom Multiple R-squared: 0.9464, Adjusted R-squared: 0.9433 F-statistic: 300.3 on 1 and 17 DF, p-value: 3.07e-12 . | . The model is $\\hat t = 153.97 + 23.784\\log p$, where $t$ stands for temperature and $p$ for pressure. Another example transformation is the square root transformation. As with log, just apply the sqrt function to the appropriate term when defining the model. | 1 2 3 . | # Build the model model.sqrt &lt;- lm(temperature ~ sqrt(pressure), data = pressure) summary(model.sqrt) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | Call: lm(formula = temperature ~ sqrt(pressure), data = pressure) Residuals: Min 1Q Median 3Q Max -98.72 -34.74 11.53 42.75 56.59 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 98.561 15.244 6.465 5.81e-06 *** sqrt(pressure) 11.446 1.367 8.372 1.95e-07 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 51.16 on 17 degrees of freedom Multiple R-squared: 0.8048, Adjusted R-squared: 0.7933 F-statistic: 70.1 on 1 and 17 DF, p-value: 1.953e-07 . | . The model is $\\hat t = 98.561 + 11.446\\sqrt{p}$, with $t$ and $p$ having the same meanings as above. Content last modified on 16 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-add-a-transformed-term-to-a-model-in-r/#solution",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model-in-r/#solution"
  },"83": {
    "doc": "How to add a transformed term to a model",
    "title": "How to add a transformed term to a model",
    "content": " ",
    "url": "/how-to-add-a-transformed-term-to-a-model/",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model/"
  },"84": {
    "doc": "How to add a transformed term to a model",
    "title": "Description",
    "content": "Sometimes, a simple linear model isn’t sufficient for our data, and we need more complex terms or transformed variables in the model to make adequate predictions. How do we include these complex and transformed terms in a regression model? . Related tasks: . | How to add a polynomial term to a model | How to add an interaction term to a model | . ",
    "url": "/how-to-add-a-transformed-term-to-a-model/#description",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model/#description"
  },"85": {
    "doc": "How to add a transformed term to a model",
    "title": "Using NumPy and sklearn, in Python",
    "content": "View this solution alone. We’re going to create the Pressure dataset as example data. It contains observations of pressure and temperature. You would use your own data instead. | 1 2 3 4 5 6 7 8 9 . | import pandas as pd pressure = pd.DataFrame( { 'temperature': [0,20,40,60,80,100,120,140,160,180,200, 220,240,260,280,300,320,340,360], 'pressure': [0.0002,0.0012,0.0060,0.0300,0.0900,0.2700,0.7500, 1.8500,4.2000,8.8000,17.3000,32.1000,57.0000,96.0000, 157.0000,247.0000,376.0000,558.0000,806.0000] } ) pressure . | . | | temperature | pressure | . | 0 | 0 | 0.0002 | . | 1 | 20 | 0.0012 | . | 2 | 40 | 0.0060 | . | 3 | 60 | 0.0300 | . | 4 | 80 | 0.0900 | . | 5 | 100 | 0.2700 | . | 6 | 120 | 0.7500 | . | 7 | 140 | 1.8500 | . | 8 | 160 | 4.2000 | . | 9 | 180 | 8.8000 | . | 10 | 200 | 17.3000 | . | 11 | 220 | 32.1000 | . | 12 | 240 | 57.0000 | . | 13 | 260 | 96.0000 | . | 14 | 280 | 157.0000 | . | 15 | 300 | 247.0000 | . | 16 | 320 | 376.0000 | . | 17 | 340 | 558.0000 | . | 18 | 360 | 806.0000 | . Let’s model temperature as the dependent variable with the logarithm of pressure as the independent variable. To transform the independent variable pressure, we use NumPy’s np.log function, as shown below. It uses the natural logarithm (base $e$). | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 . | import numpy as np # Compute the logarithm of pressure X = pressure[['pressure']] log_X = np.log(X) # Build the linear model using Scikit-Learn from sklearn.linear_model import LinearRegression y = pressure['temperature'] log_model = LinearRegression() log_model.fit(log_X, y) # Display regression coefficients and R-squared value of the model log_model.intercept_, log_model.coef_, log_model.score(log_X, y) . | . | 1 . | (153.97045660511063, array([23.78440995]), 0.9464264282083346) . | . The model is $\\hat t = 153.97 + 23.784\\log p$, where $t$ stands for temperature and $p$ for pressure. Another example transformation is the square root transformation. As with np.log, just apply the np.sqrt function to the appropriate term when defining the model. | 1 2 3 4 5 6 7 8 9 10 11 12 . | # Compute the square root of pressure X = pressure[['pressure']] sqrt_X = np.sqrt(X) # Build the linear model using Scikit-Learn from sklearn.linear_model import LinearRegression y = pressure['temperature'] sqrt_model = LinearRegression() sqrt_model.fit(sqrt_X, y) # Display regression coefficients and R-squared value of the model sqrt_model.intercept_, sqrt_model.coef_, sqrt_model.score( log_X, y ) . | . | 1 . | (98.56139249917803, array([11.44621468]), 0.29600246256782614) . | . The model is $\\hat t = 98.561 + 11.446\\sqrt{p}$, with $t$ and $p$ having the same meanings as above. Content last modified on 18 October 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-add-a-transformed-term-to-a-model/#using-numpy-and-sklearn-in-python",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model/#using-numpy-and-sklearn-in-python"
  },"86": {
    "doc": "How to add a transformed term to a model",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use the Pressure dataset in R’s ggplot library as example data. It contains observations of pressure and temperature. You would use your own data instead. | 1 2 3 . | # install.packages( \"ggplot2\" ) # if you haven't done this already library(ggplot2) data(\"pressure\") . | . Let’s model temperature as the dependent variable with the logarithm of pressure as the independent variable. To place the “log of pressure” term in the model, we use R’s log function, as shown below. It uses the naturarl logarithm (base $e$). | 1 2 3 . | # Build the model model.log &lt;- lm(temperature ~ log(pressure), data = pressure) summary(model.log) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | Call: lm(formula = temperature ~ log(pressure), data = pressure) Residuals: Min 1Q Median 3Q Max -28.60 -22.30 -10.13 20.00 48.61 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 153.970 6.330 24.32 1.20e-14 *** log(pressure) 23.784 1.372 17.33 3.07e-12 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 26.81 on 17 degrees of freedom Multiple R-squared: 0.9464, Adjusted R-squared: 0.9433 F-statistic: 300.3 on 1 and 17 DF, p-value: 3.07e-12 . | . The model is $\\hat t = 153.97 + 23.784\\log p$, where $t$ stands for temperature and $p$ for pressure. Another example transformation is the square root transformation. As with log, just apply the sqrt function to the appropriate term when defining the model. | 1 2 3 . | # Build the model model.sqrt &lt;- lm(temperature ~ sqrt(pressure), data = pressure) summary(model.sqrt) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | Call: lm(formula = temperature ~ sqrt(pressure), data = pressure) Residuals: Min 1Q Median 3Q Max -98.72 -34.74 11.53 42.75 56.59 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 98.561 15.244 6.465 5.81e-06 *** sqrt(pressure) 11.446 1.367 8.372 1.95e-07 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 51.16 on 17 degrees of freedom Multiple R-squared: 0.8048, Adjusted R-squared: 0.7933 F-statistic: 70.1 on 1 and 17 DF, p-value: 1.953e-07 . | . The model is $\\hat t = 98.561 + 11.446\\sqrt{p}$, with $t$ and $p$ having the same meanings as above. Content last modified on 16 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-add-a-transformed-term-to-a-model/#solution-in-r",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model/#solution-in-r"
  },"87": {
    "doc": "How to add a transformed term to a model",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-add-a-transformed-term-to-a-model/#topics-that-include-this-task",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model/#topics-that-include-this-task"
  },"88": {
    "doc": "How to add a transformed term to a model",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-add-a-transformed-term-to-a-model/#opportunities",
    "relUrl": "/how-to-add-a-transformed-term-to-a-model/#opportunities"
  },"89": {
    "doc": "How to add an interaction term to a model (in R)",
    "title": "How to add an interaction term to a model (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-add-an-interaction-term-to-a-model-in-r/",
    "relUrl": "/how-to-add-an-interaction-term-to-a-model-in-r/"
  },"90": {
    "doc": "How to add an interaction term to a model (in R)",
    "title": "Task",
    "content": "Sometimes, a simple linear model isn’t sufficient for our data, and we need more complex terms or transformed variables in the model to make adequate predictions. How do we include these complex and transformed terms in a regression model? . Related tasks: . | How to add a polynomial term to a model | How to add a transformed term to a model | . ",
    "url": "/how-to-add-an-interaction-term-to-a-model-in-r/#task",
    "relUrl": "/how-to-add-an-interaction-term-to-a-model-in-r/#task"
  },"91": {
    "doc": "How to add an interaction term to a model (in R)",
    "title": "Solution",
    "content": "We’re going to use the ToothGrowth dataset in R as example data. It contains observations of tooth growth for guinea pigs who received various doses of various supplements. You would use your own data instead. | 1 . | df &lt;- ToothGrowth . | . Let’s model tooth length (len) based on the product of two predictors, the supplement given (supp) and its dosage (dose). We simply use the ordinary multiplication operator in R, written *, to express the product of these two factors when creating the model, as shown below. Note that supp is a categorical variable with two values, so the model will include a binary variable for whether the supplement was equal to “VC.” . | 1 2 3 . | # Build the model model &lt;- lm(len ~ supp*dose, data = df) summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 . | Call: lm(formula = len ~ supp * dose, data = df) Residuals: Min 1Q Median 3Q Max -8.2264 -2.8462 0.0504 2.2893 7.9386 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 11.550 1.581 7.304 1.09e-09 *** suppVC -8.255 2.236 -3.691 0.000507 *** dose 7.811 1.195 6.534 2.03e-08 *** suppVC:dose 3.904 1.691 2.309 0.024631 * --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 4.083 on 56 degrees of freedom Multiple R-squared: 0.7296, Adjusted R-squared: 0.7151 F-statistic: 50.36 on 3 and 56 DF, p-value: 6.521e-16 . | . Now we have a model of the form $\\hat L = 11.55 - 8.255s + 7.811d + 3.904sd$, where $L$ stands for tooth length, $s$ for whether the VC supplement was given, and $d$ for the dose given. Content last modified on 16 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-add-an-interaction-term-to-a-model-in-r/#solution",
    "relUrl": "/how-to-add-an-interaction-term-to-a-model-in-r/#solution"
  },"92": {
    "doc": "How to add an interaction term to a model",
    "title": "How to add an interaction term to a model",
    "content": " ",
    "url": "/how-to-add-an-interaction-term-to-a-model/",
    "relUrl": "/how-to-add-an-interaction-term-to-a-model/"
  },"93": {
    "doc": "How to add an interaction term to a model",
    "title": "Description",
    "content": "Sometimes, a simple linear model isn’t sufficient for our data, and we need more complex terms or transformed variables in the model to make adequate predictions. How do we include these complex and transformed terms in a regression model? . Related tasks: . | How to add a polynomial term to a model | How to add a transformed term to a model | . ",
    "url": "/how-to-add-an-interaction-term-to-a-model/#description",
    "relUrl": "/how-to-add-an-interaction-term-to-a-model/#description"
  },"94": {
    "doc": "How to add an interaction term to a model",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use the ToothGrowth dataset in R as example data. It contains observations of tooth growth for guinea pigs who received various doses of various supplements. You would use your own data instead. | 1 . | df &lt;- ToothGrowth . | . Let’s model tooth length (len) based on the product of two predictors, the supplement given (supp) and its dosage (dose). We simply use the ordinary multiplication operator in R, written *, to express the product of these two factors when creating the model, as shown below. Note that supp is a categorical variable with two values, so the model will include a binary variable for whether the supplement was equal to “VC.” . | 1 2 3 . | # Build the model model &lt;- lm(len ~ supp*dose, data = df) summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 . | Call: lm(formula = len ~ supp * dose, data = df) Residuals: Min 1Q Median 3Q Max -8.2264 -2.8462 0.0504 2.2893 7.9386 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 11.550 1.581 7.304 1.09e-09 *** suppVC -8.255 2.236 -3.691 0.000507 *** dose 7.811 1.195 6.534 2.03e-08 *** suppVC:dose 3.904 1.691 2.309 0.024631 * --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 4.083 on 56 degrees of freedom Multiple R-squared: 0.7296, Adjusted R-squared: 0.7151 F-statistic: 50.36 on 3 and 56 DF, p-value: 6.521e-16 . | . Now we have a model of the form $\\hat L = 11.55 - 8.255s + 7.811d + 3.904sd$, where $L$ stands for tooth length, $s$ for whether the VC supplement was given, and $d$ for the dose given. Content last modified on 16 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-add-an-interaction-term-to-a-model/#solution-in-r",
    "relUrl": "/how-to-add-an-interaction-term-to-a-model/#solution-in-r"
  },"95": {
    "doc": "How to add an interaction term to a model",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-add-an-interaction-term-to-a-model/#topics-that-include-this-task",
    "relUrl": "/how-to-add-an-interaction-term-to-a-model/#topics-that-include-this-task"
  },"96": {
    "doc": "How to add an interaction term to a model",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Python | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-add-an-interaction-term-to-a-model/#opportunities",
    "relUrl": "/how-to-add-an-interaction-term-to-a-model/#opportunities"
  },"97": {
    "doc": "How to add details to a plot (in Python, using Matplotlib)",
    "title": "How to add details to a plot (in Python, using Matplotlib)",
    "content": "See all solutions. ",
    "url": "/how-to-add-details-to-a-plot-in-python-using-matplotlib/",
    "relUrl": "/how-to-add-details-to-a-plot-in-python-using-matplotlib/"
  },"98": {
    "doc": "How to add details to a plot (in Python, using Matplotlib)",
    "title": "Task",
    "content": "After making a plot, we might want to add axis labels, a title, gridlines, or text. Plotting packages provide tons of tools for this sort of thing. What are some of the essentials? . Related topics: . | How to create basic plots | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-add-details-to-a-plot-in-python-using-matplotlib/#task",
    "relUrl": "/how-to-add-details-to-a-plot-in-python-using-matplotlib/#task"
  },"99": {
    "doc": "How to add details to a plot (in Python, using Matplotlib)",
    "title": "Solution",
    "content": "We will create some fake data using Python lists, for simplicity. But everything we show below works also if your data is in columns of a DataFrame, such as df['age']. | 1 2 . | patient_height = [ 60, 64, 64, 65, 66, 66, 70, 72, 72, 76 ] patient_weight = [ 141, 182, 169, 204, 138, 198, 180, 175, 244, 196 ] . | . The conventional way to import matplotlib in Python is as follows. | 1 . | import matplotlib.pyplot as plt . | . The following code creates a plot with many details added, but each is independent of the others, so you can take just the bit of code that you need. | 1 2 3 4 5 6 7 8 9 10 . | plt.scatter( patient_height, patient_weight ) plt.xlabel( 'This is the x axis label.' ) plt.ylabel( 'This is the y axis label.' ) plt.title( 'This is the title.' ) plt.grid() # Turns on gridlines plt.text( 70, 200, 'Text at (70,200)' ) # Text method 1 plt.annotate( 'Text at (60,150)', (60,150) ) # Text method 2 plt.annotate( 'Text with arrow', xytext=(60,225), xy=(72,244), arrowprops={'color':'red'} ) # Text with arrow plt.show() . | . Content last modified on 21 June 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-add-details-to-a-plot-in-python-using-matplotlib/#solution",
    "relUrl": "/how-to-add-details-to-a-plot-in-python-using-matplotlib/#solution"
  },"100": {
    "doc": "How to add details to a plot (in R)",
    "title": "How to add details to a plot (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-add-details-to-a-plot-in-r/",
    "relUrl": "/how-to-add-details-to-a-plot-in-r/"
  },"101": {
    "doc": "How to add details to a plot (in R)",
    "title": "Task",
    "content": "After making a plot, we might want to add axis labels, a title, gridlines, or text. Plotting packages provide tons of tools for this sort of thing. What are some of the essentials? . Related topics: . | How to create basic plots | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-add-details-to-a-plot-in-r/#task",
    "relUrl": "/how-to-add-details-to-a-plot-in-r/#task"
  },"102": {
    "doc": "How to add details to a plot (in R)",
    "title": "Solution",
    "content": "We will create some fake data using R vectors, for simplicity. But everything we show below works also if your data is in columns of a data frame, such as df$age. | 1 2 . | patient_height &lt;- c( 60, 64, 64, 65, 66, 66, 70, 72, 72, 76 ) patient_weight &lt;- c( 141, 182, 169, 204, 138, 198, 180, 175, 244, 196 ) . | . The following code creates a plot with many details added, but each is independent of the others, so you can take just the bit of code that you need. | 1 2 3 4 5 6 7 8 9 . | plot( patient_height, patient_weight, main=\"This is the title.\", xlab=\"This is the x axis label.\", ylab=\"This is the y axis label.\" ) # Scatter plot with labels grid() # Turns on gridlines text( 70, 200, \"Text at (70,200)\" ) # Add text text( 65, 225, \"Point 1\", pos=2 ) # Text to the left of a point text( 72, 244, \"Point 2\", pos=4 ) # Text to the right of a point arrows( 65, 225, 72, 244, col='red' ) # Arrow from (65,225) to (72,244) . | . Content last modified on 21 June 2022. See a problem? Tell us or edit the source. Contributed by Debayan Sen (DSEN@bentley.edu) . ",
    "url": "/how-to-add-details-to-a-plot-in-r/#solution",
    "relUrl": "/how-to-add-details-to-a-plot-in-r/#solution"
  },"103": {
    "doc": "How to add details to a plot",
    "title": "How to add details to a plot",
    "content": " ",
    "url": "/how-to-add-details-to-a-plot/",
    "relUrl": "/how-to-add-details-to-a-plot/"
  },"104": {
    "doc": "How to add details to a plot",
    "title": "Description",
    "content": "After making a plot, we might want to add axis labels, a title, gridlines, or text. Plotting packages provide tons of tools for this sort of thing. What are some of the essentials? . Related topics: . | How to create basic plots | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-add-details-to-a-plot/#description",
    "relUrl": "/how-to-add-details-to-a-plot/#description"
  },"105": {
    "doc": "How to add details to a plot",
    "title": "Using Matplotlib, in Python",
    "content": "View this solution alone. We will create some fake data using Python lists, for simplicity. But everything we show below works also if your data is in columns of a DataFrame, such as df['age']. | 1 2 . | patient_height = [ 60, 64, 64, 65, 66, 66, 70, 72, 72, 76 ] patient_weight = [ 141, 182, 169, 204, 138, 198, 180, 175, 244, 196 ] . | . The conventional way to import matplotlib in Python is as follows. | 1 . | import matplotlib.pyplot as plt . | . The following code creates a plot with many details added, but each is independent of the others, so you can take just the bit of code that you need. | 1 2 3 4 5 6 7 8 9 10 . | plt.scatter( patient_height, patient_weight ) plt.xlabel( 'This is the x axis label.' ) plt.ylabel( 'This is the y axis label.' ) plt.title( 'This is the title.' ) plt.grid() # Turns on gridlines plt.text( 70, 200, 'Text at (70,200)' ) # Text method 1 plt.annotate( 'Text at (60,150)', (60,150) ) # Text method 2 plt.annotate( 'Text with arrow', xytext=(60,225), xy=(72,244), arrowprops={'color':'red'} ) # Text with arrow plt.show() . | . Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-add-details-to-a-plot/#using-matplotlib-in-python",
    "relUrl": "/how-to-add-details-to-a-plot/#using-matplotlib-in-python"
  },"106": {
    "doc": "How to add details to a plot",
    "title": "Solution, in R",
    "content": "View this solution alone. We will create some fake data using R vectors, for simplicity. But everything we show below works also if your data is in columns of a data frame, such as df$age. | 1 2 . | patient_height &lt;- c( 60, 64, 64, 65, 66, 66, 70, 72, 72, 76 ) patient_weight &lt;- c( 141, 182, 169, 204, 138, 198, 180, 175, 244, 196 ) . | . The following code creates a plot with many details added, but each is independent of the others, so you can take just the bit of code that you need. | 1 2 3 4 5 6 7 8 9 . | plot( patient_height, patient_weight, main=\"This is the title.\", xlab=\"This is the x axis label.\", ylab=\"This is the y axis label.\" ) # Scatter plot with labels grid() # Turns on gridlines text( 70, 200, \"Text at (70,200)\" ) # Add text text( 65, 225, \"Point 1\", pos=2 ) # Text to the left of a point text( 72, 244, \"Point 2\", pos=4 ) # Text to the right of a point arrows( 65, 225, 72, 244, col='red' ) # Arrow from (65,225) to (72,244) . | . Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-add-details-to-a-plot/#solution-in-r",
    "relUrl": "/how-to-add-details-to-a-plot/#solution-in-r"
  },"107": {
    "doc": "How to add details to a plot",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA346 | . ",
    "url": "/how-to-add-details-to-a-plot/#topics-that-include-this-task",
    "relUrl": "/how-to-add-details-to-a-plot/#topics-that-include-this-task"
  },"108": {
    "doc": "How to add details to a plot",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-add-details-to-a-plot/#opportunities",
    "relUrl": "/how-to-add-details-to-a-plot/#opportunities"
  },"109": {
    "doc": "How to analyze the sample means of different treatment conditions (in Python, using Matplotlib and Seaborn)",
    "title": "How to analyze the sample means of different treatment conditions (in Python, using Matplotlib and Seaborn)",
    "content": "See all solutions. ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-python-using-matplotlib-and-seaborn/",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-python-using-matplotlib-and-seaborn/"
  },"110": {
    "doc": "How to analyze the sample means of different treatment conditions (in Python, using Matplotlib and Seaborn)",
    "title": "Task",
    "content": "In a single-factor experiment with three or more treatment levels, how can we compare them to see which one impacts the outcome variable the most? . ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-python-using-matplotlib-and-seaborn/#task",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-python-using-matplotlib-and-seaborn/#task"
  },"111": {
    "doc": "How to analyze the sample means of different treatment conditions (in Python, using Matplotlib and Seaborn)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . To visually plot the means of the length of the tooth based on the Vitamin C dosage levels we can create a pointplot. We will have to import the seaborn and matplotlib.pyplot packages to be able to create it. | 1 2 3 4 5 6 . | import seaborn as sns import matplotlib.pyplot as plt sns.pointplot( x = 'dose', y = 'len', data = df, ci = 95, # ci stands for Confidence Interval capsize = 0.1 ) # the width of the \"caps\" on error bars plt.show() . | . The point plot informs us that as the dosage levels increase, the tooth length also increases. To obtain the actual numbers, we can use the groupby function to compute the treatment level means, and the mean function to compute the mean for the entire column. | 1 . | df.groupby('dose')['len'].mean() . | . | 1 2 3 4 5 . | dose 0.5 10.605 1.0 19.735 2.0 26.100 Name: len, dtype: float64 . | . | 1 . | df['len'].mean() . | . | 1 . | 18.813333333333336 . | . If you wish to display the difference between the overall mean and the group means, you can subtract the overall mean from the treatment level means. | 1 . | df.groupby('dose')['len'].mean() - df['len'].mean() . | . | 1 2 3 4 5 . | dose 0.5 -8.208333 1.0 0.921667 2.0 7.286667 Name: len, dtype: float64 . | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-python-using-matplotlib-and-seaborn/#solution",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-python-using-matplotlib-and-seaborn/#solution"
  },"112": {
    "doc": "How to analyze the sample means of different treatment conditions (in R, using gplots and emmeans)",
    "title": "How to analyze the sample means of different treatment conditions (in R, using gplots and emmeans)",
    "content": "See all solutions. ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-r-using-gplots-and-emmeans/",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-r-using-gplots-and-emmeans/"
  },"113": {
    "doc": "How to analyze the sample means of different treatment conditions (in R, using gplots and emmeans)",
    "title": "Task",
    "content": "In a single-factor experiment with three or more treatment levels, how can we compare them to see which one impacts the outcome variable the most? . ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-r-using-gplots-and-emmeans/#task",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-r-using-gplots-and-emmeans/#task"
  },"114": {
    "doc": "How to analyze the sample means of different treatment conditions (in R, using gplots and emmeans)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 . | df &lt;- ToothGrowth . | . To visually plot the means of the length of the tooth based on the Vitamin C dosage levels we can create a pointplot. We will use the gplots package. In the code below, bars=TRUE gives 95% confidence intervals for the means. | 1 2 3 . | # install.packages(\"gplots\") # If you have not yet installed it library(gplots) plotmeans(len~dose, data=df, bars=TRUE) . | . | 1 2 3 4 5 6 . | Attaching package: ‘gplots’ The following object is masked from ‘package:stats’: lowess . | . The point plot informs us that as the dosage levels increase, the tooth length also increases. To obtain the actual numbers, we can use the code below. The first line converts the numerical dosage values to a categorical variable, which may not be necessary if your data was already categorical. | 1 2 3 . | df$dose.factor = as.factor(df$dose) aov1 = aov(len~dose.factor, data=df) model.tables(aov1, type='means') . | . | 1 2 3 4 5 6 7 8 9 . | Tables of means Grand mean 18.81333 dose.factor dose.factor 0.5 1 2 10.605 19.735 26.100 . | . If you wish to display the difference between the overall mean and the group means, you can simply omit the type='means' parameter. | 1 . | model.tables(aov1) . | . | 1 2 3 4 5 6 . | Tables of effects dose.factor dose.factor 0.5 1 2 -8.208 0.922 7.287 . | . To also see the specific values for the confidence intervals plotted earlier, we can use the emmeans package (Estimated Marginal Means or Least-Squares Means). | 1 2 3 . | # install.packages(\"emmeans\") # If you have not yet installed it library(emmeans) emmeans(aov1,'dose.factor') . | . | 1 2 3 4 5 6 . | dose.factor emmean SE df lower.CL upper.CL 0.5 10.6 0.949 57 8.71 12.5 1 19.7 0.949 57 17.84 21.6 2 26.1 0.949 57 24.20 28.0 Confidence level used: 0.95 . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-r-using-gplots-and-emmeans/#solution",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions-in-r-using-gplots-and-emmeans/#solution"
  },"115": {
    "doc": "How to analyze the sample means of different treatment conditions",
    "title": "How to analyze the sample means of different treatment conditions",
    "content": " ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/"
  },"116": {
    "doc": "How to analyze the sample means of different treatment conditions",
    "title": "Description",
    "content": "In a single-factor experiment with three or more treatment levels, how can we compare them to see which one impacts the outcome variable the most? . ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/#description",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/#description"
  },"117": {
    "doc": "How to analyze the sample means of different treatment conditions",
    "title": "Using Matplotlib and Seaborn, in Python",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . To visually plot the means of the length of the tooth based on the Vitamin C dosage levels we can create a pointplot. We will have to import the seaborn and matplotlib.pyplot packages to be able to create it. | 1 2 3 4 5 6 . | import seaborn as sns import matplotlib.pyplot as plt sns.pointplot( x = 'dose', y = 'len', data = df, ci = 95, # ci stands for Confidence Interval capsize = 0.1 ) # the width of the \"caps\" on error bars plt.show() . | . The point plot informs us that as the dosage levels increase, the tooth length also increases. To obtain the actual numbers, we can use the groupby function to compute the treatment level means, and the mean function to compute the mean for the entire column. | 1 . | df.groupby('dose')['len'].mean() . | . | 1 2 3 4 5 . | dose 0.5 10.605 1.0 19.735 2.0 26.100 Name: len, dtype: float64 . | . | 1 . | df['len'].mean() . | . | 1 . | 18.813333333333336 . | . If you wish to display the difference between the overall mean and the group means, you can subtract the overall mean from the treatment level means. | 1 . | df.groupby('dose')['len'].mean() - df['len'].mean() . | . | 1 2 3 4 5 . | dose 0.5 -8.208333 1.0 0.921667 2.0 7.286667 Name: len, dtype: float64 . | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/#using-matplotlib-and-seaborn-in-python",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/#using-matplotlib-and-seaborn-in-python"
  },"118": {
    "doc": "How to analyze the sample means of different treatment conditions",
    "title": "Using gplots and emmeans, in R",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 . | df &lt;- ToothGrowth . | . To visually plot the means of the length of the tooth based on the Vitamin C dosage levels we can create a pointplot. We will use the gplots package. In the code below, bars=TRUE gives 95% confidence intervals for the means. | 1 2 3 . | # install.packages(\"gplots\") # If you have not yet installed it library(gplots) plotmeans(len~dose, data=df, bars=TRUE) . | . | 1 2 3 4 5 6 . | Attaching package: ‘gplots’ The following object is masked from ‘package:stats’: lowess . | . The point plot informs us that as the dosage levels increase, the tooth length also increases. To obtain the actual numbers, we can use the code below. The first line converts the numerical dosage values to a categorical variable, which may not be necessary if your data was already categorical. | 1 2 3 . | df$dose.factor = as.factor(df$dose) aov1 = aov(len~dose.factor, data=df) model.tables(aov1, type='means') . | . | 1 2 3 4 5 6 7 8 9 . | Tables of means Grand mean 18.81333 dose.factor dose.factor 0.5 1 2 10.605 19.735 26.100 . | . If you wish to display the difference between the overall mean and the group means, you can simply omit the type='means' parameter. | 1 . | model.tables(aov1) . | . | 1 2 3 4 5 6 . | Tables of effects dose.factor dose.factor 0.5 1 2 -8.208 0.922 7.287 . | . To also see the specific values for the confidence intervals plotted earlier, we can use the emmeans package (Estimated Marginal Means or Least-Squares Means). | 1 2 3 . | # install.packages(\"emmeans\") # If you have not yet installed it library(emmeans) emmeans(aov1,'dose.factor') . | . | 1 2 3 4 5 6 . | dose.factor emmean SE df lower.CL upper.CL 0.5 10.6 0.949 57 8.71 12.5 1 19.7 0.949 57 17.84 21.6 2 26.1 0.949 57 24.20 28.0 Confidence level used: 0.95 . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/#using-gplots-and-emmeans-in-r",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/#using-gplots-and-emmeans-in-r"
  },"119": {
    "doc": "How to analyze the sample means of different treatment conditions",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/#topics-that-include-this-task",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/#topics-that-include-this-task"
  },"120": {
    "doc": "How to analyze the sample means of different treatment conditions",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/#opportunities",
    "relUrl": "/how-to-analyze-the-sample-means-of-different-treatment-conditions/#opportunities"
  },"121": {
    "doc": "How to change axes, ticks, and scale in a plot (in Python, using Matplotlib)",
    "title": "How to change axes, ticks, and scale in a plot (in Python, using Matplotlib)",
    "content": "See all solutions. ",
    "url": "/how-to-change-axes-ticks-and-scale-in-a-plot-in-python-using-matplotlib/",
    "relUrl": "/how-to-change-axes-ticks-and-scale-in-a-plot-in-python-using-matplotlib/"
  },"122": {
    "doc": "How to change axes, ticks, and scale in a plot (in Python, using Matplotlib)",
    "title": "Task",
    "content": "The mathematical markings and measurements in a plot can make a big difference on its readability and usefulness. These include the range of each axis, which points on that axis are marked with tick marks, and whether the axes use linear or logarithmic scaling. How can we customize these options? . Related topics: . | How to create basic plots | How to create a histogram | How to create a box (and whisker) plot | How to add details to a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-change-axes-ticks-and-scale-in-a-plot-in-python-using-matplotlib/#task",
    "relUrl": "/how-to-change-axes-ticks-and-scale-in-a-plot-in-python-using-matplotlib/#task"
  },"123": {
    "doc": "How to change axes, ticks, and scale in a plot (in Python, using Matplotlib)",
    "title": "Solution",
    "content": "We will create some fake data using Python lists, for simplicity. But everything we show below works also if your data is in columns of a DataFrame, such as df['age']. | 1 2 3 . | patient_id = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ] patient_height = [ 60, 64, 64, 65, 66, 66, 70, 72, 72, 76 ] patient_weight = [ 141, 182, 169, 204, 138, 198, 180, 175, 244, 196 ] . | . The conventional way to import matplotlib in Python is as follows. | 1 . | import matplotlib.pyplot as plt . | . You can change the plot range and where tick marks are shown, in either the $x$ or $y$ directions (or both) as follows. | 1 2 3 4 5 6 . | plt.scatter( patient_height, patient_weight ) plt.xlim( [ 0, 80 ] ) # Plot from x=0 to x=80. plt.ylim( [ 0, 250 ] ) # Plot from y=0 to y=250. plt.xticks( range(0,80,10) ) # Put x axis ticks every 10 units. plt.yticks( range(0,250,50) ) # Y ticks every 50. You can provide any list. plt.show() . | . If you need either axis to be logarithmically scaled, it takes just one line of code. | 1 2 3 4 5 . | import numpy as np # Just using this to make random data. plt.scatter( np.random.rand(100), np.random.rand(100) ) plt.xscale( 'log' ) # You can include one of these two plt.yscale( 'log' ) # lines, or both, or neither. plt.show() . | . Content last modified on 23 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-change-axes-ticks-and-scale-in-a-plot-in-python-using-matplotlib/#solution",
    "relUrl": "/how-to-change-axes-ticks-and-scale-in-a-plot-in-python-using-matplotlib/#solution"
  },"124": {
    "doc": "How to change axes, ticks, and scale in a plot",
    "title": "How to change axes, ticks, and scale in a plot",
    "content": " ",
    "url": "/how-to-change-axes-ticks-and-scale-in-a-plot/",
    "relUrl": "/how-to-change-axes-ticks-and-scale-in-a-plot/"
  },"125": {
    "doc": "How to change axes, ticks, and scale in a plot",
    "title": "Description",
    "content": "The mathematical markings and measurements in a plot can make a big difference on its readability and usefulness. These include the range of each axis, which points on that axis are marked with tick marks, and whether the axes use linear or logarithmic scaling. How can we customize these options? . Related topics: . | How to create basic plots | How to create a histogram | How to create a box (and whisker) plot | How to add details to a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-change-axes-ticks-and-scale-in-a-plot/#description",
    "relUrl": "/how-to-change-axes-ticks-and-scale-in-a-plot/#description"
  },"126": {
    "doc": "How to change axes, ticks, and scale in a plot",
    "title": "Using Matplotlib, in Python",
    "content": "View this solution alone. We will create some fake data using Python lists, for simplicity. But everything we show below works also if your data is in columns of a DataFrame, such as df['age']. | 1 2 3 . | patient_id = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ] patient_height = [ 60, 64, 64, 65, 66, 66, 70, 72, 72, 76 ] patient_weight = [ 141, 182, 169, 204, 138, 198, 180, 175, 244, 196 ] . | . The conventional way to import matplotlib in Python is as follows. | 1 . | import matplotlib.pyplot as plt . | . You can change the plot range and where tick marks are shown, in either the $x$ or $y$ directions (or both) as follows. | 1 2 3 4 5 6 . | plt.scatter( patient_height, patient_weight ) plt.xlim( [ 0, 80 ] ) # Plot from x=0 to x=80. plt.ylim( [ 0, 250 ] ) # Plot from y=0 to y=250. plt.xticks( range(0,80,10) ) # Put x axis ticks every 10 units. plt.yticks( range(0,250,50) ) # Y ticks every 50. You can provide any list. plt.show() . | . If you need either axis to be logarithmically scaled, it takes just one line of code. | 1 2 3 4 5 . | import numpy as np # Just using this to make random data. plt.scatter( np.random.rand(100), np.random.rand(100) ) plt.xscale( 'log' ) # You can include one of these two plt.yscale( 'log' ) # lines, or both, or neither. plt.show() . | . Content last modified on 23 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-change-axes-ticks-and-scale-in-a-plot/#using-matplotlib-in-python",
    "relUrl": "/how-to-change-axes-ticks-and-scale-in-a-plot/#using-matplotlib-in-python"
  },"127": {
    "doc": "How to change axes, ticks, and scale in a plot",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA346 | . ",
    "url": "/how-to-change-axes-ticks-and-scale-in-a-plot/#topics-that-include-this-task",
    "relUrl": "/how-to-change-axes-ticks-and-scale-in-a-plot/#topics-that-include-this-task"
  },"128": {
    "doc": "How to change axes, ticks, and scale in a plot",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-change-axes-ticks-and-scale-in-a-plot/#opportunities",
    "relUrl": "/how-to-change-axes-ticks-and-scale-in-a-plot/#opportunities"
  },"129": {
    "doc": "How to check the assumptions of a linear model (in Python, using NumPy, SciPy, sklearn, Matplotlib and Seaborn)",
    "title": "How to check the assumptions of a linear model (in Python, using NumPy, SciPy, sklearn, Matplotlib and Seaborn)",
    "content": "See all solutions. ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model-in-python-using-numpy-scipy-sklearn-matplotlib-and-seaborn/",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model-in-python-using-numpy-scipy-sklearn-matplotlib-and-seaborn/"
  },"130": {
    "doc": "How to check the assumptions of a linear model (in Python, using NumPy, SciPy, sklearn, Matplotlib and Seaborn)",
    "title": "Task",
    "content": "If you plan to use a linear model to describe some data, it’s important to check if it satisfies the assumptions for linear regression. How can we do that? . ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model-in-python-using-numpy-scipy-sklearn-matplotlib-and-seaborn/#task",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model-in-python-using-numpy-scipy-sklearn-matplotlib-and-seaborn/#task"
  },"131": {
    "doc": "How to check the assumptions of a linear model (in Python, using NumPy, SciPy, sklearn, Matplotlib and Seaborn)",
    "title": "Solution",
    "content": "When performing a linear regression, the following assumptions should be checked. 1. We have two or more columns of numerical data of the same length. The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) We can see that our columns all have the same length. | 1 2 3 4 . | from rdatasets import data df = data('mtcars') df = df[['mpg','cyl','wt']] # Select the 3 variables we're interested in df.info() . | . | 1 2 3 4 5 6 7 8 9 10 . | &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 mpg 32 non-null float64 1 cyl 32 non-null int64 2 wt 32 non-null float64 dtypes: float64(2), int64(1) memory usage: 896.0 bytes . | . 2. Scatter plots we’ve made suggest a linear relationship. Scatterplots are covererd in how to create basic plots, but after making the model, we can also examine the residuals. So let’s make the model. Our predictors will be the number of cylinders and the weight of the car and the response will be miles per gallon. (See also how to fit a linear model to two columns of data.) . | 1 2 3 4 5 6 7 8 . | from sklearn.linear_model import LinearRegression model = LinearRegression() predictors = df[['cyl','wt']] response = df['mpg'] model.fit( X=predictors, y=response ) predictions = model.predict(predictors) . | . We test for linearity with residual plots. We show just one residual plot here; you should make one for each predictor. Seaborn has a function for just this purpose. (See also how to compute the residuals of a linear model.) . | 1 2 3 4 5 6 7 . | import seaborn as sns import matplotlib.pyplot as plt # The \"lowess\" parameter adds a smooth line through the data: sns.residplot(x = df['wt'], y = response, data=df, lowess=True) plt.xlabel(\"Weight\") plt.title('Miles per gallon') plt.show() . | . 3. After making the model, the residuals seem normally distributed. We can check this by constructing a QQ-plot, which compares the distribution of the residuals to a normal distribution. Here we use SciPy, but there are other methods; see how to create a QQ-plot. | 1 2 3 4 5 . | from scipy import stats residuals = response - predictions # Compute the residuals stats.probplot(residuals, dist=\"norm\", plot=plt) plt.title(\"Normal Q-Q Plot\") plt.show() . | . 4. After making the model, the residuals seem homoscedastic. This assumption is sometimes called “equal variance,” and can be checked by the regplot function in Seaborn. We must first standardize the residuals, which we can do with NumPy. We want to see a plot with no clear pattern; a cone shape to the data would indicate heteroscedasticity, the opposite of homoscedasticity. | 1 2 3 4 5 6 7 . | import numpy as np standardized_residuals = np.sqrt(np.abs(residuals)) sns.regplot(x = predictions, y = standardized_residuals, scatter=True, lowess=True) plt.ylabel(\"Standarized residuals\") plt.xlabel(\"Fitted value\") plt.title(\"Scale-Location\") plt.show() . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model-in-python-using-numpy-scipy-sklearn-matplotlib-and-seaborn/#solution",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model-in-python-using-numpy-scipy-sklearn-matplotlib-and-seaborn/#solution"
  },"132": {
    "doc": "How to check the assumptions of a linear model (in R)",
    "title": "How to check the assumptions of a linear model (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model-in-r/",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model-in-r/"
  },"133": {
    "doc": "How to check the assumptions of a linear model (in R)",
    "title": "Task",
    "content": "If you plan to use a linear model to describe some data, it’s important to check if it satisfies the assumptions for linear regression. How can we do that? . ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model-in-r/#task",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model-in-r/#task"
  },"134": {
    "doc": "How to check the assumptions of a linear model (in R)",
    "title": "Solution",
    "content": "When performing a linear regression, the following assumptions should be checked. 1. We have two or more columns of numerical data of the same length. The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) We can see that our columns all have the same length. | 1 2 . | df &lt;- mtcars head(df) . | . | 1 2 3 4 5 6 7 . | mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 . | . 2. Scatter plots we’ve made suggest a linear relationship. Scatterplots are covererd in how to create basic plots, but after making the model, we can also examine the residuals. So let’s make the model. Our predictors will be the number of cylinders and the weight of the car and the response will be miles per gallon. (See also how to fit a linear model to two columns of data.) . | 1 . | model = lm(mpg~ cyl + wt, data=df) . | . We test for linearity with residual plots. We show just one residual plot here; you should make one for each predictor. R’s plot function knows how to create residual plots. (See also how to compute the residuals of a linear model.) . | 1 . | plot(model, which = 1) . | . 3. After making the model, the residuals seem normally distributed. We can check this by constructing a QQ-plot, which compares the distribution of the residuals to a normal distribution. Here we use SciPy, but there are other methods; see how to create a QQ-plot. | 1 . | plot(model, which = 2) . | . 4. After making the model, the residuals seem homoscedastic. This assumption is sometimes called “equal variance,” and can be checked by the regplot function in Seaborn. We must first standardize the residuals, which we can do with NumPy. We want to see a plot with no clear pattern; a cone shape to the data would indicate heteroscedasticity, the opposite of homoscedasticity. | 1 . | plot(model, which = 3) # assumption of equal variance . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model-in-r/#solution",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model-in-r/#solution"
  },"135": {
    "doc": "How to check the assumptions of a linear model",
    "title": "How to check the assumptions of a linear model",
    "content": " ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model/",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model/"
  },"136": {
    "doc": "How to check the assumptions of a linear model",
    "title": "Description",
    "content": "If you plan to use a linear model to describe some data, it’s important to check if it satisfies the assumptions for linear regression. How can we do that? . ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model/#description",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model/#description"
  },"137": {
    "doc": "How to check the assumptions of a linear model",
    "title": "Using NumPy, SciPy, sklearn, Matplotlib and Seaborn, in Python",
    "content": "View this solution alone. When performing a linear regression, the following assumptions should be checked. 1. We have two or more columns of numerical data of the same length. The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) We can see that our columns all have the same length. | 1 2 3 4 . | from rdatasets import data df = data('mtcars') df = df[['mpg','cyl','wt']] # Select the 3 variables we're interested in df.info() . | . | 1 2 3 4 5 6 7 8 9 10 . | &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 3 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 mpg 32 non-null float64 1 cyl 32 non-null int64 2 wt 32 non-null float64 dtypes: float64(2), int64(1) memory usage: 896.0 bytes . | . 2. Scatter plots we’ve made suggest a linear relationship. Scatterplots are covererd in how to create basic plots, but after making the model, we can also examine the residuals. So let’s make the model. Our predictors will be the number of cylinders and the weight of the car and the response will be miles per gallon. (See also how to fit a linear model to two columns of data.) . | 1 2 3 4 5 6 7 8 . | from sklearn.linear_model import LinearRegression model = LinearRegression() predictors = df[['cyl','wt']] response = df['mpg'] model.fit( X=predictors, y=response ) predictions = model.predict(predictors) . | . We test for linearity with residual plots. We show just one residual plot here; you should make one for each predictor. Seaborn has a function for just this purpose. (See also how to compute the residuals of a linear model.) . | 1 2 3 4 5 6 7 . | import seaborn as sns import matplotlib.pyplot as plt # The \"lowess\" parameter adds a smooth line through the data: sns.residplot(x = df['wt'], y = response, data=df, lowess=True) plt.xlabel(\"Weight\") plt.title('Miles per gallon') plt.show() . | . 3. After making the model, the residuals seem normally distributed. We can check this by constructing a QQ-plot, which compares the distribution of the residuals to a normal distribution. Here we use SciPy, but there are other methods; see how to create a QQ-plot. | 1 2 3 4 5 . | from scipy import stats residuals = response - predictions # Compute the residuals stats.probplot(residuals, dist=\"norm\", plot=plt) plt.title(\"Normal Q-Q Plot\") plt.show() . | . 4. After making the model, the residuals seem homoscedastic. This assumption is sometimes called “equal variance,” and can be checked by the regplot function in Seaborn. We must first standardize the residuals, which we can do with NumPy. We want to see a plot with no clear pattern; a cone shape to the data would indicate heteroscedasticity, the opposite of homoscedasticity. | 1 2 3 4 5 6 7 . | import numpy as np standardized_residuals = np.sqrt(np.abs(residuals)) sns.regplot(x = predictions, y = standardized_residuals, scatter=True, lowess=True) plt.ylabel(\"Standarized residuals\") plt.xlabel(\"Fitted value\") plt.title(\"Scale-Location\") plt.show() . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model/#using-numpy-scipy-sklearn-matplotlib-and-seaborn-in-python",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model/#using-numpy-scipy-sklearn-matplotlib-and-seaborn-in-python"
  },"138": {
    "doc": "How to check the assumptions of a linear model",
    "title": "Solution, in R",
    "content": "View this solution alone. When performing a linear regression, the following assumptions should be checked. 1. We have two or more columns of numerical data of the same length. The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) We can see that our columns all have the same length. | 1 2 . | df &lt;- mtcars head(df) . | . | 1 2 3 4 5 6 7 . | mpg cyl disp hp drat wt qsec vs am gear carb Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 . | . 2. Scatter plots we’ve made suggest a linear relationship. Scatterplots are covererd in how to create basic plots, but after making the model, we can also examine the residuals. So let’s make the model. Our predictors will be the number of cylinders and the weight of the car and the response will be miles per gallon. (See also how to fit a linear model to two columns of data.) . | 1 . | model = lm(mpg~ cyl + wt, data=df) . | . We test for linearity with residual plots. We show just one residual plot here; you should make one for each predictor. R’s plot function knows how to create residual plots. (See also how to compute the residuals of a linear model.) . | 1 . | plot(model, which = 1) . | . 3. After making the model, the residuals seem normally distributed. We can check this by constructing a QQ-plot, which compares the distribution of the residuals to a normal distribution. Here we use SciPy, but there are other methods; see how to create a QQ-plot. | 1 . | plot(model, which = 2) . | . 4. After making the model, the residuals seem homoscedastic. This assumption is sometimes called “equal variance,” and can be checked by the regplot function in Seaborn. We must first standardize the residuals, which we can do with NumPy. We want to see a plot with no clear pattern; a cone shape to the data would indicate heteroscedasticity, the opposite of homoscedasticity. | 1 . | plot(model, which = 3) # assumption of equal variance . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model/#solution-in-r",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model/#solution-in-r"
  },"139": {
    "doc": "How to check the assumptions of a linear model",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model/#topics-that-include-this-task",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model/#topics-that-include-this-task"
  },"140": {
    "doc": "How to check the assumptions of a linear model",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-check-the-assumptions-of-a-linear-model/#opportunities",
    "relUrl": "/how-to-check-the-assumptions-of-a-linear-model/#opportunities"
  },"141": {
    "doc": "How to choose the sample size in a study with two population means (in Python, using statsmodels)",
    "title": "How to choose the sample size in a study with two population means (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-python-using-statsmodels/",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-python-using-statsmodels/"
  },"142": {
    "doc": "How to choose the sample size in a study with two population means (in Python, using statsmodels)",
    "title": "Task",
    "content": "When designing a study, it is important to choose a sample size that is large enough to perform a useful test but that is also economically feasible. How we choose the sample size depends on what test we plan to run on the data from our study. Here, let’s say our data will be used to compare two population means. If we are planning such a study, how do we determine how large it should be in order for the test that compares the population means to have a certain power? . Related tasks: . | How to compute the power of a test comparing two population means | . ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-python-using-statsmodels/#task"
  },"143": {
    "doc": "How to choose the sample size in a study with two population means (in Python, using statsmodels)",
    "title": "Solution",
    "content": "Example: Let’s say we’re designing a study to assess the effectiveness of a new four-week exercise program for weight loss. Assume that weight loss in four-week exercise programs is normally distributed with a standard deviation of around 5 pounds. The goal is that the new exercise program will have a 4-pound higher weight loss than the average program. (Notice that we will be comparing the means of two populations, the weight loss in each of two programs.) . We choose a value $0 \\leq \\alpha \\leq 1$ as the probability of a Type I error in our test that compares the two means. (Recall, Type I error is for a false positive, finding we should reject $H_0$ when it’s actually true). Let’s set $\\alpha$ to be 0.05 here. We choose a value $0 \\leq \\beta \\leq 1$ as the probability of a Type II error (false negative, failing to reject $H_0$ when it’s actually false). Let’s set $\\beta$ to be 0.2 here. The test’s power is $1-\\beta$, or in this case, 0.8. What should the sample size be for each group? . | 1 2 3 4 5 6 7 8 9 10 . | from statsmodels.stats.power import TTestIndPower standard_deviation = 5 desired_increase = 4 alpha = 0.05 beta = 0.2 analysis = TTestIndPower() analysis.solve_power( effect_size=desired_increase / standard_deviation, power=1 - beta, alpha=alpha) . | . | 1 . | 25.52457250047935 . | . Our sample size needs to be 26 participants in order for the power of the study to be 80% with our specified parameters. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. Contributed by Andrew Quagliaroli (aquagliaroli@falcon.bentley.edu) . ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-python-using-statsmodels/#solution"
  },"144": {
    "doc": "How to choose the sample size in a study with two population means (in R)",
    "title": "How to choose the sample size in a study with two population means (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-r/",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-r/"
  },"145": {
    "doc": "How to choose the sample size in a study with two population means (in R)",
    "title": "Task",
    "content": "When designing a study, it is important to choose a sample size that is large enough to perform a useful test but that is also economically feasible. How we choose the sample size depends on what test we plan to run on the data from our study. Here, let’s say our data will be used to compare two population means. If we are planning such a study, how do we determine how large it should be in order for the test that compares the population means to have a certain power? . Related tasks: . | How to compute the power of a test comparing two population means | . ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-r/#task",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-r/#task"
  },"146": {
    "doc": "How to choose the sample size in a study with two population means (in R)",
    "title": "Solution",
    "content": "Example: Let’s say we’re designing a study to assess the effectiveness of a new four-week exercise program for weight loss. Assume that weight loss in four-week exercise programs is normally distributed with a standard deviation of around 5 pounds. The goal is that the new exercise program will have a 4-pound higher weight loss than the average program. (Notice that we will be comparing the means of two populations, the weight loss in each of two programs.) . We choose a value $0 \\le \\alpha \\le 1$ as the probability of a Type I error in our test that compares the two means. (Recall, Type I error is for a false positive, finding we should reject $H_0$ when it’s actually true). Let’s set $\\alpha$ to be 0.05 here. We choose a value $0 \\le \\beta \\le 1$ as the probability of a Type II error (false negative, failing to reject $H_0$ when it’s actually false). Let’s set $\\beta$ to be 0.2 here. The test’s power is $1-\\beta$, or in this case, 0.8. What should the sample size be for each group? . | 1 2 3 4 5 6 . | # sd = standard deviation = 5 pounds # delta = desired increase = 4 pounds # sig.level = alpha = 0.05 # power = 1 - beta = 1 - 0.20 = 0.80 # n = NULL so R computes it for us power.t.test(n = NULL, delta = 4, sd = 5, sig.level = 0.05, power = 0.80) . | . | 1 2 3 4 5 6 7 8 9 10 . | Two-sample t test power calculation n = 25.52463 delta = 4 sd = 5 sig.level = 0.05 power = 0.8 alternative = two.sided NOTE: n is number in *each* group . | . Our sample size needs to be 26 participants in order for the power of the study to be 80% with our specified parameters. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-r/#solution",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means-in-r/#solution"
  },"147": {
    "doc": "How to choose the sample size in a study with two population means",
    "title": "How to choose the sample size in a study with two population means",
    "content": " ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/"
  },"148": {
    "doc": "How to choose the sample size in a study with two population means",
    "title": "Description",
    "content": "When designing a study, it is important to choose a sample size that is large enough to perform a useful test but that is also economically feasible. How we choose the sample size depends on what test we plan to run on the data from our study. Here, let’s say our data will be used to compare two population means. If we are planning such a study, how do we determine how large it should be in order for the test that compares the population means to have a certain power? . Related tasks: . | How to compute the power of a test comparing two population means | . ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/#description",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/#description"
  },"149": {
    "doc": "How to choose the sample size in a study with two population means",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. Example: Let’s say we’re designing a study to assess the effectiveness of a new four-week exercise program for weight loss. Assume that weight loss in four-week exercise programs is normally distributed with a standard deviation of around 5 pounds. The goal is that the new exercise program will have a 4-pound higher weight loss than the average program. (Notice that we will be comparing the means of two populations, the weight loss in each of two programs.) . We choose a value $0 \\leq \\alpha \\leq 1$ as the probability of a Type I error in our test that compares the two means. (Recall, Type I error is for a false positive, finding we should reject $H_0$ when it’s actually true). Let’s set $\\alpha$ to be 0.05 here. We choose a value $0 \\leq \\beta \\leq 1$ as the probability of a Type II error (false negative, failing to reject $H_0$ when it’s actually false). Let’s set $\\beta$ to be 0.2 here. The test’s power is $1-\\beta$, or in this case, 0.8. What should the sample size be for each group? . | 1 2 3 4 5 6 7 8 9 10 . | from statsmodels.stats.power import TTestIndPower standard_deviation = 5 desired_increase = 4 alpha = 0.05 beta = 0.2 analysis = TTestIndPower() analysis.solve_power( effect_size=desired_increase / standard_deviation, power=1 - beta, alpha=alpha) . | . | 1 . | 25.52457250047935 . | . Our sample size needs to be 26 participants in order for the power of the study to be 80% with our specified parameters. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/#using-statsmodels-in-python",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/#using-statsmodels-in-python"
  },"150": {
    "doc": "How to choose the sample size in a study with two population means",
    "title": "Solution, in R",
    "content": "View this solution alone. Example: Let’s say we’re designing a study to assess the effectiveness of a new four-week exercise program for weight loss. Assume that weight loss in four-week exercise programs is normally distributed with a standard deviation of around 5 pounds. The goal is that the new exercise program will have a 4-pound higher weight loss than the average program. (Notice that we will be comparing the means of two populations, the weight loss in each of two programs.) . We choose a value $0 \\le \\alpha \\le 1$ as the probability of a Type I error in our test that compares the two means. (Recall, Type I error is for a false positive, finding we should reject $H_0$ when it’s actually true). Let’s set $\\alpha$ to be 0.05 here. We choose a value $0 \\le \\beta \\le 1$ as the probability of a Type II error (false negative, failing to reject $H_0$ when it’s actually false). Let’s set $\\beta$ to be 0.2 here. The test’s power is $1-\\beta$, or in this case, 0.8. What should the sample size be for each group? . | 1 2 3 4 5 6 . | # sd = standard deviation = 5 pounds # delta = desired increase = 4 pounds # sig.level = alpha = 0.05 # power = 1 - beta = 1 - 0.20 = 0.80 # n = NULL so R computes it for us power.t.test(n = NULL, delta = 4, sd = 5, sig.level = 0.05, power = 0.80) . | . | 1 2 3 4 5 6 7 8 9 10 . | Two-sample t test power calculation n = 25.52463 delta = 4 sd = 5 sig.level = 0.05 power = 0.8 alternative = two.sided NOTE: n is number in *each* group . | . Our sample size needs to be 26 participants in order for the power of the study to be 80% with our specified parameters. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/#solution-in-r",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/#solution-in-r"
  },"151": {
    "doc": "How to choose the sample size in a study with two population means",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/#topics-that-include-this-task",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/#topics-that-include-this-task"
  },"152": {
    "doc": "How to choose the sample size in a study with two population means",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/#opportunities",
    "relUrl": "/how-to-choose-the-sample-size-in-a-study-with-two-population-means/#opportunities"
  },"153": {
    "doc": "How to compare two nested linear models (in Python, using statsmodels)",
    "title": "How to compare two nested linear models (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-compare-two-nested-linear-models-in-python-using-statsmodels/",
    "relUrl": "/how-to-compare-two-nested-linear-models-in-python-using-statsmodels/"
  },"154": {
    "doc": "How to compare two nested linear models (in Python, using statsmodels)",
    "title": "Task",
    "content": "Model $A$ is said to be “nested” in model $B$ if the predictors included in $A$ are a subset of those included in $B$. In such a situation, how can we determine if the larger model (in this case $B$) is significantly better than the smaller (reduced) model? We can use an Extra Sums of Squares test, also called a partial $F$-test, to compare two nested linear. This technique will also help us with another question. If we have a multivarate linear model, . \\[\\hat{y}=\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_kx_k,\\] how can we test the influence of only some of the coefficients? If we remove some of the coefficients, we have a smaller model nested in the larger one, so the question is the same. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-compare-two-nested-linear-models-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-compare-two-nested-linear-models-in-python-using-statsmodels/#task"
  },"155": {
    "doc": "How to compare two nested linear models (in Python, using statsmodels)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) . We will create two models, one nested inside the other, in a natural way in this example. But this is not the only way to create nested models; it is just an example. | 1 2 . | from rdatasets import data df = data('mtcars') . | . Consider a model using number of cylinders (cyl) and weight of car (wt) to predict its fuel efficiency (mpg). We create this model and perform an ANOVA to see if the predictors are significant. We use the Ordinary Least Squares module from statsmodels. | 1 2 3 4 5 . | from statsmodels.formula.api import ols add_model = ols('mpg ~ cyl + wt', data = df).fit() import statsmodels.api as sm sm.stats.anova_lm(add_model, typ= 1) . | . | | df | sum_sq | mean_sq | F | PR(&gt;F) | . | cyl | 1.0 | 817.712952 | 817.712952 | 124.043687 | 5.424327e-12 | . | wt | 1.0 | 117.162269 | 117.162269 | 17.773034 | 2.220200e-04 | . | Residual | 29.0 | 191.171966 | 6.592137 | NaN | NaN | . In the final column of output we see that all numbers are below $0.05$, which suggests that both predictors are significant. A natural question to ask is whether the two predictors have an interaction effect. Let’s create a model containing the interaction term. | 1 2 . | int_model = ols('mpg ~ cyl*wt', data = df).fit() sm.stats.anova_lm(int_model, typ= 1) . | . | | df | sum_sq | mean_sq | F | PR(&gt;F) | . | cyl | 1.0 | 817.712952 | 817.712952 | 145.856269 | 1.280635e-12 | . | wt | 1.0 | 117.162269 | 117.162269 | 20.898350 | 8.942713e-05 | . | cyl:wt | 1.0 | 34.195767 | 34.195767 | 6.099533 | 1.988242e-02 | . | Residual | 28.0 | 156.976199 | 5.606293 | NaN | NaN | . As seen in the final column of output, there is a significant interaction between the two predictors (bottom number being below $0.05$). We now have one model (add_model) nested inside a larger model (int_model). To check which model is better, we can conduct an ANOVA comparing the two models. We use the anova_lm function from statsmodels. | 1 2 . | from statsmodels.stats.anova import anova_lm anova_lm(add_model, int_model) . | . | | df_resid | ssr | df_diff | ss_diff | F | Pr(&gt;F) | . | 0 | 29.0 | 191.171966 | 0.0 | NaN | NaN | NaN | . | 1 | 28.0 | 156.976199 | 1.0 | 34.195767 | 6.099533 | 0.019882 | . We have just performed this hypothesis test: . $H_0 =$ the two models are equally useful for predicting the outcome . $H_a =$ the larger model is significantly better than the smaller model . In the final column of the output, called Pr(&gt;F), the only number in that column is our test statistic, $0.019882$. Since is below our chosen threshold of $0.05$, we reject the null hypothesis, and prefer to use the second model. This method can be used to check if covariates should be included in the model, or if additional variables should be added as well. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-compare-two-nested-linear-models-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-compare-two-nested-linear-models-in-python-using-statsmodels/#solution"
  },"156": {
    "doc": "How to compare two nested linear models (in R)",
    "title": "How to compare two nested linear models (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compare-two-nested-linear-models-in-r/",
    "relUrl": "/how-to-compare-two-nested-linear-models-in-r/"
  },"157": {
    "doc": "How to compare two nested linear models (in R)",
    "title": "Task",
    "content": "Model $A$ is said to be “nested” in model $B$ if the predictors included in $A$ are a subset of those included in $B$. In such a situation, how can we determine if the larger model (in this case $B$) is significantly better than the smaller (reduced) model? We can use an Extra Sums of Squares test, also called a partial $F$-test, to compare two nested linear. This technique will also help us with another question. If we have a multivarate linear model, . \\[\\hat{y}=\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_kx_k,\\] how can we test the influence of only some of the coefficients? If we remove some of the coefficients, we have a smaller model nested in the larger one, so the question is the same. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-compare-two-nested-linear-models-in-r/#task",
    "relUrl": "/how-to-compare-two-nested-linear-models-in-r/#task"
  },"158": {
    "doc": "How to compare two nested linear models (in R)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) . We will create two models, one nested inside the other, in a natural way in this example. But this is not the only way to create nested models; it is just an example. | 1 2 3 4 . | # install.packages(\"datasets\") # if you have not done so already library(datasets) data(mtcars) df &lt;- mtcars . | . Consider a model using number of cylinders (cyl) and weight of car (wt) to predict its fuel efficiency (mpg). We create this model and perform an ANOVA to see if the predictors are significant. | 1 2 3 4 . | # Build the model add_model &lt;- lm(mpg ~ cyl + wt, data = df) # Perform an ANOVA anova(add_model) . | . | 1 2 3 4 . | Df Sum Sq Mean Sq F value Pr(&gt;F) cyl 1 817.7130 817.712952 124.04369 5.424327e-12 wt 1 117.1623 117.162269 17.77303 2.220200e-04 Residuals 29 191.1720 6.592137 NA NA . | . The final column of output suggests that both predictors are significant. A natural question to ask is whether the two predictors have an interaction effect. Let’s create a model containing the interaction term. | 1 2 3 4 . | # Build the model with interaction int_model &lt;- lm(mpg ~ cyl * wt, data = df) # Perform an ANOVA anova(int_model) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) cyl 1 817.71295 817.712952 145.856269 1.280635e-12 wt 1 117.16227 117.162269 20.898350 8.942713e-05 cyl:wt 1 34.19577 34.195767 6.099533 1.988242e-02 Residuals 28 156.97620 5.606293 NA NA . | . As seen in the final column of output, there is a significant interaction between the two predictors. We now have one model (add_model) nested inside a larger model (int_model). To check which model is better, we can conduct an ANOVA comparing the two models. | 1 2 . | # Use ANOVA to compare the models anova(add_model, int_model) . | . | 1 2 3 . | Res.Df RSS Df Sum of Sq F Pr(&gt;F) 1 29 191.1720 NA NA NA NA 2 28 156.9762 1 34.19577 6.099533 0.01988242 . | . We have just performed this hypothesis test: . $H_0 =$ the two models are equally useful for predicting the outcome . $H_a =$ the larger model is significantly better than the smaller model . In the final column of the output, called Pr(&gt;F), the only number in that column is our test statistic, $0.01988$. Since is below our chosen threshold of $0.05$, we reject the null hypothesis, and prefer to use the second model. This method can be used to check if covariates should be included in the model, or if additional variables should be added as well. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by: . | Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) | Krtin Juneja (KJUNEJA@falcon.bentley.edu) | . ",
    "url": "/how-to-compare-two-nested-linear-models-in-r/#solution",
    "relUrl": "/how-to-compare-two-nested-linear-models-in-r/#solution"
  },"159": {
    "doc": "How to compare two nested linear models",
    "title": "How to compare two nested linear models",
    "content": " ",
    "url": "/how-to-compare-two-nested-linear-models/",
    "relUrl": "/how-to-compare-two-nested-linear-models/"
  },"160": {
    "doc": "How to compare two nested linear models",
    "title": "Description",
    "content": "Model $A$ is said to be “nested” in model $B$ if the predictors included in $A$ are a subset of those included in $B$. In such a situation, how can we determine if the larger model (in this case $B$) is significantly better than the smaller (reduced) model? We can use an Extra Sums of Squares test, also called a partial $F$-test, to compare two nested linear. This technique will also help us with another question. If we have a multivarate linear model, . \\[\\hat{y}=\\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\beta_kx_k,\\] how can we test the influence of only some of the coefficients? If we remove some of the coefficients, we have a smaller model nested in the larger one, so the question is the same. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-compare-two-nested-linear-models/#description",
    "relUrl": "/how-to-compare-two-nested-linear-models/#description"
  },"161": {
    "doc": "How to compare two nested linear models",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) . We will create two models, one nested inside the other, in a natural way in this example. But this is not the only way to create nested models; it is just an example. | 1 2 . | from rdatasets import data df = data('mtcars') . | . Consider a model using number of cylinders (cyl) and weight of car (wt) to predict its fuel efficiency (mpg). We create this model and perform an ANOVA to see if the predictors are significant. We use the Ordinary Least Squares module from statsmodels. | 1 2 3 4 5 . | from statsmodels.formula.api import ols add_model = ols('mpg ~ cyl + wt', data = df).fit() import statsmodels.api as sm sm.stats.anova_lm(add_model, typ= 1) . | . | | df | sum_sq | mean_sq | F | PR(&gt;F) | . | cyl | 1.0 | 817.712952 | 817.712952 | 124.043687 | 5.424327e-12 | . | wt | 1.0 | 117.162269 | 117.162269 | 17.773034 | 2.220200e-04 | . | Residual | 29.0 | 191.171966 | 6.592137 | NaN | NaN | . In the final column of output we see that all numbers are below $0.05$, which suggests that both predictors are significant. A natural question to ask is whether the two predictors have an interaction effect. Let’s create a model containing the interaction term. | 1 2 . | int_model = ols('mpg ~ cyl*wt', data = df).fit() sm.stats.anova_lm(int_model, typ= 1) . | . | | df | sum_sq | mean_sq | F | PR(&gt;F) | . | cyl | 1.0 | 817.712952 | 817.712952 | 145.856269 | 1.280635e-12 | . | wt | 1.0 | 117.162269 | 117.162269 | 20.898350 | 8.942713e-05 | . | cyl:wt | 1.0 | 34.195767 | 34.195767 | 6.099533 | 1.988242e-02 | . | Residual | 28.0 | 156.976199 | 5.606293 | NaN | NaN | . As seen in the final column of output, there is a significant interaction between the two predictors (bottom number being below $0.05$). We now have one model (add_model) nested inside a larger model (int_model). To check which model is better, we can conduct an ANOVA comparing the two models. We use the anova_lm function from statsmodels. | 1 2 . | from statsmodels.stats.anova import anova_lm anova_lm(add_model, int_model) . | . | | df_resid | ssr | df_diff | ss_diff | F | Pr(&gt;F) | . | 0 | 29.0 | 191.171966 | 0.0 | NaN | NaN | NaN | . | 1 | 28.0 | 156.976199 | 1.0 | 34.195767 | 6.099533 | 0.019882 | . We have just performed this hypothesis test: . $H_0 =$ the two models are equally useful for predicting the outcome . $H_a =$ the larger model is significantly better than the smaller model . In the final column of the output, called Pr(&gt;F), the only number in that column is our test statistic, $0.019882$. Since is below our chosen threshold of $0.05$, we reject the null hypothesis, and prefer to use the second model. This method can be used to check if covariates should be included in the model, or if additional variables should be added as well. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compare-two-nested-linear-models/#using-statsmodels-in-python",
    "relUrl": "/how-to-compare-two-nested-linear-models/#using-statsmodels-in-python"
  },"162": {
    "doc": "How to compare two nested linear models",
    "title": "Solution, in R",
    "content": "View this solution alone. The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) . We will create two models, one nested inside the other, in a natural way in this example. But this is not the only way to create nested models; it is just an example. | 1 2 3 4 . | # install.packages(\"datasets\") # if you have not done so already library(datasets) data(mtcars) df &lt;- mtcars . | . Consider a model using number of cylinders (cyl) and weight of car (wt) to predict its fuel efficiency (mpg). We create this model and perform an ANOVA to see if the predictors are significant. | 1 2 3 4 . | # Build the model add_model &lt;- lm(mpg ~ cyl + wt, data = df) # Perform an ANOVA anova(add_model) . | . | 1 2 3 4 . | Df Sum Sq Mean Sq F value Pr(&gt;F) cyl 1 817.7130 817.712952 124.04369 5.424327e-12 wt 1 117.1623 117.162269 17.77303 2.220200e-04 Residuals 29 191.1720 6.592137 NA NA . | . The final column of output suggests that both predictors are significant. A natural question to ask is whether the two predictors have an interaction effect. Let’s create a model containing the interaction term. | 1 2 3 4 . | # Build the model with interaction int_model &lt;- lm(mpg ~ cyl * wt, data = df) # Perform an ANOVA anova(int_model) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) cyl 1 817.71295 817.712952 145.856269 1.280635e-12 wt 1 117.16227 117.162269 20.898350 8.942713e-05 cyl:wt 1 34.19577 34.195767 6.099533 1.988242e-02 Residuals 28 156.97620 5.606293 NA NA . | . As seen in the final column of output, there is a significant interaction between the two predictors. We now have one model (add_model) nested inside a larger model (int_model). To check which model is better, we can conduct an ANOVA comparing the two models. | 1 2 . | # Use ANOVA to compare the models anova(add_model, int_model) . | . | 1 2 3 . | Res.Df RSS Df Sum of Sq F Pr(&gt;F) 1 29 191.1720 NA NA NA NA 2 28 156.9762 1 34.19577 6.099533 0.01988242 . | . We have just performed this hypothesis test: . $H_0 =$ the two models are equally useful for predicting the outcome . $H_a =$ the larger model is significantly better than the smaller model . In the final column of the output, called Pr(&gt;F), the only number in that column is our test statistic, $0.01988$. Since is below our chosen threshold of $0.05$, we reject the null hypothesis, and prefer to use the second model. This method can be used to check if covariates should be included in the model, or if additional variables should be added as well. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compare-two-nested-linear-models/#solution-in-r",
    "relUrl": "/how-to-compare-two-nested-linear-models/#solution-in-r"
  },"163": {
    "doc": "How to compare two nested linear models",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-compare-two-nested-linear-models/#topics-that-include-this-task",
    "relUrl": "/how-to-compare-two-nested-linear-models/#topics-that-include-this-task"
  },"164": {
    "doc": "How to compare two nested linear models",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compare-two-nested-linear-models/#opportunities",
    "relUrl": "/how-to-compare-two-nested-linear-models/#opportunities"
  },"165": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs) (in Python, using NumPy and SciPy)",
    "title": "How to compute a confidence interval for a mean difference (matched pairs) (in Python, using NumPy and SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-python-using-numpy-and-scipy/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-python-using-numpy-and-scipy/"
  },"166": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs) (in Python, using NumPy and SciPy)",
    "title": "Task",
    "content": "Say we have two sets of data that are not independent of each other and come from a matched-pairs experiment, and we want to construct a confidence interval for the mean difference between these two samples. How do we make this confidence interval? Let’s assume we’ve chosen a confidence level of $\\alpha$ = 0.05. Related tasks: . | How to do a hypothesis test for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-python-using-numpy-and-scipy/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-python-using-numpy-and-scipy/#task"
  },"167": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs) (in Python, using NumPy and SciPy)",
    "title": "Solution",
    "content": "We’ll use Numpy and SciPy to do some statistics later. | 1 2 . | import numpy as np from scipy import stats . | . This example computes a 95% confidence interval, but you can choose a different level by choosing a different value for $\\alpha$. | 1 . | alpha = 0.05 . | . We have two samples of data, $x_1, x_2, x_3, \\ldots, x_k$ and $x’_1, x’_2, x’_3, \\ldots, x’_k$. We’re going to use some fake data below just as an example; replace it with your real data. | 1 2 . | sample1 = np.array([15, 10, 7, 22, 17, 14]) sample2 = np.array([ 9, 1, 11, 13, 3, 6]) . | . And now the computations: . | 1 2 3 4 5 6 7 . | diff_samples = sample1 - sample2 # differences between the samples n = len(sample1) # number of observations per sample diff_mean = np.mean(diff_samples) # mean of the differences diff_variance = np.var( diff_samples, ddof=1 ) # variance of the differences critical_val = stats.t.ppf(q = 1-alpha/2, df = n - 1) # critical value radius = critical_val*np.sqrt(diff_variance)/np.sqrt(n) # radius of confidence interval ( diff_mean - radius, diff_mean + radius ) # confidence interval . | . | 1 . | (0.7033861582274517, 13.296613841772547) . | . Our 95% confidence interval for the mean difference is $[0.70338, 13.2966]$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-python-using-numpy-and-scipy/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-python-using-numpy-and-scipy/#solution"
  },"168": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs) (in R)",
    "title": "How to compute a confidence interval for a mean difference (matched pairs) (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-r/"
  },"169": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs) (in R)",
    "title": "Task",
    "content": "Say we have two sets of data that are not independent of each other and come from a matched-pairs experiment, and we want to construct a confidence interval for the mean difference between these two samples. How do we make this confidence interval? Let’s assume we’ve chosen a confidence level of $\\alpha$ = 0.05. Related tasks: . | How to do a hypothesis test for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-r/#task"
  },"170": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs) (in R)",
    "title": "Solution",
    "content": "We have two samples of data, $x_1, x_2, x_3, \\ldots, x_k$ and $x’_1, x’_2, x’_3, \\ldots, x’_k$. We’re going to use some fake data below just as an example; replace it with your real data. | 1 2 . | sample.1 &lt;- c(15, 10, 7, 22, 17, 14) sample.2 &lt;- c(9, 1, 11, 13, 3, 6) . | . The shortest way to create the confidence interval is with R’s t.test() function. It’s just one line of code (after we choose $\\alpha$). | 1 2 . | alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) t.test(sample.1, sample.2, paired = TRUE, conf.level = 1-alpha) . | . | 1 2 3 4 5 6 7 8 9 10 . | Paired t-test data: sample.1 and sample.2 t = 2.8577, df = 5, p-value = 0.0355 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 0.7033862 13.2966138 sample estimates: mean of the differences 7 . | . If you need the lower and upper bounds later, you can save them as variables as follows. | 1 2 3 . | conf.interval &lt;- t.test(sample.1, sample.2, paired = TRUE, conf.level = 1-alpha) lower.bound &lt;- conf.interval$conf.int[1] upper.bound &lt;- conf.interval$conf.int[2] . | . It’s also possible to do the computation manually, using the code below. | 1 2 3 4 5 6 7 8 . | diff.samples &lt;- sample.1 - sample.2 # differences between the samples n = length(sample.1) # number of observations per sample diff.mean &lt;- mean(diff.samples) # mean of the differences diff.variance &lt;- var( diff.samples ) # variance of the differences critical.val &lt;- qt(p = alpha/2, df = n - 1, lower.tail=FALSE) # critical value radius &lt;- critical.val*sqrt(diff.variance)/sqrt(n) # radius of confidence interval c( diff.mean - radius, diff.mean + radius ) # confidence interval . | . | 1 . | [1] 0.7033862 13.2966138 . | . Either method gives the same result. Our 95% confidence interval is $[0.70338, 13.2966]$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs-in-r/#solution"
  },"171": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs)",
    "title": "How to compute a confidence interval for a mean difference (matched pairs)",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/"
  },"172": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs)",
    "title": "Description",
    "content": "Say we have two sets of data that are not independent of each other and come from a matched-pairs experiment, and we want to construct a confidence interval for the mean difference between these two samples. How do we make this confidence interval? Let’s assume we’ve chosen a confidence level of $\\alpha$ = 0.05. Related tasks: . | How to do a hypothesis test for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/#description"
  },"173": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs)",
    "title": "Using NumPy and SciPy, in Python",
    "content": "View this solution alone. We’ll use Numpy and SciPy to do some statistics later. | 1 2 . | import numpy as np from scipy import stats . | . This example computes a 95% confidence interval, but you can choose a different level by choosing a different value for $\\alpha$. | 1 . | alpha = 0.05 . | . We have two samples of data, $x_1, x_2, x_3, \\ldots, x_k$ and $x’_1, x’_2, x’_3, \\ldots, x’_k$. We’re going to use some fake data below just as an example; replace it with your real data. | 1 2 . | sample1 = np.array([15, 10, 7, 22, 17, 14]) sample2 = np.array([ 9, 1, 11, 13, 3, 6]) . | . And now the computations: . | 1 2 3 4 5 6 7 . | diff_samples = sample1 - sample2 # differences between the samples n = len(sample1) # number of observations per sample diff_mean = np.mean(diff_samples) # mean of the differences diff_variance = np.var( diff_samples, ddof=1 ) # variance of the differences critical_val = stats.t.ppf(q = 1-alpha/2, df = n - 1) # critical value radius = critical_val*np.sqrt(diff_variance)/np.sqrt(n) # radius of confidence interval ( diff_mean - radius, diff_mean + radius ) # confidence interval . | . | 1 . | (0.7033861582274517, 13.296613841772547) . | . Our 95% confidence interval for the mean difference is $[0.70338, 13.2966]$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/#using-numpy-and-scipy-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/#using-numpy-and-scipy-in-python"
  },"174": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs)",
    "title": "Solution, in R",
    "content": "View this solution alone. We have two samples of data, $x_1, x_2, x_3, \\ldots, x_k$ and $x’_1, x’_2, x’_3, \\ldots, x’_k$. We’re going to use some fake data below just as an example; replace it with your real data. | 1 2 . | sample.1 &lt;- c(15, 10, 7, 22, 17, 14) sample.2 &lt;- c(9, 1, 11, 13, 3, 6) . | . The shortest way to create the confidence interval is with R’s t.test() function. It’s just one line of code (after we choose $\\alpha$). | 1 2 . | alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) t.test(sample.1, sample.2, paired = TRUE, conf.level = 1-alpha) . | . | 1 2 3 4 5 6 7 8 9 10 . | Paired t-test data: sample.1 and sample.2 t = 2.8577, df = 5, p-value = 0.0355 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 0.7033862 13.2966138 sample estimates: mean of the differences 7 . | . If you need the lower and upper bounds later, you can save them as variables as follows. | 1 2 3 . | conf.interval &lt;- t.test(sample.1, sample.2, paired = TRUE, conf.level = 1-alpha) lower.bound &lt;- conf.interval$conf.int[1] upper.bound &lt;- conf.interval$conf.int[2] . | . It’s also possible to do the computation manually, using the code below. | 1 2 3 4 5 6 7 8 . | diff.samples &lt;- sample.1 - sample.2 # differences between the samples n = length(sample.1) # number of observations per sample diff.mean &lt;- mean(diff.samples) # mean of the differences diff.variance &lt;- var( diff.samples ) # variance of the differences critical.val &lt;- qt(p = alpha/2, df = n - 1, lower.tail=FALSE) # critical value radius &lt;- critical.val*sqrt(diff.variance)/sqrt(n) # radius of confidence interval c( diff.mean - radius, diff.mean + radius ) # confidence interval . | . | 1 . | [1] 0.7033862 13.2966138 . | . Either method gives the same result. Our 95% confidence interval is $[0.70338, 13.2966]$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/#solution-in-r"
  },"175": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs)",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/#topics-that-include-this-task"
  },"176": {
    "doc": "How to compute a confidence interval for a mean difference (matched pairs)",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-mean-difference-matched-pairs/#opportunities"
  },"177": {
    "doc": "How to compute a confidence interval for a population mean (in Julia)",
    "title": "How to compute a confidence interval for a population mean (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-julia/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-julia/"
  },"178": {
    "doc": "How to compute a confidence interval for a population mean (in Julia)",
    "title": "Task",
    "content": "If we have a set of data that seems normally distributed, how can we compute a confidence interval for the mean? Assume we have some confidence level already chosen, such as $\\alpha=0.05$. We will use the $t$-distribution because we have not assumed that we know the population standard deviation, and we have not assumed anything about our sample size. If you know the population standard deviation or have a large sample size (typically at least 30), then you can use $z$-scores instead; see how to compute a confidence interval for a population mean using z-scores. Related tasks: . | How to compute a confidence interval for a population mean using z-scores | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-julia/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-julia/#task"
  },"179": {
    "doc": "How to compute a confidence interval for a population mean (in Julia)",
    "title": "Solution",
    "content": "When applying this technique, you would have a series of data values for which you needed to compute a confidence interval for the mean. But in order to provide code that runs independently, we create some fake data below. When using this code, replace our fake data with your real data. | 1 2 3 4 5 6 . | alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) data = [ 435,542,435,4,54,43,5,43,543,5,432,43,36,7,876,65,5 ] # fake # Compute the confidence interval: using HypothesisTests confint( OneSampleTTest( data ), level=1-alpha, tail=:both ) . | . | 1 . | (70.2984781107082, 350.05446306576243) . | . Note: The solution above assumes that the population is normally distributed, which is a common assumption in introductory statistics courses, but we have not verified that assumption here. Content last modified on 05 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-julia/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-julia/#solution"
  },"180": {
    "doc": "How to compute a confidence interval for a population mean (in Python, using SciPy)",
    "title": "How to compute a confidence interval for a population mean (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-python-using-scipy/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-python-using-scipy/"
  },"181": {
    "doc": "How to compute a confidence interval for a population mean (in Python, using SciPy)",
    "title": "Task",
    "content": "If we have a set of data that seems normally distributed, how can we compute a confidence interval for the mean? Assume we have some confidence level already chosen, such as $\\alpha=0.05$. We will use the $t$-distribution because we have not assumed that we know the population standard deviation, and we have not assumed anything about our sample size. If you know the population standard deviation or have a large sample size (typically at least 30), then you can use $z$-scores instead; see how to compute a confidence interval for a population mean using z-scores. Related tasks: . | How to compute a confidence interval for a population mean using z-scores | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-python-using-scipy/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-python-using-scipy/#task"
  },"182": {
    "doc": "How to compute a confidence interval for a population mean (in Python, using SciPy)",
    "title": "Solution",
    "content": "This solution uses a 95% confidence level, but you can change that in the first line of code, by specifing a different alpha. When applying this technique, you would have a series of data values for which you needed to compute a confidence interval for the mean. But in order to provide code that runs independently, we create some fake data below. When using this code, replace our fake data with your real data. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 . | alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) data = [ 435,542,435,4,54,43,5,43,543,5,432,43,36,7,876,65,5 ] # fake # We will use NumPy and SciPy to compute some of the statistics below. import numpy as np import scipy.stats as stats # Compute the sample mean, as an estimate for the population mean. sample_mean = np.mean( data ) # Compute the Standard Error for the sample Mean (SEM). sem = stats.sem( data ) # The margin of error then has the following formula. moe = sem * stats.t.ppf( 1 - alpha / 2, len( data ) - 1 ) # The confidence interval is centered on the mean with moe as its radius: ( sample_mean - moe, sample_mean + moe ) . | . | 1 . | (70.29847811072423, 350.0544630657464) . | . Note: The solution above assumes that the population is normally distributed, which is a common assumption in introductory statistics courses, but we have not verified that assumption here. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-python-using-scipy/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-python-using-scipy/#solution"
  },"183": {
    "doc": "How to compute a confidence interval for a population mean (in R)",
    "title": "How to compute a confidence interval for a population mean (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-r/"
  },"184": {
    "doc": "How to compute a confidence interval for a population mean (in R)",
    "title": "Task",
    "content": "If we have a set of data that seems normally distributed, how can we compute a confidence interval for the mean? Assume we have some confidence level already chosen, such as $\\alpha=0.05$. We will use the $t$-distribution because we have not assumed that we know the population standard deviation, and we have not assumed anything about our sample size. If you know the population standard deviation or have a large sample size (typically at least 30), then you can use $z$-scores instead; see how to compute a confidence interval for a population mean using z-scores. Related tasks: . | How to compute a confidence interval for a population mean using z-scores | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-r/#task"
  },"185": {
    "doc": "How to compute a confidence interval for a population mean (in R)",
    "title": "Solution",
    "content": "When applying this technique, you would have a series of data values for which you needed to compute a confidence interval for the mean. But in order to provide code that runs independently, we create some fake data below. When using this code, replace our fake data with your real data. | 1 2 3 4 5 6 7 8 9 10 . | alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) data &lt;- c( 435,542,435,4,54,43,5,43,543,5,432,43,36,7,876,65,5 ) # fake # If you need the two values stored in variables for later use, do: answer &lt;- t.test( data, conf.level=1-alpha ) lower_bound &lt;- answer$conf.int[1] upper_bound &lt;- answer$conf.int[2] # If you just need to see the results in a report, do this alone: t.test( data, conf.level=1-alpha ) . | . | 1 2 3 4 5 6 7 8 9 10 . | One Sample t-test data: data t = 3.1853, df = 16, p-value = 0.005753 alternative hypothesis: true mean is not equal to 0 95 percent confidence interval: 70.29848 350.05446 sample estimates: mean of x 210.1765 . | . Note: The solution above assumes that the population is normally distributed, which is a common assumption in introductory statistics courses, but we have not verified that assumption here. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-in-r/#solution"
  },"186": {
    "doc": "How to compute a confidence interval for a population mean using z-scores (in Python, using SciPy)",
    "title": "How to compute a confidence interval for a population mean using z-scores (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-python-using-scipy/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-python-using-scipy/"
  },"187": {
    "doc": "How to compute a confidence interval for a population mean using z-scores (in Python, using SciPy)",
    "title": "Task",
    "content": "If we have a set of data that seems normally distributed, how can we compute a confidence interval for the mean? Assume we have some confidence level already chosen, such as $\\alpha=0.05$. We will use the normal distribution, which assumes either that we know the population standard deviation, or we have a large enough sample size (typically at least 30). If neither of these is true in your case, then you can use $t$-scores instead; see how to compute a confidence interval for a population mean. Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a population mean | How to do a two-sided hypothesis test for two sample means | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-python-using-scipy/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-python-using-scipy/#task"
  },"188": {
    "doc": "How to compute a confidence interval for a population mean using z-scores (in Python, using SciPy)",
    "title": "Solution",
    "content": "This solution uses a 95% confidence level, but you can change that in the first line of code, by specifing a different alpha. When applying this technique, you would have a series of data values for which you needed to compute a confidence interval for the mean. But in order to provide code that runs independently, we create some fake data below. When using this code, replace our fake data with your real data. We include the population standard deviation below, assuming it is known. See the notes at the end for what to do if you do not know the population standard deviation in your situation. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) pop_std = 250 # replace with your population standard devation, if known data = [ 435,542,435,4,54,43,5,43,543,5,432,43,36,7,876,65,5 ] # fake # We will use NumPy and SciPy to compute some of the statistics below. import numpy as np import scipy.stats as stats # Compute the sample mean, as an estimate for the population mean. sample_mean = np.mean( data ) # The margin of error then has the following formula. z_score = stats.norm.ppf( 1 - alpha / 2 ) moe = pop_std * z_score / np.sqrt( len( data ) ) # The confidence interval is centered on the mean with moe as its radius: ( sample_mean - moe, sample_mean + moe ) . | . | 1 . | (91.33619807845439, 329.0167430980162) . | . Notes: . | If you do not have the population standard deviation, but your sample is large enough (typically at least 30), you can approximate the population standard deviation with the sample standard deviation, using the code std = stats.tstd( data ). If your sample is not that large, then consider using a different technique instead; see how to compute a confidence interval for a population mean. | The solution above assumes that the population is normally distributed, which is a common assumption in introductory statistics courses, but we have not verified that assumption here. | . Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-python-using-scipy/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-python-using-scipy/#solution"
  },"189": {
    "doc": "How to compute a confidence interval for a population mean using z-scores (in R)",
    "title": "How to compute a confidence interval for a population mean using z-scores (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-r/"
  },"190": {
    "doc": "How to compute a confidence interval for a population mean using z-scores (in R)",
    "title": "Task",
    "content": "If we have a set of data that seems normally distributed, how can we compute a confidence interval for the mean? Assume we have some confidence level already chosen, such as $\\alpha=0.05$. We will use the normal distribution, which assumes either that we know the population standard deviation, or we have a large enough sample size (typically at least 30). If neither of these is true in your case, then you can use $t$-scores instead; see how to compute a confidence interval for a population mean. Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a population mean | How to do a two-sided hypothesis test for two sample means | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-r/#task"
  },"191": {
    "doc": "How to compute a confidence interval for a population mean using z-scores (in R)",
    "title": "Solution",
    "content": "When applying this technique, you would have a series of data values for which you needed to compute a confidence interval for the mean. But in order to provide code that runs independently, we create some fake data below. When using this code, replace our fake data with your real data. We include the population standard deviation below, assuming it is known. See the notes at the end for what to do if you do not know the population standard deviation in your situation. | 1 2 3 4 5 6 7 8 9 10 11 12 13 . | alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) pop.std &lt;- 250 # replace with your population standard devation, if known data &lt;- c( 435,542,435,4,54,43,5,43,543,5,432,43,36,7,876,65,5 ) # fake # Compute the sample mean, as an estimate for the population mean. sample.mean &lt;- mean( data ) # The margin of error then has the following formula. z.score &lt;- qnorm( alpha / 2, lower.tail=FALSE ) moe &lt;- pop.std * z.score / sqrt( length( data ) ) # The confidence interval is centered on the mean with moe as its radius: c( sample.mean - moe, sample.mean + moe ) . | . | 1 . | [1] 91.3362 329.0167 . | . Notes: . | If you do not have the population standard deviation, but your sample is large enough (typically at least 30), you can approximate the population standard deviation with the sample standard deviation, using the code pop.std &lt;- sd( data ). If your sample is not that large, then consider using a different technique instead; see how to compute a confidence interval for a population mean. | The solution above assumes that the population is normally distributed, which is a common assumption in introductory statistics courses, but we have not verified that assumption here. | . Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores-in-r/#solution"
  },"192": {
    "doc": "How to compute a confidence interval for a population mean using z-scores",
    "title": "How to compute a confidence interval for a population mean using z-scores",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/"
  },"193": {
    "doc": "How to compute a confidence interval for a population mean using z-scores",
    "title": "Description",
    "content": "If we have a set of data that seems normally distributed, how can we compute a confidence interval for the mean? Assume we have some confidence level already chosen, such as $\\alpha=0.05$. We will use the normal distribution, which assumes either that we know the population standard deviation, or we have a large enough sample size (typically at least 30). If neither of these is true in your case, then you can use $t$-scores instead; see how to compute a confidence interval for a population mean. Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a population mean | How to do a two-sided hypothesis test for two sample means | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/#description"
  },"194": {
    "doc": "How to compute a confidence interval for a population mean using z-scores",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. This solution uses a 95% confidence level, but you can change that in the first line of code, by specifing a different alpha. When applying this technique, you would have a series of data values for which you needed to compute a confidence interval for the mean. But in order to provide code that runs independently, we create some fake data below. When using this code, replace our fake data with your real data. We include the population standard deviation below, assuming it is known. See the notes at the end for what to do if you do not know the population standard deviation in your situation. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) pop_std = 250 # replace with your population standard devation, if known data = [ 435,542,435,4,54,43,5,43,543,5,432,43,36,7,876,65,5 ] # fake # We will use NumPy and SciPy to compute some of the statistics below. import numpy as np import scipy.stats as stats # Compute the sample mean, as an estimate for the population mean. sample_mean = np.mean( data ) # The margin of error then has the following formula. z_score = stats.norm.ppf( 1 - alpha / 2 ) moe = pop_std * z_score / np.sqrt( len( data ) ) # The confidence interval is centered on the mean with moe as its radius: ( sample_mean - moe, sample_mean + moe ) . | . | 1 . | (91.33619807845439, 329.0167430980162) . | . Notes: . | If you do not have the population standard deviation, but your sample is large enough (typically at least 30), you can approximate the population standard deviation with the sample standard deviation, using the code std = stats.tstd( data ). If your sample is not that large, then consider using a different technique instead; see how to compute a confidence interval for a population mean. | The solution above assumes that the population is normally distributed, which is a common assumption in introductory statistics courses, but we have not verified that assumption here. | . Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/#using-scipy-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/#using-scipy-in-python"
  },"195": {
    "doc": "How to compute a confidence interval for a population mean using z-scores",
    "title": "Solution, in R",
    "content": "View this solution alone. When applying this technique, you would have a series of data values for which you needed to compute a confidence interval for the mean. But in order to provide code that runs independently, we create some fake data below. When using this code, replace our fake data with your real data. We include the population standard deviation below, assuming it is known. See the notes at the end for what to do if you do not know the population standard deviation in your situation. | 1 2 3 4 5 6 7 8 9 10 11 12 13 . | alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) pop.std &lt;- 250 # replace with your population standard devation, if known data &lt;- c( 435,542,435,4,54,43,5,43,543,5,432,43,36,7,876,65,5 ) # fake # Compute the sample mean, as an estimate for the population mean. sample.mean &lt;- mean( data ) # The margin of error then has the following formula. z.score &lt;- qnorm( alpha / 2, lower.tail=FALSE ) moe &lt;- pop.std * z.score / sqrt( length( data ) ) # The confidence interval is centered on the mean with moe as its radius: c( sample.mean - moe, sample.mean + moe ) . | . | 1 . | [1] 91.3362 329.0167 . | . Notes: . | If you do not have the population standard deviation, but your sample is large enough (typically at least 30), you can approximate the population standard deviation with the sample standard deviation, using the code pop.std &lt;- sd( data ). If your sample is not that large, then consider using a different technique instead; see how to compute a confidence interval for a population mean. | The solution above assumes that the population is normally distributed, which is a common assumption in introductory statistics courses, but we have not verified that assumption here. | . Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/#solution-in-r"
  },"196": {
    "doc": "How to compute a confidence interval for a population mean using z-scores",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/#topics-that-include-this-task"
  },"197": {
    "doc": "How to compute a confidence interval for a population mean using z-scores",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean-using-z-scores/#opportunities"
  },"198": {
    "doc": "How to compute a confidence interval for a population mean",
    "title": "How to compute a confidence interval for a population mean",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean/"
  },"199": {
    "doc": "How to compute a confidence interval for a population mean",
    "title": "Description",
    "content": "If we have a set of data that seems normally distributed, how can we compute a confidence interval for the mean? Assume we have some confidence level already chosen, such as $\\alpha=0.05$. We will use the $t$-distribution because we have not assumed that we know the population standard deviation, and we have not assumed anything about our sample size. If you know the population standard deviation or have a large sample size (typically at least 30), then you can use $z$-scores instead; see how to compute a confidence interval for a population mean using z-scores. Related tasks: . | How to compute a confidence interval for a population mean using z-scores | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean/#description"
  },"200": {
    "doc": "How to compute a confidence interval for a population mean",
    "title": "Solution, in Julia",
    "content": "View this solution alone. When applying this technique, you would have a series of data values for which you needed to compute a confidence interval for the mean. But in order to provide code that runs independently, we create some fake data below. When using this code, replace our fake data with your real data. | 1 2 3 4 5 6 . | alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) data = [ 435,542,435,4,54,43,5,43,543,5,432,43,36,7,876,65,5 ] # fake # Compute the confidence interval: using HypothesisTests confint( OneSampleTTest( data ), level=1-alpha, tail=:both ) . | . | 1 . | (70.2984781107082, 350.05446306576243) . | . Note: The solution above assumes that the population is normally distributed, which is a common assumption in introductory statistics courses, but we have not verified that assumption here. Content last modified on 05 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean/#solution-in-julia",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean/#solution-in-julia"
  },"201": {
    "doc": "How to compute a confidence interval for a population mean",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. This solution uses a 95% confidence level, but you can change that in the first line of code, by specifing a different alpha. When applying this technique, you would have a series of data values for which you needed to compute a confidence interval for the mean. But in order to provide code that runs independently, we create some fake data below. When using this code, replace our fake data with your real data. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 . | alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) data = [ 435,542,435,4,54,43,5,43,543,5,432,43,36,7,876,65,5 ] # fake # We will use NumPy and SciPy to compute some of the statistics below. import numpy as np import scipy.stats as stats # Compute the sample mean, as an estimate for the population mean. sample_mean = np.mean( data ) # Compute the Standard Error for the sample Mean (SEM). sem = stats.sem( data ) # The margin of error then has the following formula. moe = sem * stats.t.ppf( 1 - alpha / 2, len( data ) - 1 ) # The confidence interval is centered on the mean with moe as its radius: ( sample_mean - moe, sample_mean + moe ) . | . | 1 . | (70.29847811072423, 350.0544630657464) . | . Note: The solution above assumes that the population is normally distributed, which is a common assumption in introductory statistics courses, but we have not verified that assumption here. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean/#using-scipy-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean/#using-scipy-in-python"
  },"202": {
    "doc": "How to compute a confidence interval for a population mean",
    "title": "Solution, in R",
    "content": "View this solution alone. When applying this technique, you would have a series of data values for which you needed to compute a confidence interval for the mean. But in order to provide code that runs independently, we create some fake data below. When using this code, replace our fake data with your real data. | 1 2 3 4 5 6 7 8 9 10 . | alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) data &lt;- c( 435,542,435,4,54,43,5,43,543,5,432,43,36,7,876,65,5 ) # fake # If you need the two values stored in variables for later use, do: answer &lt;- t.test( data, conf.level=1-alpha ) lower_bound &lt;- answer$conf.int[1] upper_bound &lt;- answer$conf.int[2] # If you just need to see the results in a report, do this alone: t.test( data, conf.level=1-alpha ) . | . | 1 2 3 4 5 6 7 8 9 10 . | One Sample t-test data: data t = 3.1853, df = 16, p-value = 0.005753 alternative hypothesis: true mean is not equal to 0 95 percent confidence interval: 70.29848 350.05446 sample estimates: mean of x 210.1765 . | . Note: The solution above assumes that the population is normally distributed, which is a common assumption in introductory statistics courses, but we have not verified that assumption here. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean/#solution-in-r"
  },"203": {
    "doc": "How to compute a confidence interval for a population mean",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | Bentley University MA214 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean/#topics-that-include-this-task"
  },"204": {
    "doc": "How to compute a confidence interval for a population mean",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-population-mean/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-population-mean/#opportunities"
  },"205": {
    "doc": "How to compute a confidence interval for a regression coefficient (in Python, using statsmodels)",
    "title": "How to compute a confidence interval for a regression coefficient (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-python-using-statsmodels/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-python-using-statsmodels/"
  },"206": {
    "doc": "How to compute a confidence interval for a regression coefficient (in Python, using statsmodels)",
    "title": "Task",
    "content": "Say we have a linear regression model, either single variable or multivariate. How do we compute a confidence interval for the coefficient of one of the explanatory variables in the model? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-python-using-statsmodels/#task"
  },"207": {
    "doc": "How to compute a confidence interval for a regression coefficient (in Python, using statsmodels)",
    "title": "Solution",
    "content": "We’ll assume that you have fit a single linear model to your data, as in the code below, which uses fake example data. You can replace it with your actual data. | 1 2 3 4 5 6 7 8 . | import statsmodels.api as sm xs = [ 34, 9, 78, 60, 22, 45, 83, 59, 25 ] ys = [ 126, 347, 298, 309, 450, 187, 266, 385, 400 ] xs = sm.add_constant( xs ) model = sm.OLS( ys, xs ) results = model.fit() . | . We can use Python’s conf_int() function to find the confidence interval for the model coefficients. You can change the alpha parameter to specify a different significance level. Note that if you have a multiple regression model, it will make confidence intervals for all of the coefficient values. | 1 . | results.conf_int( alpha=0.05 ) . | . | 1 2 . | array([[172.63807531, 535.52642049], [ -4.49196063, 2.47393542]]) . | . Each list in the array represents the 95% confidence interval for the corresponding coefficient in the model beginning with the intercept and each regression coefficient thereafter. Accordingly, the 95% confidence interval for the regression coefficient is $[-4.49196063,2.47393542]$. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. Contributed by Andrew Quagliaroli (aquagliaroli@falcon.bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-python-using-statsmodels/#solution"
  },"208": {
    "doc": "How to compute a confidence interval for a regression coefficient (in R)",
    "title": "How to compute a confidence interval for a regression coefficient (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-r/"
  },"209": {
    "doc": "How to compute a confidence interval for a regression coefficient (in R)",
    "title": "Task",
    "content": "Say we have a linear regression model, either single variable or multivariate. How do we compute a confidence interval for the coefficient of one of the explanatory variables in the model? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-r/#task"
  },"210": {
    "doc": "How to compute a confidence interval for a regression coefficient (in R)",
    "title": "Solution",
    "content": "We’ll assume that you have fit a single linear model to your data, as in the code below, which uses fake example data. You can replace it with your actual data. | 1 2 3 . | x &lt;- c(34, 9, 78, 60, 22, 45, 83, 59, 25) y &lt;- c(126, 347, 298, 309, 450, 187, 266, 385, 400) model &lt;- lm(y ~ x) . | . We can use R’s confint() function to find the confidence interval for the model coefficients. You can change the level parameter to specify a different confidence level. Note that if you have a multiple regression model, it will make confidence intervals for all of the coefficient values. | 1 . | confint(model, level = 0.95) # or choose any confidence level; here we use 0.95 . | . | 1 2 3 . | 2.5 % 97.5 % (Intercept) 172.638075 535.526421 x -4.491961 2.473935 . | . The 95% confidence interval for the regression coefficient is $[-4.491961, 2.473935]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient-in-r/#solution"
  },"211": {
    "doc": "How to compute a confidence interval for a regression coefficient",
    "title": "How to compute a confidence interval for a regression coefficient",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/"
  },"212": {
    "doc": "How to compute a confidence interval for a regression coefficient",
    "title": "Description",
    "content": "Say we have a linear regression model, either single variable or multivariate. How do we compute a confidence interval for the coefficient of one of the explanatory variables in the model? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/#description"
  },"213": {
    "doc": "How to compute a confidence interval for a regression coefficient",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. We’ll assume that you have fit a single linear model to your data, as in the code below, which uses fake example data. You can replace it with your actual data. | 1 2 3 4 5 6 7 8 . | import statsmodels.api as sm xs = [ 34, 9, 78, 60, 22, 45, 83, 59, 25 ] ys = [ 126, 347, 298, 309, 450, 187, 266, 385, 400 ] xs = sm.add_constant( xs ) model = sm.OLS( ys, xs ) results = model.fit() . | . We can use Python’s conf_int() function to find the confidence interval for the model coefficients. You can change the alpha parameter to specify a different significance level. Note that if you have a multiple regression model, it will make confidence intervals for all of the coefficient values. | 1 . | results.conf_int( alpha=0.05 ) . | . | 1 2 . | array([[172.63807531, 535.52642049], [ -4.49196063, 2.47393542]]) . | . Each list in the array represents the 95% confidence interval for the corresponding coefficient in the model beginning with the intercept and each regression coefficient thereafter. Accordingly, the 95% confidence interval for the regression coefficient is $[-4.49196063,2.47393542]$. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/#using-statsmodels-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/#using-statsmodels-in-python"
  },"214": {
    "doc": "How to compute a confidence interval for a regression coefficient",
    "title": "Solution, in R",
    "content": "View this solution alone. We’ll assume that you have fit a single linear model to your data, as in the code below, which uses fake example data. You can replace it with your actual data. | 1 2 3 . | x &lt;- c(34, 9, 78, 60, 22, 45, 83, 59, 25) y &lt;- c(126, 347, 298, 309, 450, 187, 266, 385, 400) model &lt;- lm(y ~ x) . | . We can use R’s confint() function to find the confidence interval for the model coefficients. You can change the level parameter to specify a different confidence level. Note that if you have a multiple regression model, it will make confidence intervals for all of the coefficient values. | 1 . | confint(model, level = 0.95) # or choose any confidence level; here we use 0.95 . | . | 1 2 3 . | 2.5 % 97.5 % (Intercept) 172.638075 535.526421 x -4.491961 2.473935 . | . The 95% confidence interval for the regression coefficient is $[-4.491961, 2.473935]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/#solution-in-r"
  },"215": {
    "doc": "How to compute a confidence interval for a regression coefficient",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/#topics-that-include-this-task"
  },"216": {
    "doc": "How to compute a confidence interval for a regression coefficient",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-regression-coefficient/#opportunities"
  },"217": {
    "doc": "How to compute a confidence interval for a single population variance (in Python, using SciPy)",
    "title": "How to compute a confidence interval for a single population variance (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-python-using-scipy/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-python-using-scipy/"
  },"218": {
    "doc": "How to compute a confidence interval for a single population variance (in Python, using SciPy)",
    "title": "Task",
    "content": "Let’s say we want to compute a confidence interval for the variability of a population. We take a sample of data, $x_1, x_2, x_3, \\ldots, x_k$ and compute its variance, $s^2$. How do we construct a confidence interval for the population variance $\\sigma^2$? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-python-using-scipy/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-python-using-scipy/#task"
  },"219": {
    "doc": "How to compute a confidence interval for a single population variance (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’ll use R’s dataset EuStockMarkets here. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to look at the variability of Germany’s DAX closing prices. For more information on how this is done, see how to quickly load some sample data. You can replace the example data below with your actual data. | 1 2 3 4 5 6 7 . | # Load in EuStockMarkets data from rdatasets import data import pandas as pd df = data('EuStockMarkets') # Select the column for Germany's DAX closing prices sample = df['DAX'] . | . Now that we have our sample data loaded, let’s go ahead and make the confidence interval using SciPy. | 1 2 3 4 5 6 7 8 9 10 11 12 . | from scipy import stats # Find the critical values from the right and left tails of the Chi-square distribution alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) n = len( sample ) left_critical_val = stats.chi2.ppf(1-alpha/2, df=n-1) right_critical_val = stats.chi2.ppf(alpha/2, df=n-1) # Find the upper and lower bounds of the confidence interval and print them out lower_bound = ((n - 1)*sample.var())/left_critical_val upper_bound = ((n - 1)*sample.var())/right_critical_val lower_bound, upper_bound . | . | 1 . | (1104642.2801539514, 1256248.1273200295) . | . Our 95% confidence interval for the standard deviation of Germany’s DAX closing prices is $[1104642, 1256248]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-python-using-scipy/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-python-using-scipy/#solution"
  },"220": {
    "doc": "How to compute a confidence interval for a single population variance (in R)",
    "title": "How to compute a confidence interval for a single population variance (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-r/"
  },"221": {
    "doc": "How to compute a confidence interval for a single population variance (in R)",
    "title": "Task",
    "content": "Let’s say we want to compute a confidence interval for the variability of a population. We take a sample of data, $x_1, x_2, x_3, \\ldots, x_k$ and compute its variance, $s^2$. How do we construct a confidence interval for the population variance $\\sigma^2$? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-r/#task"
  },"222": {
    "doc": "How to compute a confidence interval for a single population variance (in R)",
    "title": "Solution",
    "content": "We’ll use R’s dataset EuStockMarkets here. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to look at the variability of Germany’s DAX closing prices. Feel free to replace this sample data with your actual data if you use this code. | 1 2 3 4 5 6 . | # install.packages(\"datasets\") # if you have not done so already library(datasets) # Load stock market data, convert to DataFrame, and choose the DAX column. EuStockMarkets &lt;- data.frame(EuStockMarkets) sample &lt;- EuStockMarkets$DAX . | . Now that we have our sample data loaded, let’s go ahead and make the confidence interval. | 1 2 3 4 5 6 7 8 9 10 11 . | # Find the critical values from the right and left tails of the Chi-square distribution alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) n &lt;- length(sample) left_critical_val &lt;- qchisq(p = alpha/2, df = n-1, lower.tail=FALSE) right_critical_val &lt;- qchisq(p = 1-alpha/2, df = n-1, lower.tail=FALSE) # Find the upper and lower bounds of the confidence interval and print them out lower_bound &lt;- ((n - 1)*var(sample))/left_critical_val upper_bound &lt;- ((n - 1)*var(sample))/right_critical_val lower_bound upper_bound . | . | 1 2 3 4 5 . | [1] 1104642 [1] 1256248 . | . Our 95% confidence interval for the standard deviation of Germany’s DAX closing prices is $[1104642, 1256248]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance-in-r/#solution"
  },"223": {
    "doc": "How to compute a confidence interval for a single population variance",
    "title": "How to compute a confidence interval for a single population variance",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/"
  },"224": {
    "doc": "How to compute a confidence interval for a single population variance",
    "title": "Description",
    "content": "Let’s say we want to compute a confidence interval for the variability of a population. We take a sample of data, $x_1, x_2, x_3, \\ldots, x_k$ and compute its variance, $s^2$. How do we construct a confidence interval for the population variance $\\sigma^2$? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/#description"
  },"225": {
    "doc": "How to compute a confidence interval for a single population variance",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’ll use R’s dataset EuStockMarkets here. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to look at the variability of Germany’s DAX closing prices. For more information on how this is done, see how to quickly load some sample data. You can replace the example data below with your actual data. | 1 2 3 4 5 6 7 . | # Load in EuStockMarkets data from rdatasets import data import pandas as pd df = data('EuStockMarkets') # Select the column for Germany's DAX closing prices sample = df['DAX'] . | . Now that we have our sample data loaded, let’s go ahead and make the confidence interval using SciPy. | 1 2 3 4 5 6 7 8 9 10 11 12 . | from scipy import stats # Find the critical values from the right and left tails of the Chi-square distribution alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) n = len( sample ) left_critical_val = stats.chi2.ppf(1-alpha/2, df=n-1) right_critical_val = stats.chi2.ppf(alpha/2, df=n-1) # Find the upper and lower bounds of the confidence interval and print them out lower_bound = ((n - 1)*sample.var())/left_critical_val upper_bound = ((n - 1)*sample.var())/right_critical_val lower_bound, upper_bound . | . | 1 . | (1104642.2801539514, 1256248.1273200295) . | . Our 95% confidence interval for the standard deviation of Germany’s DAX closing prices is $[1104642, 1256248]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/#using-scipy-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/#using-scipy-in-python"
  },"226": {
    "doc": "How to compute a confidence interval for a single population variance",
    "title": "Solution, in R",
    "content": "View this solution alone. We’ll use R’s dataset EuStockMarkets here. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to look at the variability of Germany’s DAX closing prices. Feel free to replace this sample data with your actual data if you use this code. | 1 2 3 4 5 6 . | # install.packages(\"datasets\") # if you have not done so already library(datasets) # Load stock market data, convert to DataFrame, and choose the DAX column. EuStockMarkets &lt;- data.frame(EuStockMarkets) sample &lt;- EuStockMarkets$DAX . | . Now that we have our sample data loaded, let’s go ahead and make the confidence interval. | 1 2 3 4 5 6 7 8 9 10 11 . | # Find the critical values from the right and left tails of the Chi-square distribution alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) n &lt;- length(sample) left_critical_val &lt;- qchisq(p = alpha/2, df = n-1, lower.tail=FALSE) right_critical_val &lt;- qchisq(p = 1-alpha/2, df = n-1, lower.tail=FALSE) # Find the upper and lower bounds of the confidence interval and print them out lower_bound &lt;- ((n - 1)*var(sample))/left_critical_val upper_bound &lt;- ((n - 1)*var(sample))/right_critical_val lower_bound upper_bound . | . | 1 2 3 4 5 . | [1] 1104642 [1] 1256248 . | . Our 95% confidence interval for the standard deviation of Germany’s DAX closing prices is $[1104642, 1256248]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/#solution-in-r"
  },"227": {
    "doc": "How to compute a confidence interval for a single population variance",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/#topics-that-include-this-task"
  },"228": {
    "doc": "How to compute a confidence interval for a single population variance",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-a-single-population-variance/#opportunities"
  },"229": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known (in Python, using NumPy and SciPy)",
    "title": "How to compute a confidence interval for the difference between two means when both population variances are known (in Python, using NumPy and SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-python-using-numpy-and-scipy/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-python-using-numpy-and-scipy/"
  },"230": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known (in Python, using NumPy and SciPy)",
    "title": "Task",
    "content": "If we have samples from two independent populations, and both of the population variances are known, how do we construct a confidence interval for the difference between the population means? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-python-using-numpy-and-scipy/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-python-using-numpy-and-scipy/#task"
  },"231": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known (in Python, using NumPy and SciPy)",
    "title": "Solution",
    "content": "We’re going to use some fake data here to illustrate how to make the confidence interval. Replace our fake data and population variances with your actual data and population variances if you use this code. | 1 2 3 4 . | sample1 = [15, 10, 7, 22, 17, 14] sample2 = [9, 1, 11, 13, 3, 6] pop1_variance = 2.3 pop2_variance = 3 . | . We will need the size and mean of each sample. | 1 2 3 4 5 . | import numpy as np n_sample1 = len(sample1) n_sample2 = len(sample2) xbar1 = np.mean(sample1) xbar2 = np.mean(sample2) . | . We can then use that data to create the confidence interval. | 1 2 3 4 5 6 7 8 9 10 11 . | # Find the critical value from the normal distribution from scipy import stats alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) critical_val = stats.norm.ppf(1-alpha/2) # Find the lower and upper bounds of the confidence interval upper_bound = (xbar1 - xbar2) + \\ critical_val*np.sqrt((pop1_variance/n_sample1) + (pop2_variance/n_sample2)) lower_bound = (xbar1 - xbar2) - \\ critical_val*np.sqrt((pop1_variance/n_sample1) + (pop2_variance/n_sample2)) lower_bound, upper_bound . | . | 1 . | (5.15791188458682, 8.842088115413178) . | . Our 95% confidence interval for the true difference between the population means is $[5.1579, 8.842]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-python-using-numpy-and-scipy/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-python-using-numpy-and-scipy/#solution"
  },"232": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known (in R)",
    "title": "How to compute a confidence interval for the difference between two means when both population variances are known (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-r/"
  },"233": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known (in R)",
    "title": "Task",
    "content": "If we have samples from two independent populations, and both of the population variances are known, how do we construct a confidence interval for the difference between the population means? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-r/#task"
  },"234": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known (in R)",
    "title": "Solution",
    "content": "We’re going to use some fake data here to illustrate how to make the confidence interval. Replace our fake data and population variances with your actual data and population variances if you use this code. | 1 2 3 4 . | sample.1 &lt;- c(15, 10, 7, 22, 17, 14) sample.2 &lt;- c(9, 1, 11, 13, 3, 6) pop1.variance &lt;- 2.3 pop2.variance &lt;- 3 . | . We will need the size and mean of each sample. | 1 2 3 4 . | n.sample1 &lt;- length(sample.1) n.sample2 &lt;- length(sample.2) xbar1 &lt;- mean(sample.1) xbar2 &lt;- mean(sample.2) . | . We can then use that data to create the confidence interval. | 1 2 3 4 5 6 7 8 9 10 . | # Find the critical value from the normal distribution alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) critical.val &lt;- qnorm(p=alpha/2, lower.tail=FALSE) # Find the lower and upper bounds of the confidence interval radius &lt;- critical.val*sqrt(pop1.variance/n.sample1 + pop2.variance/n.sample2) upper.bound &lt;- (xbar1 - xbar2) + radius lower.bound &lt;- (xbar1 - xbar2) - radius lower.bound upper.bound . | . | 1 2 3 4 5 . | [1] 5.157912 [1] 8.842088 . | . Our 95% confidence interval for the true difference between the population means is $[5.1579, 8.842]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known-in-r/#solution"
  },"235": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known",
    "title": "How to compute a confidence interval for the difference between two means when both population variances are known",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/"
  },"236": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known",
    "title": "Description",
    "content": "If we have samples from two independent populations, and both of the population variances are known, how do we construct a confidence interval for the difference between the population means? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/#description"
  },"237": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known",
    "title": "Using NumPy and SciPy, in Python",
    "content": "View this solution alone. We’re going to use some fake data here to illustrate how to make the confidence interval. Replace our fake data and population variances with your actual data and population variances if you use this code. | 1 2 3 4 . | sample1 = [15, 10, 7, 22, 17, 14] sample2 = [9, 1, 11, 13, 3, 6] pop1_variance = 2.3 pop2_variance = 3 . | . We will need the size and mean of each sample. | 1 2 3 4 5 . | import numpy as np n_sample1 = len(sample1) n_sample2 = len(sample2) xbar1 = np.mean(sample1) xbar2 = np.mean(sample2) . | . We can then use that data to create the confidence interval. | 1 2 3 4 5 6 7 8 9 10 11 . | # Find the critical value from the normal distribution from scipy import stats alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) critical_val = stats.norm.ppf(1-alpha/2) # Find the lower and upper bounds of the confidence interval upper_bound = (xbar1 - xbar2) + \\ critical_val*np.sqrt((pop1_variance/n_sample1) + (pop2_variance/n_sample2)) lower_bound = (xbar1 - xbar2) - \\ critical_val*np.sqrt((pop1_variance/n_sample1) + (pop2_variance/n_sample2)) lower_bound, upper_bound . | . | 1 . | (5.15791188458682, 8.842088115413178) . | . Our 95% confidence interval for the true difference between the population means is $[5.1579, 8.842]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/#using-numpy-and-scipy-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/#using-numpy-and-scipy-in-python"
  },"238": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use some fake data here to illustrate how to make the confidence interval. Replace our fake data and population variances with your actual data and population variances if you use this code. | 1 2 3 4 . | sample.1 &lt;- c(15, 10, 7, 22, 17, 14) sample.2 &lt;- c(9, 1, 11, 13, 3, 6) pop1.variance &lt;- 2.3 pop2.variance &lt;- 3 . | . We will need the size and mean of each sample. | 1 2 3 4 . | n.sample1 &lt;- length(sample.1) n.sample2 &lt;- length(sample.2) xbar1 &lt;- mean(sample.1) xbar2 &lt;- mean(sample.2) . | . We can then use that data to create the confidence interval. | 1 2 3 4 5 6 7 8 9 10 . | # Find the critical value from the normal distribution alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) critical.val &lt;- qnorm(p=alpha/2, lower.tail=FALSE) # Find the lower and upper bounds of the confidence interval radius &lt;- critical.val*sqrt(pop1.variance/n.sample1 + pop2.variance/n.sample2) upper.bound &lt;- (xbar1 - xbar2) + radius lower.bound &lt;- (xbar1 - xbar2) - radius lower.bound upper.bound . | . | 1 2 3 4 5 . | [1] 5.157912 [1] 8.842088 . | . Our 95% confidence interval for the true difference between the population means is $[5.1579, 8.842]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/#solution-in-r"
  },"239": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/#topics-that-include-this-task"
  },"240": {
    "doc": "How to compute a confidence interval for the difference between two means when both population variances are known",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-both-population-variances-are-known/#opportunities"
  },"241": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown (in Python, using NumPy and SciPy)",
    "title": "How to compute a confidence interval for the difference between two means when population variances are unknown (in Python, using NumPy and SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-python-using-numpy-and-scipy/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-python-using-numpy-and-scipy/"
  },"242": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown (in Python, using NumPy and SciPy)",
    "title": "Task",
    "content": "If we have samples from two independent populations and both of the population variances are unknown, how do we compute a confidence interval for the difference between the population means? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-python-using-numpy-and-scipy/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-python-using-numpy-and-scipy/#task"
  },"243": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown (in Python, using NumPy and SciPy)",
    "title": "Solution",
    "content": "We’re going to use some fake data here to illustrate how to make the confidence interval. Replace our fake data with your actual data if you use this code. | 1 2 . | sample1 = [15, 10, 7, 22, 17, 14] sample2 = [9, 1, 11, 13, 3, 6] . | . We will need the sizes, means, and variances of each sample. | 1 2 3 4 5 6 7 . | import numpy as np n_sample1 = len(sample1) n_sample2 = len(sample2) xbar1 = np.mean(sample1) xbar2 = np.mean(sample2) var_sample1 = np.var(sample1, ddof = 1) var_sample2 = np.var(sample2, ddof = 1) . | . Before we can compute the confidence interval, we must ask, can we assume that the two population variances are equal? . IF YES: We compute the degrees of freedom and the radius of the confidence interval as follows. | 1 2 3 . | df = n_sample1 + n_sample2 - 2 pooled_var = ((n_sample1-1)*var_sample1 + (n_sample2-1)*var_sample2) / df radius = pooled_var*(1/n_sample1 + 1/n_sample2) . | . IF NO: We replace the above code with the following code instead, which does not make the assumption that the population variances are equal. | 1 2 3 4 . | # ratio1 = var_sample1/n_sample1 # ratio2 = var_sample2/n_sample2 # df = (ratio1 + ratio2)**2 / (ratio1**2/(n_sample1-1) + ratio2**2/(n_sample2-1)) # radius = ratio1 + ratio2 . | . Then, whichever of the two methods above was used, we compute the confidence interval as follows. | 1 2 3 4 5 6 7 8 9 10 . | from scipy import stats # Find the critical value from the normal distribution alpha = 0.05 critical_val = stats.t.ppf(q = 1-alpha/2, df = df) # Find the lower and upper bound of the confidence interval upper_bound = (xbar1 - xbar2) + critical_val*np.sqrt(radius) lower_bound = (xbar1 - xbar2) - critical_val*np.sqrt(radius) lower_bound, upper_bound . | . | 1 . | (0.5980039236697818, 13.401996076330217) . | . The 95% confidence interval for the true difference between these population means is $[0.598,13.402]$. That was computed under the assumption that the variances were equal. See the alternative code above for if the variances were not assumed to be equal; in that case, we would get the slightly different result of $[0.5852, 13.4147]$ instead. Content last modified on 07 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-python-using-numpy-and-scipy/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-python-using-numpy-and-scipy/#solution"
  },"244": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown (in R)",
    "title": "How to compute a confidence interval for the difference between two means when population variances are unknown (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-r/"
  },"245": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown (in R)",
    "title": "Task",
    "content": "If we have samples from two independent populations and both of the population variances are unknown, how do we compute a confidence interval for the difference between the population means? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-r/#task"
  },"246": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown (in R)",
    "title": "Solution",
    "content": "We’re going to use some fake data here to illustrate how to make the confidence interval. Replace our fake data with your actual data if you use this code. | 1 2 . | sample.1 &lt;- c(15, 10, 7, 22, 17, 14) sample.2 &lt;- c(9, 1, 11, 13, 3, 6) . | . In the example below, we specify var.equal = FALSE to indicate that we cannot assume that the variances are equal. If you know them to be equal in your situation, replace FALSE with TRUE. | 1 2 3 4 5 6 7 8 . | alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) conf.interval &lt;- t.test(sample.1, sample.2, var.equal = FALSE, conf.level = 1-alpha) # If you need the upper and lower bounds later, store them in variables like this: lower.bound &lt;- conf.interval$conf.int[1] upper.bound &lt;- conf.interval$conf.int[2] # Print out the lower and upper bounds lower.bound upper.bound . | . | 1 2 3 4 5 . | [1] 0.5852484 [1] 13.41475 . | . Our 95% confidence interval for the true difference between these population means is $[0.5852, 13.4147]$. You can also see the test statistic and $p$-value by inspecting the result of the t.test function we ran above. | 1 . | conf.interval . | . | 1 2 3 4 5 6 7 8 9 10 . | Welch Two Sample t-test data: sample.1 and sample.2 t = 2.4363, df = 9.8554, p-value = 0.0354 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 0.5852484 13.4147516 sample estimates: mean of x mean of y 14.166667 7.166667 . | . Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown-in-r/#solution"
  },"247": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown",
    "title": "How to compute a confidence interval for the difference between two means when population variances are unknown",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/"
  },"248": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown",
    "title": "Description",
    "content": "If we have samples from two independent populations and both of the population variances are unknown, how do we compute a confidence interval for the difference between the population means? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/#description"
  },"249": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown",
    "title": "Using NumPy and SciPy, in Python",
    "content": "View this solution alone. We’re going to use some fake data here to illustrate how to make the confidence interval. Replace our fake data with your actual data if you use this code. | 1 2 . | sample1 = [15, 10, 7, 22, 17, 14] sample2 = [9, 1, 11, 13, 3, 6] . | . We will need the sizes, means, and variances of each sample. | 1 2 3 4 5 6 7 . | import numpy as np n_sample1 = len(sample1) n_sample2 = len(sample2) xbar1 = np.mean(sample1) xbar2 = np.mean(sample2) var_sample1 = np.var(sample1, ddof = 1) var_sample2 = np.var(sample2, ddof = 1) . | . Before we can compute the confidence interval, we must ask, can we assume that the two population variances are equal? . IF YES: We compute the degrees of freedom and the radius of the confidence interval as follows. | 1 2 3 . | df = n_sample1 + n_sample2 - 2 pooled_var = ((n_sample1-1)*var_sample1 + (n_sample2-1)*var_sample2) / df radius = pooled_var*(1/n_sample1 + 1/n_sample2) . | . IF NO: We replace the above code with the following code instead, which does not make the assumption that the population variances are equal. | 1 2 3 4 . | # ratio1 = var_sample1/n_sample1 # ratio2 = var_sample2/n_sample2 # df = (ratio1 + ratio2)**2 / (ratio1**2/(n_sample1-1) + ratio2**2/(n_sample2-1)) # radius = ratio1 + ratio2 . | . Then, whichever of the two methods above was used, we compute the confidence interval as follows. | 1 2 3 4 5 6 7 8 9 10 . | from scipy import stats # Find the critical value from the normal distribution alpha = 0.05 critical_val = stats.t.ppf(q = 1-alpha/2, df = df) # Find the lower and upper bound of the confidence interval upper_bound = (xbar1 - xbar2) + critical_val*np.sqrt(radius) lower_bound = (xbar1 - xbar2) - critical_val*np.sqrt(radius) lower_bound, upper_bound . | . | 1 . | (0.5980039236697818, 13.401996076330217) . | . The 95% confidence interval for the true difference between these population means is $[0.598,13.402]$. That was computed under the assumption that the variances were equal. See the alternative code above for if the variances were not assumed to be equal; in that case, we would get the slightly different result of $[0.5852, 13.4147]$ instead. Content last modified on 07 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/#using-numpy-and-scipy-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/#using-numpy-and-scipy-in-python"
  },"250": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use some fake data here to illustrate how to make the confidence interval. Replace our fake data with your actual data if you use this code. | 1 2 . | sample.1 &lt;- c(15, 10, 7, 22, 17, 14) sample.2 &lt;- c(9, 1, 11, 13, 3, 6) . | . In the example below, we specify var.equal = FALSE to indicate that we cannot assume that the variances are equal. If you know them to be equal in your situation, replace FALSE with TRUE. | 1 2 3 4 5 6 7 8 . | alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) conf.interval &lt;- t.test(sample.1, sample.2, var.equal = FALSE, conf.level = 1-alpha) # If you need the upper and lower bounds later, store them in variables like this: lower.bound &lt;- conf.interval$conf.int[1] upper.bound &lt;- conf.interval$conf.int[2] # Print out the lower and upper bounds lower.bound upper.bound . | . | 1 2 3 4 5 . | [1] 0.5852484 [1] 13.41475 . | . Our 95% confidence interval for the true difference between these population means is $[0.5852, 13.4147]$. You can also see the test statistic and $p$-value by inspecting the result of the t.test function we ran above. | 1 . | conf.interval . | . | 1 2 3 4 5 6 7 8 9 10 . | Welch Two Sample t-test data: sample.1 and sample.2 t = 2.4363, df = 9.8554, p-value = 0.0354 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 0.5852484 13.4147516 sample estimates: mean of x mean of y 14.166667 7.166667 . | . Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/#solution-in-r"
  },"251": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/#topics-that-include-this-task"
  },"252": {
    "doc": "How to compute a confidence interval for the difference between two means when population variances are unknown",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-means-when-population-variances-are-unknown/#opportunities"
  },"253": {
    "doc": "How to compute a confidence interval for the difference between two proportions (in Python, using SciPy)",
    "title": "How to compute a confidence interval for the difference between two proportions (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-python-using-scipy/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-python-using-scipy/"
  },"254": {
    "doc": "How to compute a confidence interval for the difference between two proportions (in Python, using SciPy)",
    "title": "Task",
    "content": "When dealing with qualitative data, we often want to construct a confidence interval for the difference between two population proportions. For example, if we are trying a drug on experimental and control groups of patients, we probably want to compare the proportion of patients who got well in one group versus the other. How do we make such a comparison using a confidence interval? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-python-using-scipy/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-python-using-scipy/#task"
  },"255": {
    "doc": "How to compute a confidence interval for the difference between two proportions (in Python, using SciPy)",
    "title": "Solution",
    "content": "Here is some fake data for the purposes of this illustration. Let’s say we conduct a survey of people in Boston and of people in Nashville and ask them if they prefer chocolate or vanilla ice cream. We want to compare the proportions of people from the two cities who like vanilla. | Out of 150 people in Boston surveyed, 90 prefer vanilla. | Out of 135 people in Nashville surveyed, 50 prefer vanilla. | . We’ll let $\\bar{p_1}$ represent the proportion of people from Boston who like vanilla and $\\bar{p_2}$ represent the proportion of people from Nashville who like vanilla. You can replace the code for this fake data below with your real data. | 1 2 3 4 5 6 . | # number of observations in the samples n1 = 150 n2 = 135 # proportions in the two samples p_bar1 = 90/150 p_bar2 = 50/135 . | . We now compute the confidence interval using tools from SciPy and NumPy. | 1 2 3 4 5 6 7 8 9 10 11 12 13 . | # Find the critical value to compute the confidence interval from scipy import stats alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) critical_value = stats.norm.ppf(1-alpha/2) # Compute the standard error of the proportions import numpy as np std_error = np.sqrt( p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2 ) # Compute the upper and lower bounds of the confidence interval upper_bound = (p_bar1 - p_bar2) + critical_value*std_error lower_bound = (p_bar1 - p_bar2) - critical_value*std_error lower_bound, upper_bound . | . | 1 . | (0.11657216971616415, 0.3426870895430951) . | . The confidence interval for the difference between these two proportions is $[0.11657, 0.34269]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-python-using-scipy/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-python-using-scipy/#solution"
  },"256": {
    "doc": "How to compute a confidence interval for the difference between two proportions (in R)",
    "title": "How to compute a confidence interval for the difference between two proportions (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-r/"
  },"257": {
    "doc": "How to compute a confidence interval for the difference between two proportions (in R)",
    "title": "Task",
    "content": "When dealing with qualitative data, we often want to construct a confidence interval for the difference between two population proportions. For example, if we are trying a drug on experimental and control groups of patients, we probably want to compare the proportion of patients who got well in one group versus the other. How do we make such a comparison using a confidence interval? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-r/#task"
  },"258": {
    "doc": "How to compute a confidence interval for the difference between two proportions (in R)",
    "title": "Solution",
    "content": "Here is some fake data for the purposes of this illustration. Let’s say we conduct a survey of people in Boston and of people in Nashville and ask them if they prefer chocolate or vanilla ice cream. We want to compare the proportions of people from the two cities who like vanilla. | Out of 150 people in Boston surveyed, 90 prefer vanilla. | Out of 135 people in Nashville surveyed, 50 prefer vanilla. | . We’ll let $\\bar{p_1}$ represent the proportion of people from Boston who like vanilla and $\\bar{p_2}$ represent the proportion of people from Nashville who like vanilla. You can replace the code for this fake data below with your real data. | 1 2 3 4 5 6 . | # number of observations in the samples n1 &lt;- 150 n2 &lt;- 135 # proportions in the two samples p_bar1 &lt;- 90/150 p_bar2 &lt;- 50/135 . | . We now compute the confidence interval using R’s qnorm function. | 1 2 3 4 5 6 7 8 9 10 11 12 . | # Find the critical value to compute the confidence interval alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) critical_value &lt;- qnorm(p = alpha/2, lower.tail=FALSE) # Compute the standard error of the proportions std_error &lt;- sqrt( p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2 ) # Compute the upper and lower bounds of the confidence interval and print them out upper_bound &lt;- (p_bar1 - p_bar2) + critical_value*std_error lower_bound &lt;- (p_bar1 - p_bar2) - critical_value*std_error lower_bound upper_bound . | . | 1 2 3 4 5 . | [1] 0.1165722 [1] 0.3426871 . | . The confidence interval for the difference between these two proportions is $[0.11657, 0.34269]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions-in-r/#solution"
  },"259": {
    "doc": "How to compute a confidence interval for the difference between two proportions",
    "title": "How to compute a confidence interval for the difference between two proportions",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/"
  },"260": {
    "doc": "How to compute a confidence interval for the difference between two proportions",
    "title": "Description",
    "content": "When dealing with qualitative data, we often want to construct a confidence interval for the difference between two population proportions. For example, if we are trying a drug on experimental and control groups of patients, we probably want to compare the proportion of patients who got well in one group versus the other. How do we make such a comparison using a confidence interval? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/#description"
  },"261": {
    "doc": "How to compute a confidence interval for the difference between two proportions",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. Here is some fake data for the purposes of this illustration. Let’s say we conduct a survey of people in Boston and of people in Nashville and ask them if they prefer chocolate or vanilla ice cream. We want to compare the proportions of people from the two cities who like vanilla. | Out of 150 people in Boston surveyed, 90 prefer vanilla. | Out of 135 people in Nashville surveyed, 50 prefer vanilla. | . We’ll let $\\bar{p_1}$ represent the proportion of people from Boston who like vanilla and $\\bar{p_2}$ represent the proportion of people from Nashville who like vanilla. You can replace the code for this fake data below with your real data. | 1 2 3 4 5 6 . | # number of observations in the samples n1 = 150 n2 = 135 # proportions in the two samples p_bar1 = 90/150 p_bar2 = 50/135 . | . We now compute the confidence interval using tools from SciPy and NumPy. | 1 2 3 4 5 6 7 8 9 10 11 12 13 . | # Find the critical value to compute the confidence interval from scipy import stats alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) critical_value = stats.norm.ppf(1-alpha/2) # Compute the standard error of the proportions import numpy as np std_error = np.sqrt( p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2 ) # Compute the upper and lower bounds of the confidence interval upper_bound = (p_bar1 - p_bar2) + critical_value*std_error lower_bound = (p_bar1 - p_bar2) - critical_value*std_error lower_bound, upper_bound . | . | 1 . | (0.11657216971616415, 0.3426870895430951) . | . The confidence interval for the difference between these two proportions is $[0.11657, 0.34269]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/#using-scipy-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/#using-scipy-in-python"
  },"262": {
    "doc": "How to compute a confidence interval for the difference between two proportions",
    "title": "Solution, in R",
    "content": "View this solution alone. Here is some fake data for the purposes of this illustration. Let’s say we conduct a survey of people in Boston and of people in Nashville and ask them if they prefer chocolate or vanilla ice cream. We want to compare the proportions of people from the two cities who like vanilla. | Out of 150 people in Boston surveyed, 90 prefer vanilla. | Out of 135 people in Nashville surveyed, 50 prefer vanilla. | . We’ll let $\\bar{p_1}$ represent the proportion of people from Boston who like vanilla and $\\bar{p_2}$ represent the proportion of people from Nashville who like vanilla. You can replace the code for this fake data below with your real data. | 1 2 3 4 5 6 . | # number of observations in the samples n1 &lt;- 150 n2 &lt;- 135 # proportions in the two samples p_bar1 &lt;- 90/150 p_bar2 &lt;- 50/135 . | . We now compute the confidence interval using R’s qnorm function. | 1 2 3 4 5 6 7 8 9 10 11 12 . | # Find the critical value to compute the confidence interval alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) critical_value &lt;- qnorm(p = alpha/2, lower.tail=FALSE) # Compute the standard error of the proportions std_error &lt;- sqrt( p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2 ) # Compute the upper and lower bounds of the confidence interval and print them out upper_bound &lt;- (p_bar1 - p_bar2) + critical_value*std_error lower_bound &lt;- (p_bar1 - p_bar2) - critical_value*std_error lower_bound upper_bound . | . | 1 2 3 4 5 . | [1] 0.1165722 [1] 0.3426871 . | . The confidence interval for the difference between these two proportions is $[0.11657, 0.34269]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/#solution-in-r"
  },"263": {
    "doc": "How to compute a confidence interval for the difference between two proportions",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/#topics-that-include-this-task"
  },"264": {
    "doc": "How to compute a confidence interval for the difference between two proportions",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-difference-between-two-proportions/#opportunities"
  },"265": {
    "doc": "How to compute a confidence interval for the expected value of a response variable (in Python, using statsmodels and sklearn)",
    "title": "How to compute a confidence interval for the expected value of a response variable (in Python, using statsmodels and sklearn)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-python-using-statsmodels-and-sklearn/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-python-using-statsmodels-and-sklearn/"
  },"266": {
    "doc": "How to compute a confidence interval for the expected value of a response variable (in Python, using statsmodels and sklearn)",
    "title": "Task",
    "content": "If we have a simple linear regression model, $y = \\beta_0 + \\beta_1x + \\epsilon$, where $\\epsilon$ is some random error, then given any $x$ input, $y$ can be veiwed as a random variable because of $\\epsilon$. Let’s consider its expected value. How do we construct a confidence interval for that expected value, given a value for the predictor $x$? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-python-using-statsmodels-and-sklearn/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-python-using-statsmodels-and-sklearn/#task"
  },"267": {
    "doc": "How to compute a confidence interval for the expected value of a response variable (in Python, using statsmodels and sklearn)",
    "title": "Solution",
    "content": "Let’s assume that you already have a linear model. We construct an example one here from some fabricated data. For a review of how this preparatory code works, see how to fit a linear model to two columns of data. | 1 2 3 4 5 6 7 8 9 . | import statsmodels.api as sm # Replace the following fake data with your actual data: xs = [ 34, 9, 78, 60, 22, 45, 83, 59, 25 ] ys = [ 126, 347, 298, 309, 450, 187, 266, 385, 400 ] # Create and fit a linear model to the data: xs = sm.add_constant( xs ) model = sm.OLS( ys, xs ).fit() . | . Ask the model to do a prediction of one particular input, in this example $x=40$, with a $95\\%$ confidence interval included ($\\alpha=0.05$). You can replce the $40$ with your chosen $x$ value, or an array of them, and you can replace the $0.05$ with your chosen value of $\\alpha$. (The extra 1 in the input to get_prediction is a placeholder, required because the model has been expanded to include a constant term.) . | 1 . | model.get_prediction( [1,40] ).summary_frame( alpha=0.05 ) . | . | | mean | mean_se | mean_ci_lower | mean_ci_upper | obs_ci_lower | obs_ci_upper | . | 0 | 313.721744 | 36.823483 | 226.648043 | 400.795444 | 45.876725 | 581.566762 | . Our 95% confidence interval is $[226.648, 400.7954]$. We can be 95% confident that the true average value of $y$, given that $x$ is 40, is between 226.648 and 400.7954. Content last modified on 08 November 2022. See a problem? Tell us or edit the source. Contributed by: . | Ni Shi (shi_ni@bentley.edu) | Nathan Carter (ncarter@bentley.edu) | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-python-using-statsmodels-and-sklearn/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-python-using-statsmodels-and-sklearn/#solution"
  },"268": {
    "doc": "How to compute a confidence interval for the expected value of a response variable (in R)",
    "title": "How to compute a confidence interval for the expected value of a response variable (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-r/"
  },"269": {
    "doc": "How to compute a confidence interval for the expected value of a response variable (in R)",
    "title": "Task",
    "content": "If we have a simple linear regression model, $y = \\beta_0 + \\beta_1x + \\epsilon$, where $\\epsilon$ is some random error, then given any $x$ input, $y$ can be veiwed as a random variable because of $\\epsilon$. Let’s consider its expected value. How do we construct a confidence interval for that expected value, given a value for the predictor $x$? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-r/#task"
  },"270": {
    "doc": "How to compute a confidence interval for the expected value of a response variable (in R)",
    "title": "Solution",
    "content": "Let’s assume that you already have a linear model. We construct an example one here from some fabricated data. | 1 2 3 4 . | # Make the linear model x &lt;- c(34, 9, 78, 60, 22, 45, 83, 59, 25) y &lt;- c(126, 347, 298, 309, 450, 187, 266, 385, 400) model &lt;- lm(y ~ x) . | . Construct a data frame containing just one entry, the value of the independent variable for which you want to compute the confidence interval. That data frame can then be passed to R’s predict function to get a confidence interval for the expected value of $y$. | 1 2 3 4 . | # Use your chosen value of x below: data &lt;- data.frame(x=40) # Compute the confidence interval for y: predict(model, data, interval=\"confidence\", level=0.95) # or choose a different confidence level; here we use 0.95 . | . | 1 2 . | fit lwr upr 1 313.7217 226.648 400.7954 . | . Our 95% confidence interval is $[226.648, 400.7954]$. We can be 95% confident that the true average value of $y$, given that $x$ is 40, is between 226.648 and 400.7954. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable-in-r/#solution"
  },"271": {
    "doc": "How to compute a confidence interval for the expected value of a response variable",
    "title": "How to compute a confidence interval for the expected value of a response variable",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/"
  },"272": {
    "doc": "How to compute a confidence interval for the expected value of a response variable",
    "title": "Description",
    "content": "If we have a simple linear regression model, $y = \\beta_0 + \\beta_1x + \\epsilon$, where $\\epsilon$ is some random error, then given any $x$ input, $y$ can be veiwed as a random variable because of $\\epsilon$. Let’s consider its expected value. How do we construct a confidence interval for that expected value, given a value for the predictor $x$? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the population proportion | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/#description"
  },"273": {
    "doc": "How to compute a confidence interval for the expected value of a response variable",
    "title": "Using statsmodels and sklearn, in Python",
    "content": "View this solution alone. Let’s assume that you already have a linear model. We construct an example one here from some fabricated data. For a review of how this preparatory code works, see how to fit a linear model to two columns of data. | 1 2 3 4 5 6 7 8 9 . | import statsmodels.api as sm # Replace the following fake data with your actual data: xs = [ 34, 9, 78, 60, 22, 45, 83, 59, 25 ] ys = [ 126, 347, 298, 309, 450, 187, 266, 385, 400 ] # Create and fit a linear model to the data: xs = sm.add_constant( xs ) model = sm.OLS( ys, xs ).fit() . | . Ask the model to do a prediction of one particular input, in this example $x=40$, with a $95\\%$ confidence interval included ($\\alpha=0.05$). You can replce the $40$ with your chosen $x$ value, or an array of them, and you can replace the $0.05$ with your chosen value of $\\alpha$. (The extra 1 in the input to get_prediction is a placeholder, required because the model has been expanded to include a constant term.) . | 1 . | model.get_prediction( [1,40] ).summary_frame( alpha=0.05 ) . | . | | mean | mean_se | mean_ci_lower | mean_ci_upper | obs_ci_lower | obs_ci_upper | . | 0 | 313.721744 | 36.823483 | 226.648043 | 400.795444 | 45.876725 | 581.566762 | . Our 95% confidence interval is $[226.648, 400.7954]$. We can be 95% confident that the true average value of $y$, given that $x$ is 40, is between 226.648 and 400.7954. Content last modified on 08 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/#using-statsmodels-and-sklearn-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/#using-statsmodels-and-sklearn-in-python"
  },"274": {
    "doc": "How to compute a confidence interval for the expected value of a response variable",
    "title": "Solution, in R",
    "content": "View this solution alone. Let’s assume that you already have a linear model. We construct an example one here from some fabricated data. | 1 2 3 4 . | # Make the linear model x &lt;- c(34, 9, 78, 60, 22, 45, 83, 59, 25) y &lt;- c(126, 347, 298, 309, 450, 187, 266, 385, 400) model &lt;- lm(y ~ x) . | . Construct a data frame containing just one entry, the value of the independent variable for which you want to compute the confidence interval. That data frame can then be passed to R’s predict function to get a confidence interval for the expected value of $y$. | 1 2 3 4 . | # Use your chosen value of x below: data &lt;- data.frame(x=40) # Compute the confidence interval for y: predict(model, data, interval=\"confidence\", level=0.95) # or choose a different confidence level; here we use 0.95 . | . | 1 2 . | fit lwr upr 1 313.7217 226.648 400.7954 . | . Our 95% confidence interval is $[226.648, 400.7954]$. We can be 95% confident that the true average value of $y$, given that $x$ is 40, is between 226.648 and 400.7954. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/#solution-in-r"
  },"275": {
    "doc": "How to compute a confidence interval for the expected value of a response variable",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | Bentley University MA252 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/#topics-that-include-this-task"
  },"276": {
    "doc": "How to compute a confidence interval for the expected value of a response variable",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-expected-value-of-a-response-variable/#opportunities"
  },"277": {
    "doc": "How to compute a confidence interval for the population proportion (in Python, using SciPy)",
    "title": "How to compute a confidence interval for the population proportion (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-python-using-scipy/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-python-using-scipy/"
  },"278": {
    "doc": "How to compute a confidence interval for the population proportion (in Python, using SciPy)",
    "title": "Task",
    "content": "If we have a sample of qualitative data from a normally distributed population, then how do we compute a confidence interval for a population proportion? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-python-using-scipy/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-python-using-scipy/#task"
  },"279": {
    "doc": "How to compute a confidence interval for the population proportion (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’re going to use some fake data here for illustrative purposes, but you can replace our fake data with your real data in the code below. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 . | # Replace the next two lines of code with your real data sample_size = 30 sample_proportion = .39 # Find the margin of error from scipy import stats import numpy as np alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) moe = stats.norm.ppf(1-alpha/2) * np.sqrt(sample_proportion*(1-sample_proportion)/sample_size) # Find the confidence interval lower_bound = sample_proportion - moe upper_bound = sample_proportion + moe lower_bound, upper_bound . | . | 1 . | (0.21546413420702207, 0.564535865792978) . | . Our 95% confidence interval is $[0.2155, 0.5645]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-python-using-scipy/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-python-using-scipy/#solution"
  },"280": {
    "doc": "How to compute a confidence interval for the population proportion (in R)",
    "title": "How to compute a confidence interval for the population proportion (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-r/"
  },"281": {
    "doc": "How to compute a confidence interval for the population proportion (in R)",
    "title": "Task",
    "content": "If we have a sample of qualitative data from a normally distributed population, then how do we compute a confidence interval for a population proportion? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-r/#task"
  },"282": {
    "doc": "How to compute a confidence interval for the population proportion (in R)",
    "title": "Solution",
    "content": "We’re going to use some fake data here for illustrative purposes, but you can replace our fake data with your real data in the code below. | 1 2 3 4 5 6 7 8 9 10 11 12 13 . | # Replace the next two lines of code with your real data sample_size = 30 sample_proportion = 0.39 # Find the margin of error alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) moe &lt;- qnorm(1-alpha/2, 0, 1) * sqrt(sample_proportion*(1-sample_proportion)/sample_size) # Find the confidence interval upper_bound &lt;- sample_proportion + moe lower_bound &lt;- sample_proportion - moe lower_bound upper_bound . | . | 1 2 3 4 5 . | [1] 0.2154641 [1] 0.5645359 . | . Our 95% confidence interval is $[0.2155, 0.5645]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion-in-r/#solution"
  },"283": {
    "doc": "How to compute a confidence interval for the population proportion",
    "title": "How to compute a confidence interval for the population proportion",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion/"
  },"284": {
    "doc": "How to compute a confidence interval for the population proportion",
    "title": "Description",
    "content": "If we have a sample of qualitative data from a normally distributed population, then how do we compute a confidence interval for a population proportion? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the ratio of two population variances | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion/#description"
  },"285": {
    "doc": "How to compute a confidence interval for the population proportion",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’re going to use some fake data here for illustrative purposes, but you can replace our fake data with your real data in the code below. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 . | # Replace the next two lines of code with your real data sample_size = 30 sample_proportion = .39 # Find the margin of error from scipy import stats import numpy as np alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) moe = stats.norm.ppf(1-alpha/2) * np.sqrt(sample_proportion*(1-sample_proportion)/sample_size) # Find the confidence interval lower_bound = sample_proportion - moe upper_bound = sample_proportion + moe lower_bound, upper_bound . | . | 1 . | (0.21546413420702207, 0.564535865792978) . | . Our 95% confidence interval is $[0.2155, 0.5645]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion/#using-scipy-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion/#using-scipy-in-python"
  },"286": {
    "doc": "How to compute a confidence interval for the population proportion",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use some fake data here for illustrative purposes, but you can replace our fake data with your real data in the code below. | 1 2 3 4 5 6 7 8 9 10 11 12 13 . | # Replace the next two lines of code with your real data sample_size = 30 sample_proportion = 0.39 # Find the margin of error alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) moe &lt;- qnorm(1-alpha/2, 0, 1) * sqrt(sample_proportion*(1-sample_proportion)/sample_size) # Find the confidence interval upper_bound &lt;- sample_proportion + moe lower_bound &lt;- sample_proportion - moe lower_bound upper_bound . | . | 1 2 3 4 5 . | [1] 0.2154641 [1] 0.5645359 . | . Our 95% confidence interval is $[0.2155, 0.5645]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion/#solution-in-r"
  },"287": {
    "doc": "How to compute a confidence interval for the population proportion",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion/#topics-that-include-this-task"
  },"288": {
    "doc": "How to compute a confidence interval for the population proportion",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-population-proportion/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-population-proportion/#opportunities"
  },"289": {
    "doc": "How to compute a confidence interval for the ratio of two population variances (in Python, using SciPy)",
    "title": "How to compute a confidence interval for the ratio of two population variances (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-python-using-scipy/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-python-using-scipy/"
  },"290": {
    "doc": "How to compute a confidence interval for the ratio of two population variances (in Python, using SciPy)",
    "title": "Task",
    "content": "Let’s say we want to compute a confidence interval for two population variances. We take two samples of data, $x_1, x_2, x_3, \\ldots, x_k$ and $x’_1, x’_2, x’_3, \\ldots, x’_k$, and compute their variances, $\\sigma_1^2$ and $\\sigma_2^2$. How do we compute a confidence interval for $\\frac{\\sigma_1^2}{\\sigma_2^2}$? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-python-using-scipy/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-python-using-scipy/#task"
  },"291": {
    "doc": "How to compute a confidence interval for the ratio of two population variances (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’ll use R’s dataset EuStockMarkets as an example; of course you should replace this example data with your actual data when using this code. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to compare the variability of Germany’s DAX and France’s CAC closing prices here. Let’s load in the dataset using the process explained in how to quickly load some sample data. | 1 2 3 4 5 6 7 8 9 10 . | from rdatasets import data import pandas as pd # Load in the EuStockMarkets data and convert to a DataFrame EuStockMarkets = data('EuStockMarkets') df = pd.DataFrame(EuStockMarkets[['DAX', 'CAC']]) # Our two samples are its DAX and CAC columns sample1 = df['DAX'].tolist() sample2 = df['CAC'].tolist() . | . Now that we have our data loaded we can compute the confidence interval. You can change the confidence level by changing the value of $\\alpha$ below. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 . | # The degrees of freedom in each sample is its length minus 1 sample1_df = len(sample1) - 1 sample2_df = len(sample2) - 1 # Compute the ratio of the variances import statistics ratio = statistics.variance(sample1) / statistics.variance(sample2) # Find the critical values from the F-distribution from scipy import stats alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) lower_critical_value = 1 / stats.f.ppf(q = 1 - alpha/2, dfn = sample1_df, dfd = sample2_df) upper_critical_value = stats.f.ppf(q = 1 - alpha/2, dfn = sample2_df, dfd = sample1_df) # Compute the confidence interval lower_bound = ratio * lower_critical_value upper_bound = ratio * upper_critical_value lower_bound, upper_bound . | . | 1 . | (3.190589226470889, 3.827043522824141) . | . The 95% confidence interval for the ratio of the variances for Germany’s DAX and France’s CAC is $[3.191, 3.827]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-python-using-scipy/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-python-using-scipy/#solution"
  },"292": {
    "doc": "How to compute a confidence interval for the ratio of two population variances (in R)",
    "title": "How to compute a confidence interval for the ratio of two population variances (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-r/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-r/"
  },"293": {
    "doc": "How to compute a confidence interval for the ratio of two population variances (in R)",
    "title": "Task",
    "content": "Let’s say we want to compute a confidence interval for two population variances. We take two samples of data, $x_1, x_2, x_3, \\ldots, x_k$ and $x’_1, x’_2, x’_3, \\ldots, x’_k$, and compute their variances, $\\sigma_1^2$ and $\\sigma_2^2$. How do we compute a confidence interval for $\\frac{\\sigma_1^2}{\\sigma_2^2}$? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-r/#task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-r/#task"
  },"294": {
    "doc": "How to compute a confidence interval for the ratio of two population variances (in R)",
    "title": "Solution",
    "content": "We’ll use R’s dataset EuStockMarkets as an example; of course you should replace this example data with your actual data when using this code. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to compare the variability of Germany’s DAX and France’s CAC closing prices here. | 1 2 3 4 5 6 7 8 9 . | # install.packages(\"datasets\") # if you have not done so already library(datasets) # Load in the EuStockMarkets data and convert to a DataFrame EuStockMarkets &lt;- data.frame(EuStockMarkets) # Our two samples are its DAX and CAC columns sample.1 &lt;- EuStockMarkets$DAX sample.2 &lt;- EuStockMarkets$CAC . | . Now that we have our data loaded we can compute the confidence interval. You can change the confidence level by changing the value of $\\alpha$ below. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | # The degrees of freedom in each sample is its length minus 1 df_1 = length(sample.1) - 1 df_2 = length(sample.2) - 1 # Compute the ratio of the variances test.stat.ratio &lt;- var(sample.1)/var(sample.2) # Find the critical values from the F-distribution alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) lower_critical_value &lt;- 1 / qf(p = alpha/2, df1 = df_1, df2 = df_2, lower.tail = FALSE) upper_critical_value &lt;- qf(p = alpha/2, df1 = df_2, df2 = df_1, lower.tail = FALSE) # Compute the confidence interval and print it out lower_bound &lt;- test.stat.ratio*lower_critical_value upper_bound &lt;- test.stat.ratio*upper_critical_value lower_bound upper_bound . | . | 1 2 3 4 5 . | [1] 3.190589 [1] 3.827044 . | . The 95% confidence interval for the ratio of the variances for Germany’s DAX and France’s CAC is $[3.191, 3.827]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-r/#solution",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances-in-r/#solution"
  },"295": {
    "doc": "How to compute a confidence interval for the ratio of two population variances",
    "title": "How to compute a confidence interval for the ratio of two population variances",
    "content": " ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/"
  },"296": {
    "doc": "How to compute a confidence interval for the ratio of two population variances",
    "title": "Description",
    "content": "Let’s say we want to compute a confidence interval for two population variances. We take two samples of data, $x_1, x_2, x_3, \\ldots, x_k$ and $x’_1, x’_2, x’_3, \\ldots, x’_k$, and compute their variances, $\\sigma_1^2$ and $\\sigma_2^2$. How do we compute a confidence interval for $\\frac{\\sigma_1^2}{\\sigma_2^2}$? . Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to compute a confidence interval for a regression coefficient | How to compute a confidence interval for a population mean | How to compute a confidence interval for a single population variance | How to compute a confidence interval for the difference between two means when both population variances are known | How to compute a confidence interval for the difference between two means when population variances are unknown | How to compute a confidence interval for the difference between two proportions | How to compute a confidence interval for the expected value of a response variable | How to compute a confidence interval for the population proportion | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/#description",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/#description"
  },"297": {
    "doc": "How to compute a confidence interval for the ratio of two population variances",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’ll use R’s dataset EuStockMarkets as an example; of course you should replace this example data with your actual data when using this code. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to compare the variability of Germany’s DAX and France’s CAC closing prices here. Let’s load in the dataset using the process explained in how to quickly load some sample data. | 1 2 3 4 5 6 7 8 9 10 . | from rdatasets import data import pandas as pd # Load in the EuStockMarkets data and convert to a DataFrame EuStockMarkets = data('EuStockMarkets') df = pd.DataFrame(EuStockMarkets[['DAX', 'CAC']]) # Our two samples are its DAX and CAC columns sample1 = df['DAX'].tolist() sample2 = df['CAC'].tolist() . | . Now that we have our data loaded we can compute the confidence interval. You can change the confidence level by changing the value of $\\alpha$ below. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 . | # The degrees of freedom in each sample is its length minus 1 sample1_df = len(sample1) - 1 sample2_df = len(sample2) - 1 # Compute the ratio of the variances import statistics ratio = statistics.variance(sample1) / statistics.variance(sample2) # Find the critical values from the F-distribution from scipy import stats alpha = 0.05 # replace with your chosen alpha (here, a 95% confidence level) lower_critical_value = 1 / stats.f.ppf(q = 1 - alpha/2, dfn = sample1_df, dfd = sample2_df) upper_critical_value = stats.f.ppf(q = 1 - alpha/2, dfn = sample2_df, dfd = sample1_df) # Compute the confidence interval lower_bound = ratio * lower_critical_value upper_bound = ratio * upper_critical_value lower_bound, upper_bound . | . | 1 . | (3.190589226470889, 3.827043522824141) . | . The 95% confidence interval for the ratio of the variances for Germany’s DAX and France’s CAC is $[3.191, 3.827]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/#using-scipy-in-python",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/#using-scipy-in-python"
  },"298": {
    "doc": "How to compute a confidence interval for the ratio of two population variances",
    "title": "Solution, in R",
    "content": "View this solution alone. We’ll use R’s dataset EuStockMarkets as an example; of course you should replace this example data with your actual data when using this code. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to compare the variability of Germany’s DAX and France’s CAC closing prices here. | 1 2 3 4 5 6 7 8 9 . | # install.packages(\"datasets\") # if you have not done so already library(datasets) # Load in the EuStockMarkets data and convert to a DataFrame EuStockMarkets &lt;- data.frame(EuStockMarkets) # Our two samples are its DAX and CAC columns sample.1 &lt;- EuStockMarkets$DAX sample.2 &lt;- EuStockMarkets$CAC . | . Now that we have our data loaded we can compute the confidence interval. You can change the confidence level by changing the value of $\\alpha$ below. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | # The degrees of freedom in each sample is its length minus 1 df_1 = length(sample.1) - 1 df_2 = length(sample.2) - 1 # Compute the ratio of the variances test.stat.ratio &lt;- var(sample.1)/var(sample.2) # Find the critical values from the F-distribution alpha &lt;- 0.05 # replace with your chosen alpha (here, a 95% confidence level) lower_critical_value &lt;- 1 / qf(p = alpha/2, df1 = df_1, df2 = df_2, lower.tail = FALSE) upper_critical_value &lt;- qf(p = alpha/2, df1 = df_2, df2 = df_1, lower.tail = FALSE) # Compute the confidence interval and print it out lower_bound &lt;- test.stat.ratio*lower_critical_value upper_bound &lt;- test.stat.ratio*upper_critical_value lower_bound upper_bound . | . | 1 2 3 4 5 . | [1] 3.190589 [1] 3.827044 . | . The 95% confidence interval for the ratio of the variances for Germany’s DAX and France’s CAC is $[3.191, 3.827]$. Content last modified on 09 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/#solution-in-r",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/#solution-in-r"
  },"299": {
    "doc": "How to compute a confidence interval for the ratio of two population variances",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/#topics-that-include-this-task"
  },"300": {
    "doc": "How to compute a confidence interval for the ratio of two population variances",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/#opportunities",
    "relUrl": "/how-to-compute-a-confidence-interval-for-the-ratio-of-two-population-variances/#opportunities"
  },"301": {
    "doc": "How to compute adjusted R-squared (in Python, using statsmodels)",
    "title": "How to compute adjusted R-squared (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-adjusted-r-squared-in-python-using-statsmodels/",
    "relUrl": "/how-to-compute-adjusted-r-squared-in-python-using-statsmodels/"
  },"302": {
    "doc": "How to compute adjusted R-squared (in Python, using statsmodels)",
    "title": "Task",
    "content": "If we have fit a multivariate linear model, how can we compute the Adjusted $R^2$ for that model, to measure its goodness of fit? . Related tasks: . | How to compute R-squared for a simple linear model | . ",
    "url": "/how-to-compute-adjusted-r-squared-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-compute-adjusted-r-squared-in-python-using-statsmodels/#task"
  },"303": {
    "doc": "How to compute adjusted R-squared (in Python, using statsmodels)",
    "title": "Solution",
    "content": "We assume you have already fit a multivariate linear model to some data, as in the code below. (If you’re unfamiliar with how to do so, see how to fit a multivariate linear model.) The data shown below is fake, and we assume you will replace it with your own real data if you use this code. | 1 2 3 4 5 6 7 8 9 10 11 12 . | import pandas as pd import statsmodels.api as sm df = pd.DataFrame( { 'x1':[2, 7, 4, 3, 11, 18, 6, 15, 9, 12], 'x2':[4, 6, 10, 1, 18, 11, 8, 20, 16, 13], 'x3':[11, 16, 20, 6, 14, 8, 5, 23, 13, 10], 'y':[24, 60, 32, 29, 90, 45, 130, 76, 100, 120] } ) xs = df[['x1', 'x2', 'x3']] y = df['y'] xs = sm.add_constant(xs) model = sm.OLS(y, xs).fit() . | . | 1 2 . | /opt/conda/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only x = pd.concat(x[::order], 1) . | . You can get a lot of information about your model from its summary. | 1 . | model.summary() . | . | 1 2 . | /opt/conda/lib/python3.9/site-packages/scipy/stats/stats.py:1541: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=10 warnings.warn(\"kurtosistest only valid for n&gt;=20 ... continuing \" . | . OLS Regression Results | Dep. Variable: | y | R-squared: | 0.594 | . | Model: | OLS | Adj. R-squared: | 0.390 | . | Method: | Least Squares | F-statistic: | 2.921 | . | Date: | Tue, 07 Dec 2021 | Prob (F-statistic): | 0.122 | . | Time: | 15:06:52 | Log-Likelihood: | -45.689 | . | No. Observations: | 10 | AIC: | 99.38 | . | Df Residuals: | 6 | BIC: | 100.6 | . | Df Model: | 3 | | | . | Covariance Type: | nonrobust | | | . | | coef | std err | t | P&gt;|t| | [0.025 | 0.975] | . | const | 77.2443 | 27.366 | 2.823 | 0.030 | 10.282 | 144.206 | . | x1 | -2.7009 | 2.855 | -0.946 | 0.381 | -9.686 | 4.284 | . | x2 | 7.2989 | 2.875 | 2.539 | 0.044 | 0.265 | 14.333 | . | x3 | -4.8607 | 2.187 | -2.223 | 0.068 | -10.211 | 0.490 | . | Omnibus: | 2.691 | Durbin-Watson: | 2.123 | . | Prob(Omnibus): | 0.260 | Jarque-Bera (JB): | 1.251 | . | Skew: | 0.524 | Prob(JB): | 0.535 | . | Kurtosis: | 1.620 | Cond. No. | 58.2 | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. In particular, that printout contains the Adjusted $R^2$ value; it is the second value in the right-hand column, near the top. You can also obtain it directly, as follows: . | 1 . | model.rsquared_adj . | . | 1 . | 0.390392407508503 . | . In this case, the Adjusted $R^2$ is $0.3904$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-adjusted-r-squared-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-compute-adjusted-r-squared-in-python-using-statsmodels/#solution"
  },"304": {
    "doc": "How to compute adjusted R-squared (in R)",
    "title": "How to compute adjusted R-squared (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-adjusted-r-squared-in-r/",
    "relUrl": "/how-to-compute-adjusted-r-squared-in-r/"
  },"305": {
    "doc": "How to compute adjusted R-squared (in R)",
    "title": "Task",
    "content": "If we have fit a multivariate linear model, how can we compute the Adjusted $R^2$ for that model, to measure its goodness of fit? . Related tasks: . | How to compute R-squared for a simple linear model | . ",
    "url": "/how-to-compute-adjusted-r-squared-in-r/#task",
    "relUrl": "/how-to-compute-adjusted-r-squared-in-r/#task"
  },"306": {
    "doc": "How to compute adjusted R-squared (in R)",
    "title": "Solution",
    "content": "We assume you have already fit a multivariate linear model to the data, as in the code below. (If you’re unfamiliar with how to do so, see how to fit a multivariate linear model.) The data shown below is fake, and we assume you will replace it with your own real data if you use this code. | 1 2 3 4 5 . | x1 &lt;- c(2, 7, 4, 3, 11, 18, 6, 15, 9, 12) x2 &lt;- c(4, 6, 10, 1, 18, 11, 8, 20, 16, 13) x3 &lt;- c(11, 16, 20, 6, 14, 8, 5, 23, 13, 10) y &lt;- c(24, 60, 32, 29, 90, 45, 130, 76, 100, 120) model &lt;- lm(y ~ x1 + x2 + x3) . | . You can get a lot of information about your model from its summary. | 1 . | summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 . | Call: lm(formula = y ~ x1 + x2 + x3) Residuals: Min 1Q Median 3Q Max -25.031 -20.218 -8.373 22.937 35.640 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 77.244 27.366 2.823 0.0302 * x1 -2.701 2.855 -0.946 0.3806 x2 7.299 2.875 2.539 0.0441 * x3 -4.861 2.187 -2.223 0.0679 . --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 30.13 on 6 degrees of freedom Multiple R-squared: 0.5936, Adjusted R-squared: 0.3904 F-statistic: 2.921 on 3 and 6 DF, p-value: 0.1222 . | . In particular, that printout contains the Adjusted $R^2$ value; it is the second value in the right-hand column, near the top. You can also obtain it directly, as follows: . | 1 . | summary(model)$adj.r.squared . | . | 1 . | [1] 0.3903924 . | . In this case, the Adjusted $R^2$ is $0.3904$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-adjusted-r-squared-in-r/#solution",
    "relUrl": "/how-to-compute-adjusted-r-squared-in-r/#solution"
  },"307": {
    "doc": "How to compute adjusted R-squared",
    "title": "How to compute adjusted R-squared",
    "content": " ",
    "url": "/how-to-compute-adjusted-r-squared/",
    "relUrl": "/how-to-compute-adjusted-r-squared/"
  },"308": {
    "doc": "How to compute adjusted R-squared",
    "title": "Description",
    "content": "If we have fit a multivariate linear model, how can we compute the Adjusted $R^2$ for that model, to measure its goodness of fit? . Related tasks: . | How to compute R-squared for a simple linear model | . ",
    "url": "/how-to-compute-adjusted-r-squared/#description",
    "relUrl": "/how-to-compute-adjusted-r-squared/#description"
  },"309": {
    "doc": "How to compute adjusted R-squared",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. We assume you have already fit a multivariate linear model to some data, as in the code below. (If you’re unfamiliar with how to do so, see how to fit a multivariate linear model.) The data shown below is fake, and we assume you will replace it with your own real data if you use this code. | 1 2 3 4 5 6 7 8 9 10 11 12 . | import pandas as pd import statsmodels.api as sm df = pd.DataFrame( { 'x1':[2, 7, 4, 3, 11, 18, 6, 15, 9, 12], 'x2':[4, 6, 10, 1, 18, 11, 8, 20, 16, 13], 'x3':[11, 16, 20, 6, 14, 8, 5, 23, 13, 10], 'y':[24, 60, 32, 29, 90, 45, 130, 76, 100, 120] } ) xs = df[['x1', 'x2', 'x3']] y = df['y'] xs = sm.add_constant(xs) model = sm.OLS(y, xs).fit() . | . | 1 2 . | /opt/conda/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only x = pd.concat(x[::order], 1) . | . You can get a lot of information about your model from its summary. | 1 . | model.summary() . | . | 1 2 . | /opt/conda/lib/python3.9/site-packages/scipy/stats/stats.py:1541: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=10 warnings.warn(\"kurtosistest only valid for n&gt;=20 ... continuing \" . | . OLS Regression Results | Dep. Variable: | y | R-squared: | 0.594 | . | Model: | OLS | Adj. R-squared: | 0.390 | . | Method: | Least Squares | F-statistic: | 2.921 | . | Date: | Tue, 07 Dec 2021 | Prob (F-statistic): | 0.122 | . | Time: | 15:06:52 | Log-Likelihood: | -45.689 | . | No. Observations: | 10 | AIC: | 99.38 | . | Df Residuals: | 6 | BIC: | 100.6 | . | Df Model: | 3 | | | . | Covariance Type: | nonrobust | | | . | | coef | std err | t | P&gt;|t| | [0.025 | 0.975] | . | const | 77.2443 | 27.366 | 2.823 | 0.030 | 10.282 | 144.206 | . | x1 | -2.7009 | 2.855 | -0.946 | 0.381 | -9.686 | 4.284 | . | x2 | 7.2989 | 2.875 | 2.539 | 0.044 | 0.265 | 14.333 | . | x3 | -4.8607 | 2.187 | -2.223 | 0.068 | -10.211 | 0.490 | . | Omnibus: | 2.691 | Durbin-Watson: | 2.123 | . | Prob(Omnibus): | 0.260 | Jarque-Bera (JB): | 1.251 | . | Skew: | 0.524 | Prob(JB): | 0.535 | . | Kurtosis: | 1.620 | Cond. No. | 58.2 | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. In particular, that printout contains the Adjusted $R^2$ value; it is the second value in the right-hand column, near the top. You can also obtain it directly, as follows: . | 1 . | model.rsquared_adj . | . | 1 . | 0.390392407508503 . | . In this case, the Adjusted $R^2$ is $0.3904$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-adjusted-r-squared/#using-statsmodels-in-python",
    "relUrl": "/how-to-compute-adjusted-r-squared/#using-statsmodels-in-python"
  },"310": {
    "doc": "How to compute adjusted R-squared",
    "title": "Solution, in R",
    "content": "View this solution alone. We assume you have already fit a multivariate linear model to the data, as in the code below. (If you’re unfamiliar with how to do so, see how to fit a multivariate linear model.) The data shown below is fake, and we assume you will replace it with your own real data if you use this code. | 1 2 3 4 5 . | x1 &lt;- c(2, 7, 4, 3, 11, 18, 6, 15, 9, 12) x2 &lt;- c(4, 6, 10, 1, 18, 11, 8, 20, 16, 13) x3 &lt;- c(11, 16, 20, 6, 14, 8, 5, 23, 13, 10) y &lt;- c(24, 60, 32, 29, 90, 45, 130, 76, 100, 120) model &lt;- lm(y ~ x1 + x2 + x3) . | . You can get a lot of information about your model from its summary. | 1 . | summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 . | Call: lm(formula = y ~ x1 + x2 + x3) Residuals: Min 1Q Median 3Q Max -25.031 -20.218 -8.373 22.937 35.640 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 77.244 27.366 2.823 0.0302 * x1 -2.701 2.855 -0.946 0.3806 x2 7.299 2.875 2.539 0.0441 * x3 -4.861 2.187 -2.223 0.0679 . --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 30.13 on 6 degrees of freedom Multiple R-squared: 0.5936, Adjusted R-squared: 0.3904 F-statistic: 2.921 on 3 and 6 DF, p-value: 0.1222 . | . In particular, that printout contains the Adjusted $R^2$ value; it is the second value in the right-hand column, near the top. You can also obtain it directly, as follows: . | 1 . | summary(model)$adj.r.squared . | . | 1 . | [1] 0.3903924 . | . In this case, the Adjusted $R^2$ is $0.3904$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-adjusted-r-squared/#solution-in-r",
    "relUrl": "/how-to-compute-adjusted-r-squared/#solution-in-r"
  },"311": {
    "doc": "How to compute adjusted R-squared",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-compute-adjusted-r-squared/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-adjusted-r-squared/#topics-that-include-this-task"
  },"312": {
    "doc": "How to compute adjusted R-squared",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-adjusted-r-squared/#opportunities",
    "relUrl": "/how-to-compute-adjusted-r-squared/#opportunities"
  },"313": {
    "doc": "How to compute covariance and correlation coefficients (in Python, using pandas and NumPy)",
    "title": "How to compute covariance and correlation coefficients (in Python, using pandas and NumPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients-in-python-using-pandas-and-numpy/",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients-in-python-using-pandas-and-numpy/"
  },"314": {
    "doc": "How to compute covariance and correlation coefficients (in Python, using pandas and NumPy)",
    "title": "Task",
    "content": "Covariance is a measure of how much two variables “change together.” It is positive when the variables tend to increase or decrease together, and negative when they upward motion of one variable is correlated with downward motion of the other. Correlation normalizes covariance to the interval $[-1,1]$. ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients-in-python-using-pandas-and-numpy/#task",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients-in-python-using-pandas-and-numpy/#task"
  },"315": {
    "doc": "How to compute covariance and correlation coefficients (in Python, using pandas and NumPy)",
    "title": "Solution",
    "content": "We will construct some random data here, but when applying this, you would use your own data, of course. | 1 2 3 4 5 . | import pandas as pd import numpy as np df = pd.DataFrame(np.random.rand(10,5)) df.columns = [ 'col1','col2','col3','col4','col5' ] df.head() . | . | | col1 | col2 | col3 | col4 | col5 | . | 0 | 0.499459 | 0.544642 | 0.416081 | 0.770145 | 0.365638 | . | 1 | 0.051560 | 0.094024 | 0.821636 | 0.307194 | 0.269724 | . | 2 | 0.775610 | 0.411586 | 0.754904 | 0.174790 | 0.559466 | . | 3 | 0.747098 | 0.783076 | 0.955363 | 0.944042 | 0.875185 | . | 4 | 0.814148 | 0.943769 | 0.249496 | 0.577307 | 0.715827 | . If you have two pandas Series, you can compute the covariance of just those two variables. Note that every column in a DataFrame is a pandas series. | 1 . | np.cov( df['col1'], df['col2'] ) . | . | 1 2 . | array([[0.10369366, 0.08926178], [0.08926178, 0.10982211]]) . | . You can also compare all of a DataFrame’s columns among one another, each as a separate variable. | 1 . | df.cov() . | . | | col1 | col2 | col3 | col4 | col5 | . | col1 | 0.103694 | 0.089262 | -0.029498 | -0.005259 | 0.056009 | . | col2 | 0.089262 | 0.109822 | -0.068362 | 0.014306 | 0.050707 | . | col3 | -0.029498 | -0.068362 | 0.107503 | 0.003484 | 0.004916 | . | col4 | -0.005259 | 0.014306 | 0.003484 | 0.070548 | -0.017955 | . | col5 | 0.056009 | 0.050707 | 0.004916 | -0.017955 | 0.093274 | . The Pearson correlation coefficient can be computed with np.corrcoef in place of np.cov. | 1 . | np.corrcoef( df['col1'], df['col2'] ) . | . | 1 2 . | array([[1. , 0.83645878], [0.83645878, 1. ]]) . | . And pandas DataFrames have a built in method to do this for all numeric columns. | 1 . | df.corr() . | . | | col1 | col2 | col3 | col4 | col5 | . | col1 | 1.000000 | 0.836459 | -0.279384 | -0.061490 | 0.569506 | . | col2 | 0.836459 | 1.000000 | -0.629158 | 0.162532 | 0.501009 | . | col3 | -0.279384 | -0.629158 | 1.000000 | 0.040002 | 0.049098 | . | col4 | -0.061490 | 0.162532 | 0.040002 | 1.000000 | -0.221339 | . | col5 | 0.569506 | 0.501009 | 0.049098 | -0.221339 | 1.000000 | . Content last modified on 10 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients-in-python-using-pandas-and-numpy/#solution",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients-in-python-using-pandas-and-numpy/#solution"
  },"316": {
    "doc": "How to compute covariance and correlation coefficients (in R)",
    "title": "How to compute covariance and correlation coefficients (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients-in-r/",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients-in-r/"
  },"317": {
    "doc": "How to compute covariance and correlation coefficients (in R)",
    "title": "Task",
    "content": "Covariance is a measure of how much two variables “change together.” It is positive when the variables tend to increase or decrease together, and negative when they upward motion of one variable is correlated with downward motion of the other. Correlation normalizes covariance to the interval $[-1,1]$. ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients-in-r/#task",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients-in-r/#task"
  },"318": {
    "doc": "How to compute covariance and correlation coefficients (in R)",
    "title": "Solution",
    "content": "We will construct some random data here, but when applying this, you would use your own data, of course. | 1 2 3 4 5 . | # Create a dataframe with random values between 0 and 1 set.seed(1) df &lt;- as.data.frame(matrix(runif(n=50,min=0,max=1),nrow = 10)) names(df) &lt;- c('col1','col2','col3','col4','col5') head(df) . | . | 1 2 3 4 5 6 7 . | col1 col2 col3 col4 col5 1 0.2655087 0.2059746 0.9347052 0.4820801 0.8209463 2 0.3721239 0.1765568 0.2121425 0.5995658 0.6470602 3 0.5728534 0.6870228 0.6516738 0.4935413 0.7829328 4 0.9082078 0.3841037 0.1255551 0.1862176 0.5530363 5 0.2016819 0.7698414 0.2672207 0.8273733 0.5297196 6 0.8983897 0.4976992 0.3861141 0.6684667 0.7893562 . | . In R, we can use the cov() function to calculate the covariance between two variables. The default method is Pearson. | 1 . | cov( df$col1, df$col2 ) . | . | 1 . | [1] 0.0004115864 . | . You can also compare all of a DataFrame’s columns among one another, each as a separate variable. | 1 . | cov(df) . | . | 1 2 3 4 5 6 . | col1 col2 col3 col4 col5 col1 0.0996382947 0.0004115864 -0.0287090091 -0.0052485522 -0.029944309 col2 0.0004115864 0.0731549057 -0.0255386673 -0.0112688616 -0.026535785 col3 -0.0287090091 -0.0255386673 0.0942522913 0.0009465216 0.050640298 col4 -0.0052485522 -0.0112688616 0.0009465216 0.0593140088 -0.008714775 col5 -0.0299443088 -0.0265357850 0.0506402980 -0.0087147752 0.055665077 . | . The Pearson correlation coefficient can be computed with cor() in place of cov(). | 1 . | cor(df$col1,df$col2) . | . | 1 . | [1] 0.004820878 . | . And you can compute correlation coefficients for all numeric columns in a DataFrame. | 1 . | cor(df) . | . | 1 2 3 4 5 6 . | col1 col2 col3 col4 col5 col1 1.000000000 0.004820878 -0.29625051 -0.06827280 -0.4020775 col2 0.004820878 1.000000000 -0.30756049 -0.17107229 -0.4158329 col3 -0.296250506 -0.307560491 1.00000000 0.01265919 0.6991315 col4 -0.068272803 -0.171072293 0.01265919 1.00000000 -0.1516653 col5 -0.402077472 -0.415832858 0.69913152 -0.15166527 1.0000000 . | . Content last modified on 10 November 2022. See a problem? Tell us or edit the source. Contributed by Ni Shi (shi_ni@bentley.edu) . ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients-in-r/#solution",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients-in-r/#solution"
  },"319": {
    "doc": "How to compute covariance and correlation coefficients",
    "title": "How to compute covariance and correlation coefficients",
    "content": " ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients/",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients/"
  },"320": {
    "doc": "How to compute covariance and correlation coefficients",
    "title": "Description",
    "content": "Covariance is a measure of how much two variables “change together.” It is positive when the variables tend to increase or decrease together, and negative when they upward motion of one variable is correlated with downward motion of the other. Correlation normalizes covariance to the interval $[-1,1]$. ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients/#description",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients/#description"
  },"321": {
    "doc": "How to compute covariance and correlation coefficients",
    "title": "Using pandas and NumPy, in Python",
    "content": "View this solution alone. We will construct some random data here, but when applying this, you would use your own data, of course. | 1 2 3 4 5 . | import pandas as pd import numpy as np df = pd.DataFrame(np.random.rand(10,5)) df.columns = [ 'col1','col2','col3','col4','col5' ] df.head() . | . | | col1 | col2 | col3 | col4 | col5 | . | 0 | 0.499459 | 0.544642 | 0.416081 | 0.770145 | 0.365638 | . | 1 | 0.051560 | 0.094024 | 0.821636 | 0.307194 | 0.269724 | . | 2 | 0.775610 | 0.411586 | 0.754904 | 0.174790 | 0.559466 | . | 3 | 0.747098 | 0.783076 | 0.955363 | 0.944042 | 0.875185 | . | 4 | 0.814148 | 0.943769 | 0.249496 | 0.577307 | 0.715827 | . If you have two pandas Series, you can compute the covariance of just those two variables. Note that every column in a DataFrame is a pandas series. | 1 . | np.cov( df['col1'], df['col2'] ) . | . | 1 2 . | array([[0.10369366, 0.08926178], [0.08926178, 0.10982211]]) . | . You can also compare all of a DataFrame’s columns among one another, each as a separate variable. | 1 . | df.cov() . | . | | col1 | col2 | col3 | col4 | col5 | . | col1 | 0.103694 | 0.089262 | -0.029498 | -0.005259 | 0.056009 | . | col2 | 0.089262 | 0.109822 | -0.068362 | 0.014306 | 0.050707 | . | col3 | -0.029498 | -0.068362 | 0.107503 | 0.003484 | 0.004916 | . | col4 | -0.005259 | 0.014306 | 0.003484 | 0.070548 | -0.017955 | . | col5 | 0.056009 | 0.050707 | 0.004916 | -0.017955 | 0.093274 | . The Pearson correlation coefficient can be computed with np.corrcoef in place of np.cov. | 1 . | np.corrcoef( df['col1'], df['col2'] ) . | . | 1 2 . | array([[1. , 0.83645878], [0.83645878, 1. ]]) . | . And pandas DataFrames have a built in method to do this for all numeric columns. | 1 . | df.corr() . | . | | col1 | col2 | col3 | col4 | col5 | . | col1 | 1.000000 | 0.836459 | -0.279384 | -0.061490 | 0.569506 | . | col2 | 0.836459 | 1.000000 | -0.629158 | 0.162532 | 0.501009 | . | col3 | -0.279384 | -0.629158 | 1.000000 | 0.040002 | 0.049098 | . | col4 | -0.061490 | 0.162532 | 0.040002 | 1.000000 | -0.221339 | . | col5 | 0.569506 | 0.501009 | 0.049098 | -0.221339 | 1.000000 | . Content last modified on 10 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients/#using-pandas-and-numpy-in-python",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients/#using-pandas-and-numpy-in-python"
  },"322": {
    "doc": "How to compute covariance and correlation coefficients",
    "title": "Solution, in R",
    "content": "View this solution alone. We will construct some random data here, but when applying this, you would use your own data, of course. | 1 2 3 4 5 . | # Create a dataframe with random values between 0 and 1 set.seed(1) df &lt;- as.data.frame(matrix(runif(n=50,min=0,max=1),nrow = 10)) names(df) &lt;- c('col1','col2','col3','col4','col5') head(df) . | . | 1 2 3 4 5 6 7 . | col1 col2 col3 col4 col5 1 0.2655087 0.2059746 0.9347052 0.4820801 0.8209463 2 0.3721239 0.1765568 0.2121425 0.5995658 0.6470602 3 0.5728534 0.6870228 0.6516738 0.4935413 0.7829328 4 0.9082078 0.3841037 0.1255551 0.1862176 0.5530363 5 0.2016819 0.7698414 0.2672207 0.8273733 0.5297196 6 0.8983897 0.4976992 0.3861141 0.6684667 0.7893562 . | . In R, we can use the cov() function to calculate the covariance between two variables. The default method is Pearson. | 1 . | cov( df$col1, df$col2 ) . | . | 1 . | [1] 0.0004115864 . | . You can also compare all of a DataFrame’s columns among one another, each as a separate variable. | 1 . | cov(df) . | . | 1 2 3 4 5 6 . | col1 col2 col3 col4 col5 col1 0.0996382947 0.0004115864 -0.0287090091 -0.0052485522 -0.029944309 col2 0.0004115864 0.0731549057 -0.0255386673 -0.0112688616 -0.026535785 col3 -0.0287090091 -0.0255386673 0.0942522913 0.0009465216 0.050640298 col4 -0.0052485522 -0.0112688616 0.0009465216 0.0593140088 -0.008714775 col5 -0.0299443088 -0.0265357850 0.0506402980 -0.0087147752 0.055665077 . | . The Pearson correlation coefficient can be computed with cor() in place of cov(). | 1 . | cor(df$col1,df$col2) . | . | 1 . | [1] 0.004820878 . | . And you can compute correlation coefficients for all numeric columns in a DataFrame. | 1 . | cor(df) . | . | 1 2 3 4 5 6 . | col1 col2 col3 col4 col5 col1 1.000000000 0.004820878 -0.29625051 -0.06827280 -0.4020775 col2 0.004820878 1.000000000 -0.30756049 -0.17107229 -0.4158329 col3 -0.296250506 -0.307560491 1.00000000 0.01265919 0.6991315 col4 -0.068272803 -0.171072293 0.01265919 1.00000000 -0.1516653 col5 -0.402077472 -0.415832858 0.69913152 -0.15166527 1.0000000 . | . Content last modified on 10 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients/#solution-in-r",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients/#solution-in-r"
  },"323": {
    "doc": "How to compute covariance and correlation coefficients",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | Bentley University MA346 | . ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients/#topics-that-include-this-task"
  },"324": {
    "doc": "How to compute covariance and correlation coefficients",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-covariance-and-correlation-coefficients/#opportunities",
    "relUrl": "/how-to-compute-covariance-and-correlation-coefficients/#opportunities"
  },"325": {
    "doc": "How to compute Fisher's confidence intervals (in R)",
    "title": "How to compute Fisher’s confidence intervals (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-fisher-s-confidence-intervals-in-r/#how-to-compute-fishers-confidence-intervals-in-r",
    "relUrl": "/how-to-compute-fisher-s-confidence-intervals-in-r/#how-to-compute-fishers-confidence-intervals-in-r"
  },"326": {
    "doc": "How to compute Fisher's confidence intervals (in R)",
    "title": "Task",
    "content": "If we run a one-way ANOVA test and find that there is a significant difference between population means, we might want to know which means are actually different from each other. One way to do so is with Fisher’s Least Significant Difference Confidence Intervals, which forms a confidence interval for each pair of samples. How do we go about making these confidence intervals? . ",
    "url": "/how-to-compute-fisher-s-confidence-intervals-in-r/#task",
    "relUrl": "/how-to-compute-fisher-s-confidence-intervals-in-r/#task"
  },"327": {
    "doc": "How to compute Fisher's confidence intervals (in R)",
    "title": "Solution",
    "content": "We will use some fake data for the purposes of an example, but you can replace it with your real data in the code below. Consider an ice cream shop’s sales data over several weekends. | 1 2 3 4 . | num.transactions &lt;- c(91, 134, 98, 105, 93, 89, 145, 132, 109, 94, 105, 99, 84, 128, 120, 115, 118) days &lt;- c(\"Fri\", \"Sun\", \"Sun\", \"Sat\", \"Fri\", \"Fri\", \"Sat\", \"Sun\", \"Sun\", \"Fri\", \"Sat\", \"Sat\", \"Fri\", \"Sun\", \"Fri\", \"Sat\", \"Sun\") . | . Let’s assume that you have already performed an ANOVA on this data, as shown below. (If you’re not familiar with ANOVA, see how to do a one-way ANOVA test.) Let’s assume that we chose $\\alpha$ to be 0.05. | 1 2 . | model &lt;- aov(num.transactions ~ days) summary(model) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) days 2 1965 982.7 4.348 0.034 * Residuals 14 3164 226.0 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . From the $p$-value in the Pr(&gt;F) column, we can see that, at the 5% significance level, there are significant differences between the mean number of transactions at the ice cream shop across these weekend days. We’ll use the LSD.test function (Least Significant Difference) from R’s agricolae package to get the confidence intervals for each pair of days. Let’s use $\\alpha=0.05$ again so that we get 95% confidence intervals. | 1 2 3 4 5 . | # install.packages(\"agricolae\") # if you have not already done so library(agricolae) test &lt;- LSD.test(model, alpha=0.05, \"days\") test . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 . | $statistics MSerror Df Mean CV 226.0333 14 109.3529 13.74851 $parameters test p.ajusted name.t ntr alpha Fisher-LSD none days 3 0.05 $means num.transactions std r LCL UCL Min Max Q25 Q50 Q75 Fri 95.16667 12.67149 6 82.00246 108.3309 84 120 89.50 92 93.75 Sat 113.80000 18.36301 5 99.37933 128.2207 99 145 105.00 105 115.00 Sun 119.83333 14.23259 6 106.66913 132.9975 98 134 111.25 123 131.00 $comparison NULL $groups num.transactions groups Sun 119.83333 a Sat 113.80000 ab Fri 95.16667 b attr(,\"class\") [1] \"group\" . | . The portion of this lengthy output on which to focus is the $groups section. If the categories share a letter in the “groups” column, then their means are not significantly different from each other. Therefore: . | Sunday and Saturday share the letter “a,” so we know that the number of transactions on these two days are not significantly different from each other. | The same goes for Saturday and Friday, which share the letter “b.” | But Sunday and Friday do not share a letter, so the number of transactions on these two days is significantly different. | . Content last modified on 08 November 2022. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-compute-fisher-s-confidence-intervals-in-r/#solution",
    "relUrl": "/how-to-compute-fisher-s-confidence-intervals-in-r/#solution"
  },"328": {
    "doc": "How to compute Fisher's confidence intervals (in R)",
    "title": "How to compute Fisher's confidence intervals (in R)",
    "content": " ",
    "url": "/how-to-compute-fisher-s-confidence-intervals-in-r/",
    "relUrl": "/how-to-compute-fisher-s-confidence-intervals-in-r/"
  },"329": {
    "doc": "How to compute Fisher's confidence intervals",
    "title": "How to compute Fisher’s confidence intervals",
    "content": " ",
    "url": "/how-to-compute-fisher-s-confidence-intervals/#how-to-compute-fishers-confidence-intervals",
    "relUrl": "/how-to-compute-fisher-s-confidence-intervals/#how-to-compute-fishers-confidence-intervals"
  },"330": {
    "doc": "How to compute Fisher's confidence intervals",
    "title": "Description",
    "content": "If we run a one-way ANOVA test and find that there is a significant difference between population means, we might want to know which means are actually different from each other. One way to do so is with Fisher’s Least Significant Difference Confidence Intervals, which forms a confidence interval for each pair of samples. How do we go about making these confidence intervals? . ",
    "url": "/how-to-compute-fisher-s-confidence-intervals/#description",
    "relUrl": "/how-to-compute-fisher-s-confidence-intervals/#description"
  },"331": {
    "doc": "How to compute Fisher's confidence intervals",
    "title": "Solution, in R",
    "content": "View this solution alone. We will use some fake data for the purposes of an example, but you can replace it with your real data in the code below. Consider an ice cream shop’s sales data over several weekends. | 1 2 3 4 . | num.transactions &lt;- c(91, 134, 98, 105, 93, 89, 145, 132, 109, 94, 105, 99, 84, 128, 120, 115, 118) days &lt;- c(\"Fri\", \"Sun\", \"Sun\", \"Sat\", \"Fri\", \"Fri\", \"Sat\", \"Sun\", \"Sun\", \"Fri\", \"Sat\", \"Sat\", \"Fri\", \"Sun\", \"Fri\", \"Sat\", \"Sun\") . | . Let’s assume that you have already performed an ANOVA on this data, as shown below. (If you’re not familiar with ANOVA, see how to do a one-way ANOVA test.) Let’s assume that we chose $\\alpha$ to be 0.05. | 1 2 . | model &lt;- aov(num.transactions ~ days) summary(model) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) days 2 1965 982.7 4.348 0.034 * Residuals 14 3164 226.0 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . From the $p$-value in the Pr(&gt;F) column, we can see that, at the 5% significance level, there are significant differences between the mean number of transactions at the ice cream shop across these weekend days. We’ll use the LSD.test function (Least Significant Difference) from R’s agricolae package to get the confidence intervals for each pair of days. Let’s use $\\alpha=0.05$ again so that we get 95% confidence intervals. | 1 2 3 4 5 . | # install.packages(\"agricolae\") # if you have not already done so library(agricolae) test &lt;- LSD.test(model, alpha=0.05, \"days\") test . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 . | $statistics MSerror Df Mean CV 226.0333 14 109.3529 13.74851 $parameters test p.ajusted name.t ntr alpha Fisher-LSD none days 3 0.05 $means num.transactions std r LCL UCL Min Max Q25 Q50 Q75 Fri 95.16667 12.67149 6 82.00246 108.3309 84 120 89.50 92 93.75 Sat 113.80000 18.36301 5 99.37933 128.2207 99 145 105.00 105 115.00 Sun 119.83333 14.23259 6 106.66913 132.9975 98 134 111.25 123 131.00 $comparison NULL $groups num.transactions groups Sun 119.83333 a Sat 113.80000 ab Fri 95.16667 b attr(,\"class\") [1] \"group\" . | . The portion of this lengthy output on which to focus is the $groups section. If the categories share a letter in the “groups” column, then their means are not significantly different from each other. Therefore: . | Sunday and Saturday share the letter “a,” so we know that the number of transactions on these two days are not significantly different from each other. | The same goes for Saturday and Friday, which share the letter “b.” | But Sunday and Friday do not share a letter, so the number of transactions on these two days is significantly different. | . Content last modified on 08 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-fisher-s-confidence-intervals/#solution-in-r",
    "relUrl": "/how-to-compute-fisher-s-confidence-intervals/#solution-in-r"
  },"332": {
    "doc": "How to compute Fisher's confidence intervals",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-compute-fisher-s-confidence-intervals/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-fisher-s-confidence-intervals/#topics-that-include-this-task"
  },"333": {
    "doc": "How to compute Fisher's confidence intervals",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Python | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-fisher-s-confidence-intervals/#opportunities",
    "relUrl": "/how-to-compute-fisher-s-confidence-intervals/#opportunities"
  },"334": {
    "doc": "How to compute Fisher's confidence intervals",
    "title": "How to compute Fisher's confidence intervals",
    "content": " ",
    "url": "/how-to-compute-fisher-s-confidence-intervals/",
    "relUrl": "/how-to-compute-fisher-s-confidence-intervals/"
  },"335": {
    "doc": "How to compute probabilities from a distribution (in Excel)",
    "title": "How to compute probabilities from a distribution (in Excel)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-excel/",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-excel/"
  },"336": {
    "doc": "How to compute probabilities from a distribution (in Excel)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to compute the probability of a value/values occurring? . Related tasks: . | How to generate random values from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-excel/#task",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-excel/#task"
  },"337": {
    "doc": "How to compute probabilities from a distribution (in Excel)",
    "title": "Solution",
    "content": "If the probability distribution is a common discrete distribution, you can simply use a built-in function from Excel’s set of statistical functions to compute any probability from it. For example, to find the probability that a binomial random variable with p=0.25 yields 3 successes in 5 trials, you can use =BINOM.DIST(3,5,0.25,FALSE). The final parameter, FALSE, tells Excel you are asking only about 3 successes, not the cumulative probability of up to 3 successes. For other discrete random variables, see the Excel help on POISSON.DIST and HYPGEOM.DIST. If the probability distribution is a common continuous distribution, you must ask about the probability of a random value falling in a certain range. You do so by subtracting two outputs of the cumulative distribution function (CDF). For example, to find the probability that a normal random variable with mean 5 and standard deviation 2 falls in the interval [6,7], you can use =NORM.DIST(7,5,2,TRUE)-NORM.DIST(6,5,2,TRUE). Notice: . | It is important to subtract the lower end of the interval from the higher end, not the other way around. (If your probability comes out negative, you have it backwards.) . | The final parameter, TRUE, tells Excel you are using the CDF of the distribution. If you use FALSE instead, you will get a wrong answer. | . For other continuous random variables, see the Excel help on BETA.DIST, CHISQ.DIST, F.DIST, GAMMA.DIST, LOGNORM.DIST, and T.DIST. Content last modified on 09 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-excel/#solution",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-excel/#solution"
  },"338": {
    "doc": "How to compute probabilities from a distribution (in Julia)",
    "title": "How to compute probabilities from a distribution (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-julia/",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-julia/"
  },"339": {
    "doc": "How to compute probabilities from a distribution (in Julia)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to compute the probability of a value/values occurring? . Related tasks: . | How to generate random values from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-julia/#task",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-julia/#task"
  },"340": {
    "doc": "How to compute probabilities from a distribution (in Julia)",
    "title": "Solution",
    "content": "You can import many different random variables from Julia’s Distributions package. The full list of them is online here. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. To compute a probability from a discrete distribution, create a random variable, then use the pdf function. (This is a slight misnomer, because PDF stands for Probability Density Function, which is a concept related to continuous random variables, but it’s the function Julia uses.) . | 1 2 3 4 5 6 7 8 . | using Distributions # Create a binomial random variable with 10 trials # and probability 0.5 of success on each trial X = Binomial( 10, 0.5 ) # What is the probability of exactly 3 successes? pdf( X, 3 ) . | . | 1 . | 0.1171875000000004 . | . To compute a probability from a continuous distribution, create a random variable, then use its Cumulative Density Function, cdf. You can only compute the probability that a random value will fall in an interval $[a,b]$, not the probability that it will equal a specific value. | 1 2 3 4 5 6 7 . | using Distributions # Create a normal random variable with mean μ=10 and standard deviation σ=5 X = Normal( 10, 5 ) # What is the probability of the value lying in the interval [12,13]? cdf( X, 13 ) - cdf( X, 12 ) . | . | 1 . | 0.07032514063960227 . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-julia/#solution",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-julia/#solution"
  },"341": {
    "doc": "How to compute probabilities from a distribution (in Python, using SciPy)",
    "title": "How to compute probabilities from a distribution (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-python-using-scipy/",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-python-using-scipy/"
  },"342": {
    "doc": "How to compute probabilities from a distribution (in Python, using SciPy)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to compute the probability of a value/values occurring? . Related tasks: . | How to generate random values from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-python-using-scipy/#task",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-python-using-scipy/#task"
  },"343": {
    "doc": "How to compute probabilities from a distribution (in Python, using SciPy)",
    "title": "Solution",
    "content": "You can import many different random variables from SciPy’s stats module. The full list of them is online here. To compute a probability from a discrete distribution, create a random variable, then use its Probability Mass Function, pmf. | 1 2 3 4 5 6 7 8 . | from scipy import stats # Create a binomial random variable with 10 trials # and probability 0.5 of success on each trial X = stats.binom( 10, 0.5 ) # What is the probability of exactly 3 successes? X.pmf( 3 ) . | . | 1 . | 0.1171875 . | . To compute a probability from a continuous distribution, create a random variable, then use its Cumulative Density Function, cdf. You can only compute the probability that a random value will fall in an interval $[a,b]$, not the probability that it will equal a specific value. | 1 2 3 4 5 6 7 . | from scipy import stats # Create a normal random variable with mean μ=10 and standard deviation σ=5 X = stats.norm( 10, 5 ) # What is the probability of the value lying in the interval [12,13]? X.cdf( 13 ) - X.cdf( 12 ) . | . | 1 . | 0.07032514063960227 . | . Content last modified on 27 May 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-python-using-scipy/#solution",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-python-using-scipy/#solution"
  },"344": {
    "doc": "How to compute probabilities from a distribution (in R)",
    "title": "How to compute probabilities from a distribution (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-r/",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-r/"
  },"345": {
    "doc": "How to compute probabilities from a distribution (in R)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to compute the probability of a value/values occurring? . Related tasks: . | How to generate random values from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-r/#task",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-r/#task"
  },"346": {
    "doc": "How to compute probabilities from a distribution (in R)",
    "title": "Solution",
    "content": "Because R is designed for use in statistics, it comes with many probability distributions built in. A list of them is online here. To compute a probability from a discrete distribution, prefix the name of the distribution with d (for “density”) and call it as a function on the value whose probability you want to know, plus any parameters the distrubtion needs. | 1 2 3 4 . | # For a binomial random variable with 10 trials # and probability 0.5 of success on each trial, # what is the probability of exactly 3 successes? dbinom( 3, size=10, prob=0.5 ) . | . | 1 . | [1] 0.1171875 . | . If you change the prefix to p, then R will compute the probability up to the parameter you specify, as in the following example. | 1 2 3 4 . | # For a binomial random variable with 10 trials # and probability 0.5 of success on each trial, # what is the probability of up to (and including) 3 successes? pbinom( 3, size=10, prob=0.5 ) . | . | 1 . | [1] 0.171875 . | . To compute a probability from a continuous distribution, prefix the name with d, just as in the example above. But you can compute only the probability that a random value will fall in an interval $[a,b]$, not the probability that it will equal a specific value. | 1 2 3 . | # For a normal random variable with mean μ=10 and standard deviation σ=5, # what is the probability of the value lying in the interval [12,13]? pnorm( 13, mean=10, sd=5 ) - pnorm( 12, mean=10, sd=5 ) . | . | 1 . | [1] 0.07032514 . | . Consequently, we can also compute: . | 1 2 . | pnorm( 13, mean=10, sd=5 ) # the probability of a value &lt; 13 1 - pnorm( 13, mean=10, sd=5 ) # the probability of a value &gt; 13 . | . | 1 2 3 4 5 . | [1] 0.7257469 [1] 0.2742531 . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. Contributed by: . | Nathan Carter (ncarter@bentley.edu) | Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) | . ",
    "url": "/how-to-compute-probabilities-from-a-distribution-in-r/#solution",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution-in-r/#solution"
  },"347": {
    "doc": "How to compute probabilities from a distribution",
    "title": "How to compute probabilities from a distribution",
    "content": " ",
    "url": "/how-to-compute-probabilities-from-a-distribution/",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution/"
  },"348": {
    "doc": "How to compute probabilities from a distribution",
    "title": "Description",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to compute the probability of a value/values occurring? . Related tasks: . | How to generate random values from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/how-to-compute-probabilities-from-a-distribution/#description",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution/#description"
  },"349": {
    "doc": "How to compute probabilities from a distribution",
    "title": "Solution, in Excel",
    "content": "View this solution alone. If the probability distribution is a common discrete distribution, you can simply use a built-in function from Excel’s set of statistical functions to compute any probability from it. For example, to find the probability that a binomial random variable with p=0.25 yields 3 successes in 5 trials, you can use =BINOM.DIST(3,5,0.25,FALSE). The final parameter, FALSE, tells Excel you are asking only about 3 successes, not the cumulative probability of up to 3 successes. For other discrete random variables, see the Excel help on POISSON.DIST and HYPGEOM.DIST. If the probability distribution is a common continuous distribution, you must ask about the probability of a random value falling in a certain range. You do so by subtracting two outputs of the cumulative distribution function (CDF). For example, to find the probability that a normal random variable with mean 5 and standard deviation 2 falls in the interval [6,7], you can use =NORM.DIST(7,5,2,TRUE)-NORM.DIST(6,5,2,TRUE). Notice: . | It is important to subtract the lower end of the interval from the higher end, not the other way around. (If your probability comes out negative, you have it backwards.) . | The final parameter, TRUE, tells Excel you are using the CDF of the distribution. If you use FALSE instead, you will get a wrong answer. | . For other continuous random variables, see the Excel help on BETA.DIST, CHISQ.DIST, F.DIST, GAMMA.DIST, LOGNORM.DIST, and T.DIST. Content last modified on 09 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-probabilities-from-a-distribution/#solution-in-excel",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution/#solution-in-excel"
  },"350": {
    "doc": "How to compute probabilities from a distribution",
    "title": "Solution, in Julia",
    "content": "View this solution alone. You can import many different random variables from Julia’s Distributions package. The full list of them is online here. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. To compute a probability from a discrete distribution, create a random variable, then use the pdf function. (This is a slight misnomer, because PDF stands for Probability Density Function, which is a concept related to continuous random variables, but it’s the function Julia uses.) . | 1 2 3 4 5 6 7 8 . | using Distributions # Create a binomial random variable with 10 trials # and probability 0.5 of success on each trial X = Binomial( 10, 0.5 ) # What is the probability of exactly 3 successes? pdf( X, 3 ) . | . | 1 . | 0.1171875000000004 . | . To compute a probability from a continuous distribution, create a random variable, then use its Cumulative Density Function, cdf. You can only compute the probability that a random value will fall in an interval $[a,b]$, not the probability that it will equal a specific value. | 1 2 3 4 5 6 7 . | using Distributions # Create a normal random variable with mean μ=10 and standard deviation σ=5 X = Normal( 10, 5 ) # What is the probability of the value lying in the interval [12,13]? cdf( X, 13 ) - cdf( X, 12 ) . | . | 1 . | 0.07032514063960227 . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-probabilities-from-a-distribution/#solution-in-julia",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution/#solution-in-julia"
  },"351": {
    "doc": "How to compute probabilities from a distribution",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. You can import many different random variables from SciPy’s stats module. The full list of them is online here. To compute a probability from a discrete distribution, create a random variable, then use its Probability Mass Function, pmf. | 1 2 3 4 5 6 7 8 . | from scipy import stats # Create a binomial random variable with 10 trials # and probability 0.5 of success on each trial X = stats.binom( 10, 0.5 ) # What is the probability of exactly 3 successes? X.pmf( 3 ) . | . | 1 . | 0.1171875 . | . To compute a probability from a continuous distribution, create a random variable, then use its Cumulative Density Function, cdf. You can only compute the probability that a random value will fall in an interval $[a,b]$, not the probability that it will equal a specific value. | 1 2 3 4 5 6 7 . | from scipy import stats # Create a normal random variable with mean μ=10 and standard deviation σ=5 X = stats.norm( 10, 5 ) # What is the probability of the value lying in the interval [12,13]? X.cdf( 13 ) - X.cdf( 12 ) . | . | 1 . | 0.07032514063960227 . | . Content last modified on 27 May 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-probabilities-from-a-distribution/#using-scipy-in-python",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution/#using-scipy-in-python"
  },"352": {
    "doc": "How to compute probabilities from a distribution",
    "title": "Solution, in R",
    "content": "View this solution alone. Because R is designed for use in statistics, it comes with many probability distributions built in. A list of them is online here. To compute a probability from a discrete distribution, prefix the name of the distribution with d (for “density”) and call it as a function on the value whose probability you want to know, plus any parameters the distrubtion needs. | 1 2 3 4 . | # For a binomial random variable with 10 trials # and probability 0.5 of success on each trial, # what is the probability of exactly 3 successes? dbinom( 3, size=10, prob=0.5 ) . | . | 1 . | [1] 0.1171875 . | . If you change the prefix to p, then R will compute the probability up to the parameter you specify, as in the following example. | 1 2 3 4 . | # For a binomial random variable with 10 trials # and probability 0.5 of success on each trial, # what is the probability of up to (and including) 3 successes? pbinom( 3, size=10, prob=0.5 ) . | . | 1 . | [1] 0.171875 . | . To compute a probability from a continuous distribution, prefix the name with d, just as in the example above. But you can compute only the probability that a random value will fall in an interval $[a,b]$, not the probability that it will equal a specific value. | 1 2 3 . | # For a normal random variable with mean μ=10 and standard deviation σ=5, # what is the probability of the value lying in the interval [12,13]? pnorm( 13, mean=10, sd=5 ) - pnorm( 12, mean=10, sd=5 ) . | . | 1 . | [1] 0.07032514 . | . Consequently, we can also compute: . | 1 2 . | pnorm( 13, mean=10, sd=5 ) # the probability of a value &lt; 13 1 - pnorm( 13, mean=10, sd=5 ) # the probability of a value &gt; 13 . | . | 1 2 3 4 5 . | [1] 0.7257469 [1] 0.2742531 . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-probabilities-from-a-distribution/#solution-in-r",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution/#solution-in-r"
  },"353": {
    "doc": "How to compute probabilities from a distribution",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | . ",
    "url": "/how-to-compute-probabilities-from-a-distribution/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-probabilities-from-a-distribution/#topics-that-include-this-task"
  },"354": {
    "doc": "How to compute R-squared for a simple linear model (in Julia)",
    "title": "How to compute R-squared for a simple linear model (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model-in-julia/",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model-in-julia/"
  },"355": {
    "doc": "How to compute R-squared for a simple linear model (in Julia)",
    "title": "Task",
    "content": "Let’s say we have fit a linear model to two columns of data, one for a single independent variable $x$ and the other for a single dependent variable $y$. How can we compute $R^2$ for that model, to measure its goodness of fit? . Related tasks: . | How to fit a linear model to two columns of data | How to compute adjusted R-squared | . ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model-in-julia/#task",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model-in-julia/#task"
  },"356": {
    "doc": "How to compute R-squared for a simple linear model (in Julia)",
    "title": "Solution",
    "content": "We assume you have already fit a linear model to the data, as in the code below, which is explained fully in a separate task, how to fit a linear model to two columns of data. | 1 2 3 4 5 . | using GLM, DataFrames xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] data = DataFrame( xs=xs, ys=ys ) model = lm( @formula( ys ~ xs ), data ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}} ys ~ 1 + xs Coefficients: ─────────────────────────────────────────────────────────────────────────── Coef. Std. Error t Pr(&gt;|t|) Lower 95% Upper 95% ─────────────────────────────────────────────────────────────────────────── (Intercept) -37.3214 18.9954 -1.96 0.1066 -86.1508 11.5079 xs 0.13272 0.029589 4.49 0.0065 0.0566587 0.20878 ─────────────────────────────────────────────────────────────────────────── . | . You can get the $R^2$ value from your model using the r2 function in the GLM package. | 1 . | r2( model ) . | . | 1 . | 0.8009488239830588 . | . Content last modified on 05 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model-in-julia/#solution",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model-in-julia/#solution"
  },"357": {
    "doc": "How to compute R-squared for a simple linear model (in Python, using SciPy)",
    "title": "How to compute R-squared for a simple linear model (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model-in-python-using-scipy/",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model-in-python-using-scipy/"
  },"358": {
    "doc": "How to compute R-squared for a simple linear model (in Python, using SciPy)",
    "title": "Task",
    "content": "Let’s say we have fit a linear model to two columns of data, one for a single independent variable $x$ and the other for a single dependent variable $y$. How can we compute $R^2$ for that model, to measure its goodness of fit? . Related tasks: . | How to fit a linear model to two columns of data | How to compute adjusted R-squared | . ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model-in-python-using-scipy/#task",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model-in-python-using-scipy/#task"
  },"359": {
    "doc": "How to compute R-squared for a simple linear model (in Python, using SciPy)",
    "title": "Solution",
    "content": "We assume you have already fit a linear model to the data, as in the code below, which is explained fully in a separate task, how to fit a linear model to two columns of data. | 1 2 3 4 . | import scipy.stats as stats xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] model = stats.linregress( xs, ys ) . | . The $R$ value is part of the model object that stats.linregress returns. | 1 . | model.rvalue . | . | 1 . | 0.8949574425541466 . | . You can compute $R^2$ just by squaring it. | 1 . | model.rvalue ** 2 . | . | 1 . | 0.8009488239830586 . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model-in-python-using-scipy/#solution",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model-in-python-using-scipy/#solution"
  },"360": {
    "doc": "How to compute R-squared for a simple linear model (in R)",
    "title": "How to compute R-squared for a simple linear model (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model-in-r/",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model-in-r/"
  },"361": {
    "doc": "How to compute R-squared for a simple linear model (in R)",
    "title": "Task",
    "content": "Let’s say we have fit a linear model to two columns of data, one for a single independent variable $x$ and the other for a single dependent variable $y$. How can we compute $R^2$ for that model, to measure its goodness of fit? . Related tasks: . | How to fit a linear model to two columns of data | How to compute adjusted R-squared | . ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model-in-r/#task",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model-in-r/#task"
  },"362": {
    "doc": "How to compute R-squared for a simple linear model (in R)",
    "title": "Solution",
    "content": "We assume you have already fit a linear model to the data, as in the code below, which is explained fully in a separate task, how to fit a linear model to two columns of data. | 1 2 3 . | xs &lt;- c( 393, 453, 553, 679, 729, 748, 817 ) ys &lt;- c( 24, 25, 27, 36, 55, 68, 84 ) model &lt;- lm( ys ~ xs ) . | . You can get a lot of information about your model from its summary. | 1 . | summary( model ) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | Call: lm(formula = ys ~ xs) Residuals: 1 2 3 4 5 6 7 9.163 2.199 -9.072 -16.795 -4.431 6.047 12.890 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -37.32142 18.99544 -1.965 0.10664 xs 0.13272 0.02959 4.485 0.00649 ** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 11.62 on 5 degrees of freedom Multiple R-squared: 0.8009, Adjusted R-squared: 0.7611 F-statistic: 20.12 on 1 and 5 DF, p-value: 0.006486 . | . In particular, it contains the $R^2$ value. | 1 . | summary( model )$r.squared . | . | 1 . | [1] 0.8009488 . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model-in-r/#solution",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model-in-r/#solution"
  },"363": {
    "doc": "How to compute R-squared for a simple linear model",
    "title": "How to compute R-squared for a simple linear model",
    "content": " ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model/",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model/"
  },"364": {
    "doc": "How to compute R-squared for a simple linear model",
    "title": "Description",
    "content": "Let’s say we have fit a linear model to two columns of data, one for a single independent variable $x$ and the other for a single dependent variable $y$. How can we compute $R^2$ for that model, to measure its goodness of fit? . Related tasks: . | How to fit a linear model to two columns of data | How to compute adjusted R-squared | . ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model/#description",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model/#description"
  },"365": {
    "doc": "How to compute R-squared for a simple linear model",
    "title": "Solution, in Julia",
    "content": "View this solution alone. We assume you have already fit a linear model to the data, as in the code below, which is explained fully in a separate task, how to fit a linear model to two columns of data. | 1 2 3 4 5 . | using GLM, DataFrames xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] data = DataFrame( xs=xs, ys=ys ) model = lm( @formula( ys ~ xs ), data ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}} ys ~ 1 + xs Coefficients: ─────────────────────────────────────────────────────────────────────────── Coef. Std. Error t Pr(&gt;|t|) Lower 95% Upper 95% ─────────────────────────────────────────────────────────────────────────── (Intercept) -37.3214 18.9954 -1.96 0.1066 -86.1508 11.5079 xs 0.13272 0.029589 4.49 0.0065 0.0566587 0.20878 ─────────────────────────────────────────────────────────────────────────── . | . You can get the $R^2$ value from your model using the r2 function in the GLM package. | 1 . | r2( model ) . | . | 1 . | 0.8009488239830588 . | . Content last modified on 05 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model/#solution-in-julia",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model/#solution-in-julia"
  },"366": {
    "doc": "How to compute R-squared for a simple linear model",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We assume you have already fit a linear model to the data, as in the code below, which is explained fully in a separate task, how to fit a linear model to two columns of data. | 1 2 3 4 . | import scipy.stats as stats xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] model = stats.linregress( xs, ys ) . | . The $R$ value is part of the model object that stats.linregress returns. | 1 . | model.rvalue . | . | 1 . | 0.8949574425541466 . | . You can compute $R^2$ just by squaring it. | 1 . | model.rvalue ** 2 . | . | 1 . | 0.8009488239830586 . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model/#using-scipy-in-python",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model/#using-scipy-in-python"
  },"367": {
    "doc": "How to compute R-squared for a simple linear model",
    "title": "Solution, in R",
    "content": "View this solution alone. We assume you have already fit a linear model to the data, as in the code below, which is explained fully in a separate task, how to fit a linear model to two columns of data. | 1 2 3 . | xs &lt;- c( 393, 453, 553, 679, 729, 748, 817 ) ys &lt;- c( 24, 25, 27, 36, 55, 68, 84 ) model &lt;- lm( ys ~ xs ) . | . You can get a lot of information about your model from its summary. | 1 . | summary( model ) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | Call: lm(formula = ys ~ xs) Residuals: 1 2 3 4 5 6 7 9.163 2.199 -9.072 -16.795 -4.431 6.047 12.890 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -37.32142 18.99544 -1.965 0.10664 xs 0.13272 0.02959 4.485 0.00649 ** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 11.62 on 5 degrees of freedom Multiple R-squared: 0.8009, Adjusted R-squared: 0.7611 F-statistic: 20.12 on 1 and 5 DF, p-value: 0.006486 . | . In particular, it contains the $R^2$ value. | 1 . | summary( model )$r.squared . | . | 1 . | [1] 0.8009488 . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model/#solution-in-r",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model/#solution-in-r"
  },"368": {
    "doc": "How to compute R-squared for a simple linear model",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | Bentley University MA214 | Bentley University MA252 | . ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model/#topics-that-include-this-task"
  },"369": {
    "doc": "How to compute R-squared for a simple linear model",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-r-squared-for-a-simple-linear-model/#opportunities",
    "relUrl": "/how-to-compute-r-squared-for-a-simple-linear-model/#opportunities"
  },"370": {
    "doc": "How to compute summary statistics (in Excel)",
    "title": "How to compute summary statistics (in Excel)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-summary-statistics-in-excel/",
    "relUrl": "/how-to-compute-summary-statistics-in-excel/"
  },"371": {
    "doc": "How to compute summary statistics (in Excel)",
    "title": "Task",
    "content": "The phrase “summary statistics” usually refers to a common set of simple computations that can be done about any dataset, including mean, median, variance, and some of the others shown below. Related tasks: . | How to summarize a column | How to summarize and compare data by groups | . ",
    "url": "/how-to-compute-summary-statistics-in-excel/#task",
    "relUrl": "/how-to-compute-summary-statistics-in-excel/#task"
  },"372": {
    "doc": "How to compute summary statistics (in Excel)",
    "title": "Solution",
    "content": "Let’s assume you have some data in an Excel workbook. We show the first 10 rows the famous example dataset “iris” below, but we assume you are applying what we cover here to your own real data. To compute descriptive statistics, you will need the Data Analysis Toolpak. If you’ve never enabled it before, see these instructions from Microsoft on how to do so. On the Data tab, click the Data Analysis button, shown below. From the list of tools it provides, choose Descriptive Statistics, as shown below, then click OK. Highlight as input only the numeric columns in your data, because the Data Analysis Toolpak cannot summarize other kinds of input. (Do not include column headers in your selection.) Then check the “Summary statistics” checkbox, as shown below. Then click OK. Excel will create a new sheet that reports the mean, median, variance, and more, for each column, as shown below. To get a report of the unique values in your column and the frequency of each, you can use a pivot table. Place your cursor anywhere in your data, then on the Insert tab, choose Pivot Table, as shown below. Drag any column’s name from the list of pivot table fields down into both the Rows and Values areas, as shown below. If the column is numeric, then in the drop-down under Values, choose “Value field settings…” and change Sum to Count, then click OK. This is not necessary for non-numeric columns. (See how to summarize a column for an example.) . Your pivot table will now contain the desired report. In the iris dataset used in this example, there were precisely 50 observations of each variety. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-summary-statistics-in-excel/#solution",
    "relUrl": "/how-to-compute-summary-statistics-in-excel/#solution"
  },"373": {
    "doc": "How to compute summary statistics (in Julia)",
    "title": "How to compute summary statistics (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-summary-statistics-in-julia/",
    "relUrl": "/how-to-compute-summary-statistics-in-julia/"
  },"374": {
    "doc": "How to compute summary statistics (in Julia)",
    "title": "Task",
    "content": "The phrase “summary statistics” usually refers to a common set of simple computations that can be done about any dataset, including mean, median, variance, and some of the others shown below. Related tasks: . | How to summarize a column | How to summarize and compare data by groups | . ",
    "url": "/how-to-compute-summary-statistics-in-julia/#task",
    "relUrl": "/how-to-compute-summary-statistics-in-julia/#task"
  },"375": {
    "doc": "How to compute summary statistics (in Julia)",
    "title": "Solution",
    "content": "We first load a famous dataset, Fisher’s irises, just to have some example data to use in the code that follows. (See how to quickly load some sample data.) . | 1 2 . | using RDatasets iris = dataset( \"datasets\", \"iris\" ); . | . How big is the dataset? The output shows number of rows then number of columns. | 1 . | size( iris ) . | . | 1 . | (150, 5) . | . What are the columns and their data types? The following command shows the first 5 rows, plus the column names and types. | 1 . | first( iris, 5 ) . | . 5×5 DataFrame | Row | SepalLength | SepalWidth | PetalLength | PetalWidth | Species | . | | Float64 | Float64 | Float64 | Float64 | Cat… | . | 1 | 5.1 | 3.5 | 1.4 | 0.2 | setosa | . | 2 | 4.9 | 3.0 | 1.4 | 0.2 | setosa | . | 3 | 4.7 | 3.2 | 1.3 | 0.2 | setosa | . | 4 | 4.6 | 3.1 | 1.5 | 0.2 | setosa | . | 5 | 5.0 | 3.6 | 1.4 | 0.2 | setosa | . Are any values missing? The following command answers that question, plus provides summary statistics, and the same data type information from above. | 1 . | describe( iris ) . | . 5×7 DataFrame | Row | variable | mean | min | median | max | nmissing | eltype | . | | Symbol | Union… | Any | Union… | Any | Int64 | DataType | . | 1 | SepalLength | 5.84333 | 4.3 | 5.8 | 7.9 | 0 | Float64 | . | 2 | SepalWidth | 3.05733 | 2.0 | 3.0 | 4.4 | 0 | Float64 | . | 3 | PetalLength | 3.758 | 1.0 | 4.35 | 6.9 | 0 | Float64 | . | 4 | PetalWidth | 1.19933 | 0.1 | 1.3 | 2.5 | 0 | Float64 | . | 5 | Species | | setosa | | virginica | 0 | CategoricalValue{String, UInt8} | . The individual statistics are the column headings, and the numeric columns from the original dataset are listed under the “Symbol” heading. We can also compute these statistics (and others) one at a time for any given set of data points. Here, we let xs be one column from the above DataFrame, but you could use any array or DataFrame instead. | 1 2 3 4 5 6 7 8 9 10 11 . | xs = iris.\"SepalLength\" using Statistics mean( xs ) # mean, or average, or center of mass median( xs ) # 50th percentile quantile!( xs, 0.25 ) # compute any percentile, such as the 25th var( xs ) # variance std( xs ) # standard deviation, the square root of the variance sort( xs ) # data in increasing order sum( xs ) # sum, or total . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-summary-statistics-in-julia/#solution",
    "relUrl": "/how-to-compute-summary-statistics-in-julia/#solution"
  },"376": {
    "doc": "How to compute summary statistics (in Python, using pandas and NumPy)",
    "title": "How to compute summary statistics (in Python, using pandas and NumPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-summary-statistics-in-python-using-pandas-and-numpy/",
    "relUrl": "/how-to-compute-summary-statistics-in-python-using-pandas-and-numpy/"
  },"377": {
    "doc": "How to compute summary statistics (in Python, using pandas and NumPy)",
    "title": "Task",
    "content": "The phrase “summary statistics” usually refers to a common set of simple computations that can be done about any dataset, including mean, median, variance, and some of the others shown below. Related tasks: . | How to summarize a column | How to summarize and compare data by groups | . ",
    "url": "/how-to-compute-summary-statistics-in-python-using-pandas-and-numpy/#task",
    "relUrl": "/how-to-compute-summary-statistics-in-python-using-pandas-and-numpy/#task"
  },"378": {
    "doc": "How to compute summary statistics (in Python, using pandas and NumPy)",
    "title": "Solution",
    "content": "We first load a famous dataset, Fisher’s irises, just to have some example data to use in the code that follows. (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data( 'iris' ) . | . How big is the dataset? The output shows number of rows then number of columns. | 1 . | df.shape . | . | 1 . | (150, 5) . | . What are the columns and their data types? Are any values missing? . | 1 . | df.info() . | . | 1 2 3 4 5 6 7 8 9 10 11 12 . | &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 150 entries, 0 to 149 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Sepal.Length 150 non-null float64 1 Sepal.Width 150 non-null float64 2 Petal.Length 150 non-null float64 3 Petal.Width 150 non-null float64 4 Species 150 non-null object dtypes: float64(4), object(1) memory usage: 6.0+ KB . | . What do the first few rows look like? . | 1 . | df.head() # Default is 5, but you can do df.head(20) or any number. | . | | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species | . | 0 | 5.1 | 3.5 | 1.4 | 0.2 | setosa | . | 1 | 4.9 | 3.0 | 1.4 | 0.2 | setosa | . | 2 | 4.7 | 3.2 | 1.3 | 0.2 | setosa | . | 3 | 4.6 | 3.1 | 1.5 | 0.2 | setosa | . | 4 | 5.0 | 3.6 | 1.4 | 0.2 | setosa | . The easiest way to get summary statistics for a pandas DataFrame is with the describe function. | 1 . | df.describe() . | . | | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | . | count | 150.000000 | 150.000000 | 150.000000 | 150.000000 | . | mean | 5.843333 | 3.057333 | 3.758000 | 1.199333 | . | std | 0.828066 | 0.435866 | 1.765298 | 0.762238 | . | min | 4.300000 | 2.000000 | 1.000000 | 0.100000 | . | 25% | 5.100000 | 2.800000 | 1.600000 | 0.300000 | . | 50% | 5.800000 | 3.000000 | 4.350000 | 1.300000 | . | 75% | 6.400000 | 3.300000 | 5.100000 | 1.800000 | . | max | 7.900000 | 4.400000 | 6.900000 | 2.500000 | . The individual statistics are the row headings, and the numeric columns from the original dataset are listed across the top. We can also compute these statistics (and others) one at a time for any given set of data points. Here, we let xs be one column from the above DataFrame, but you could use any NumPy array or pandas DataFrame instead. | 1 2 3 4 5 6 7 8 9 10 11 . | xs = df['Sepal.Length'] import numpy as np np.mean( xs ) # mean, or average, or center of mass np.median( xs ) # 50th percentile np.percentile( xs, 25 ) # compute any percentile, such as the 25th np.var( xs ) # variance np.std( xs ) # standard deviation, the square root of the variance np.sort( xs ) # data in increasing order np.sum( xs ) # sum, or total . | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-summary-statistics-in-python-using-pandas-and-numpy/#solution",
    "relUrl": "/how-to-compute-summary-statistics-in-python-using-pandas-and-numpy/#solution"
  },"379": {
    "doc": "How to compute summary statistics (in R)",
    "title": "How to compute summary statistics (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-summary-statistics-in-r/",
    "relUrl": "/how-to-compute-summary-statistics-in-r/"
  },"380": {
    "doc": "How to compute summary statistics (in R)",
    "title": "Task",
    "content": "The phrase “summary statistics” usually refers to a common set of simple computations that can be done about any dataset, including mean, median, variance, and some of the others shown below. Related tasks: . | How to summarize a column | How to summarize and compare data by groups | . ",
    "url": "/how-to-compute-summary-statistics-in-r/#task",
    "relUrl": "/how-to-compute-summary-statistics-in-r/#task"
  },"381": {
    "doc": "How to compute summary statistics (in R)",
    "title": "Solution",
    "content": "We first load a famous dataset, Fisher’s irises, just to have some example data to use in the code that follows. (See how to quickly load some sample data.) . | 1 2 . | library(datasets) data(iris) . | . How big is the dataset? The output shows number of rows then number of columns. | 1 . | dim(iris) # Short for \"dimensions.\" . | . | 1 . | [1] 150 5 . | . What are the columns and their data types? Can I see a sample of each column? . | 1 . | str(iris) # Short for \"structure.\" . | . | 1 2 3 4 5 6 . | 'data.frame': 150 obs. of 5 variables: $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... $ Species : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ... | . What do the first few rows look like? . | 1 . | head(iris) # Gives 5 rows by default. You can do head(iris,10), etc. | . | 1 2 3 4 5 6 7 . | Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa . | . The easiest way to get summary statistics for an R data.frame is with the summary function. | 1 . | summary(iris) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | Sepal.Length Sepal.Width Petal.Length Petal.Width Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 Median :5.800 Median :3.000 Median :4.350 Median :1.300 Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 Species setosa :50 versicolor:50 virginica :50 . | . The columns from the original dataset are the column headings in the summary output, and the statistics computed for each are listed below those headings. We can also compute these statistics (and others) one at a time for any given set of data points. Here, we let xs be one column from the above data.frame but you could use any vector or list. | 1 2 3 4 5 6 7 8 9 . | xs &lt;- iris$Sepal.Length mean( xs ) # mean, or average, or center of mass median( xs ) # 50th percentile quantile( xs, 0.25 ) # compute any percentile, such as the 25th var( xs ) # variance sd( xs ) # standard deviation, the square root of the variance sort( xs ) # data in increasing order sum( xs ) # sum, or total . | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-summary-statistics-in-r/#solution",
    "relUrl": "/how-to-compute-summary-statistics-in-r/#solution"
  },"382": {
    "doc": "How to compute summary statistics",
    "title": "How to compute summary statistics",
    "content": " ",
    "url": "/how-to-compute-summary-statistics/",
    "relUrl": "/how-to-compute-summary-statistics/"
  },"383": {
    "doc": "How to compute summary statistics",
    "title": "Description",
    "content": "The phrase “summary statistics” usually refers to a common set of simple computations that can be done about any dataset, including mean, median, variance, and some of the others shown below. Related tasks: . | How to summarize a column | How to summarize and compare data by groups | . ",
    "url": "/how-to-compute-summary-statistics/#description",
    "relUrl": "/how-to-compute-summary-statistics/#description"
  },"384": {
    "doc": "How to compute summary statistics",
    "title": "Solution, in Excel",
    "content": "View this solution alone. Let’s assume you have some data in an Excel workbook. We show the first 10 rows the famous example dataset “iris” below, but we assume you are applying what we cover here to your own real data. To compute descriptive statistics, you will need the Data Analysis Toolpak. If you’ve never enabled it before, see these instructions from Microsoft on how to do so. On the Data tab, click the Data Analysis button, shown below. From the list of tools it provides, choose Descriptive Statistics, as shown below, then click OK. Highlight as input only the numeric columns in your data, because the Data Analysis Toolpak cannot summarize other kinds of input. (Do not include column headers in your selection.) Then check the “Summary statistics” checkbox, as shown below. Then click OK. Excel will create a new sheet that reports the mean, median, variance, and more, for each column, as shown below. To get a report of the unique values in your column and the frequency of each, you can use a pivot table. Place your cursor anywhere in your data, then on the Insert tab, choose Pivot Table, as shown below. Drag any column’s name from the list of pivot table fields down into both the Rows and Values areas, as shown below. If the column is numeric, then in the drop-down under Values, choose “Value field settings…” and change Sum to Count, then click OK. This is not necessary for non-numeric columns. (See how to summarize a column for an example.) . Your pivot table will now contain the desired report. In the iris dataset used in this example, there were precisely 50 observations of each variety. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-summary-statistics/#solution-in-excel",
    "relUrl": "/how-to-compute-summary-statistics/#solution-in-excel"
  },"385": {
    "doc": "How to compute summary statistics",
    "title": "Solution, in Julia",
    "content": "View this solution alone. We first load a famous dataset, Fisher’s irises, just to have some example data to use in the code that follows. (See how to quickly load some sample data.) . | 1 2 . | using RDatasets iris = dataset( \"datasets\", \"iris\" ); . | . How big is the dataset? The output shows number of rows then number of columns. | 1 . | size( iris ) . | . | 1 . | (150, 5) . | . What are the columns and their data types? The following command shows the first 5 rows, plus the column names and types. | 1 . | first( iris, 5 ) . | . 5×5 DataFrame | Row | SepalLength | SepalWidth | PetalLength | PetalWidth | Species | . | | Float64 | Float64 | Float64 | Float64 | Cat… | . | 1 | 5.1 | 3.5 | 1.4 | 0.2 | setosa | . | 2 | 4.9 | 3.0 | 1.4 | 0.2 | setosa | . | 3 | 4.7 | 3.2 | 1.3 | 0.2 | setosa | . | 4 | 4.6 | 3.1 | 1.5 | 0.2 | setosa | . | 5 | 5.0 | 3.6 | 1.4 | 0.2 | setosa | . Are any values missing? The following command answers that question, plus provides summary statistics, and the same data type information from above. | 1 . | describe( iris ) . | . 5×7 DataFrame | Row | variable | mean | min | median | max | nmissing | eltype | . | | Symbol | Union… | Any | Union… | Any | Int64 | DataType | . | 1 | SepalLength | 5.84333 | 4.3 | 5.8 | 7.9 | 0 | Float64 | . | 2 | SepalWidth | 3.05733 | 2.0 | 3.0 | 4.4 | 0 | Float64 | . | 3 | PetalLength | 3.758 | 1.0 | 4.35 | 6.9 | 0 | Float64 | . | 4 | PetalWidth | 1.19933 | 0.1 | 1.3 | 2.5 | 0 | Float64 | . | 5 | Species | | setosa | | virginica | 0 | CategoricalValue{String, UInt8} | . The individual statistics are the column headings, and the numeric columns from the original dataset are listed under the “Symbol” heading. We can also compute these statistics (and others) one at a time for any given set of data points. Here, we let xs be one column from the above DataFrame, but you could use any array or DataFrame instead. | 1 2 3 4 5 6 7 8 9 10 11 . | xs = iris.\"SepalLength\" using Statistics mean( xs ) # mean, or average, or center of mass median( xs ) # 50th percentile quantile!( xs, 0.25 ) # compute any percentile, such as the 25th var( xs ) # variance std( xs ) # standard deviation, the square root of the variance sort( xs ) # data in increasing order sum( xs ) # sum, or total . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-summary-statistics/#solution-in-julia",
    "relUrl": "/how-to-compute-summary-statistics/#solution-in-julia"
  },"386": {
    "doc": "How to compute summary statistics",
    "title": "Using pandas and NumPy, in Python",
    "content": "View this solution alone. We first load a famous dataset, Fisher’s irises, just to have some example data to use in the code that follows. (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data( 'iris' ) . | . How big is the dataset? The output shows number of rows then number of columns. | 1 . | df.shape . | . | 1 . | (150, 5) . | . What are the columns and their data types? Are any values missing? . | 1 . | df.info() . | . | 1 2 3 4 5 6 7 8 9 10 11 12 . | &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 150 entries, 0 to 149 Data columns (total 5 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Sepal.Length 150 non-null float64 1 Sepal.Width 150 non-null float64 2 Petal.Length 150 non-null float64 3 Petal.Width 150 non-null float64 4 Species 150 non-null object dtypes: float64(4), object(1) memory usage: 6.0+ KB . | . What do the first few rows look like? . | 1 . | df.head() # Default is 5, but you can do df.head(20) or any number. | . | | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species | . | 0 | 5.1 | 3.5 | 1.4 | 0.2 | setosa | . | 1 | 4.9 | 3.0 | 1.4 | 0.2 | setosa | . | 2 | 4.7 | 3.2 | 1.3 | 0.2 | setosa | . | 3 | 4.6 | 3.1 | 1.5 | 0.2 | setosa | . | 4 | 5.0 | 3.6 | 1.4 | 0.2 | setosa | . The easiest way to get summary statistics for a pandas DataFrame is with the describe function. | 1 . | df.describe() . | . | | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | . | count | 150.000000 | 150.000000 | 150.000000 | 150.000000 | . | mean | 5.843333 | 3.057333 | 3.758000 | 1.199333 | . | std | 0.828066 | 0.435866 | 1.765298 | 0.762238 | . | min | 4.300000 | 2.000000 | 1.000000 | 0.100000 | . | 25% | 5.100000 | 2.800000 | 1.600000 | 0.300000 | . | 50% | 5.800000 | 3.000000 | 4.350000 | 1.300000 | . | 75% | 6.400000 | 3.300000 | 5.100000 | 1.800000 | . | max | 7.900000 | 4.400000 | 6.900000 | 2.500000 | . The individual statistics are the row headings, and the numeric columns from the original dataset are listed across the top. We can also compute these statistics (and others) one at a time for any given set of data points. Here, we let xs be one column from the above DataFrame, but you could use any NumPy array or pandas DataFrame instead. | 1 2 3 4 5 6 7 8 9 10 11 . | xs = df['Sepal.Length'] import numpy as np np.mean( xs ) # mean, or average, or center of mass np.median( xs ) # 50th percentile np.percentile( xs, 25 ) # compute any percentile, such as the 25th np.var( xs ) # variance np.std( xs ) # standard deviation, the square root of the variance np.sort( xs ) # data in increasing order np.sum( xs ) # sum, or total . | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-summary-statistics/#using-pandas-and-numpy-in-python",
    "relUrl": "/how-to-compute-summary-statistics/#using-pandas-and-numpy-in-python"
  },"387": {
    "doc": "How to compute summary statistics",
    "title": "Solution, in R",
    "content": "View this solution alone. We first load a famous dataset, Fisher’s irises, just to have some example data to use in the code that follows. (See how to quickly load some sample data.) . | 1 2 . | library(datasets) data(iris) . | . How big is the dataset? The output shows number of rows then number of columns. | 1 . | dim(iris) # Short for \"dimensions.\" . | . | 1 . | [1] 150 5 . | . What are the columns and their data types? Can I see a sample of each column? . | 1 . | str(iris) # Short for \"structure.\" . | . | 1 2 3 4 5 6 . | 'data.frame': 150 obs. of 5 variables: $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... $ Species : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ... | . What do the first few rows look like? . | 1 . | head(iris) # Gives 5 rows by default. You can do head(iris,10), etc. | . | 1 2 3 4 5 6 7 . | Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa . | . The easiest way to get summary statistics for an R data.frame is with the summary function. | 1 . | summary(iris) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | Sepal.Length Sepal.Width Petal.Length Petal.Width Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 Median :5.800 Median :3.000 Median :4.350 Median :1.300 Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 Species setosa :50 versicolor:50 virginica :50 . | . The columns from the original dataset are the column headings in the summary output, and the statistics computed for each are listed below those headings. We can also compute these statistics (and others) one at a time for any given set of data points. Here, we let xs be one column from the above data.frame but you could use any vector or list. | 1 2 3 4 5 6 7 8 9 . | xs &lt;- iris$Sepal.Length mean( xs ) # mean, or average, or center of mass median( xs ) # 50th percentile quantile( xs, 0.25 ) # compute any percentile, such as the 25th var( xs ) # variance sd( xs ) # standard deviation, the square root of the variance sort( xs ) # data in increasing order sum( xs ) # sum, or total . | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-summary-statistics/#solution-in-r",
    "relUrl": "/how-to-compute-summary-statistics/#solution-in-r"
  },"388": {
    "doc": "How to compute summary statistics",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | Bentley University MA255 | Bentley University MA346 | . ",
    "url": "/how-to-compute-summary-statistics/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-summary-statistics/#topics-that-include-this-task"
  },"389": {
    "doc": "How to compute the derivative of a function (in Python, using SymPy)",
    "title": "How to compute the derivative of a function (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-derivative-of-a-function-in-python-using-sympy/",
    "relUrl": "/how-to-compute-the-derivative-of-a-function-in-python-using-sympy/"
  },"390": {
    "doc": "How to compute the derivative of a function (in Python, using SymPy)",
    "title": "Task",
    "content": "Given a mathematical function $f(x)$, we write $f’(x)$ or $\\frac{d}{dx}f(x)$ to represent its derivative, or the rate of change of $f$ with respect to $x$. How can we compute $f’(x)$ using mathematical software? . ",
    "url": "/how-to-compute-the-derivative-of-a-function-in-python-using-sympy/#task",
    "relUrl": "/how-to-compute-the-derivative-of-a-function-in-python-using-sympy/#task"
  },"391": {
    "doc": "How to compute the derivative of a function (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . In SymPy, we tend to work with formulas (that is, mathematical expressions) rather than functions (like $f(x)$). So if we wish to compute the derivative of $f(x)=10x^2-16x+1$, we will focus on just the $10x^2-16x+1$ portion. | 1 2 3 . | var( 'x' ) formula = 10*x**2 - 16*x + 1 formula . | . $\\displaystyle 10 x^{2} - 16 x + 1$ . We can compute its derivative by using the diff function. | 1 . | diff( formula ) . | . $\\displaystyle 20 x - 16$ . If it had been a multi-variable function, we would need to specify the variable with respect to which we wanted to compute a derivative. | 1 2 3 . | var( 'y' ) # introduce a new variable formula2 = x**2 - y**2 # consider the formula x^2 + y^2 diff( formula2, y ) # differentiate with respect to y . | . $\\displaystyle - 2 y$ . We can compute second or third derivatives by repeating the variable with respect to which we’re differentiating. To do partial derivatives, use multiple variables. | 1 . | diff( formula, x, x ) # second derivative with respect to x . | . $\\displaystyle 20$ . | 1 . | diff( formula2, x, y ) # mixed partial derivative . | . $\\displaystyle 0$ . Content last modified on 31 August 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-the-derivative-of-a-function-in-python-using-sympy/#solution",
    "relUrl": "/how-to-compute-the-derivative-of-a-function-in-python-using-sympy/#solution"
  },"392": {
    "doc": "How to compute the derivative of a function (in R)",
    "title": "How to compute the derivative of a function (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-derivative-of-a-function-in-r/",
    "relUrl": "/how-to-compute-the-derivative-of-a-function-in-r/"
  },"393": {
    "doc": "How to compute the derivative of a function (in R)",
    "title": "Task",
    "content": "Given a mathematical function $f(x)$, we write $f’(x)$ or $\\frac{d}{dx}f(x)$ to represent its derivative, or the rate of change of $f$ with respect to $x$. How can we compute $f’(x)$ using mathematical software? . ",
    "url": "/how-to-compute-the-derivative-of-a-function-in-r/#task",
    "relUrl": "/how-to-compute-the-derivative-of-a-function-in-r/#task"
  },"394": {
    "doc": "How to compute the derivative of a function (in R)",
    "title": "Solution",
    "content": "Let’s consider the function $f(x)=10x^2-16x+1$. We focus not on the whole function, but just the expression on the right-hand side, $10x^2-16x+1$. | 1 . | formula &lt;- expression( 10*x^2 - 16*x + 1 ) . | . We can compute its derivative using the D function. | 1 . | D( formula, \"x\" ) # derivative with respect to x . | . | 1 . | 10 * (2 * x) - 16 . | . R does not simplify the output, but if we do so ourselves, we find that $f’(x)=20x-16$. If it had been a multi-variable function, we would need to specify the variable with respect to which we wanted to compute a derivative. | 1 2 . | formula2 &lt;- expression( x^2-y^2 ) # consider the formula x^2 - y^2 D( formula2, \"y\" ) # differentiate with respect to y . | . | 1 . | -(2 * y) . | . That output says that $\\frac{\\partial}{\\partial y}(x^2-y^2)=-2y$. We can compute the second derivative by using the D function twice and specifying the variables with respect to which we are computing the derivative. | 1 . | D( D( formula2, \"x\" ), \"x\" ) # second derivative with respect to x . | . | 1 . | [1] 2 . | . | 1 . | D( D( formula2, \"x\" ), \"y\" ) # mixed partial derivative . | . | 1 . | [1] 0 . | . Content last modified on 21 June 2022. See a problem? Tell us or edit the source. Contributed by Debayan Sen (DSEN@bentley.edu) . ",
    "url": "/how-to-compute-the-derivative-of-a-function-in-r/#solution",
    "relUrl": "/how-to-compute-the-derivative-of-a-function-in-r/#solution"
  },"395": {
    "doc": "How to compute the derivative of a function",
    "title": "How to compute the derivative of a function",
    "content": " ",
    "url": "/how-to-compute-the-derivative-of-a-function/",
    "relUrl": "/how-to-compute-the-derivative-of-a-function/"
  },"396": {
    "doc": "How to compute the derivative of a function",
    "title": "Description",
    "content": "Given a mathematical function $f(x)$, we write $f’(x)$ or $\\frac{d}{dx}f(x)$ to represent its derivative, or the rate of change of $f$ with respect to $x$. How can we compute $f’(x)$ using mathematical software? . ",
    "url": "/how-to-compute-the-derivative-of-a-function/#description",
    "relUrl": "/how-to-compute-the-derivative-of-a-function/#description"
  },"397": {
    "doc": "How to compute the derivative of a function",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . In SymPy, we tend to work with formulas (that is, mathematical expressions) rather than functions (like $f(x)$). So if we wish to compute the derivative of $f(x)=10x^2-16x+1$, we will focus on just the $10x^2-16x+1$ portion. | 1 2 3 . | var( 'x' ) formula = 10*x**2 - 16*x + 1 formula . | . $\\displaystyle 10 x^{2} - 16 x + 1$ . We can compute its derivative by using the diff function. | 1 . | diff( formula ) . | . $\\displaystyle 20 x - 16$ . If it had been a multi-variable function, we would need to specify the variable with respect to which we wanted to compute a derivative. | 1 2 3 . | var( 'y' ) # introduce a new variable formula2 = x**2 - y**2 # consider the formula x^2 + y^2 diff( formula2, y ) # differentiate with respect to y . | . $\\displaystyle - 2 y$ . We can compute second or third derivatives by repeating the variable with respect to which we’re differentiating. To do partial derivatives, use multiple variables. | 1 . | diff( formula, x, x ) # second derivative with respect to x . | . $\\displaystyle 20$ . | 1 . | diff( formula2, x, y ) # mixed partial derivative . | . $\\displaystyle 0$ . Content last modified on 31 August 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-derivative-of-a-function/#using-sympy-in-python",
    "relUrl": "/how-to-compute-the-derivative-of-a-function/#using-sympy-in-python"
  },"398": {
    "doc": "How to compute the derivative of a function",
    "title": "Solution, in R",
    "content": "View this solution alone. Let’s consider the function $f(x)=10x^2-16x+1$. We focus not on the whole function, but just the expression on the right-hand side, $10x^2-16x+1$. | 1 . | formula &lt;- expression( 10*x^2 - 16*x + 1 ) . | . We can compute its derivative using the D function. | 1 . | D( formula, \"x\" ) # derivative with respect to x . | . | 1 . | 10 * (2 * x) - 16 . | . R does not simplify the output, but if we do so ourselves, we find that $f’(x)=20x-16$. If it had been a multi-variable function, we would need to specify the variable with respect to which we wanted to compute a derivative. | 1 2 . | formula2 &lt;- expression( x^2-y^2 ) # consider the formula x^2 - y^2 D( formula2, \"y\" ) # differentiate with respect to y . | . | 1 . | -(2 * y) . | . That output says that $\\frac{\\partial}{\\partial y}(x^2-y^2)=-2y$. We can compute the second derivative by using the D function twice and specifying the variables with respect to which we are computing the derivative. | 1 . | D( D( formula2, \"x\" ), \"x\" ) # second derivative with respect to x . | . | 1 . | [1] 2 . | . | 1 . | D( D( formula2, \"x\" ), \"y\" ) # mixed partial derivative . | . | 1 . | [1] 0 . | . Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-derivative-of-a-function/#solution-in-r",
    "relUrl": "/how-to-compute-the-derivative-of-a-function/#solution-in-r"
  },"399": {
    "doc": "How to compute the derivative of a function",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-compute-the-derivative-of-a-function/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-the-derivative-of-a-function/#topics-that-include-this-task"
  },"400": {
    "doc": "How to compute the derivative of a function",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-the-derivative-of-a-function/#opportunities",
    "relUrl": "/how-to-compute-the-derivative-of-a-function/#opportunities"
  },"401": {
    "doc": "How to compute the domain of a function (in Python, using SymPy)",
    "title": "How to compute the domain of a function (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-domain-of-a-function-in-python-using-sympy/",
    "relUrl": "/how-to-compute-the-domain-of-a-function-in-python-using-sympy/"
  },"402": {
    "doc": "How to compute the domain of a function (in Python, using SymPy)",
    "title": "Task",
    "content": "Given a mathematical function $f(x)$, we often want to know the set of $x$ values for which the function is defined. That set is called its domain. How can we compute the domain of $f(x)$ using mathematical software? . ",
    "url": "/how-to-compute-the-domain-of-a-function-in-python-using-sympy/#task",
    "relUrl": "/how-to-compute-the-domain-of-a-function-in-python-using-sympy/#task"
  },"403": {
    "doc": "How to compute the domain of a function (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . We also need to import another tool that SymPy doesn’t pull in by default. | 1 . | from sympy.calculus.util import continuous_domain . | . We can then ask about a function’s domain. We provide the function, the variable we’re asking about, and the set of numbers we’re working inside of. For a simple one-variable function, we’re typically working in just the real numbers. | 1 2 3 . | var( 'x' ) formula = 1 / ( x + 1 ) continuous_domain( formula, x, S.Reals ) . | . $\\displaystyle \\left(-\\infty, -1\\right) \\cup \\left(-1, \\infty\\right)$ . It’s sometimes easier to instead ask where the function is not defined. We can just ask for the complement of the domain. | 1 2 . | domain = continuous_domain( formula, x, S.Reals ) Complement( S.Reals, domain ) . | . $\\displaystyle \\left\\{-1\\right\\}$ . The function is undefined only at $x=-1$. Content last modified on 13 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-the-domain-of-a-function-in-python-using-sympy/#solution",
    "relUrl": "/how-to-compute-the-domain-of-a-function-in-python-using-sympy/#solution"
  },"404": {
    "doc": "How to compute the domain of a function",
    "title": "How to compute the domain of a function",
    "content": " ",
    "url": "/how-to-compute-the-domain-of-a-function/",
    "relUrl": "/how-to-compute-the-domain-of-a-function/"
  },"405": {
    "doc": "How to compute the domain of a function",
    "title": "Description",
    "content": "Given a mathematical function $f(x)$, we often want to know the set of $x$ values for which the function is defined. That set is called its domain. How can we compute the domain of $f(x)$ using mathematical software? . ",
    "url": "/how-to-compute-the-domain-of-a-function/#description",
    "relUrl": "/how-to-compute-the-domain-of-a-function/#description"
  },"406": {
    "doc": "How to compute the domain of a function",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . We also need to import another tool that SymPy doesn’t pull in by default. | 1 . | from sympy.calculus.util import continuous_domain . | . We can then ask about a function’s domain. We provide the function, the variable we’re asking about, and the set of numbers we’re working inside of. For a simple one-variable function, we’re typically working in just the real numbers. | 1 2 3 . | var( 'x' ) formula = 1 / ( x + 1 ) continuous_domain( formula, x, S.Reals ) . | . $\\displaystyle \\left(-\\infty, -1\\right) \\cup \\left(-1, \\infty\\right)$ . It’s sometimes easier to instead ask where the function is not defined. We can just ask for the complement of the domain. | 1 2 . | domain = continuous_domain( formula, x, S.Reals ) Complement( S.Reals, domain ) . | . $\\displaystyle \\left\\{-1\\right\\}$ . The function is undefined only at $x=-1$. Content last modified on 13 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-domain-of-a-function/#using-sympy-in-python",
    "relUrl": "/how-to-compute-the-domain-of-a-function/#using-sympy-in-python"
  },"407": {
    "doc": "How to compute the domain of a function",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-compute-the-domain-of-a-function/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-the-domain-of-a-function/#topics-that-include-this-task"
  },"408": {
    "doc": "How to compute the domain of a function",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-the-domain-of-a-function/#opportunities",
    "relUrl": "/how-to-compute-the-domain-of-a-function/#opportunities"
  },"409": {
    "doc": "How to compute the error bounds on a Taylor approximation (in Python, using SymPy)",
    "title": "How to compute the error bounds on a Taylor approximation (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-error-bounds-on-a-taylor-approximation-in-python-using-sympy/",
    "relUrl": "/how-to-compute-the-error-bounds-on-a-taylor-approximation-in-python-using-sympy/"
  },"410": {
    "doc": "How to compute the error bounds on a Taylor approximation (in Python, using SymPy)",
    "title": "Task",
    "content": "A Taylor series approximation of degree $n$ to the function $f(x)$, centered at the point $x=a$, has an error bounded by the following formula, where $c$ ranges over all points between $x=a$ and the point $x=x_0$ at which we will be applying the approximation. \\[\\frac{|x_0-a|^{n+1}}{(n+1)!}\\max|f^{(n+1)}(c)|\\] How can we compute this error bound using mathematical software? . Related tasks: . | How to compute the Taylor series for a function | . ",
    "url": "/how-to-compute-the-error-bounds-on-a-taylor-approximation-in-python-using-sympy/#task",
    "relUrl": "/how-to-compute-the-error-bounds-on-a-taylor-approximation-in-python-using-sympy/#task"
  },"411": {
    "doc": "How to compute the error bounds on a Taylor approximation (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s create a simple example. We’ll be approximating $f(x)=\\sin x$ centered at $a=0$ with a Taylor series of degree $n=5$. We will be applying our approximation at $x_0=1$. What is the error bound? . | 1 2 3 4 5 . | var( 'x' ) formula = sin(x) a = 0 x_0 = 1 n = 5 . | . We will not ask SymPy to compute the formula exactly, but will instead have it sample a large number of $c$ values from the interval in question, and compute the maximum over those samples. (The exact solution can be too hard for SymPy to compute.) . | 1 2 3 4 5 6 7 8 . | # Get 1000 evenly-spaced c values: cs = [ Min(x_0,a) + abs(x_0-a)*i/1000 for i in range(1001) ] # Create the formula |f^(n+1)(x)|: formula2 = abs( diff( formula, x, n+1 ) ) # Find the max of it on all the 1000 values: m = Max( *[ formula2.subs(x,c) for c in cs ] ) # Compute the error bound: N( abs(x_0-a)**(n+1) / factorial(n+1) * m ) . | . $\\displaystyle 0.00116870970112208$ . The error is at most $0.00116871\\ldots$. Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-the-error-bounds-on-a-taylor-approximation-in-python-using-sympy/#solution",
    "relUrl": "/how-to-compute-the-error-bounds-on-a-taylor-approximation-in-python-using-sympy/#solution"
  },"412": {
    "doc": "How to compute the error bounds on a Taylor approximation",
    "title": "How to compute the error bounds on a Taylor approximation",
    "content": " ",
    "url": "/how-to-compute-the-error-bounds-on-a-taylor-approximation/",
    "relUrl": "/how-to-compute-the-error-bounds-on-a-taylor-approximation/"
  },"413": {
    "doc": "How to compute the error bounds on a Taylor approximation",
    "title": "Description",
    "content": "A Taylor series approximation of degree $n$ to the function $f(x)$, centered at the point $x=a$, has an error bounded by the following formula, where $c$ ranges over all points between $x=a$ and the point $x=x_0$ at which we will be applying the approximation. \\[\\frac{|x_0-a|^{n+1}}{(n+1)!}\\max|f^{(n+1)}(c)|\\] How can we compute this error bound using mathematical software? . Related tasks: . | How to compute the Taylor series for a function | . ",
    "url": "/how-to-compute-the-error-bounds-on-a-taylor-approximation/#description",
    "relUrl": "/how-to-compute-the-error-bounds-on-a-taylor-approximation/#description"
  },"414": {
    "doc": "How to compute the error bounds on a Taylor approximation",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s create a simple example. We’ll be approximating $f(x)=\\sin x$ centered at $a=0$ with a Taylor series of degree $n=5$. We will be applying our approximation at $x_0=1$. What is the error bound? . | 1 2 3 4 5 . | var( 'x' ) formula = sin(x) a = 0 x_0 = 1 n = 5 . | . We will not ask SymPy to compute the formula exactly, but will instead have it sample a large number of $c$ values from the interval in question, and compute the maximum over those samples. (The exact solution can be too hard for SymPy to compute.) . | 1 2 3 4 5 6 7 8 . | # Get 1000 evenly-spaced c values: cs = [ Min(x_0,a) + abs(x_0-a)*i/1000 for i in range(1001) ] # Create the formula |f^(n+1)(x)|: formula2 = abs( diff( formula, x, n+1 ) ) # Find the max of it on all the 1000 values: m = Max( *[ formula2.subs(x,c) for c in cs ] ) # Compute the error bound: N( abs(x_0-a)**(n+1) / factorial(n+1) * m ) . | . $\\displaystyle 0.00116870970112208$ . The error is at most $0.00116871\\ldots$. Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-error-bounds-on-a-taylor-approximation/#using-sympy-in-python",
    "relUrl": "/how-to-compute-the-error-bounds-on-a-taylor-approximation/#using-sympy-in-python"
  },"415": {
    "doc": "How to compute the error bounds on a Taylor approximation",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-compute-the-error-bounds-on-a-taylor-approximation/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-the-error-bounds-on-a-taylor-approximation/#topics-that-include-this-task"
  },"416": {
    "doc": "How to compute the error bounds on a Taylor approximation",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-the-error-bounds-on-a-taylor-approximation/#opportunities",
    "relUrl": "/how-to-compute-the-error-bounds-on-a-taylor-approximation/#opportunities"
  },"417": {
    "doc": "How to compute the limit of a function (in Python, using SymPy)",
    "title": "How to compute the limit of a function (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-limit-of-a-function-in-python-using-sympy/",
    "relUrl": "/how-to-compute-the-limit-of-a-function-in-python-using-sympy/"
  },"418": {
    "doc": "How to compute the limit of a function (in Python, using SymPy)",
    "title": "Task",
    "content": "In mathematics, we write . \\[\\lim_{x\\to a} f(x)\\] to refer to the value that $f$ approaches as $x$ gets close to $a$, called “the limit of $f(x)$ as $x$ approaches $a$.” . How can we use software to compute such limits? . ",
    "url": "/how-to-compute-the-limit-of-a-function-in-python-using-sympy/#task",
    "relUrl": "/how-to-compute-the-limit-of-a-function-in-python-using-sympy/#task"
  },"419": {
    "doc": "How to compute the limit of a function (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Here we define a simple mathematical formula, $\\frac{x^2-x-2}{x-2}$, and compute the limit as $x$ approaches 2. We use SymPy’s built-in limit function, which takes the formula $f(x)$, the variable $x$, and the value $a$. | 1 2 3 . | var( 'x' ) formula = ( x**2 - x - 2 ) / ( x - 2 ) limit( formula, x, 2 ) . | . $\\displaystyle 3$ . You can also compute one-sided limits. For instance, the limit of $\\frac{\\vert x\\vert}{x}$ is $1$ as $x$ approaches 0 from the right, but it is $-1$ as $x$ approaches 0 from the left. | 1 . | limit( abs(x)/x, x, 0, \"-\" ) # \"-\" means from the left . | . $\\displaystyle -1$ . | 1 . | limit( abs(x)/x, x, 0, \"+\" ) # \"+\" means from the right . | . $\\displaystyle 1$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-the-limit-of-a-function-in-python-using-sympy/#solution",
    "relUrl": "/how-to-compute-the-limit-of-a-function-in-python-using-sympy/#solution"
  },"420": {
    "doc": "How to compute the limit of a function",
    "title": "How to compute the limit of a function",
    "content": " ",
    "url": "/how-to-compute-the-limit-of-a-function/",
    "relUrl": "/how-to-compute-the-limit-of-a-function/"
  },"421": {
    "doc": "How to compute the limit of a function",
    "title": "Description",
    "content": "In mathematics, we write . \\[\\lim_{x\\to a} f(x)\\] to refer to the value that $f$ approaches as $x$ gets close to $a$, called “the limit of $f(x)$ as $x$ approaches $a$.” . How can we use software to compute such limits? . ",
    "url": "/how-to-compute-the-limit-of-a-function/#description",
    "relUrl": "/how-to-compute-the-limit-of-a-function/#description"
  },"422": {
    "doc": "How to compute the limit of a function",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Here we define a simple mathematical formula, $\\frac{x^2-x-2}{x-2}$, and compute the limit as $x$ approaches 2. We use SymPy’s built-in limit function, which takes the formula $f(x)$, the variable $x$, and the value $a$. | 1 2 3 . | var( 'x' ) formula = ( x**2 - x - 2 ) / ( x - 2 ) limit( formula, x, 2 ) . | . $\\displaystyle 3$ . You can also compute one-sided limits. For instance, the limit of $\\frac{\\vert x\\vert}{x}$ is $1$ as $x$ approaches 0 from the right, but it is $-1$ as $x$ approaches 0 from the left. | 1 . | limit( abs(x)/x, x, 0, \"-\" ) # \"-\" means from the left . | . $\\displaystyle -1$ . | 1 . | limit( abs(x)/x, x, 0, \"+\" ) # \"+\" means from the right . | . $\\displaystyle 1$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-limit-of-a-function/#using-sympy-in-python",
    "relUrl": "/how-to-compute-the-limit-of-a-function/#using-sympy-in-python"
  },"423": {
    "doc": "How to compute the limit of a function",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-compute-the-limit-of-a-function/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-the-limit-of-a-function/#topics-that-include-this-task"
  },"424": {
    "doc": "How to compute the limit of a function",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-the-limit-of-a-function/#opportunities",
    "relUrl": "/how-to-compute-the-limit-of-a-function/#opportunities"
  },"425": {
    "doc": "How to compute the power of a test comparing two population means (in Python, using statsmodels)",
    "title": "How to compute the power of a test comparing two population means (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-python-using-statsmodels/",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-python-using-statsmodels/"
  },"426": {
    "doc": "How to compute the power of a test comparing two population means (in Python, using statsmodels)",
    "title": "Task",
    "content": "When creating a factorial design, it is important that it has adequate power to detect significant main effects and interaction effects of interest. How can we calculate the power of a two-sample $t$ test that we aim to perform in such a situation? . Related tasks: . | How to choose the sample size in a study with two population means | . ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-python-using-statsmodels/#task"
  },"427": {
    "doc": "How to compute the power of a test comparing two population means (in Python, using statsmodels)",
    "title": "Solution",
    "content": "From statsmodels, we use the solve_power function in the TTestIndPower class. That function embodies a relationship among five variables; you provide any four of them and it will compute the fifth to be consistent with the first four, regarding the two-sample $t$-test you plan to perform. Let’s get started by importing the package and create a TTestIndPower object. | 1 2 . | from statsmodels.stats.power import TTestIndPower analysis = TTestIndPower() . | . For this example, let’s say that: . | You plan to create a balanced $4\\times2$ factorial experiment with 32 subjects. | You expect the effect size for the main effect of factor A to be medium (0.25 according to Cohen’s 1988 text). | You want to know the expected power for the test of a main effect of factor A. | Your significance level is $\\alpha=0.05$. | . We proceed as follows. | 1 2 3 4 5 6 7 . | obs = 32 # number of subjects (or observations) effect = 0.25 # effect size alpha = 0.05 # significance level ratio = 1 # ratio of the number of observations in one sample to the other # We leave power unspecified, so that solve_power will compute it for us: analysis.solve_power( effect_size=effect, power=None, nobs1=obs, ratio=ratio, alpha=alpha ) . | . | 1 . | 0.1662985260871502 . | . The power is 0.1663, which means that the probability of rejecting the null hypothesis when in fact it is false OR the probability of avoiding a Type II error is 0.1663. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-python-using-statsmodels/#solution"
  },"428": {
    "doc": "How to compute the power of a test comparing two population means (in R)",
    "title": "How to compute the power of a test comparing two population means (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-r/",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-r/"
  },"429": {
    "doc": "How to compute the power of a test comparing two population means (in R)",
    "title": "Task",
    "content": "When creating a factorial design, it is important that it has adequate power to detect significant main effects and interaction effects of interest. How can we calculate the power of a two-sample $t$ test that we aim to perform in such a situation? . Related tasks: . | How to choose the sample size in a study with two population means | . ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-r/#task",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-r/#task"
  },"430": {
    "doc": "How to compute the power of a test comparing two population means (in R)",
    "title": "Solution",
    "content": "We use the power.t.test function in R. It embodies a relationship among five variables; you provide any four of them and it will compute the fifth to be consistent with the first four, regarding the two-sample $t$-test you plan . For this example, let’s say that: . | You plan to create a balanced $4\\times2$ factorial experiment with 32 subjects. | You wish to be able to detect a difference | You want to know the expected power for the test of a main effect of factor A. | Your significance level is $\\alpha=0.05$. | . We proceed as follows. | 1 2 3 4 5 6 7 8 9 10 . | # install.packages('pwr') # if you have not already installed it library(pwr) obs &lt;- 32 # number of subjects (or observations) effect &lt;- 0.25 # effect size alpha &lt;- 0.05 # significance level ratio &lt;- 1 # ratio of the number of observations in one sample to the other # We leave power unspecified, so that power.t2n.test will compute it for us: pwr.t2n.test(n1=obs, n2=obs, d=effect, sig.level=alpha, power=NULL) . | . | 1 2 3 4 5 6 7 8 . | t test power calculation n1 = 32 n2 = 32 d = 0.25 sig.level = 0.05 power = 0.1662985 alternative = two.sided . | . The power is 0.1663, which means that the probability of rejecting the null hypothesis when in fact it is false OR the probability of avoiding a Type II error is 0.1663. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-r/#solution",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means-in-r/#solution"
  },"431": {
    "doc": "How to compute the power of a test comparing two population means",
    "title": "How to compute the power of a test comparing two population means",
    "content": " ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/"
  },"432": {
    "doc": "How to compute the power of a test comparing two population means",
    "title": "Description",
    "content": "When creating a factorial design, it is important that it has adequate power to detect significant main effects and interaction effects of interest. How can we calculate the power of a two-sample $t$ test that we aim to perform in such a situation? . Related tasks: . | How to choose the sample size in a study with two population means | . ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/#description",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/#description"
  },"433": {
    "doc": "How to compute the power of a test comparing two population means",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. From statsmodels, we use the solve_power function in the TTestIndPower class. That function embodies a relationship among five variables; you provide any four of them and it will compute the fifth to be consistent with the first four, regarding the two-sample $t$-test you plan to perform. Let’s get started by importing the package and create a TTestIndPower object. | 1 2 . | from statsmodels.stats.power import TTestIndPower analysis = TTestIndPower() . | . For this example, let’s say that: . | You plan to create a balanced $4\\times2$ factorial experiment with 32 subjects. | You expect the effect size for the main effect of factor A to be medium (0.25 according to Cohen’s 1988 text). | You want to know the expected power for the test of a main effect of factor A. | Your significance level is $\\alpha=0.05$. | . We proceed as follows. | 1 2 3 4 5 6 7 . | obs = 32 # number of subjects (or observations) effect = 0.25 # effect size alpha = 0.05 # significance level ratio = 1 # ratio of the number of observations in one sample to the other # We leave power unspecified, so that solve_power will compute it for us: analysis.solve_power( effect_size=effect, power=None, nobs1=obs, ratio=ratio, alpha=alpha ) . | . | 1 . | 0.1662985260871502 . | . The power is 0.1663, which means that the probability of rejecting the null hypothesis when in fact it is false OR the probability of avoiding a Type II error is 0.1663. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/#using-statsmodels-in-python",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/#using-statsmodels-in-python"
  },"434": {
    "doc": "How to compute the power of a test comparing two population means",
    "title": "Solution, in R",
    "content": "View this solution alone. We use the power.t.test function in R. It embodies a relationship among five variables; you provide any four of them and it will compute the fifth to be consistent with the first four, regarding the two-sample $t$-test you plan . For this example, let’s say that: . | You plan to create a balanced $4\\times2$ factorial experiment with 32 subjects. | You wish to be able to detect a difference | You want to know the expected power for the test of a main effect of factor A. | Your significance level is $\\alpha=0.05$. | . We proceed as follows. | 1 2 3 4 5 6 7 8 9 10 . | # install.packages('pwr') # if you have not already installed it library(pwr) obs &lt;- 32 # number of subjects (or observations) effect &lt;- 0.25 # effect size alpha &lt;- 0.05 # significance level ratio &lt;- 1 # ratio of the number of observations in one sample to the other # We leave power unspecified, so that power.t2n.test will compute it for us: pwr.t2n.test(n1=obs, n2=obs, d=effect, sig.level=alpha, power=NULL) . | . | 1 2 3 4 5 6 7 8 . | t test power calculation n1 = 32 n2 = 32 d = 0.25 sig.level = 0.05 power = 0.1662985 alternative = two.sided . | . The power is 0.1663, which means that the probability of rejecting the null hypothesis when in fact it is false OR the probability of avoiding a Type II error is 0.1663. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/#solution-in-r",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/#solution-in-r"
  },"435": {
    "doc": "How to compute the power of a test comparing two population means",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/#topics-that-include-this-task"
  },"436": {
    "doc": "How to compute the power of a test comparing two population means",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/#opportunities",
    "relUrl": "/how-to-compute-the-power-of-a-test-comparing-two-population-means/#opportunities"
  },"437": {
    "doc": "How to compute the residuals of a linear model (in Python, using statsmodels)",
    "title": "How to compute the residuals of a linear model (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model-in-python-using-statsmodels/",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model-in-python-using-statsmodels/"
  },"438": {
    "doc": "How to compute the residuals of a linear model (in Python, using statsmodels)",
    "title": "Task",
    "content": "If a model has been fit to a dataset, the residuals are the differences between the actual data points and the results the model would predict. Given a linear model and a dataset, how can we compute those residuals? . ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model-in-python-using-statsmodels/#task"
  },"439": {
    "doc": "How to compute the residuals of a linear model (in Python, using statsmodels)",
    "title": "Solution",
    "content": "Let’s assume that you’ve already built a linear model similar to the one below. This one uses a small amount of fake data, but it’s just an example. | 1 2 3 4 5 6 7 . | import statsmodels.api as sm xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] xs = sm.add_constant( xs ) reg = sm.OLS( ys, xs ).fit() . | . We can extract the residuals of the model by calling the model’s resid attribute. | 1 . | reg.resid . | . | 1 2 . | array([ 9.16263041, 2.19945659, -9.07249979, -16.79516483, -4.43114302, 6.04718527, 12.88953537]) . | . The result is an array of the residuals for every value in the data set. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. Contributed by Andrew Quagliaroli (aquagliaroli@falcon.bentley.edu) . ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model-in-python-using-statsmodels/#solution"
  },"440": {
    "doc": "How to compute the residuals of a linear model (in R)",
    "title": "How to compute the residuals of a linear model (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model-in-r/",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model-in-r/"
  },"441": {
    "doc": "How to compute the residuals of a linear model (in R)",
    "title": "Task",
    "content": "If a model has been fit to a dataset, the residuals are the differences between the actual data points and the results the model would predict. Given a linear model and a dataset, how can we compute those residuals? . ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model-in-r/#task",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model-in-r/#task"
  },"442": {
    "doc": "How to compute the residuals of a linear model (in R)",
    "title": "Solution",
    "content": "Let’s assume that you’ve already built a linear model similar to the one below. This one uses a small amount of fake data, but it’s just an example. See also how to fit a linear model to two columns of data. | 1 2 3 . | xs &lt;- c( 393, 453, 553, 679, 729, 748, 817 ) ys &lt;- c( 24, 25, 27, 36, 55, 68, 84 ) model &lt;- lm(ys ~ xs) . | . We can extract the residuals of the model in either of two ways. R has a built-in residuals() function for this purpose. | 1 . | residuals(model) . | . | 1 2 . | 1 2 3 4 5 6 7 9.162630 2.199457 -9.072500 -16.795165 -4.431143 6.047185 12.889535 . | . The model itself has a $residuals attribute. | 1 . | model$residuals . | . | 1 2 . | 1 2 3 4 5 6 7 9.162630 2.199457 -9.072500 -16.795165 -4.431143 6.047185 12.889535 . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model-in-r/#solution",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model-in-r/#solution"
  },"443": {
    "doc": "How to compute the residuals of a linear model",
    "title": "How to compute the residuals of a linear model",
    "content": " ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model/",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model/"
  },"444": {
    "doc": "How to compute the residuals of a linear model",
    "title": "Description",
    "content": "If a model has been fit to a dataset, the residuals are the differences between the actual data points and the results the model would predict. Given a linear model and a dataset, how can we compute those residuals? . ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model/#description",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model/#description"
  },"445": {
    "doc": "How to compute the residuals of a linear model",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. Let’s assume that you’ve already built a linear model similar to the one below. This one uses a small amount of fake data, but it’s just an example. | 1 2 3 4 5 6 7 . | import statsmodels.api as sm xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] xs = sm.add_constant( xs ) reg = sm.OLS( ys, xs ).fit() . | . We can extract the residuals of the model by calling the model’s resid attribute. | 1 . | reg.resid . | . | 1 2 . | array([ 9.16263041, 2.19945659, -9.07249979, -16.79516483, -4.43114302, 6.04718527, 12.88953537]) . | . The result is an array of the residuals for every value in the data set. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model/#using-statsmodels-in-python",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model/#using-statsmodels-in-python"
  },"446": {
    "doc": "How to compute the residuals of a linear model",
    "title": "Solution, in R",
    "content": "View this solution alone. Let’s assume that you’ve already built a linear model similar to the one below. This one uses a small amount of fake data, but it’s just an example. See also how to fit a linear model to two columns of data. | 1 2 3 . | xs &lt;- c( 393, 453, 553, 679, 729, 748, 817 ) ys &lt;- c( 24, 25, 27, 36, 55, 68, 84 ) model &lt;- lm(ys ~ xs) . | . We can extract the residuals of the model in either of two ways. R has a built-in residuals() function for this purpose. | 1 . | residuals(model) . | . | 1 2 . | 1 2 3 4 5 6 7 9.162630 2.199457 -9.072500 -16.795165 -4.431143 6.047185 12.889535 . | . The model itself has a $residuals attribute. | 1 . | model$residuals . | . | 1 2 . | 1 2 3 4 5 6 7 9.162630 2.199457 -9.072500 -16.795165 -4.431143 6.047185 12.889535 . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model/#solution-in-r",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model/#solution-in-r"
  },"447": {
    "doc": "How to compute the residuals of a linear model",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model/#topics-that-include-this-task"
  },"448": {
    "doc": "How to compute the residuals of a linear model",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-the-residuals-of-a-linear-model/#opportunities",
    "relUrl": "/how-to-compute-the-residuals-of-a-linear-model/#opportunities"
  },"449": {
    "doc": "How to compute the standard error of the estimate for a model (in Python, using statsmodels)",
    "title": "How to compute the standard error of the estimate for a model (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-python-using-statsmodels/",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-python-using-statsmodels/"
  },"450": {
    "doc": "How to compute the standard error of the estimate for a model (in Python, using statsmodels)",
    "title": "Task",
    "content": "One measure of the goodness of fit of a model is the standard error of its estimates. If the actual values are $y_i$ and the estimates are $\\hat y_i$, the definition of this quantity is as follows, for $n$ data points. \\[\\sigma_{\\text{est}} = \\sqrt{ \\frac{ \\sum (y_i-\\hat y_i)^2 }{ n } }\\] If we’ve fit a linear model, how do we compute the standard error of its estimates? . ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-python-using-statsmodels/#task"
  },"451": {
    "doc": "How to compute the standard error of the estimate for a model (in Python, using statsmodels)",
    "title": "Solution",
    "content": "Let’s assume that you already fit the linear model, as shown in the code below. This one uses a small amount of fake data, but it’s just an example. See also how to fit a linear model to two columns of data. | 1 2 3 4 5 6 7 8 . | # Below is the fake data as an example. You can replace with your real data. x = [ 34, 9, 78, 60, 22, 45, 83, 59, 25 ] y = [ 126, 347, 298, 309, 450, 187, 266, 385, 400 ] # Use statsmodels to build a linear regression model import statsmodels.api as sm x = sm.add_constant( x ) model = sm.OLS( y, x ).fit() . | . The standard error is shown as part of the model summary, reported by statsmodels’s built-in summary function. See the column entitled “std err” in the output below. | 1 . | model.summary() . | . | 1 2 . | /opt/conda/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1772: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=9 warnings.warn(\"kurtosistest only valid for n&gt;=20 ... continuing \" . | . OLS Regression Results | Dep. Variable: | y | R-squared: | 0.063 | . | Model: | OLS | Adj. R-squared: | -0.071 | . | Method: | Least Squares | F-statistic: | 0.4693 | . | Date: | Tue, 08 Nov 2022 | Prob (F-statistic): | 0.515 | . | Time: | 21:56:16 | Log-Likelihood: | -53.705 | . | No. Observations: | 9 | AIC: | 111.4 | . | Df Residuals: | 7 | BIC: | 111.8 | . | Df Model: | 1 | | | . | Covariance Type: | nonrobust | | | . | | coef | std err | t | P&gt;|t| | [0.025 | 0.975] | . | const | 354.0822 | 76.733 | 4.614 | 0.002 | 172.638 | 535.526 | . | x1 | -1.0090 | 1.473 | -0.685 | 0.515 | -4.492 | 2.474 | . | Omnibus: | 2.324 | Durbin-Watson: | 1.618 | . | Prob(Omnibus): | 0.313 | Jarque-Bera (JB): | 1.079 | . | Skew: | -0.832 | Prob(JB): | 0.583 | . | Kurtosis: | 2.674 | Cond. No. | 112. | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. If we need to extract just the estimates or their standard errors, we can use code like the following. | 1 . | model.params # just the model coefficients . | . | 1 . | array([354.0822479 , -1.00901261]) . | . | 1 . | model.bse # just the standard errors of those estimates . | . | 1 . | array([76.73277161, 1.47293931]) . | . The standard error of the estimate for the intercept is is 76.73277161 and the standard error of the estimate for the slope is 1.47293931. Content last modified on 08 November 2022. See a problem? Tell us or edit the source. Contributed by: . | Ni Shi (shi_ni@bentley.edu) | Nathan Carter (ncarter@bentley.edu) | . ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-python-using-statsmodels/#solution"
  },"452": {
    "doc": "How to compute the standard error of the estimate for a model (in R)",
    "title": "How to compute the standard error of the estimate for a model (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-r/",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-r/"
  },"453": {
    "doc": "How to compute the standard error of the estimate for a model (in R)",
    "title": "Task",
    "content": "One measure of the goodness of fit of a model is the standard error of its estimates. If the actual values are $y_i$ and the estimates are $\\hat y_i$, the definition of this quantity is as follows, for $n$ data points. \\[\\sigma_{\\text{est}} = \\sqrt{ \\frac{ \\sum (y_i-\\hat y_i)^2 }{ n } }\\] If we’ve fit a linear model, how do we compute the standard error of its estimates? . ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-r/#task",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-r/#task"
  },"454": {
    "doc": "How to compute the standard error of the estimate for a model (in R)",
    "title": "Solution",
    "content": "Let’s assume that you already fit the linear model, as shown in the code below. This one uses a small amount of fake data, but it’s just an example. See also how to fit a linear model to two columns of data. | 1 2 3 . | x &lt;- c(34, 9, 78, 60, 22, 45, 83, 59, 25) y &lt;- c(126, 347, 298, 309, 450, 187, 266, 385, 400) model &lt;- lm(y ~ x) . | . The standard error for each estimate is shown as part of the model summary, reported by R’s built-in summary function. See the column entitled “Std. Error” in the output below. | 1 . | summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | Call: lm(formula = y ~ x) Residuals: Min 1Q Median 3Q Max -193.776 -4.334 15.459 71.143 118.116 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 354.082 76.733 4.614 0.00244 ** x -1.009 1.473 -0.685 0.51536 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 107.1 on 7 degrees of freedom Multiple R-squared: 0.06283, Adjusted R-squared: -0.07106 F-statistic: 0.4693 on 1 and 7 DF, p-value: 0.5154 . | . If we need to extract just the model coefficients table, or even just the “Std. Error” column of it, we can use code like the following. | 1 2 . | coef(summary(model)) coef(summary(model))[,2] . | . | 1 2 3 4 5 6 7 8 . | Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 354.082248 76.732772 4.6144853 0.002441995 x -1.009013 1.472939 -0.6850334 0.515358250 (Intercept) x 76.732772 1.472939 . | . The standard error of the estimate for the intercept is is 76.733 and the standard error of the estimate for the slope is 1.473. Content last modified on 08 November 2022. See a problem? Tell us or edit the source. Contributed by: . | Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) | Nathan Carter (ncarter@bentley.edu) | . ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-r/#solution",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model-in-r/#solution"
  },"455": {
    "doc": "How to compute the standard error of the estimate for a model",
    "title": "How to compute the standard error of the estimate for a model",
    "content": " ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/"
  },"456": {
    "doc": "How to compute the standard error of the estimate for a model",
    "title": "Description",
    "content": "One measure of the goodness of fit of a model is the standard error of its estimates. If the actual values are $y_i$ and the estimates are $\\hat y_i$, the definition of this quantity is as follows, for $n$ data points. \\[\\sigma_{\\text{est}} = \\sqrt{ \\frac{ \\sum (y_i-\\hat y_i)^2 }{ n } }\\] If we’ve fit a linear model, how do we compute the standard error of its estimates? . ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/#description",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/#description"
  },"457": {
    "doc": "How to compute the standard error of the estimate for a model",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. Let’s assume that you already fit the linear model, as shown in the code below. This one uses a small amount of fake data, but it’s just an example. See also how to fit a linear model to two columns of data. | 1 2 3 4 5 6 7 8 . | # Below is the fake data as an example. You can replace with your real data. x = [ 34, 9, 78, 60, 22, 45, 83, 59, 25 ] y = [ 126, 347, 298, 309, 450, 187, 266, 385, 400 ] # Use statsmodels to build a linear regression model import statsmodels.api as sm x = sm.add_constant( x ) model = sm.OLS( y, x ).fit() . | . The standard error is shown as part of the model summary, reported by statsmodels’s built-in summary function. See the column entitled “std err” in the output below. | 1 . | model.summary() . | . | 1 2 . | /opt/conda/lib/python3.10/site-packages/scipy/stats/_stats_py.py:1772: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=9 warnings.warn(\"kurtosistest only valid for n&gt;=20 ... continuing \" . | . OLS Regression Results | Dep. Variable: | y | R-squared: | 0.063 | . | Model: | OLS | Adj. R-squared: | -0.071 | . | Method: | Least Squares | F-statistic: | 0.4693 | . | Date: | Tue, 08 Nov 2022 | Prob (F-statistic): | 0.515 | . | Time: | 21:56:16 | Log-Likelihood: | -53.705 | . | No. Observations: | 9 | AIC: | 111.4 | . | Df Residuals: | 7 | BIC: | 111.8 | . | Df Model: | 1 | | | . | Covariance Type: | nonrobust | | | . | | coef | std err | t | P&gt;|t| | [0.025 | 0.975] | . | const | 354.0822 | 76.733 | 4.614 | 0.002 | 172.638 | 535.526 | . | x1 | -1.0090 | 1.473 | -0.685 | 0.515 | -4.492 | 2.474 | . | Omnibus: | 2.324 | Durbin-Watson: | 1.618 | . | Prob(Omnibus): | 0.313 | Jarque-Bera (JB): | 1.079 | . | Skew: | -0.832 | Prob(JB): | 0.583 | . | Kurtosis: | 2.674 | Cond. No. | 112. | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. If we need to extract just the estimates or their standard errors, we can use code like the following. | 1 . | model.params # just the model coefficients . | . | 1 . | array([354.0822479 , -1.00901261]) . | . | 1 . | model.bse # just the standard errors of those estimates . | . | 1 . | array([76.73277161, 1.47293931]) . | . The standard error of the estimate for the intercept is is 76.73277161 and the standard error of the estimate for the slope is 1.47293931. Content last modified on 08 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/#using-statsmodels-in-python",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/#using-statsmodels-in-python"
  },"458": {
    "doc": "How to compute the standard error of the estimate for a model",
    "title": "Solution, in R",
    "content": "View this solution alone. Let’s assume that you already fit the linear model, as shown in the code below. This one uses a small amount of fake data, but it’s just an example. See also how to fit a linear model to two columns of data. | 1 2 3 . | x &lt;- c(34, 9, 78, 60, 22, 45, 83, 59, 25) y &lt;- c(126, 347, 298, 309, 450, 187, 266, 385, 400) model &lt;- lm(y ~ x) . | . The standard error for each estimate is shown as part of the model summary, reported by R’s built-in summary function. See the column entitled “Std. Error” in the output below. | 1 . | summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | Call: lm(formula = y ~ x) Residuals: Min 1Q Median 3Q Max -193.776 -4.334 15.459 71.143 118.116 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 354.082 76.733 4.614 0.00244 ** x -1.009 1.473 -0.685 0.51536 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 107.1 on 7 degrees of freedom Multiple R-squared: 0.06283, Adjusted R-squared: -0.07106 F-statistic: 0.4693 on 1 and 7 DF, p-value: 0.5154 . | . If we need to extract just the model coefficients table, or even just the “Std. Error” column of it, we can use code like the following. | 1 2 . | coef(summary(model)) coef(summary(model))[,2] . | . | 1 2 3 4 5 6 7 8 . | Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 354.082248 76.732772 4.6144853 0.002441995 x -1.009013 1.472939 -0.6850334 0.515358250 (Intercept) x 76.732772 1.472939 . | . The standard error of the estimate for the intercept is is 76.733 and the standard error of the estimate for the slope is 1.473. Content last modified on 08 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/#solution-in-r",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/#solution-in-r"
  },"459": {
    "doc": "How to compute the standard error of the estimate for a model",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/#topics-that-include-this-task"
  },"460": {
    "doc": "How to compute the standard error of the estimate for a model",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/#opportunities",
    "relUrl": "/how-to-compute-the-standard-error-of-the-estimate-for-a-model/#opportunities"
  },"461": {
    "doc": "How to compute the Taylor series for a function (in Python, using SymPy)",
    "title": "How to compute the Taylor series for a function (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-compute-the-taylor-series-for-a-function-in-python-using-sympy/",
    "relUrl": "/how-to-compute-the-taylor-series-for-a-function-in-python-using-sympy/"
  },"462": {
    "doc": "How to compute the Taylor series for a function (in Python, using SymPy)",
    "title": "Task",
    "content": "Any function that has arbitrarily many derivatives at a given point can have a Taylor series computed for the function centered at that point. How can we ask symbolic mathematics software to do this for us? . Related tasks: . | How to compute the error bounds on a Taylor approximation | . ",
    "url": "/how-to-compute-the-taylor-series-for-a-function-in-python-using-sympy/#task",
    "relUrl": "/how-to-compute-the-taylor-series-for-a-function-in-python-using-sympy/#task"
  },"463": {
    "doc": "How to compute the Taylor series for a function (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s define an example function whose Taylor series we’d like to compute. | 1 2 3 . | var( 'x' ) formula = exp( 2*x + 1 ) formula . | . $\\displaystyle e^{2 x + 1}$ . Let’s ask for a degree-5 Taylor series centered at $x=2$. From the code below, you can tell that the third parameter is the center point and the fourth parameter is the degree. | 1 . | series( formula, x, 2, 5 ) . | . $\\displaystyle e^{5} + 2 \\left(x - 2\\right) e^{5} + 2 \\left(x - 2\\right)^{2} e^{5} + \\frac{4 \\left(x - 2\\right)^{3} e^{5}}{3} + \\frac{2 \\left(x - 2\\right)^{4} e^{5}}{3} + O\\left(\\left(x - 2\\right)^{5}; x\\rightarrow 2\\right)$ . The final term (starting with O—oh, not zero) means that there are more terms in the infinite Taylor series not shown in this finite approximation. If you want to show just the approximation, you can tell it to remove the O term. | 1 . | series( formula, x, 2, 5 ).removeO() . | . $\\displaystyle \\frac{2 \\left(x - 2\\right)^{4} e^{5}}{3} + \\frac{4 \\left(x - 2\\right)^{3} e^{5}}{3} + 2 \\left(x - 2\\right)^{2} e^{5} + 2 \\left(x - 2\\right) e^{5} + e^{5}$ . You can also compute individual coefficients in a Taylor series by remembering the formula for the $n^\\text{th}$ term in the series and applying it, as follows. The formula for a series centered on $x=a$ is $\\frac{f^{(n)}(a)}{n!}$. From the answer above, we can see that the coefficient on the $n=3$ term is $\\frac43e^5$. | 1 2 3 . | n = 3 a = 2 diff( formula, x, n ).subs( x, a ) / factorial( n ) . | . $\\displaystyle \\frac{4 e^{5}}{3}$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-compute-the-taylor-series-for-a-function-in-python-using-sympy/#solution",
    "relUrl": "/how-to-compute-the-taylor-series-for-a-function-in-python-using-sympy/#solution"
  },"464": {
    "doc": "How to compute the Taylor series for a function",
    "title": "How to compute the Taylor series for a function",
    "content": " ",
    "url": "/how-to-compute-the-taylor-series-for-a-function/",
    "relUrl": "/how-to-compute-the-taylor-series-for-a-function/"
  },"465": {
    "doc": "How to compute the Taylor series for a function",
    "title": "Description",
    "content": "Any function that has arbitrarily many derivatives at a given point can have a Taylor series computed for the function centered at that point. How can we ask symbolic mathematics software to do this for us? . Related tasks: . | How to compute the error bounds on a Taylor approximation | . ",
    "url": "/how-to-compute-the-taylor-series-for-a-function/#description",
    "relUrl": "/how-to-compute-the-taylor-series-for-a-function/#description"
  },"466": {
    "doc": "How to compute the Taylor series for a function",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s define an example function whose Taylor series we’d like to compute. | 1 2 3 . | var( 'x' ) formula = exp( 2*x + 1 ) formula . | . $\\displaystyle e^{2 x + 1}$ . Let’s ask for a degree-5 Taylor series centered at $x=2$. From the code below, you can tell that the third parameter is the center point and the fourth parameter is the degree. | 1 . | series( formula, x, 2, 5 ) . | . $\\displaystyle e^{5} + 2 \\left(x - 2\\right) e^{5} + 2 \\left(x - 2\\right)^{2} e^{5} + \\frac{4 \\left(x - 2\\right)^{3} e^{5}}{3} + \\frac{2 \\left(x - 2\\right)^{4} e^{5}}{3} + O\\left(\\left(x - 2\\right)^{5}; x\\rightarrow 2\\right)$ . The final term (starting with O—oh, not zero) means that there are more terms in the infinite Taylor series not shown in this finite approximation. If you want to show just the approximation, you can tell it to remove the O term. | 1 . | series( formula, x, 2, 5 ).removeO() . | . $\\displaystyle \\frac{2 \\left(x - 2\\right)^{4} e^{5}}{3} + \\frac{4 \\left(x - 2\\right)^{3} e^{5}}{3} + 2 \\left(x - 2\\right)^{2} e^{5} + 2 \\left(x - 2\\right) e^{5} + e^{5}$ . You can also compute individual coefficients in a Taylor series by remembering the formula for the $n^\\text{th}$ term in the series and applying it, as follows. The formula for a series centered on $x=a$ is $\\frac{f^{(n)}(a)}{n!}$. From the answer above, we can see that the coefficient on the $n=3$ term is $\\frac43e^5$. | 1 2 3 . | n = 3 a = 2 diff( formula, x, n ).subs( x, a ) / factorial( n ) . | . $\\displaystyle \\frac{4 e^{5}}{3}$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-compute-the-taylor-series-for-a-function/#using-sympy-in-python",
    "relUrl": "/how-to-compute-the-taylor-series-for-a-function/#using-sympy-in-python"
  },"467": {
    "doc": "How to compute the Taylor series for a function",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-compute-the-taylor-series-for-a-function/#topics-that-include-this-task",
    "relUrl": "/how-to-compute-the-taylor-series-for-a-function/#topics-that-include-this-task"
  },"468": {
    "doc": "How to compute the Taylor series for a function",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-compute-the-taylor-series-for-a-function/#opportunities",
    "relUrl": "/how-to-compute-the-taylor-series-for-a-function/#opportunities"
  },"469": {
    "doc": "How to conduct a mixed designs ANOVA (in Python, using pandas and pingouin)",
    "title": "How to conduct a mixed designs ANOVA (in Python, using pandas and pingouin)",
    "content": "See all solutions. ",
    "url": "/how-to-conduct-a-mixed-designs-anova-in-python-using-pandas-and-pingouin/",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova-in-python-using-pandas-and-pingouin/"
  },"470": {
    "doc": "How to conduct a mixed designs ANOVA (in Python, using pandas and pingouin)",
    "title": "Task",
    "content": "When you have a dataset that includes the responses of a mixed design test, where one factor is a within-subjects factor and the other is a between-subjects factor, and you wish check if there is a significant difference for both factors, this requires a Mixed Design ANOVA. How can we conduct one? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-conduct-a-mixed-designs-anova-in-python-using-pandas-and-pingouin/#task",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova-in-python-using-pandas-and-pingouin/#task"
  },"471": {
    "doc": "How to conduct a mixed designs ANOVA (in Python, using pandas and pingouin)",
    "title": "Solution",
    "content": "We create the data for a hypothetical $2\\times2$ mixed design with the following attributes. | Between-subjects treatment factor: Type of music played (classical vs. rock) | Within-subjects treatment factor: Type of room (light vs. no light) | Outcome variable: Heart rate of subject | . | 1 2 3 4 5 6 7 8 9 10 11 12 . | import pandas as pd df = pd.DataFrame( { 'Subject' : [1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10], 'Music' : ['Classical','Rock','Classical','Rock','Classical','Rock','Classical', 'Rock','Classical','Rock','Classical','Rock','Classical','Rock','Classical', 'Rock','Classical','Rock','Classical','Rock'], 'Room Type' : ['Light','Light','Light','Light','Light','Light','Light','Light','Light', 'Light','No Light','No Light','No Light','No Light','No Light','No Light', 'No Light','No Light','No Light','No Light'], 'Heart Rate' : [78,60,85,75,99,94,75,84,100,76,90,109,99,94,113,92,91,88,89,90] } ) df.head() . | . | | Subject | Music | Room Type | Heart Rate | . | 0 | 1 | Classical | Light | 78 | . | 1 | 2 | Rock | Light | 60 | . | 2 | 3 | Classical | Light | 85 | . | 3 | 4 | Rock | Light | 75 | . | 4 | 5 | Classical | Light | 99 | . We will use the pingouin statistics package to conduct a two-way mixed-design ANOVA. The parameters are as follows: . | dv: name of the column containing the dependant variable | within: name of the column containing the within-group factor | between: name of the column containing the between-group factor | subject: name of the column identifying each subject | data: the pandas DataFrame containing all the data | . | 1 2 . | import pingouin as pg pg.mixed_anova( dv='Heart Rate', within='Room Type', between='Music', subject='Subject', data=df ) . | . | | Source | SS | DF1 | DF2 | MS | F | p-unc | np2 | eps | . | 0 | Music | 162.45 | 1 | 8 | 162.45 | 1.586813 | 0.243288 | 0.165520 | NaN | . | 1 | Room Type | 832.05 | 1 | 8 | 832.05 | 6.416426 | 0.035088 | 0.445077 | 1.0 | . | 2 | Interaction | 76.05 | 1 | 8 | 76.05 | 0.586466 | 0.465781 | 0.068301 | NaN | . The output informs us that, on average, the subjects that listened to classical music did not significantly differ ($p = 0.243288 &gt; 0.05$) from those that listened to rock music. However, there is, on average, a significant difference ($p = 0.035088 &lt; 0.05$) between each of the subject’s heart rate when put in a room with or without light. Additionally, since the interaction term is not significant ($p = 0.465781 &gt; 0.05$), we can use the additive (no interaction) model. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-conduct-a-mixed-designs-anova-in-python-using-pandas-and-pingouin/#solution",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova-in-python-using-pandas-and-pingouin/#solution"
  },"472": {
    "doc": "How to conduct a mixed designs ANOVA (in R)",
    "title": "How to conduct a mixed designs ANOVA (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-conduct-a-mixed-designs-anova-in-r/",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova-in-r/"
  },"473": {
    "doc": "How to conduct a mixed designs ANOVA (in R)",
    "title": "Task",
    "content": "When you have a dataset that includes the responses of a mixed design test, where one factor is a within-subjects factor and the other is a between-subjects factor, and you wish check if there is a significant difference for both factors, this requires a Mixed Design ANOVA. How can we conduct one? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-conduct-a-mixed-designs-anova-in-r/#task",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova-in-r/#task"
  },"474": {
    "doc": "How to conduct a mixed designs ANOVA (in R)",
    "title": "Solution",
    "content": "We create the data for a hypothetical $2\\times2$ mixed design with the following attributes. | Between-subjects treatment factor: Type of music played (classical vs. rock) | Within-subjects treatment factor: Type of room (light vs. no light) | Outcome variable: Heart rate of subject | . | 1 2 3 4 5 6 7 8 9 10 . | subject &lt;- as.factor(c(1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10)) music &lt;- c('Classical','Rock','Classical','Rock','Classical','Rock','Classical', 'Rock','Classical','Rock','Classical','Rock','Classical','Rock','Classical', 'Rock','Classical','Rock','Classical','Rock') room.type &lt;- c('Light','Light','Light','Light','Light','Light','Light','Light','Light', 'Light','No Light','No Light','No Light','No Light','No Light','No Light', 'No Light','No Light','No Light', 'No Light') heart.rate &lt;- c(78,60,85,75,99,94,75,84,100,76,90,109,99,94,113,92,91,88,89,90) df &lt;- data.frame(subject,music,room.type,heart.rate) head(df) . | . | 1 2 3 4 5 6 7 . | subject music room.type heart.rate 1 1 Classical Light 78 2 2 Rock Light 60 3 3 Classical Light 85 4 4 Rock Light 75 5 5 Classical Light 99 6 6 Rock Light 94 . | . We conduct a two-way mixed-design ANOVA as shown below. The specific parameters have these meanings: . | The dependent variable is heart.rate. | The within-group factor is room.type. | The between-group factor is music. | The Error() term is critical in differentiating between a between subjects and within subjects model. It tells R that there is one observation per subject for each level of room.type. | . | 1 2 . | aov_mixed &lt;- aov(heart.rate ~ room.type*music + Error(subject/room.type), data=df) summary(aov_mixed) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 . | Error: subject Df Sum Sq Mean Sq F value Pr(&gt;F) music 1 162.4 162.4 1.587 0.243 Residuals 8 819.0 102.4 Error: subject:room.type Df Sum Sq Mean Sq F value Pr(&gt;F) room.type 1 832.1 832.1 6.416 0.0351 * room.type:music 1 76.0 76.0 0.586 0.4658 Residuals 8 1037.4 129.7 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The output informs us that, on average, the subjects that listened to classical music did not significantly differ ($p = 0.243 &gt; 0.05$) from those that listened to rock music. However, there is, on average, a significant difference ($p = 0.0351 &lt; 0.05$) between each of the subject’s heart rate when put in a room with or without light. Additionally, since the interaction term is not significant ($p = 0.4658 &gt; 0.05$), we can use the additive (no interaction) model. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-conduct-a-mixed-designs-anova-in-r/#solution",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova-in-r/#solution"
  },"475": {
    "doc": "How to conduct a mixed designs ANOVA",
    "title": "How to conduct a mixed designs ANOVA",
    "content": " ",
    "url": "/how-to-conduct-a-mixed-designs-anova/",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova/"
  },"476": {
    "doc": "How to conduct a mixed designs ANOVA",
    "title": "Description",
    "content": "When you have a dataset that includes the responses of a mixed design test, where one factor is a within-subjects factor and the other is a between-subjects factor, and you wish check if there is a significant difference for both factors, this requires a Mixed Design ANOVA. How can we conduct one? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-conduct-a-mixed-designs-anova/#description",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova/#description"
  },"477": {
    "doc": "How to conduct a mixed designs ANOVA",
    "title": "Using pandas and pingouin, in Python",
    "content": "View this solution alone. We create the data for a hypothetical $2\\times2$ mixed design with the following attributes. | Between-subjects treatment factor: Type of music played (classical vs. rock) | Within-subjects treatment factor: Type of room (light vs. no light) | Outcome variable: Heart rate of subject | . | 1 2 3 4 5 6 7 8 9 10 11 12 . | import pandas as pd df = pd.DataFrame( { 'Subject' : [1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10], 'Music' : ['Classical','Rock','Classical','Rock','Classical','Rock','Classical', 'Rock','Classical','Rock','Classical','Rock','Classical','Rock','Classical', 'Rock','Classical','Rock','Classical','Rock'], 'Room Type' : ['Light','Light','Light','Light','Light','Light','Light','Light','Light', 'Light','No Light','No Light','No Light','No Light','No Light','No Light', 'No Light','No Light','No Light','No Light'], 'Heart Rate' : [78,60,85,75,99,94,75,84,100,76,90,109,99,94,113,92,91,88,89,90] } ) df.head() . | . | | Subject | Music | Room Type | Heart Rate | . | 0 | 1 | Classical | Light | 78 | . | 1 | 2 | Rock | Light | 60 | . | 2 | 3 | Classical | Light | 85 | . | 3 | 4 | Rock | Light | 75 | . | 4 | 5 | Classical | Light | 99 | . We will use the pingouin statistics package to conduct a two-way mixed-design ANOVA. The parameters are as follows: . | dv: name of the column containing the dependant variable | within: name of the column containing the within-group factor | between: name of the column containing the between-group factor | subject: name of the column identifying each subject | data: the pandas DataFrame containing all the data | . | 1 2 . | import pingouin as pg pg.mixed_anova( dv='Heart Rate', within='Room Type', between='Music', subject='Subject', data=df ) . | . | | Source | SS | DF1 | DF2 | MS | F | p-unc | np2 | eps | . | 0 | Music | 162.45 | 1 | 8 | 162.45 | 1.586813 | 0.243288 | 0.165520 | NaN | . | 1 | Room Type | 832.05 | 1 | 8 | 832.05 | 6.416426 | 0.035088 | 0.445077 | 1.0 | . | 2 | Interaction | 76.05 | 1 | 8 | 76.05 | 0.586466 | 0.465781 | 0.068301 | NaN | . The output informs us that, on average, the subjects that listened to classical music did not significantly differ ($p = 0.243288 &gt; 0.05$) from those that listened to rock music. However, there is, on average, a significant difference ($p = 0.035088 &lt; 0.05$) between each of the subject’s heart rate when put in a room with or without light. Additionally, since the interaction term is not significant ($p = 0.465781 &gt; 0.05$), we can use the additive (no interaction) model. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-conduct-a-mixed-designs-anova/#using-pandas-and-pingouin-in-python",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova/#using-pandas-and-pingouin-in-python"
  },"478": {
    "doc": "How to conduct a mixed designs ANOVA",
    "title": "Solution, in R",
    "content": "View this solution alone. We create the data for a hypothetical $2\\times2$ mixed design with the following attributes. | Between-subjects treatment factor: Type of music played (classical vs. rock) | Within-subjects treatment factor: Type of room (light vs. no light) | Outcome variable: Heart rate of subject | . | 1 2 3 4 5 6 7 8 9 10 . | subject &lt;- as.factor(c(1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10)) music &lt;- c('Classical','Rock','Classical','Rock','Classical','Rock','Classical', 'Rock','Classical','Rock','Classical','Rock','Classical','Rock','Classical', 'Rock','Classical','Rock','Classical','Rock') room.type &lt;- c('Light','Light','Light','Light','Light','Light','Light','Light','Light', 'Light','No Light','No Light','No Light','No Light','No Light','No Light', 'No Light','No Light','No Light', 'No Light') heart.rate &lt;- c(78,60,85,75,99,94,75,84,100,76,90,109,99,94,113,92,91,88,89,90) df &lt;- data.frame(subject,music,room.type,heart.rate) head(df) . | . | 1 2 3 4 5 6 7 . | subject music room.type heart.rate 1 1 Classical Light 78 2 2 Rock Light 60 3 3 Classical Light 85 4 4 Rock Light 75 5 5 Classical Light 99 6 6 Rock Light 94 . | . We conduct a two-way mixed-design ANOVA as shown below. The specific parameters have these meanings: . | The dependent variable is heart.rate. | The within-group factor is room.type. | The between-group factor is music. | The Error() term is critical in differentiating between a between subjects and within subjects model. It tells R that there is one observation per subject for each level of room.type. | . | 1 2 . | aov_mixed &lt;- aov(heart.rate ~ room.type*music + Error(subject/room.type), data=df) summary(aov_mixed) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 . | Error: subject Df Sum Sq Mean Sq F value Pr(&gt;F) music 1 162.4 162.4 1.587 0.243 Residuals 8 819.0 102.4 Error: subject:room.type Df Sum Sq Mean Sq F value Pr(&gt;F) room.type 1 832.1 832.1 6.416 0.0351 * room.type:music 1 76.0 76.0 0.586 0.4658 Residuals 8 1037.4 129.7 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The output informs us that, on average, the subjects that listened to classical music did not significantly differ ($p = 0.243 &gt; 0.05$) from those that listened to rock music. However, there is, on average, a significant difference ($p = 0.0351 &lt; 0.05$) between each of the subject’s heart rate when put in a room with or without light. Additionally, since the interaction term is not significant ($p = 0.4658 &gt; 0.05$), we can use the additive (no interaction) model. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-conduct-a-mixed-designs-anova/#solution-in-r",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova/#solution-in-r"
  },"479": {
    "doc": "How to conduct a mixed designs ANOVA",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-conduct-a-mixed-designs-anova/#topics-that-include-this-task",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova/#topics-that-include-this-task"
  },"480": {
    "doc": "How to conduct a mixed designs ANOVA",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-conduct-a-mixed-designs-anova/#opportunities",
    "relUrl": "/how-to-conduct-a-mixed-designs-anova/#opportunities"
  },"481": {
    "doc": "How to conduct a repeated measures ANOVA (in Python, using pandas and pingouin)",
    "title": "How to conduct a repeated measures ANOVA (in Python, using pandas and pingouin)",
    "content": "See all solutions. ",
    "url": "/how-to-conduct-a-repeated-measures-anova-in-python-using-pandas-and-pingouin/",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova-in-python-using-pandas-and-pingouin/"
  },"482": {
    "doc": "How to conduct a repeated measures ANOVA (in Python, using pandas and pingouin)",
    "title": "Task",
    "content": "In a repeated measures test, the same subject receives multiple treatments. When you have a dataset that includes the responses of a repeated measures test where the measurements are dependent (within subjects design), you may wish to check if there is a difference in the treatment effects. How would you conduct a repeated measures ANOVA to answer that question? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a mixed designs ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-conduct-a-repeated-measures-anova-in-python-using-pandas-and-pingouin/#task",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova-in-python-using-pandas-and-pingouin/#task"
  },"483": {
    "doc": "How to conduct a repeated measures ANOVA (in Python, using pandas and pingouin)",
    "title": "Solution",
    "content": "We create a hypothetical repeated measures dataset where the 5 subjects undergo all 4 skin treatments and their rating of the treatment is measured. | 1 2 3 4 5 6 7 8 . | import pandas as pd df = pd.DataFrame( { 'Subject': [1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5], 'Skin Treatment': ['W','X','Y','Z','W','X','Y','Z','W','X', 'Y','Z','W','X','Y','Z','W','X','Y','Z'], 'Rating': [7,5,8,4,8,10,7,5,7,6,5,4,7,7,4,5,8,8,6,6] } ) df.head() . | . | | Subject | Skin Treatment | Rating | . | 0 | 1 | W | 7 | . | 1 | 1 | X | 5 | . | 2 | 1 | Y | 8 | . | 3 | 1 | Z | 4 | . | 4 | 2 | W | 8 | . Before we conduct a repeated measures ANOVA, we need to decide which approach to use - Univariate or Multivariate. We decide this using Mauchly’s test of sphericity. If we fail to reject the null hypothesis then we use the univariate approach. | $H_0 =$ the sphericity assumption holds | $H_A =$ the sphericity assumption is violated | . We use the pingouin statistics package to conduct the test. Most of the parameters below are self-explanatory, except that dv stands for dependent variable. | 1 2 . | import pingouin as pg pg.sphericity( dv='Rating', within='Skin Treatment', subject='Subject', method='mauchly', data=df ) . | . | 1 2 3 4 5 6 7 8 9 . | /opt/conda/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.4.0, the latest is 0.5.0. Set the environment variable OUTDATED_IGNORE=1 to disable these warnings. return warn( SpherResults(spher=True, W=0.06210054956238558, chi2=7.565056754547507, dof=5, pval=0.20708214225927316) . | . Since the $p$ value of skin_treatment is about $0.2071$, we fail to reject the sphericity assumption at a 5% significance level and use the univariate approach to conduct the repeated measures ANOVA. | 1 2 . | # Compute a repeated measures ANOVA using a function pingouin adds to our DataFrame: df.rm_anova( dv='Rating', within='Skin Treatment', subject='Subject', detailed=False ) . | . | | Source | ddof1 | ddof2 | F | p-unc | np2 | eps | . | 0 | Skin Treatment | 3 | 12 | 5.117647 | 0.016501 | 0.56129 | 0.541199 | . Since the $p$ value of about $0.017$ is less than 0.05, we conclude that there is significant evidence of a treatment effect. Note: If there is more than 1 repeated measures factor, you can add a list of them to the within parameter and conduct the test. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-conduct-a-repeated-measures-anova-in-python-using-pandas-and-pingouin/#solution",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova-in-python-using-pandas-and-pingouin/#solution"
  },"484": {
    "doc": "How to conduct a repeated measures ANOVA (in R, using rstatix and tidyr and car)",
    "title": "How to conduct a repeated measures ANOVA (in R, using rstatix and tidyr and car)",
    "content": "See all solutions. ",
    "url": "/how-to-conduct-a-repeated-measures-anova-in-r-using-rstatix-and-tidyr-and-car/",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova-in-r-using-rstatix-and-tidyr-and-car/"
  },"485": {
    "doc": "How to conduct a repeated measures ANOVA (in R, using rstatix and tidyr and car)",
    "title": "Task",
    "content": "In a repeated measures test, the same subject receives multiple treatments. When you have a dataset that includes the responses of a repeated measures test where the measurements are dependent (within subjects design), you may wish to check if there is a difference in the treatment effects. How would you conduct a repeated measures ANOVA to answer that question? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a mixed designs ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-conduct-a-repeated-measures-anova-in-r-using-rstatix-and-tidyr-and-car/#task",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova-in-r-using-rstatix-and-tidyr-and-car/#task"
  },"486": {
    "doc": "How to conduct a repeated measures ANOVA (in R, using rstatix and tidyr and car)",
    "title": "Solution",
    "content": "We create a hypothetical repeated measures dataset where the 5 subjects undergo all 4 skin treatments and their rating of the treatment is measured. | 1 2 3 4 5 6 . | subject &lt;- as.factor(c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5)) skin.treatment &lt;- c('W','X','Y','Z','W','X','Y','Z','W','X', 'Y','Z','W','X','Y','Z','W','X','Y','Z') rating &lt;- c(7,5,8,4,8,10,7,5,7,6,5,4,7,7,4,5,8,8,6,6) df &lt;- data.frame(subject,skin.treatment,rating) head(df) . | . | 1 2 3 4 5 6 7 . | subject skin.treatment rating 1 1 W 7 2 1 X 5 3 1 Y 8 4 1 Z 4 5 2 W 8 6 2 X 10 . | . Before we conduct a repeated measures ANOVA, we need to decide which approach to use - Univariate or Multivariate. We decide this using Mauchly’s test of sphericity. If we fail to reject the null hypothesis then we use the univariate approach. | $H_0 =$ the sphericity assumption holds | $H_A =$ the sphericity assumption is violated | . We use the rstatix package to conduct the test. | The dependent variable is rating. | The within-group factor is skin.treatment. | The Error() term is critical in differentiating between a between subjects and within subjects model. It tells R that there is one observation per subject for each level of skin.treatment. | . | 1 2 3 . | # install.packages(\"rstatix\") # If you have not already installed it library(rstatix) anova_test(rating ~ skin.treatment + Error(subject/skin.treatment), data=df) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 . | Attaching package: ‘rstatix’ The following object is masked from ‘package:stats’: filter ANOVA Table (type III tests) $ANOVA Effect DFn DFd F p p&lt;.05 ges 1 skin.treatment 3 12 5.118 0.017 * 0.43 $`Mauchly's Test for Sphericity` Effect W p p&lt;.05 1 skin.treatment 0.062 0.207 $`Sphericity Corrections` Effect GGe DF[GG] p[GG] p[GG]&lt;.05 HFe DF[HF] p[HF] 1 skin.treatment 0.541 1.62, 6.49 0.051 0.858 2.57, 10.3 0.023 p[HF]&lt;.05 1 * . | . The $p$-value we care about in the output is under “Macuhly’s test for sphericity,” for the variable skin.treatment. Because the $p$-value is 0.207, we fail to reject the sphericity assumption at a 5% significance level and use the univariate approach. to conduct the repeated measures ANOVA. Repeated measures ANOVA - univariate . | 1 2 . | aov1 &lt;- aov(rating ~ skin.treatment + Error(subject/skin.treatment), data=df) summary(aov1) . | . | 1 2 3 4 5 6 7 8 9 10 . | Error: subject Df Sum Sq Mean Sq F value Pr(&gt;F) Residuals 4 11.8 2.95 Error: subject:skin.treatment Df Sum Sq Mean Sq F value Pr(&gt;F) skin.treatment 3 21.75 7.250 5.118 0.0165 * Residuals 12 17.00 1.417 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . You can find the $p$-value at the end of the row of output marked for skin.treatment; it is 0.0165. This is less than 0.05, so we conclude that there is significant evidence of a treatment effect. Repeated measures ANOVA - multivariate . If instead the first test had rejected the sphericity assumption, we would have used a multivariate approach for the repeated measures ANOVA. We show here how to do such a test, even though it does not apply to this situation. We must first reorganize the data into a matrix where each row represents a single subject, and columns represent levels of the treatment factor. This is possible using the tidyr package. | 1 2 3 4 5 . | # install.packages(\"tidyr\") # If you have not already installed it library(tidyr) multi.data &lt;- spread(df, skin.treatment, rating) multi.data &lt;- as.matrix(multi.data[,-c(1)]) multi.data . | . | 1 2 3 4 5 6 . | W X Y Z [1,] 7 5 8 4 [2,] 8 10 7 5 [3,] 7 6 5 4 [4,] 7 7 4 5 [5,] 8 8 6 6 . | . We then create a multivariate model and also set up a variable that defines the design of the study. | 1 2 3 4 . | # In this model there are no between-subjects factors, so we write ~ 1: multi.ml &lt;- lm(multi.data ~ 1) # The design of the study is a single factor with four levels: rfactor &lt;- factor(c(\"f1\", \"f2\", \"f3\", \"f4\")) . | . Conduct the repeated measures ANOVA using a multivariate approach. This requires creating a new model using the Anova() function that calculates ANOVA tables. The car package provides the Anova() function. The parameters have the following meanings. | idata includes information about the number of levels, in this case four. | idesign states that rfactor describes a repeated-measures variable. | type tells Anova() to calculate the “Type-III” sums of squares when forming the ANOVA table. | multivariate suppresses output about multivariate statistical tests, which are relevant only when the experimental design includes multiple dependent variables. | . | 1 2 3 4 . | # install.packages(\"car\") # If you have not already installed it library(car) multi.ml &lt;- Anova(multi.ml, idata=data.frame(rfactor), idesign = ~rfactor, type=\"III\") summary(multi.ml, multivariate=FALSE) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 . | Loading required package: carData Univariate Type III Repeated-Measures ANOVA Assuming Sphericity Sum Sq num Df Error SS den Df F value Pr(&gt;F) (Intercept) 806.45 1 11.8 4 273.3729 7.837e-05 *** rfactor 21.75 3 17.0 12 5.1176 0.0165 * --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Mauchly Tests for Sphericity Test statistic p-value rfactor 0.062101 0.20708 Greenhouse-Geisser and Huynh-Feldt Corrections for Departure from Sphericity GG eps Pr(&gt;F[GG]) rfactor 0.5412 0.05068 . --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 HF eps Pr(&gt;F[HF]) rfactor 0.858156 0.02319302 . | . Although this test was run just as an example, and does not actually apply in this dataset, the output shows a $p$-value of 0.0165, at the end of the first rfactor row. That $p$-value could be compared to a chosen $\\alpha$. (We also see that Mauchly’s test was performed, which is not significant, and is the reason this data actually demands a univariate approach.) . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-conduct-a-repeated-measures-anova-in-r-using-rstatix-and-tidyr-and-car/#solution",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova-in-r-using-rstatix-and-tidyr-and-car/#solution"
  },"487": {
    "doc": "How to conduct a repeated measures ANOVA",
    "title": "How to conduct a repeated measures ANOVA",
    "content": " ",
    "url": "/how-to-conduct-a-repeated-measures-anova/",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova/"
  },"488": {
    "doc": "How to conduct a repeated measures ANOVA",
    "title": "Description",
    "content": "In a repeated measures test, the same subject receives multiple treatments. When you have a dataset that includes the responses of a repeated measures test where the measurements are dependent (within subjects design), you may wish to check if there is a difference in the treatment effects. How would you conduct a repeated measures ANOVA to answer that question? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a mixed designs ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-conduct-a-repeated-measures-anova/#description",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova/#description"
  },"489": {
    "doc": "How to conduct a repeated measures ANOVA",
    "title": "Using pandas and pingouin, in Python",
    "content": "View this solution alone. We create a hypothetical repeated measures dataset where the 5 subjects undergo all 4 skin treatments and their rating of the treatment is measured. | 1 2 3 4 5 6 7 8 . | import pandas as pd df = pd.DataFrame( { 'Subject': [1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5], 'Skin Treatment': ['W','X','Y','Z','W','X','Y','Z','W','X', 'Y','Z','W','X','Y','Z','W','X','Y','Z'], 'Rating': [7,5,8,4,8,10,7,5,7,6,5,4,7,7,4,5,8,8,6,6] } ) df.head() . | . | | Subject | Skin Treatment | Rating | . | 0 | 1 | W | 7 | . | 1 | 1 | X | 5 | . | 2 | 1 | Y | 8 | . | 3 | 1 | Z | 4 | . | 4 | 2 | W | 8 | . Before we conduct a repeated measures ANOVA, we need to decide which approach to use - Univariate or Multivariate. We decide this using Mauchly’s test of sphericity. If we fail to reject the null hypothesis then we use the univariate approach. | $H_0 =$ the sphericity assumption holds | $H_A =$ the sphericity assumption is violated | . We use the pingouin statistics package to conduct the test. Most of the parameters below are self-explanatory, except that dv stands for dependent variable. | 1 2 . | import pingouin as pg pg.sphericity( dv='Rating', within='Skin Treatment', subject='Subject', method='mauchly', data=df ) . | . | 1 2 3 4 5 6 7 8 9 . | /opt/conda/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.4.0, the latest is 0.5.0. Set the environment variable OUTDATED_IGNORE=1 to disable these warnings. return warn( SpherResults(spher=True, W=0.06210054956238558, chi2=7.565056754547507, dof=5, pval=0.20708214225927316) . | . Since the $p$ value of skin_treatment is about $0.2071$, we fail to reject the sphericity assumption at a 5% significance level and use the univariate approach to conduct the repeated measures ANOVA. | 1 2 . | # Compute a repeated measures ANOVA using a function pingouin adds to our DataFrame: df.rm_anova( dv='Rating', within='Skin Treatment', subject='Subject', detailed=False ) . | . | | Source | ddof1 | ddof2 | F | p-unc | np2 | eps | . | 0 | Skin Treatment | 3 | 12 | 5.117647 | 0.016501 | 0.56129 | 0.541199 | . Since the $p$ value of about $0.017$ is less than 0.05, we conclude that there is significant evidence of a treatment effect. Note: If there is more than 1 repeated measures factor, you can add a list of them to the within parameter and conduct the test. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-conduct-a-repeated-measures-anova/#using-pandas-and-pingouin-in-python",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova/#using-pandas-and-pingouin-in-python"
  },"490": {
    "doc": "How to conduct a repeated measures ANOVA",
    "title": "Using rstatix and tidyr and car, in R",
    "content": "View this solution alone. We create a hypothetical repeated measures dataset where the 5 subjects undergo all 4 skin treatments and their rating of the treatment is measured. | 1 2 3 4 5 6 . | subject &lt;- as.factor(c(1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5)) skin.treatment &lt;- c('W','X','Y','Z','W','X','Y','Z','W','X', 'Y','Z','W','X','Y','Z','W','X','Y','Z') rating &lt;- c(7,5,8,4,8,10,7,5,7,6,5,4,7,7,4,5,8,8,6,6) df &lt;- data.frame(subject,skin.treatment,rating) head(df) . | . | 1 2 3 4 5 6 7 . | subject skin.treatment rating 1 1 W 7 2 1 X 5 3 1 Y 8 4 1 Z 4 5 2 W 8 6 2 X 10 . | . Before we conduct a repeated measures ANOVA, we need to decide which approach to use - Univariate or Multivariate. We decide this using Mauchly’s test of sphericity. If we fail to reject the null hypothesis then we use the univariate approach. | $H_0 =$ the sphericity assumption holds | $H_A =$ the sphericity assumption is violated | . We use the rstatix package to conduct the test. | The dependent variable is rating. | The within-group factor is skin.treatment. | The Error() term is critical in differentiating between a between subjects and within subjects model. It tells R that there is one observation per subject for each level of skin.treatment. | . | 1 2 3 . | # install.packages(\"rstatix\") # If you have not already installed it library(rstatix) anova_test(rating ~ skin.treatment + Error(subject/skin.treatment), data=df) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 . | Attaching package: ‘rstatix’ The following object is masked from ‘package:stats’: filter ANOVA Table (type III tests) $ANOVA Effect DFn DFd F p p&lt;.05 ges 1 skin.treatment 3 12 5.118 0.017 * 0.43 $`Mauchly's Test for Sphericity` Effect W p p&lt;.05 1 skin.treatment 0.062 0.207 $`Sphericity Corrections` Effect GGe DF[GG] p[GG] p[GG]&lt;.05 HFe DF[HF] p[HF] 1 skin.treatment 0.541 1.62, 6.49 0.051 0.858 2.57, 10.3 0.023 p[HF]&lt;.05 1 * . | . The $p$-value we care about in the output is under “Macuhly’s test for sphericity,” for the variable skin.treatment. Because the $p$-value is 0.207, we fail to reject the sphericity assumption at a 5% significance level and use the univariate approach. to conduct the repeated measures ANOVA. Repeated measures ANOVA - univariate . | 1 2 . | aov1 &lt;- aov(rating ~ skin.treatment + Error(subject/skin.treatment), data=df) summary(aov1) . | . | 1 2 3 4 5 6 7 8 9 10 . | Error: subject Df Sum Sq Mean Sq F value Pr(&gt;F) Residuals 4 11.8 2.95 Error: subject:skin.treatment Df Sum Sq Mean Sq F value Pr(&gt;F) skin.treatment 3 21.75 7.250 5.118 0.0165 * Residuals 12 17.00 1.417 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . You can find the $p$-value at the end of the row of output marked for skin.treatment; it is 0.0165. This is less than 0.05, so we conclude that there is significant evidence of a treatment effect. Repeated measures ANOVA - multivariate . If instead the first test had rejected the sphericity assumption, we would have used a multivariate approach for the repeated measures ANOVA. We show here how to do such a test, even though it does not apply to this situation. We must first reorganize the data into a matrix where each row represents a single subject, and columns represent levels of the treatment factor. This is possible using the tidyr package. | 1 2 3 4 5 . | # install.packages(\"tidyr\") # If you have not already installed it library(tidyr) multi.data &lt;- spread(df, skin.treatment, rating) multi.data &lt;- as.matrix(multi.data[,-c(1)]) multi.data . | . | 1 2 3 4 5 6 . | W X Y Z [1,] 7 5 8 4 [2,] 8 10 7 5 [3,] 7 6 5 4 [4,] 7 7 4 5 [5,] 8 8 6 6 . | . We then create a multivariate model and also set up a variable that defines the design of the study. | 1 2 3 4 . | # In this model there are no between-subjects factors, so we write ~ 1: multi.ml &lt;- lm(multi.data ~ 1) # The design of the study is a single factor with four levels: rfactor &lt;- factor(c(\"f1\", \"f2\", \"f3\", \"f4\")) . | . Conduct the repeated measures ANOVA using a multivariate approach. This requires creating a new model using the Anova() function that calculates ANOVA tables. The car package provides the Anova() function. The parameters have the following meanings. | idata includes information about the number of levels, in this case four. | idesign states that rfactor describes a repeated-measures variable. | type tells Anova() to calculate the “Type-III” sums of squares when forming the ANOVA table. | multivariate suppresses output about multivariate statistical tests, which are relevant only when the experimental design includes multiple dependent variables. | . | 1 2 3 4 . | # install.packages(\"car\") # If you have not already installed it library(car) multi.ml &lt;- Anova(multi.ml, idata=data.frame(rfactor), idesign = ~rfactor, type=\"III\") summary(multi.ml, multivariate=FALSE) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 . | Loading required package: carData Univariate Type III Repeated-Measures ANOVA Assuming Sphericity Sum Sq num Df Error SS den Df F value Pr(&gt;F) (Intercept) 806.45 1 11.8 4 273.3729 7.837e-05 *** rfactor 21.75 3 17.0 12 5.1176 0.0165 * --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Mauchly Tests for Sphericity Test statistic p-value rfactor 0.062101 0.20708 Greenhouse-Geisser and Huynh-Feldt Corrections for Departure from Sphericity GG eps Pr(&gt;F[GG]) rfactor 0.5412 0.05068 . --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 HF eps Pr(&gt;F[HF]) rfactor 0.858156 0.02319302 . | . Although this test was run just as an example, and does not actually apply in this dataset, the output shows a $p$-value of 0.0165, at the end of the first rfactor row. That $p$-value could be compared to a chosen $\\alpha$. (We also see that Mauchly’s test was performed, which is not significant, and is the reason this data actually demands a univariate approach.) . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-conduct-a-repeated-measures-anova/#using-rstatix-and-tidyr-and-car-in-r",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova/#using-rstatix-and-tidyr-and-car-in-r"
  },"491": {
    "doc": "How to conduct a repeated measures ANOVA",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-conduct-a-repeated-measures-anova/#topics-that-include-this-task",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova/#topics-that-include-this-task"
  },"492": {
    "doc": "How to conduct a repeated measures ANOVA",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-conduct-a-repeated-measures-anova/#opportunities",
    "relUrl": "/how-to-conduct-a-repeated-measures-anova/#opportunities"
  },"493": {
    "doc": "How to convert a text column into dates (in Python, using pandas)",
    "title": "How to convert a text column into dates (in Python, using pandas)",
    "content": "See all solutions. ",
    "url": "/how-to-convert-a-text-column-into-dates-in-python-using-pandas/",
    "relUrl": "/how-to-convert-a-text-column-into-dates-in-python-using-pandas/"
  },"494": {
    "doc": "How to convert a text column into dates (in Python, using pandas)",
    "title": "Task",
    "content": "When loading data, many software systems make intelligent guesses about the format and data type of each column, but sometimes that is not sufficient. If you have a column of text that should be interpreted as dates, how can we ask the software to convert it? . ",
    "url": "/how-to-convert-a-text-column-into-dates-in-python-using-pandas/#task",
    "relUrl": "/how-to-convert-a-text-column-into-dates-in-python-using-pandas/#task"
  },"495": {
    "doc": "How to convert a text column into dates (in Python, using pandas)",
    "title": "Solution",
    "content": "Let’s create a small example DataFrame to use here (using the method from how to create a data frame from scratch). Naturally, you would apply this solution to your own data instead. | 1 2 3 4 . | import pandas as pd df = pd.DataFrame( { 'Date' : [ '5/7/19', '5/10/19', '5/11/19' ], 'Event' : [ 'Work', 'Party', 'More work' ] } ) df . | . | | Date | Event | . | 0 | 5/7/19 | Work | . | 1 | 5/10/19 | Party | . | 2 | 5/11/19 | More work | . If you’ve already got the data in a DataFrame column, and you wish to convert it to dates, use the pd.to_datetime function, which will do its best to read whatever format your dates are in: . | 1 2 . | df['Date'] = pd.to_datetime( df['Date'] ) df . | . | | Date | Event | . | 0 | 2019-05-07 | Work | . | 1 | 2019-05-10 | Party | . | 2 | 2019-05-11 | More work | . But if they aren’t in a standard format, you can specify just about any format as in the following example. See the Python documentation for format details. | 1 2 . | # If the dates had been, for example, 5-7-2019 10:15:00 df['Date'] = pd.to_datetime( df['Date'], format=\"%m-%d-%Y %H:%M:%S\" ) . | . It’s often easier to handle date conversions while reading the data. You can tell pandas to read dates in most of the common date formats using any of the following methods. | 1 2 3 4 5 6 7 8 9 10 . | # Any columns that look like dates, treat as dates: df = pd.read_csv( \"example.csv\", parse_dates=True ) # Convert the specific columns you name into dates: df = pd.read_csv( \"example.csv\", parse_dates=['col1','col2'] ) # If the date is spread over multiple columns, do this: # (Let's say the year, month, and day are in columns, 4, 5, and 6.) df = pd.read_csv( \"example.csv\", parse_dates=[[4,5,6]] ) # Note the double brackets, and indices start counting at zero. | . Content last modified on 10 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-convert-a-text-column-into-dates-in-python-using-pandas/#solution",
    "relUrl": "/how-to-convert-a-text-column-into-dates-in-python-using-pandas/#solution"
  },"496": {
    "doc": "How to convert a text column into dates (in R)",
    "title": "How to convert a text column into dates (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-convert-a-text-column-into-dates-in-r/",
    "relUrl": "/how-to-convert-a-text-column-into-dates-in-r/"
  },"497": {
    "doc": "How to convert a text column into dates (in R)",
    "title": "Task",
    "content": "When loading data, many software systems make intelligent guesses about the format and data type of each column, but sometimes that is not sufficient. If you have a column of text that should be interpreted as dates, how can we ask the software to convert it? . ",
    "url": "/how-to-convert-a-text-column-into-dates-in-r/#task",
    "relUrl": "/how-to-convert-a-text-column-into-dates-in-r/#task"
  },"498": {
    "doc": "How to convert a text column into dates (in R)",
    "title": "Solution",
    "content": "Let’s create a small example DataFrame to use here (using the method from how to create a data frame from scratch). Naturally, you would apply this solution to your own data instead. | 1 2 3 4 5 . | df &lt;- data.frame( Date = c( '5/7/19', '5/10/19', '5/11/19' ), Event = c( 'Work', 'Party', 'More work' ) ) df . | . | 1 2 3 4 . | Date Event 1 5/7/19 Work 2 5/10/19 Party 3 5/11/19 More work . | . We use the as.Date() function to convert a text column into dates. If the input dates are not in the standard format, we can use the format= argument to change the format. Note the difference between %y and %Y: The %y code means a 2-digit year, but the %Y code means a 4-digit year. | 1 2 . | df$Date = as.Date( df$Date, format='%m/%d/%y' ) df . | . | 1 2 3 4 . | Date Event 1 2019-05-07 Work 2 2019-05-10 Party 3 2019-05-11 More work . | . It’s often easier to handle date conversions while reading the data file. You can use the read_csv() function in the readr package, which will automatically recognize dates in some common formats. Additionaly, you can use the anytime() function in the anytime package to automatically parse strings as dates regardless of the format. | 1 2 3 4 . | # Use anytime() to attempt to parse various formats: library(anytime) examples &lt;- c( \"Nov 01 2022\", \"2022-11-01\", \"22-11-01\" ) anytime( examples ) . | . | 1 . | [1] \"2022-11-01 UTC\" \"2022-11-01 UTC\" NA . | . Note that it succeeded in two cases, but not the third. Content last modified on 10 November 2022. See a problem? Tell us or edit the source. Contributed by Ni Shi (shi_ni@bentley.edu) . ",
    "url": "/how-to-convert-a-text-column-into-dates-in-r/#solution",
    "relUrl": "/how-to-convert-a-text-column-into-dates-in-r/#solution"
  },"499": {
    "doc": "How to convert a text column into dates",
    "title": "How to convert a text column into dates",
    "content": " ",
    "url": "/how-to-convert-a-text-column-into-dates/",
    "relUrl": "/how-to-convert-a-text-column-into-dates/"
  },"500": {
    "doc": "How to convert a text column into dates",
    "title": "Description",
    "content": "When loading data, many software systems make intelligent guesses about the format and data type of each column, but sometimes that is not sufficient. If you have a column of text that should be interpreted as dates, how can we ask the software to convert it? . ",
    "url": "/how-to-convert-a-text-column-into-dates/#description",
    "relUrl": "/how-to-convert-a-text-column-into-dates/#description"
  },"501": {
    "doc": "How to convert a text column into dates",
    "title": "Using pandas, in Python",
    "content": "View this solution alone. Let’s create a small example DataFrame to use here (using the method from how to create a data frame from scratch). Naturally, you would apply this solution to your own data instead. | 1 2 3 4 . | import pandas as pd df = pd.DataFrame( { 'Date' : [ '5/7/19', '5/10/19', '5/11/19' ], 'Event' : [ 'Work', 'Party', 'More work' ] } ) df . | . | | Date | Event | . | 0 | 5/7/19 | Work | . | 1 | 5/10/19 | Party | . | 2 | 5/11/19 | More work | . If you’ve already got the data in a DataFrame column, and you wish to convert it to dates, use the pd.to_datetime function, which will do its best to read whatever format your dates are in: . | 1 2 . | df['Date'] = pd.to_datetime( df['Date'] ) df . | . | | Date | Event | . | 0 | 2019-05-07 | Work | . | 1 | 2019-05-10 | Party | . | 2 | 2019-05-11 | More work | . But if they aren’t in a standard format, you can specify just about any format as in the following example. See the Python documentation for format details. | 1 2 . | # If the dates had been, for example, 5-7-2019 10:15:00 df['Date'] = pd.to_datetime( df['Date'], format=\"%m-%d-%Y %H:%M:%S\" ) . | . It’s often easier to handle date conversions while reading the data. You can tell pandas to read dates in most of the common date formats using any of the following methods. | 1 2 3 4 5 6 7 8 9 10 . | # Any columns that look like dates, treat as dates: df = pd.read_csv( \"example.csv\", parse_dates=True ) # Convert the specific columns you name into dates: df = pd.read_csv( \"example.csv\", parse_dates=['col1','col2'] ) # If the date is spread over multiple columns, do this: # (Let's say the year, month, and day are in columns, 4, 5, and 6.) df = pd.read_csv( \"example.csv\", parse_dates=[[4,5,6]] ) # Note the double brackets, and indices start counting at zero. | . Content last modified on 10 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-convert-a-text-column-into-dates/#using-pandas-in-python",
    "relUrl": "/how-to-convert-a-text-column-into-dates/#using-pandas-in-python"
  },"502": {
    "doc": "How to convert a text column into dates",
    "title": "Solution, in R",
    "content": "View this solution alone. Let’s create a small example DataFrame to use here (using the method from how to create a data frame from scratch). Naturally, you would apply this solution to your own data instead. | 1 2 3 4 5 . | df &lt;- data.frame( Date = c( '5/7/19', '5/10/19', '5/11/19' ), Event = c( 'Work', 'Party', 'More work' ) ) df . | . | 1 2 3 4 . | Date Event 1 5/7/19 Work 2 5/10/19 Party 3 5/11/19 More work . | . We use the as.Date() function to convert a text column into dates. If the input dates are not in the standard format, we can use the format= argument to change the format. Note the difference between %y and %Y: The %y code means a 2-digit year, but the %Y code means a 4-digit year. | 1 2 . | df$Date = as.Date( df$Date, format='%m/%d/%y' ) df . | . | 1 2 3 4 . | Date Event 1 2019-05-07 Work 2 2019-05-10 Party 3 2019-05-11 More work . | . It’s often easier to handle date conversions while reading the data file. You can use the read_csv() function in the readr package, which will automatically recognize dates in some common formats. Additionaly, you can use the anytime() function in the anytime package to automatically parse strings as dates regardless of the format. | 1 2 3 4 . | # Use anytime() to attempt to parse various formats: library(anytime) examples &lt;- c( \"Nov 01 2022\", \"2022-11-01\", \"22-11-01\" ) anytime( examples ) . | . | 1 . | [1] \"2022-11-01 UTC\" \"2022-11-01 UTC\" NA . | . Note that it succeeded in two cases, but not the third. Content last modified on 10 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-convert-a-text-column-into-dates/#solution-in-r",
    "relUrl": "/how-to-convert-a-text-column-into-dates/#solution-in-r"
  },"503": {
    "doc": "How to convert a text column into dates",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA346 | . ",
    "url": "/how-to-convert-a-text-column-into-dates/#topics-that-include-this-task",
    "relUrl": "/how-to-convert-a-text-column-into-dates/#topics-that-include-this-task"
  },"504": {
    "doc": "How to convert a text column into dates",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-convert-a-text-column-into-dates/#opportunities",
    "relUrl": "/how-to-convert-a-text-column-into-dates/#opportunities"
  },"505": {
    "doc": "How to create a box (and whisker) plot (in Python, using Matplotlib)",
    "title": "How to create a box (and whisker) plot (in Python, using Matplotlib)",
    "content": "See all solutions. ",
    "url": "/how-to-create-a-box-and-whisker-plot-in-python-using-matplotlib/",
    "relUrl": "/how-to-create-a-box-and-whisker-plot-in-python-using-matplotlib/"
  },"506": {
    "doc": "How to create a box (and whisker) plot (in Python, using Matplotlib)",
    "title": "Task",
    "content": "A box plot, or a box and whisker plot, shows the quartiles of a single variable from a dataset (one of which is the median) and may also show the outliers. It is a simplified way to see the distribution of a variable. Sometimes multiple box plots (one for each of several variables) are shown side-by-side on a plot, to compare the variables. How can we create such graphs? . Related topics: . | How to create basic plots | How to add details to a plot | How to create a histogram | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-a-box-and-whisker-plot-in-python-using-matplotlib/#task",
    "relUrl": "/how-to-create-a-box-and-whisker-plot-in-python-using-matplotlib/#task"
  },"507": {
    "doc": "How to create a box (and whisker) plot (in Python, using Matplotlib)",
    "title": "Solution",
    "content": "We will create some fake data using Python lists, for simplicity. But everything we show below works also if your data is in columns of a DataFrame, such as df['age']. | 1 2 3 . | patient_id = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ] patient_height = [ 60, 64, 64, 65, 66, 66, 70, 72, 72, 76 ] patient_weight = [ 141, 182, 169, 204, 138, 198, 180, 175, 244, 196 ] . | . The conventional way to import matplotlib in Python is as follows. | 1 . | import matplotlib.pyplot as plt . | . To create a box-and-whisker plot, sometimes called just a box plot requires just one line of code, plus one to show the plot. | 1 2 . | plt.boxplot( patient_height ) plt.show() . | . You can show more than one variable’s box plot side-by-side by forming a list of the data. | 1 2 . | plt.boxplot( [ patient_height, patient_weight ] ) plt.show() . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-create-a-box-and-whisker-plot-in-python-using-matplotlib/#solution",
    "relUrl": "/how-to-create-a-box-and-whisker-plot-in-python-using-matplotlib/#solution"
  },"508": {
    "doc": "How to create a box (and whisker) plot (in R)",
    "title": "How to create a box (and whisker) plot (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-create-a-box-and-whisker-plot-in-r/",
    "relUrl": "/how-to-create-a-box-and-whisker-plot-in-r/"
  },"509": {
    "doc": "How to create a box (and whisker) plot (in R)",
    "title": "Task",
    "content": "A box plot, or a box and whisker plot, shows the quartiles of a single variable from a dataset (one of which is the median) and may also show the outliers. It is a simplified way to see the distribution of a variable. Sometimes multiple box plots (one for each of several variables) are shown side-by-side on a plot, to compare the variables. How can we create such graphs? . Related topics: . | How to create basic plots | How to add details to a plot | How to create a histogram | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-a-box-and-whisker-plot-in-r/#task",
    "relUrl": "/how-to-create-a-box-and-whisker-plot-in-r/#task"
  },"510": {
    "doc": "How to create a box (and whisker) plot (in R)",
    "title": "Solution",
    "content": "We will create some fake data using vectors, for simplicity. But everything we show below works also if your data is in columns of a DataFrame. | 1 2 3 . | patient_id &lt;- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) patient_height &lt;- c(60, 64, 64, 65, 66, 66, 70, 72, 72, 76) patient_weight &lt;- c(141, 182, 169, 204, 138, 198, 180, 175, 244, 196) . | . We can use R’s boxplot() function to make the plot. | 1 . | boxplot(patient_weight) . | . You can show more than one variable’s box plot side-by-side by passing both variables into the boxplot() function. | 1 . | boxplot(patient_height, patient_weight) . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-create-a-box-and-whisker-plot-in-r/#solution",
    "relUrl": "/how-to-create-a-box-and-whisker-plot-in-r/#solution"
  },"511": {
    "doc": "How to create a box (and whisker) plot",
    "title": "How to create a box (and whisker) plot",
    "content": " ",
    "url": "/how-to-create-a-box-and-whisker-plot/",
    "relUrl": "/how-to-create-a-box-and-whisker-plot/"
  },"512": {
    "doc": "How to create a box (and whisker) plot",
    "title": "Description",
    "content": "A box plot, or a box and whisker plot, shows the quartiles of a single variable from a dataset (one of which is the median) and may also show the outliers. It is a simplified way to see the distribution of a variable. Sometimes multiple box plots (one for each of several variables) are shown side-by-side on a plot, to compare the variables. How can we create such graphs? . Related topics: . | How to create basic plots | How to add details to a plot | How to create a histogram | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-a-box-and-whisker-plot/#description",
    "relUrl": "/how-to-create-a-box-and-whisker-plot/#description"
  },"513": {
    "doc": "How to create a box (and whisker) plot",
    "title": "Using Matplotlib, in Python",
    "content": "View this solution alone. We will create some fake data using Python lists, for simplicity. But everything we show below works also if your data is in columns of a DataFrame, such as df['age']. | 1 2 3 . | patient_id = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ] patient_height = [ 60, 64, 64, 65, 66, 66, 70, 72, 72, 76 ] patient_weight = [ 141, 182, 169, 204, 138, 198, 180, 175, 244, 196 ] . | . The conventional way to import matplotlib in Python is as follows. | 1 . | import matplotlib.pyplot as plt . | . To create a box-and-whisker plot, sometimes called just a box plot requires just one line of code, plus one to show the plot. | 1 2 . | plt.boxplot( patient_height ) plt.show() . | . You can show more than one variable’s box plot side-by-side by forming a list of the data. | 1 2 . | plt.boxplot( [ patient_height, patient_weight ] ) plt.show() . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-a-box-and-whisker-plot/#using-matplotlib-in-python",
    "relUrl": "/how-to-create-a-box-and-whisker-plot/#using-matplotlib-in-python"
  },"514": {
    "doc": "How to create a box (and whisker) plot",
    "title": "Solution, in R",
    "content": "View this solution alone. We will create some fake data using vectors, for simplicity. But everything we show below works also if your data is in columns of a DataFrame. | 1 2 3 . | patient_id &lt;- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) patient_height &lt;- c(60, 64, 64, 65, 66, 66, 70, 72, 72, 76) patient_weight &lt;- c(141, 182, 169, 204, 138, 198, 180, 175, 244, 196) . | . We can use R’s boxplot() function to make the plot. | 1 . | boxplot(patient_weight) . | . You can show more than one variable’s box plot side-by-side by passing both variables into the boxplot() function. | 1 . | boxplot(patient_height, patient_weight) . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-a-box-and-whisker-plot/#solution-in-r",
    "relUrl": "/how-to-create-a-box-and-whisker-plot/#solution-in-r"
  },"515": {
    "doc": "How to create a box (and whisker) plot",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA346 | . ",
    "url": "/how-to-create-a-box-and-whisker-plot/#topics-that-include-this-task",
    "relUrl": "/how-to-create-a-box-and-whisker-plot/#topics-that-include-this-task"
  },"516": {
    "doc": "How to create a box (and whisker) plot",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-create-a-box-and-whisker-plot/#opportunities",
    "relUrl": "/how-to-create-a-box-and-whisker-plot/#opportunities"
  },"517": {
    "doc": "How to create a data frame from scratch (in Python)",
    "title": "How to create a data frame from scratch (in Python)",
    "content": "See all solutions. ",
    "url": "/how-to-create-a-data-frame-from-scratch-in-python/",
    "relUrl": "/how-to-create-a-data-frame-from-scratch-in-python/"
  },"518": {
    "doc": "How to create a data frame from scratch (in Python)",
    "title": "Task",
    "content": "Sometimes it is useful to create a small table of data directly in code, without first needing to store the data in a file and load it from there. This can be useful for creating small tables for testing purposes, or for creating small lookup tables that hold abbreviations, IDs, etc. What’s the easiest way to build such a table? . ",
    "url": "/how-to-create-a-data-frame-from-scratch-in-python/#task",
    "relUrl": "/how-to-create-a-data-frame-from-scratch-in-python/#task"
  },"519": {
    "doc": "How to create a data frame from scratch (in Python)",
    "title": "Solution",
    "content": "In pandas, the pd.DataFrame function can construct new DataFrames. Just provide it with a dictionary whose keys are the column headers and whose values are the column contents. Here’s an example: . | 1 2 3 4 5 6 7 . | import pandas as pd df = pd.DataFrame( { 'Last name' : [ 'Potter', 'Weasley', 'Granger', 'Malfoy' ], 'First name' : [ 'Harry', 'Ron', 'Hermione', 'Draco' ], 'House' : [ 'Gryffindor', 'Gryffindor', 'Gryffindor', 'Slytherin' ] } ) df . | . | | Last name | First name | House | . | 0 | Potter | Harry | Gryffindor | . | 1 | Weasley | Ron | Gryffindor | . | 2 | Granger | Hermione | Gryffindor | . | 3 | Malfoy | Draco | Slytherin | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-create-a-data-frame-from-scratch-in-python/#solution",
    "relUrl": "/how-to-create-a-data-frame-from-scratch-in-python/#solution"
  },"520": {
    "doc": "How to create a data frame from scratch (in R)",
    "title": "How to create a data frame from scratch (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-create-a-data-frame-from-scratch-in-r/",
    "relUrl": "/how-to-create-a-data-frame-from-scratch-in-r/"
  },"521": {
    "doc": "How to create a data frame from scratch (in R)",
    "title": "Task",
    "content": "Sometimes it is useful to create a small table of data directly in code, without first needing to store the data in a file and load it from there. This can be useful for creating small tables for testing purposes, or for creating small lookup tables that hold abbreviations, IDs, etc. What’s the easiest way to build such a table? . ",
    "url": "/how-to-create-a-data-frame-from-scratch-in-r/#task",
    "relUrl": "/how-to-create-a-data-frame-from-scratch-in-r/#task"
  },"522": {
    "doc": "How to create a data frame from scratch (in R)",
    "title": "Solution",
    "content": "In R, the data.frame function can be used to build data frames. Each column in your data should be a separate parameter, with its name provided, followed by an equals sign, followed by the vector of column contents, as shown in the example below. | 1 2 3 4 5 6 . | data &lt;- data.frame( last.name = c( 'Potter', 'Weasley', 'Granger', 'Malfoy' ), first.name = c( 'Harry', 'Ron', 'Hermione', 'Draco' ), house = c( 'Griffindor', 'Griffindor', 'Griffindor', 'Slytherin' ) ) data . | . | 1 2 3 4 5 . | last.name first.name house 1 Potter Harry Griffindor 2 Weasley Ron Griffindor 3 Granger Hermione Griffindor 4 Malfoy Draco Slytherin . | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-create-a-data-frame-from-scratch-in-r/#solution",
    "relUrl": "/how-to-create-a-data-frame-from-scratch-in-r/#solution"
  },"523": {
    "doc": "How to create a data frame from scratch",
    "title": "How to create a data frame from scratch",
    "content": " ",
    "url": "/how-to-create-a-data-frame-from-scratch/",
    "relUrl": "/how-to-create-a-data-frame-from-scratch/"
  },"524": {
    "doc": "How to create a data frame from scratch",
    "title": "Description",
    "content": "Sometimes it is useful to create a small table of data directly in code, without first needing to store the data in a file and load it from there. This can be useful for creating small tables for testing purposes, or for creating small lookup tables that hold abbreviations, IDs, etc. What’s the easiest way to build such a table? . ",
    "url": "/how-to-create-a-data-frame-from-scratch/#description",
    "relUrl": "/how-to-create-a-data-frame-from-scratch/#description"
  },"525": {
    "doc": "How to create a data frame from scratch",
    "title": "Solution, in Python",
    "content": "View this solution alone. In pandas, the pd.DataFrame function can construct new DataFrames. Just provide it with a dictionary whose keys are the column headers and whose values are the column contents. Here’s an example: . | 1 2 3 4 5 6 7 . | import pandas as pd df = pd.DataFrame( { 'Last name' : [ 'Potter', 'Weasley', 'Granger', 'Malfoy' ], 'First name' : [ 'Harry', 'Ron', 'Hermione', 'Draco' ], 'House' : [ 'Gryffindor', 'Gryffindor', 'Gryffindor', 'Slytherin' ] } ) df . | . | | Last name | First name | House | . | 0 | Potter | Harry | Gryffindor | . | 1 | Weasley | Ron | Gryffindor | . | 2 | Granger | Hermione | Gryffindor | . | 3 | Malfoy | Draco | Slytherin | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-a-data-frame-from-scratch/#solution-in-python",
    "relUrl": "/how-to-create-a-data-frame-from-scratch/#solution-in-python"
  },"526": {
    "doc": "How to create a data frame from scratch",
    "title": "Solution, in R",
    "content": "View this solution alone. In R, the data.frame function can be used to build data frames. Each column in your data should be a separate parameter, with its name provided, followed by an equals sign, followed by the vector of column contents, as shown in the example below. | 1 2 3 4 5 6 . | data &lt;- data.frame( last.name = c( 'Potter', 'Weasley', 'Granger', 'Malfoy' ), first.name = c( 'Harry', 'Ron', 'Hermione', 'Draco' ), house = c( 'Griffindor', 'Griffindor', 'Griffindor', 'Slytherin' ) ) data . | . | 1 2 3 4 5 . | last.name first.name house 1 Potter Harry Griffindor 2 Weasley Ron Griffindor 3 Granger Hermione Griffindor 4 Malfoy Draco Slytherin . | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-a-data-frame-from-scratch/#solution-in-r",
    "relUrl": "/how-to-create-a-data-frame-from-scratch/#solution-in-r"
  },"527": {
    "doc": "How to create a data frame from scratch",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA346 | . ",
    "url": "/how-to-create-a-data-frame-from-scratch/#topics-that-include-this-task",
    "relUrl": "/how-to-create-a-data-frame-from-scratch/#topics-that-include-this-task"
  },"528": {
    "doc": "How to create a data frame from scratch",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-create-a-data-frame-from-scratch/#opportunities",
    "relUrl": "/how-to-create-a-data-frame-from-scratch/#opportunities"
  },"529": {
    "doc": "How to create a histogram (in Python, using Matplotlib)",
    "title": "How to create a histogram (in Python, using Matplotlib)",
    "content": "See all solutions. ",
    "url": "/how-to-create-a-histogram-in-python-using-matplotlib/",
    "relUrl": "/how-to-create-a-histogram-in-python-using-matplotlib/"
  },"530": {
    "doc": "How to create a histogram (in Python, using Matplotlib)",
    "title": "Task",
    "content": "A histogram is a very common and useful data visualization. It displays an approximation of the distribution in single series of data points (one variable) by grouping the data into bins, each bin draw as a vertical bar. How can we create such a visualization? . Related topics: . | How to create basic plots | How to create a box (and whisker) plot | How to add details to a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-a-histogram-in-python-using-matplotlib/#task",
    "relUrl": "/how-to-create-a-histogram-in-python-using-matplotlib/#task"
  },"531": {
    "doc": "How to create a histogram (in Python, using Matplotlib)",
    "title": "Solution",
    "content": "We will create some random data using NumPy, but that’s just for demonstration purposes. You can apply the answer below to any data, even if it’s stored just in plain Python lists. | 1 2 . | import numpy as np data = np.random.normal( size=1000 ) . | . The conventional way to import matplotlib in Python is as follows. | 1 . | import matplotlib.pyplot as plt . | . To create a histogram with 10 bins (the default): . | 1 2 . | plt.hist( data ) # or plt.hist( bins=20 ), or any number plt.show() . | . The $y$ axis in a histogram is frequency, or number of occurrences. You can change it to probabilities instead. | 1 2 . | plt.hist( data, density=True ) plt.show() . | . You can also choose your own bin boundaries. | 1 2 . | plt.hist( data, bins=range(-10,10,1) ) plt.show() . | . Content last modified on 23 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-create-a-histogram-in-python-using-matplotlib/#solution",
    "relUrl": "/how-to-create-a-histogram-in-python-using-matplotlib/#solution"
  },"532": {
    "doc": "How to create a histogram (in R)",
    "title": "How to create a histogram (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-create-a-histogram-in-r/",
    "relUrl": "/how-to-create-a-histogram-in-r/"
  },"533": {
    "doc": "How to create a histogram (in R)",
    "title": "Task",
    "content": "A histogram is a very common and useful data visualization. It displays an approximation of the distribution in single series of data points (one variable) by grouping the data into bins, each bin draw as a vertical bar. How can we create such a visualization? . Related topics: . | How to create basic plots | How to create a box (and whisker) plot | How to add details to a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-a-histogram-in-r/#task",
    "relUrl": "/how-to-create-a-histogram-in-r/#task"
  },"534": {
    "doc": "How to create a histogram (in R)",
    "title": "Solution",
    "content": "We will create some random data, but that’s just for demonstration purposes. You can apply the answer below to any data. Simply replace the data variable with your real data (a list, a column of a dataframe, etc.). | 1 . | data &lt;- rnorm(1000) . | . We can use R’s hist() function to create the histogram. | 1 . | hist(data) . | . The y axis in a histogram is frequency, or the number of occurences. You can change it to probabilities instead. | 1 . | hist(data, prob = TRUE) . | . You can also choose your own bin boundaries. You might specify the number of bin breaks you want, or you can choose the exact bin breaks that you want. | 1 2 . | hist(data, breaks = 8) # Specify number of bin breaks hist(data, breaks = c(seq(-5, 5, 1))) # Choose exact bin breaks . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-create-a-histogram-in-r/#solution",
    "relUrl": "/how-to-create-a-histogram-in-r/#solution"
  },"535": {
    "doc": "How to create a histogram",
    "title": "How to create a histogram",
    "content": " ",
    "url": "/how-to-create-a-histogram/",
    "relUrl": "/how-to-create-a-histogram/"
  },"536": {
    "doc": "How to create a histogram",
    "title": "Description",
    "content": "A histogram is a very common and useful data visualization. It displays an approximation of the distribution in single series of data points (one variable) by grouping the data into bins, each bin draw as a vertical bar. How can we create such a visualization? . Related topics: . | How to create basic plots | How to create a box (and whisker) plot | How to add details to a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-a-histogram/#description",
    "relUrl": "/how-to-create-a-histogram/#description"
  },"537": {
    "doc": "How to create a histogram",
    "title": "Using Matplotlib, in Python",
    "content": "View this solution alone. We will create some random data using NumPy, but that’s just for demonstration purposes. You can apply the answer below to any data, even if it’s stored just in plain Python lists. | 1 2 . | import numpy as np data = np.random.normal( size=1000 ) . | . The conventional way to import matplotlib in Python is as follows. | 1 . | import matplotlib.pyplot as plt . | . To create a histogram with 10 bins (the default): . | 1 2 . | plt.hist( data ) # or plt.hist( bins=20 ), or any number plt.show() . | . The $y$ axis in a histogram is frequency, or number of occurrences. You can change it to probabilities instead. | 1 2 . | plt.hist( data, density=True ) plt.show() . | . You can also choose your own bin boundaries. | 1 2 . | plt.hist( data, bins=range(-10,10,1) ) plt.show() . | . Content last modified on 23 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-a-histogram/#using-matplotlib-in-python",
    "relUrl": "/how-to-create-a-histogram/#using-matplotlib-in-python"
  },"538": {
    "doc": "How to create a histogram",
    "title": "Solution, in R",
    "content": "View this solution alone. We will create some random data, but that’s just for demonstration purposes. You can apply the answer below to any data. Simply replace the data variable with your real data (a list, a column of a dataframe, etc.). | 1 . | data &lt;- rnorm(1000) . | . We can use R’s hist() function to create the histogram. | 1 . | hist(data) . | . The y axis in a histogram is frequency, or the number of occurences. You can change it to probabilities instead. | 1 . | hist(data, prob = TRUE) . | . You can also choose your own bin boundaries. You might specify the number of bin breaks you want, or you can choose the exact bin breaks that you want. | 1 2 . | hist(data, breaks = 8) # Specify number of bin breaks hist(data, breaks = c(seq(-5, 5, 1))) # Choose exact bin breaks . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-a-histogram/#solution-in-r",
    "relUrl": "/how-to-create-a-histogram/#solution-in-r"
  },"539": {
    "doc": "How to create a histogram",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA346 | . ",
    "url": "/how-to-create-a-histogram/#topics-that-include-this-task",
    "relUrl": "/how-to-create-a-histogram/#topics-that-include-this-task"
  },"540": {
    "doc": "How to create a histogram",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-create-a-histogram/#opportunities",
    "relUrl": "/how-to-create-a-histogram/#opportunities"
  },"541": {
    "doc": "How to create a QQ-plot (in Python, using SciPy)",
    "title": "How to create a QQ-plot (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-create-a-qq-plot-in-python-using-scipy/",
    "relUrl": "/how-to-create-a-qq-plot-in-python-using-scipy/"
  },"542": {
    "doc": "How to create a QQ-plot (in Python, using SciPy)",
    "title": "Task",
    "content": "We often want to know whether a set of data is normally distributed, so that we can deduce what inference tests are appropriate to conduct. If we have a set of data and want to figure out if it comes from a population that follows a normal distribution, one tool that can help is a QQ plot. How do we make and interpret one? . Related tasks: . | How to test data for normality with Pearson’s chi-squared test | How to test data for normality with the D’Agostino-Pearson test | How to test data for normality with the Jarque-Bera test | . ",
    "url": "/how-to-create-a-qq-plot-in-python-using-scipy/#task",
    "relUrl": "/how-to-create-a-qq-plot-in-python-using-scipy/#task"
  },"543": {
    "doc": "How to create a QQ-plot (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’re going to use some fake data here by generating random numbers, but you can replace our fake data with your real data in the code below. | 1 2 3 . | # Replace this with your data, such as a variable or column in a DataFrame import numpy as np values = np.random.normal(0, 1, 50) # 50 random values . | . If the data is normally distributed, then we expect that the QQ plot will show the observed values (blue dots) falling very clsoe to the red line (the quantiles for the normal distribution). | 1 2 3 4 5 . | from scipy import stats import matplotlib.pyplot as plt stats.probplot(values, dist=\"norm\", plot=plt) plt.show() . | . Our observed values fall pretty close to the reference line. In this case, we expected that, because we created fake data that was normally distributed. But for real data, it may not stay so close to the red line. Content last modified on 14 September 2021. See a problem? Tell us or edit the source. Contributed by: . | Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) | Nathan Carter (ncarter@bentley.edu) | . ",
    "url": "/how-to-create-a-qq-plot-in-python-using-scipy/#solution",
    "relUrl": "/how-to-create-a-qq-plot-in-python-using-scipy/#solution"
  },"544": {
    "doc": "How to create a QQ-plot (in Python, using statsmodels)",
    "title": "How to create a QQ-plot (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-create-a-qq-plot-in-python-using-statsmodels/",
    "relUrl": "/how-to-create-a-qq-plot-in-python-using-statsmodels/"
  },"545": {
    "doc": "How to create a QQ-plot (in Python, using statsmodels)",
    "title": "Task",
    "content": "We often want to know whether a set of data is normally distributed, so that we can deduce what inference tests are appropriate to conduct. If we have a set of data and want to figure out if it comes from a population that follows a normal distribution, one tool that can help is a QQ plot. How do we make and interpret one? . Related tasks: . | How to test data for normality with Pearson’s chi-squared test | How to test data for normality with the D’Agostino-Pearson test | How to test data for normality with the Jarque-Bera test | . ",
    "url": "/how-to-create-a-qq-plot-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-create-a-qq-plot-in-python-using-statsmodels/#task"
  },"546": {
    "doc": "How to create a QQ-plot (in Python, using statsmodels)",
    "title": "Solution",
    "content": "We’re going to use some fake data here by generating random numbers, but you can replace our fake data with your real data in the code below. | 1 2 3 . | # Replace this with your data, such as a variable or column in a DataFrame import numpy as np values = np.random.normal(0, 1, 50) # 50 random values . | . If the data is normally distributed, then we expect that the QQ plot will show the observed values (blue dots) falling very clsoe to the red line (the quantiles for the normal distribution). | 1 2 3 4 5 . | import statsmodels.api as sm import matplotlib.pyplot as plt sm.qqplot(values, line = '45') plt.show() . | . | 1 2 . | /opt/conda/lib/python3.9/site-packages/statsmodels/graphics/gofplots.py:993: UserWarning: marker is redundantly defined by the 'marker' keyword argument and the fmt string \"bo\" (-&gt; marker='o'). The keyword argument will take precedence. ax.plot(x, y, fmt, **plot_style) . | . Our observed values fall pretty close to the reference line. In this case, we expected that, because we created fake data that was normally distributed. But for real data, it may not stay so close to the red line. Content last modified on 16 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-create-a-qq-plot-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-create-a-qq-plot-in-python-using-statsmodels/#solution"
  },"547": {
    "doc": "How to create a QQ-plot (in R)",
    "title": "How to create a QQ-plot (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-create-a-qq-plot-in-r/",
    "relUrl": "/how-to-create-a-qq-plot-in-r/"
  },"548": {
    "doc": "How to create a QQ-plot (in R)",
    "title": "Task",
    "content": "We often want to know whether a set of data is normally distributed, so that we can deduce what inference tests are appropriate to conduct. If we have a set of data and want to figure out if it comes from a population that follows a normal distribution, one tool that can help is a QQ plot. How do we make and interpret one? . Related tasks: . | How to test data for normality with Pearson’s chi-squared test | How to test data for normality with the D’Agostino-Pearson test | How to test data for normality with the Jarque-Bera test | . ",
    "url": "/how-to-create-a-qq-plot-in-r/#task",
    "relUrl": "/how-to-create-a-qq-plot-in-r/#task"
  },"549": {
    "doc": "How to create a QQ-plot (in R)",
    "title": "Solution",
    "content": "We’re going to use some fake data here by generating random numbers, but you can replace our fake data with your real data in the code below. | 1 2 . | # Replace this with your data, such as a variable or column in a DataFrame values &lt;- c(4, 90, 85, 49, 34, 23, 17, 10, 20, 59, 100, 112, 46, 10, 4, 39, 24, 77, 63, 23, 67, 109, 70) . | . If the data is normally distributed, then we expect that the QQ plot will show the observed values (black circles) falling very clsoe to the red line (the quantiles for the normal distribution). | 1 2 3 4 . | # Make a QQ plot for the data qqnorm(values, pch = 1) # Add the reference line representing what the data should look like if normally distributed qqline(values, col = \"red\", lwd = 2) . | . Our observed values fall pretty close to the reference line. In this case, we expected that, because we created fake data that was normally distributed. But for real data, it may not stay so close to the red line. Content last modified on 14 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-create-a-qq-plot-in-r/#solution",
    "relUrl": "/how-to-create-a-qq-plot-in-r/#solution"
  },"550": {
    "doc": "How to create a QQ-plot",
    "title": "How to create a QQ-plot",
    "content": " ",
    "url": "/how-to-create-a-qq-plot/",
    "relUrl": "/how-to-create-a-qq-plot/"
  },"551": {
    "doc": "How to create a QQ-plot",
    "title": "Description",
    "content": "We often want to know whether a set of data is normally distributed, so that we can deduce what inference tests are appropriate to conduct. If we have a set of data and want to figure out if it comes from a population that follows a normal distribution, one tool that can help is a QQ plot. How do we make and interpret one? . Related tasks: . | How to test data for normality with Pearson’s chi-squared test | How to test data for normality with the D’Agostino-Pearson test | How to test data for normality with the Jarque-Bera test | . ",
    "url": "/how-to-create-a-qq-plot/#description",
    "relUrl": "/how-to-create-a-qq-plot/#description"
  },"552": {
    "doc": "How to create a QQ-plot",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’re going to use some fake data here by generating random numbers, but you can replace our fake data with your real data in the code below. | 1 2 3 . | # Replace this with your data, such as a variable or column in a DataFrame import numpy as np values = np.random.normal(0, 1, 50) # 50 random values . | . If the data is normally distributed, then we expect that the QQ plot will show the observed values (blue dots) falling very clsoe to the red line (the quantiles for the normal distribution). | 1 2 3 4 5 . | from scipy import stats import matplotlib.pyplot as plt stats.probplot(values, dist=\"norm\", plot=plt) plt.show() . | . Our observed values fall pretty close to the reference line. In this case, we expected that, because we created fake data that was normally distributed. But for real data, it may not stay so close to the red line. Content last modified on 14 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-a-qq-plot/#using-scipy-in-python",
    "relUrl": "/how-to-create-a-qq-plot/#using-scipy-in-python"
  },"553": {
    "doc": "How to create a QQ-plot",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. We’re going to use some fake data here by generating random numbers, but you can replace our fake data with your real data in the code below. | 1 2 3 . | # Replace this with your data, such as a variable or column in a DataFrame import numpy as np values = np.random.normal(0, 1, 50) # 50 random values . | . If the data is normally distributed, then we expect that the QQ plot will show the observed values (blue dots) falling very clsoe to the red line (the quantiles for the normal distribution). | 1 2 3 4 5 . | import statsmodels.api as sm import matplotlib.pyplot as plt sm.qqplot(values, line = '45') plt.show() . | . | 1 2 . | /opt/conda/lib/python3.9/site-packages/statsmodels/graphics/gofplots.py:993: UserWarning: marker is redundantly defined by the 'marker' keyword argument and the fmt string \"bo\" (-&gt; marker='o'). The keyword argument will take precedence. ax.plot(x, y, fmt, **plot_style) . | . Our observed values fall pretty close to the reference line. In this case, we expected that, because we created fake data that was normally distributed. But for real data, it may not stay so close to the red line. Content last modified on 16 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-a-qq-plot/#using-statsmodels-in-python",
    "relUrl": "/how-to-create-a-qq-plot/#using-statsmodels-in-python"
  },"554": {
    "doc": "How to create a QQ-plot",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use some fake data here by generating random numbers, but you can replace our fake data with your real data in the code below. | 1 2 . | # Replace this with your data, such as a variable or column in a DataFrame values &lt;- c(4, 90, 85, 49, 34, 23, 17, 10, 20, 59, 100, 112, 46, 10, 4, 39, 24, 77, 63, 23, 67, 109, 70) . | . If the data is normally distributed, then we expect that the QQ plot will show the observed values (black circles) falling very clsoe to the red line (the quantiles for the normal distribution). | 1 2 3 4 . | # Make a QQ plot for the data qqnorm(values, pch = 1) # Add the reference line representing what the data should look like if normally distributed qqline(values, col = \"red\", lwd = 2) . | . Our observed values fall pretty close to the reference line. In this case, we expected that, because we created fake data that was normally distributed. But for real data, it may not stay so close to the red line. Content last modified on 14 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-a-qq-plot/#solution-in-r",
    "relUrl": "/how-to-create-a-qq-plot/#solution-in-r"
  },"555": {
    "doc": "How to create a QQ-plot",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | Bentley University MA346 | . ",
    "url": "/how-to-create-a-qq-plot/#topics-that-include-this-task",
    "relUrl": "/how-to-create-a-qq-plot/#topics-that-include-this-task"
  },"556": {
    "doc": "How to create a QQ-plot",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-create-a-qq-plot/#opportunities",
    "relUrl": "/how-to-create-a-qq-plot/#opportunities"
  },"557": {
    "doc": "How to create basic plots (in Python, using Matplotlib)",
    "title": "How to create basic plots (in Python, using Matplotlib)",
    "content": "See all solutions. ",
    "url": "/how-to-create-basic-plots-in-python-using-matplotlib/",
    "relUrl": "/how-to-create-basic-plots-in-python-using-matplotlib/"
  },"558": {
    "doc": "How to create basic plots (in Python, using Matplotlib)",
    "title": "Task",
    "content": "Plotting is a huge topic with many options and variations, but the most foundational types of plots are a line plot and a scatterplot. How can we create those? . Related topics: . | How to add details to a plot | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-basic-plots-in-python-using-matplotlib/#task",
    "relUrl": "/how-to-create-basic-plots-in-python-using-matplotlib/#task"
  },"559": {
    "doc": "How to create basic plots (in Python, using Matplotlib)",
    "title": "Solution",
    "content": "We will create some fake data using Python lists, for simplicity. But everything we show below works also if your data is in columns of a DataFrame, such as df['age']. | 1 2 3 . | patient_id = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ] patient_height = [ 60, 64, 64, 65, 66, 66, 70, 72, 72, 76 ] patient_weight = [ 141, 182, 169, 204, 138, 198, 180, 175, 244, 196 ] . | . The conventional way to import matplotlib in Python is as follows. | 1 . | import matplotlib.pyplot as plt . | . Make a line plot by giving the $x$ and $y$​ data values in separate lists (or in this case pandas Series). This line plot is very jagged just because the data was random. | 1 2 . | plt.plot( patient_id, patient_height ) # create plot plt.show() # display plot . | . You can make a scatterplot as follows. | 1 2 . | plt.scatter( patient_height, patient_weight ) # create plot plt.show() # display plot . | . If your data is already in a pandas DataFrame, there are shortcuts: . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 . | # Plot all columns: df.plot() plt.show() # Plot all columns in separate subplots: df.plot( subplots = True ) plt.show() # Plot one column: df['column'].plot() plt.show() # Plot specific columns: df.plot( x='col name', y='other col name' ) plt.show() . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-create-basic-plots-in-python-using-matplotlib/#solution",
    "relUrl": "/how-to-create-basic-plots-in-python-using-matplotlib/#solution"
  },"560": {
    "doc": "How to create basic plots (in R)",
    "title": "How to create basic plots (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-create-basic-plots-in-r/",
    "relUrl": "/how-to-create-basic-plots-in-r/"
  },"561": {
    "doc": "How to create basic plots (in R)",
    "title": "Task",
    "content": "Plotting is a huge topic with many options and variations, but the most foundational types of plots are a line plot and a scatterplot. How can we create those? . Related topics: . | How to add details to a plot | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-basic-plots-in-r/#task",
    "relUrl": "/how-to-create-basic-plots-in-r/#task"
  },"562": {
    "doc": "How to create basic plots (in R)",
    "title": "Solution",
    "content": "We will create some fake data using vectors, for simplicity. But everything we show below works also if your data is in columns of a DataFrame. | 1 2 3 . | patient.id &lt;- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) patient.height &lt;- c(60, 64, 64, 65, 66, 66, 70, 72, 72, 76) patient.weight &lt;- c(141, 182, 169, 204, 138, 198, 180, 175, 244, 196) . | . We can make a line plot if we use the type=\"l\" option (which is an “ell,” not a number one). | 1 . | plot(patient.id, patient.height, main=\"Patient heights\", type=\"l\") . | . We can create a scatterplot if we have two numerical columns, such as the height and weight in the data above. | 1 . | plot(patient.height, patient.weight, main = \"Height vs. Weight\") . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. Contributed by: . | Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) | Nathan Carter (ncarter@bentley.edu) | . ",
    "url": "/how-to-create-basic-plots-in-r/#solution",
    "relUrl": "/how-to-create-basic-plots-in-r/#solution"
  },"563": {
    "doc": "How to create basic plots",
    "title": "How to create basic plots",
    "content": " ",
    "url": "/how-to-create-basic-plots/",
    "relUrl": "/how-to-create-basic-plots/"
  },"564": {
    "doc": "How to create basic plots",
    "title": "Description",
    "content": "Plotting is a huge topic with many options and variations, but the most foundational types of plots are a line plot and a scatterplot. How can we create those? . Related topics: . | How to add details to a plot | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-basic-plots/#description",
    "relUrl": "/how-to-create-basic-plots/#description"
  },"565": {
    "doc": "How to create basic plots",
    "title": "Using Matplotlib, in Python",
    "content": "View this solution alone. We will create some fake data using Python lists, for simplicity. But everything we show below works also if your data is in columns of a DataFrame, such as df['age']. | 1 2 3 . | patient_id = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ] patient_height = [ 60, 64, 64, 65, 66, 66, 70, 72, 72, 76 ] patient_weight = [ 141, 182, 169, 204, 138, 198, 180, 175, 244, 196 ] . | . The conventional way to import matplotlib in Python is as follows. | 1 . | import matplotlib.pyplot as plt . | . Make a line plot by giving the $x$ and $y$​ data values in separate lists (or in this case pandas Series). This line plot is very jagged just because the data was random. | 1 2 . | plt.plot( patient_id, patient_height ) # create plot plt.show() # display plot . | . You can make a scatterplot as follows. | 1 2 . | plt.scatter( patient_height, patient_weight ) # create plot plt.show() # display plot . | . If your data is already in a pandas DataFrame, there are shortcuts: . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 . | # Plot all columns: df.plot() plt.show() # Plot all columns in separate subplots: df.plot( subplots = True ) plt.show() # Plot one column: df['column'].plot() plt.show() # Plot specific columns: df.plot( x='col name', y='other col name' ) plt.show() . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-basic-plots/#using-matplotlib-in-python",
    "relUrl": "/how-to-create-basic-plots/#using-matplotlib-in-python"
  },"566": {
    "doc": "How to create basic plots",
    "title": "Solution, in R",
    "content": "View this solution alone. We will create some fake data using vectors, for simplicity. But everything we show below works also if your data is in columns of a DataFrame. | 1 2 3 . | patient.id &lt;- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9) patient.height &lt;- c(60, 64, 64, 65, 66, 66, 70, 72, 72, 76) patient.weight &lt;- c(141, 182, 169, 204, 138, 198, 180, 175, 244, 196) . | . We can make a line plot if we use the type=\"l\" option (which is an “ell,” not a number one). | 1 . | plot(patient.id, patient.height, main=\"Patient heights\", type=\"l\") . | . We can create a scatterplot if we have two numerical columns, such as the height and weight in the data above. | 1 . | plot(patient.height, patient.weight, main = \"Height vs. Weight\") . | . Content last modified on 14 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-basic-plots/#solution-in-r",
    "relUrl": "/how-to-create-basic-plots/#solution-in-r"
  },"567": {
    "doc": "How to create basic plots",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA346 | . ",
    "url": "/how-to-create-basic-plots/#topics-that-include-this-task",
    "relUrl": "/how-to-create-basic-plots/#topics-that-include-this-task"
  },"568": {
    "doc": "How to create basic plots",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-create-basic-plots/#opportunities",
    "relUrl": "/how-to-create-basic-plots/#opportunities"
  },"569": {
    "doc": "How to create bivariate plots to compare groups (in Python, using Matplotlib and Seaborn)",
    "title": "How to create bivariate plots to compare groups (in Python, using Matplotlib and Seaborn)",
    "content": "See all solutions. ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups-in-python-using-matplotlib-and-seaborn/",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups-in-python-using-matplotlib-and-seaborn/"
  },"570": {
    "doc": "How to create bivariate plots to compare groups (in Python, using Matplotlib and Seaborn)",
    "title": "Task",
    "content": "Suppose we have a dataset with different treatment conditions and an outcome variable, and we want to perform exploratory data analysis. How would we visually compare the treatment conditions with regards to the outcome variable? . Related tasks: . | How to create basic plots | How to add details to a plot | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups-in-python-using-matplotlib-and-seaborn/#task",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups-in-python-using-matplotlib-and-seaborn/#task"
  },"571": {
    "doc": "How to create bivariate plots to compare groups (in Python, using Matplotlib and Seaborn)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . If you wish to understand the distribution of a numeric variable (here “len”) compared across different values of a categorical variable (here “supp”), you can construct a bivariate histogram. We use Seaborn and Matplotlib to do so. | 1 2 3 4 . | import seaborn as sns import matplotlib.pyplot as plt sns.displot(df, x=\"len\", col=\"supp\", stat=\"density\") plt.show() . | . To visualize the same information summarized using quartiles only, you can construct a bivariate box plot. | 1 2 . | sns.boxplot(x=\"supp\", y=\"len\", data = df, order = ['OJ','VC']) plt.show() . | . Even more simply, we may wish to plot just the means and 95% confidence intervals around the mean for the quantitative variable, for each of the values of the categorical variable. We do so with a point plot. | 1 2 3 4 . | sns.pointplot(x = 'supp', y = 'len', data = df, ci = 95, # Which confidence interval? Here 95%. capsize = 0.1) # Size of \"cap\" drawn on each confidence interval. plt.show() . | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups-in-python-using-matplotlib-and-seaborn/#solution",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups-in-python-using-matplotlib-and-seaborn/#solution"
  },"572": {
    "doc": "How to create bivariate plots to compare groups (in R, using lattice and gplots)",
    "title": "How to create bivariate plots to compare groups (in R, using lattice and gplots)",
    "content": "See all solutions. ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups-in-r-using-lattice-and-gplots/",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups-in-r-using-lattice-and-gplots/"
  },"573": {
    "doc": "How to create bivariate plots to compare groups (in R, using lattice and gplots)",
    "title": "Task",
    "content": "Suppose we have a dataset with different treatment conditions and an outcome variable, and we want to perform exploratory data analysis. How would we visually compare the treatment conditions with regards to the outcome variable? . Related tasks: . | How to create basic plots | How to add details to a plot | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups-in-r-using-lattice-and-gplots/#task",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups-in-r-using-lattice-and-gplots/#task"
  },"574": {
    "doc": "How to create bivariate plots to compare groups (in R, using lattice and gplots)",
    "title": "Solution",
    "content": "We use a built-in dataset called ToothGrowth that discusses the length of the teeth (len) in each of 10 guinea pigs at three Vitamin C dosage levels ($0.5$, $1$, and $2$ mg) with two delivery methods - orange juice or ascorbic acid (supp). | 1 2 . | # You can replace this example data frame with your own data df &lt;- ToothGrowth . | . If you wish to understand the distribution of the length of the tooth based on the delivery methods, you can construct a bivariate histogram plot. | 1 2 3 . | # install.packages( \"lattice\" ) # if you have not already done this library(lattice) histogram( ~ len | supp, data = df) . | . To visualize the summary statistics of the length of the tooth based on the delivery methods, you can construct a bivariate box plot. | 1 2 3 . | bwplot(df$len ~ df$supp) # Or the following code produces a similar figure, using the mosaic package: # boxplot(len ~ supp, data = df) . | . To plot the means for both treatment levels of supp for the len column, we load the gplots package and use the plotmeans function. | 1 2 3 . | # install.packages( \"gplots\" ) # if you have not already done this library(gplots) plotmeans(df$len ~ df$supp) . | . | 1 2 3 4 5 6 . | Attaching package: ‘gplots’ The following object is masked from ‘package:stats’: lowess . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups-in-r-using-lattice-and-gplots/#solution",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups-in-r-using-lattice-and-gplots/#solution"
  },"575": {
    "doc": "How to create bivariate plots to compare groups",
    "title": "How to create bivariate plots to compare groups",
    "content": " ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups/",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups/"
  },"576": {
    "doc": "How to create bivariate plots to compare groups",
    "title": "Description",
    "content": "Suppose we have a dataset with different treatment conditions and an outcome variable, and we want to perform exploratory data analysis. How would we visually compare the treatment conditions with regards to the outcome variable? . Related tasks: . | How to create basic plots | How to add details to a plot | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to plot interaction effects of treatments | . ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups/#description",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups/#description"
  },"577": {
    "doc": "How to create bivariate plots to compare groups",
    "title": "Using Matplotlib and Seaborn, in Python",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . If you wish to understand the distribution of a numeric variable (here “len”) compared across different values of a categorical variable (here “supp”), you can construct a bivariate histogram. We use Seaborn and Matplotlib to do so. | 1 2 3 4 . | import seaborn as sns import matplotlib.pyplot as plt sns.displot(df, x=\"len\", col=\"supp\", stat=\"density\") plt.show() . | . To visualize the same information summarized using quartiles only, you can construct a bivariate box plot. | 1 2 . | sns.boxplot(x=\"supp\", y=\"len\", data = df, order = ['OJ','VC']) plt.show() . | . Even more simply, we may wish to plot just the means and 95% confidence intervals around the mean for the quantitative variable, for each of the values of the categorical variable. We do so with a point plot. | 1 2 3 4 . | sns.pointplot(x = 'supp', y = 'len', data = df, ci = 95, # Which confidence interval? Here 95%. capsize = 0.1) # Size of \"cap\" drawn on each confidence interval. plt.show() . | . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups/#using-matplotlib-and-seaborn-in-python",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups/#using-matplotlib-and-seaborn-in-python"
  },"578": {
    "doc": "How to create bivariate plots to compare groups",
    "title": "Using lattice and gplots, in R",
    "content": "View this solution alone. We use a built-in dataset called ToothGrowth that discusses the length of the teeth (len) in each of 10 guinea pigs at three Vitamin C dosage levels ($0.5$, $1$, and $2$ mg) with two delivery methods - orange juice or ascorbic acid (supp). | 1 2 . | # You can replace this example data frame with your own data df &lt;- ToothGrowth . | . If you wish to understand the distribution of the length of the tooth based on the delivery methods, you can construct a bivariate histogram plot. | 1 2 3 . | # install.packages( \"lattice\" ) # if you have not already done this library(lattice) histogram( ~ len | supp, data = df) . | . To visualize the summary statistics of the length of the tooth based on the delivery methods, you can construct a bivariate box plot. | 1 2 3 . | bwplot(df$len ~ df$supp) # Or the following code produces a similar figure, using the mosaic package: # boxplot(len ~ supp, data = df) . | . To plot the means for both treatment levels of supp for the len column, we load the gplots package and use the plotmeans function. | 1 2 3 . | # install.packages( \"gplots\" ) # if you have not already done this library(gplots) plotmeans(df$len ~ df$supp) . | . | 1 2 3 4 5 6 . | Attaching package: ‘gplots’ The following object is masked from ‘package:stats’: lowess . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups/#using-lattice-and-gplots-in-r",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups/#using-lattice-and-gplots-in-r"
  },"579": {
    "doc": "How to create bivariate plots to compare groups",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups/#topics-that-include-this-task",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups/#topics-that-include-this-task"
  },"580": {
    "doc": "How to create bivariate plots to compare groups",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-create-bivariate-plots-to-compare-groups/#opportunities",
    "relUrl": "/how-to-create-bivariate-plots-to-compare-groups/#opportunities"
  },"581": {
    "doc": "How to create symbolic variables (in Python, using SymPy)",
    "title": "How to create symbolic variables (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-create-symbolic-variables-in-python-using-sympy/",
    "relUrl": "/how-to-create-symbolic-variables-in-python-using-sympy/"
  },"582": {
    "doc": "How to create symbolic variables (in Python, using SymPy)",
    "title": "Task",
    "content": "The word “variable” does not mean the same thing in mathematics as it does in computer programming. In mathematics, we often use it to mean an unknown for which we might solve; but in programming, variables typically have known values. If we want to do symbolic mathematics in a software package, how can we tell the computer that we want to use variables in the mathematical sense, as symbols whose value may be unknown? . Related tasks: . | How to substitute a value for a symbolic variable | . ",
    "url": "/how-to-create-symbolic-variables-in-python-using-sympy/#task",
    "relUrl": "/how-to-create-symbolic-variables-in-python-using-sympy/#task"
  },"583": {
    "doc": "How to create symbolic variables (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . You can define any number of variables as follows. Here we define $x$, $y$, and $z$. | 1 . | var( 'x y z' ) . | . $\\displaystyle \\left( x, \\ y, \\ z\\right)$ . You can tell that they are variables, because when you ask Python to print them out, it does not print a value (such as a number) but rather just the symbol itself. | 1 . | x . | . $\\displaystyle x$ . And when you use a symbol inside a larger formula, it doesn’t attempt to compute a result, but stores the entire formula symbolically. | 1 2 . | formula = sqrt(x) + 5 formula . | . $\\displaystyle \\sqrt{x} + 5$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-create-symbolic-variables-in-python-using-sympy/#solution",
    "relUrl": "/how-to-create-symbolic-variables-in-python-using-sympy/#solution"
  },"584": {
    "doc": "How to create symbolic variables",
    "title": "How to create symbolic variables",
    "content": " ",
    "url": "/how-to-create-symbolic-variables/",
    "relUrl": "/how-to-create-symbolic-variables/"
  },"585": {
    "doc": "How to create symbolic variables",
    "title": "Description",
    "content": "The word “variable” does not mean the same thing in mathematics as it does in computer programming. In mathematics, we often use it to mean an unknown for which we might solve; but in programming, variables typically have known values. If we want to do symbolic mathematics in a software package, how can we tell the computer that we want to use variables in the mathematical sense, as symbols whose value may be unknown? . Related tasks: . | How to substitute a value for a symbolic variable | . ",
    "url": "/how-to-create-symbolic-variables/#description",
    "relUrl": "/how-to-create-symbolic-variables/#description"
  },"586": {
    "doc": "How to create symbolic variables",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . You can define any number of variables as follows. Here we define $x$, $y$, and $z$. | 1 . | var( 'x y z' ) . | . $\\displaystyle \\left( x, \\ y, \\ z\\right)$ . You can tell that they are variables, because when you ask Python to print them out, it does not print a value (such as a number) but rather just the symbol itself. | 1 . | x . | . $\\displaystyle x$ . And when you use a symbol inside a larger formula, it doesn’t attempt to compute a result, but stores the entire formula symbolically. | 1 2 . | formula = sqrt(x) + 5 formula . | . $\\displaystyle \\sqrt{x} + 5$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-create-symbolic-variables/#using-sympy-in-python",
    "relUrl": "/how-to-create-symbolic-variables/#using-sympy-in-python"
  },"587": {
    "doc": "How to create symbolic variables",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-create-symbolic-variables/#topics-that-include-this-task",
    "relUrl": "/how-to-create-symbolic-variables/#topics-that-include-this-task"
  },"588": {
    "doc": "How to create symbolic variables",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-create-symbolic-variables/#opportunities",
    "relUrl": "/how-to-create-symbolic-variables/#opportunities"
  },"589": {
    "doc": "How to define a mathematical sequence (in Python, using SymPy)",
    "title": "How to define a mathematical sequence (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-define-a-mathematical-sequence-in-python-using-sympy/",
    "relUrl": "/how-to-define-a-mathematical-sequence-in-python-using-sympy/"
  },"590": {
    "doc": "How to define a mathematical sequence (in Python, using SymPy)",
    "title": "Task",
    "content": "In mathematics, a sequence is an infinite list of values, typically real numbers, often written $a_0,a_1,a_2,\\ldots$, or collectively as $a_n$. (Let’s assume that sequences are indexed starting with index 0, at $a_0$, even though some definitions start with index 1, at $a_1$, instead.) . How can we express sequences in mathematical software? . Related tasks: . | How to define a mathematical series | . ",
    "url": "/how-to-define-a-mathematical-sequence-in-python-using-sympy/#task",
    "relUrl": "/how-to-define-a-mathematical-sequence-in-python-using-sympy/#task"
  },"591": {
    "doc": "How to define a mathematical sequence (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Sequences are typically written in terms of an independent variable $n$, so we will tell SymPy to use $n$ as a symbol, then define our sequence in terms of $n$. We define a term of an example sequence as $a_n=\\frac{1}{n+1}$, then build a sequence from that term. The code (n,0,oo) means that $n$ starts counting at $n=0$ and goes on forever (with oo being the SymPy notation for $\\infty$). | 1 2 3 4 . | var( 'n' ) # use n as a symbol a_n = 1 / ( n + 1 ) # formula for a term seq = sequence( a_n, (n,0,oo) ) # build the sequence seq . | . $\\displaystyle \\left[1, \\frac{1}{2}, \\frac{1}{3}, \\frac{1}{4}, \\ldots\\right]$ . You can ask for specific terms in the sequence, or many terms in a row, as follows. | 1 . | seq[20] . | . $\\displaystyle \\frac{1}{21}$ . | 1 . | seq[:10] . | . $\\displaystyle \\left[ 1, \\ \\frac{1}{2}, \\ \\frac{1}{3}, \\ \\frac{1}{4}, \\ \\frac{1}{5}, \\ \\frac{1}{6}, \\ \\frac{1}{7}, \\ \\frac{1}{8}, \\ \\frac{1}{9}, \\ \\frac{1}{10}\\right]$ . You can compute the limit of a sequence, . \\[\\lim_{n\\to\\infty} a_n.\\] | 1 . | limit( a_n, n, oo ) . | . $\\displaystyle 0$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-define-a-mathematical-sequence-in-python-using-sympy/#solution",
    "relUrl": "/how-to-define-a-mathematical-sequence-in-python-using-sympy/#solution"
  },"592": {
    "doc": "How to define a mathematical sequence",
    "title": "How to define a mathematical sequence",
    "content": " ",
    "url": "/how-to-define-a-mathematical-sequence/",
    "relUrl": "/how-to-define-a-mathematical-sequence/"
  },"593": {
    "doc": "How to define a mathematical sequence",
    "title": "Description",
    "content": "In mathematics, a sequence is an infinite list of values, typically real numbers, often written $a_0,a_1,a_2,\\ldots$, or collectively as $a_n$. (Let’s assume that sequences are indexed starting with index 0, at $a_0$, even though some definitions start with index 1, at $a_1$, instead.) . How can we express sequences in mathematical software? . Related tasks: . | How to define a mathematical series | . ",
    "url": "/how-to-define-a-mathematical-sequence/#description",
    "relUrl": "/how-to-define-a-mathematical-sequence/#description"
  },"594": {
    "doc": "How to define a mathematical sequence",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Sequences are typically written in terms of an independent variable $n$, so we will tell SymPy to use $n$ as a symbol, then define our sequence in terms of $n$. We define a term of an example sequence as $a_n=\\frac{1}{n+1}$, then build a sequence from that term. The code (n,0,oo) means that $n$ starts counting at $n=0$ and goes on forever (with oo being the SymPy notation for $\\infty$). | 1 2 3 4 . | var( 'n' ) # use n as a symbol a_n = 1 / ( n + 1 ) # formula for a term seq = sequence( a_n, (n,0,oo) ) # build the sequence seq . | . $\\displaystyle \\left[1, \\frac{1}{2}, \\frac{1}{3}, \\frac{1}{4}, \\ldots\\right]$ . You can ask for specific terms in the sequence, or many terms in a row, as follows. | 1 . | seq[20] . | . $\\displaystyle \\frac{1}{21}$ . | 1 . | seq[:10] . | . $\\displaystyle \\left[ 1, \\ \\frac{1}{2}, \\ \\frac{1}{3}, \\ \\frac{1}{4}, \\ \\frac{1}{5}, \\ \\frac{1}{6}, \\ \\frac{1}{7}, \\ \\frac{1}{8}, \\ \\frac{1}{9}, \\ \\frac{1}{10}\\right]$ . You can compute the limit of a sequence, . \\[\\lim_{n\\to\\infty} a_n.\\] | 1 . | limit( a_n, n, oo ) . | . $\\displaystyle 0$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-define-a-mathematical-sequence/#using-sympy-in-python",
    "relUrl": "/how-to-define-a-mathematical-sequence/#using-sympy-in-python"
  },"595": {
    "doc": "How to define a mathematical sequence",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-define-a-mathematical-sequence/#topics-that-include-this-task",
    "relUrl": "/how-to-define-a-mathematical-sequence/#topics-that-include-this-task"
  },"596": {
    "doc": "How to define a mathematical sequence",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-define-a-mathematical-sequence/#opportunities",
    "relUrl": "/how-to-define-a-mathematical-sequence/#opportunities"
  },"597": {
    "doc": "How to define a mathematical series (in Python, using SymPy)",
    "title": "How to define a mathematical series (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-define-a-mathematical-series-in-python-using-sympy/",
    "relUrl": "/how-to-define-a-mathematical-series-in-python-using-sympy/"
  },"598": {
    "doc": "How to define a mathematical series (in Python, using SymPy)",
    "title": "Task",
    "content": "In mathematics, a series is a sum of values from a sequence, typically real numbers. Finite series are written as $a_0+a_1+\\cdots+a_n$, or . \\[\\sum_{i=0}^n a_i.\\] Infinite series are written as $a_0+a_1+a_2+\\cdots$, or . \\[\\sum_{n=0}^\\infty a_n.\\] How can we express series in mathematical software? . Related tasks: . | How to define a mathematical series | . ",
    "url": "/how-to-define-a-mathematical-series-in-python-using-sympy/#task",
    "relUrl": "/how-to-define-a-mathematical-series-in-python-using-sympy/#task"
  },"599": {
    "doc": "How to define a mathematical series (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . We define here the same sequence we defined in the task entitled how to define a mathematical sequence. | 1 2 3 4 . | var( 'n' ) # use n as a symbol a_n = 1 / ( n + 1 ) # formula for a term seq = sequence( a_n, (n,0,oo) ) # build the sequence seq . | . $\\displaystyle \\left[1, \\frac{1}{2}, \\frac{1}{3}, \\frac{1}{4}, \\ldots\\right]$ . We can turn it into a mathematical series by simply replacing the word sequence with the word Sum. This does not compute the answer, but just writes the series for us to view. In this case, it is an infinite series. | 1 . | Sum( a_n, (n,0,oo) ) . | . $\\displaystyle \\sum_{n=0}^{\\infty} \\frac{1}{n + 1}$ . You can compute the answer by appending the code .doit() to the above code, which asks SymPy to “do” (or evaluate) the sum. | 1 . | Sum( a_n, (n,0,oo) ).doit() . | . $\\displaystyle \\infty$ . In this case, the series diverges. We can also create and evaluate finite series by replacing the oo with a number. | 1 . | Sum( a_n, (n,0,10) ).doit() . | . $\\displaystyle \\frac{83711}{27720}$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-define-a-mathematical-series-in-python-using-sympy/#solution",
    "relUrl": "/how-to-define-a-mathematical-series-in-python-using-sympy/#solution"
  },"600": {
    "doc": "How to define a mathematical series",
    "title": "How to define a mathematical series",
    "content": " ",
    "url": "/how-to-define-a-mathematical-series/",
    "relUrl": "/how-to-define-a-mathematical-series/"
  },"601": {
    "doc": "How to define a mathematical series",
    "title": "Description",
    "content": "In mathematics, a series is a sum of values from a sequence, typically real numbers. Finite series are written as $a_0+a_1+\\cdots+a_n$, or . \\[\\sum_{i=0}^n a_i.\\] Infinite series are written as $a_0+a_1+a_2+\\cdots$, or . \\[\\sum_{n=0}^\\infty a_n.\\] How can we express series in mathematical software? . Related tasks: . | How to define a mathematical series | . ",
    "url": "/how-to-define-a-mathematical-series/#description",
    "relUrl": "/how-to-define-a-mathematical-series/#description"
  },"602": {
    "doc": "How to define a mathematical series",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . We define here the same sequence we defined in the task entitled how to define a mathematical sequence. | 1 2 3 4 . | var( 'n' ) # use n as a symbol a_n = 1 / ( n + 1 ) # formula for a term seq = sequence( a_n, (n,0,oo) ) # build the sequence seq . | . $\\displaystyle \\left[1, \\frac{1}{2}, \\frac{1}{3}, \\frac{1}{4}, \\ldots\\right]$ . We can turn it into a mathematical series by simply replacing the word sequence with the word Sum. This does not compute the answer, but just writes the series for us to view. In this case, it is an infinite series. | 1 . | Sum( a_n, (n,0,oo) ) . | . $\\displaystyle \\sum_{n=0}^{\\infty} \\frac{1}{n + 1}$ . You can compute the answer by appending the code .doit() to the above code, which asks SymPy to “do” (or evaluate) the sum. | 1 . | Sum( a_n, (n,0,oo) ).doit() . | . $\\displaystyle \\infty$ . In this case, the series diverges. We can also create and evaluate finite series by replacing the oo with a number. | 1 . | Sum( a_n, (n,0,10) ).doit() . | . $\\displaystyle \\frac{83711}{27720}$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-define-a-mathematical-series/#using-sympy-in-python",
    "relUrl": "/how-to-define-a-mathematical-series/#using-sympy-in-python"
  },"603": {
    "doc": "How to define a mathematical series",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-define-a-mathematical-series/#topics-that-include-this-task",
    "relUrl": "/how-to-define-a-mathematical-series/#topics-that-include-this-task"
  },"604": {
    "doc": "How to define a mathematical series",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-define-a-mathematical-series/#opportunities",
    "relUrl": "/how-to-define-a-mathematical-series/#opportunities"
  },"605": {
    "doc": "How to do a goodness of fit test for a multinomial experiment (in Python, using SciPy)",
    "title": "How to do a goodness of fit test for a multinomial experiment (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-python-using-scipy/"
  },"606": {
    "doc": "How to do a goodness of fit test for a multinomial experiment (in Python, using SciPy)",
    "title": "Task",
    "content": "If we have historical values for multiple population proportions, plus more recent samples from those same populations, we may want to compare to see if the proportions appear to have changed. This is called a goodness of fit test for a multinomial experiment. How can we execute it? . ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-python-using-scipy/#task"
  },"607": {
    "doc": "How to do a goodness of fit test for a multinomial experiment (in Python, using SciPy)",
    "title": "Solution",
    "content": "Let’s say we have a dataset with the previous population proportions for four categories. (This is contrived data, but the code below can be used on your actual data.) . | Category | Frequency | Proportion | . | A | 43 | 0.25 | . | B | 62 | 0.36 | . | C | 52 | 0.30 | . | D | 16 | 0.09 | . We have also taken a more recent sample and found the number of observations from it that belong to each category. We want to determine if the proportions coming from the recent sample are equal to the previous proportions. SciPy expects that we will have two lists, one with the expected number of observations in each group (from the previous, or hypothesized proportions) and the other with the actual number of observations in each group (from the more recent sample). SciPy also expects that the total number of observations in each list is the same. We’ll create two lists below with the fake data from above, but you can replace them with your real data . | 1 2 3 . | # Replace your data in the next two lines old_observations = [43, 62, 52, 16] new_observations = [56, 80, 12, 25] . | . We set the null hypothesis to be that the proportions of each category from the recent sample are equal to the previous proportions . \\[H_0: p_A = 0.25\\text{ and }\\ p_B = 0.36\\text{ and }\\ p_C = 0.30\\text{ and }\\ p_D=0.09.\\] We choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. We’ll let $\\alpha$ be 0.05 here. | 1 2 3 . | # Run the Chi-square test, giving the test statistic and p-value from scipy import stats stats.chisquare(f_obs=new_observations, f_exp=old_observations) . | . | 1 . | Power_divergenceResult(statistic=44.98776977898321, pvalue=9.30824439694332e-10) . | . Our $p$-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. It does appear that the proportion of at least one of the four categories is significantly different now from what it was previously. Content last modified on 23 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-python-using-scipy/#solution"
  },"608": {
    "doc": "How to do a goodness of fit test for a multinomial experiment (in R)",
    "title": "How to do a goodness of fit test for a multinomial experiment (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-r/",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-r/"
  },"609": {
    "doc": "How to do a goodness of fit test for a multinomial experiment (in R)",
    "title": "Task",
    "content": "If we have historical values for multiple population proportions, plus more recent samples from those same populations, we may want to compare to see if the proportions appear to have changed. This is called a goodness of fit test for a multinomial experiment. How can we execute it? . ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-r/#task",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-r/#task"
  },"610": {
    "doc": "How to do a goodness of fit test for a multinomial experiment (in R)",
    "title": "Solution",
    "content": "Let’s say we have a dataset with the previous population proportions for four categories. (This is contrived data, but the code below can be used on your actual data.) . | Category | Frequency | Proportion | . | A | 43 | 0.25 | . | B | 62 | 0.36 | . | C | 52 | 0.30 | . | D | 16 | 0.09 | . We have also taken a more recent sample and found the number of observations from it that belong to each category. We want to determine if the proportions coming from the recent sample are equal to the previous proportions. R expects that we will have two vectors, one with the expected number of observations in each group (from the previous, or hypothesized proportions) and the other with the actual number of observations in each group (from the more recent sample). R also expects that the total number of observations in each vector is the same. We’ll create two vectors below with the fake data from above, but you can replace them with your real data . | 1 2 3 4 5 6 . | # our fake data: old.observations &lt;- c(43, 62, 52, 16) new.observations &lt;- c(56, 80, 12, 25) # now organized into a data frame: categories &lt;- c(\"A\", \"B\", \"C\", \"D\") data &lt;- data.frame(categories, old.observations, new.observations) . | . We set the null hypothesis to be that the proportions of each category from the recent sample are equal to the previous proportions. \\[H_0: p_A = 0.25\\text{ and }\\ p_B = 0.36\\text{ and }\\ p_C = 0.30\\text{ and }\\ p_D=0.09.\\] We choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. We’ll let $\\alpha$ be 0.05 here. | 1 2 . | # Run the Chi-Square test, giving the test statistic and p-value chisq.test(data$new.observations, p=data$old.observations, rescale.p=TRUE) . | . | 1 2 3 4 . | Chi-squared test for given probabilities data: data$new.observations X-squared = 44.988, df = 3, p-value = 9.308e-10 . | . Our $p$-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. It does appear that the proportion of at least one of the four categories is significantly different now from what it was previously. If instead you provided the population proportions as the old observations, that is, a vector of values that sum to 1, you can omit the rescale.p argument. Content last modified on 23 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-r/#solution",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment-in-r/#solution"
  },"611": {
    "doc": "How to do a goodness of fit test for a multinomial experiment",
    "title": "How to do a goodness of fit test for a multinomial experiment",
    "content": " ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/"
  },"612": {
    "doc": "How to do a goodness of fit test for a multinomial experiment",
    "title": "Description",
    "content": "If we have historical values for multiple population proportions, plus more recent samples from those same populations, we may want to compare to see if the proportions appear to have changed. This is called a goodness of fit test for a multinomial experiment. How can we execute it? . ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/#description",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/#description"
  },"613": {
    "doc": "How to do a goodness of fit test for a multinomial experiment",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. Let’s say we have a dataset with the previous population proportions for four categories. (This is contrived data, but the code below can be used on your actual data.) . | Category | Frequency | Proportion | . | A | 43 | 0.25 | . | B | 62 | 0.36 | . | C | 52 | 0.30 | . | D | 16 | 0.09 | . We have also taken a more recent sample and found the number of observations from it that belong to each category. We want to determine if the proportions coming from the recent sample are equal to the previous proportions. SciPy expects that we will have two lists, one with the expected number of observations in each group (from the previous, or hypothesized proportions) and the other with the actual number of observations in each group (from the more recent sample). SciPy also expects that the total number of observations in each list is the same. We’ll create two lists below with the fake data from above, but you can replace them with your real data . | 1 2 3 . | # Replace your data in the next two lines old_observations = [43, 62, 52, 16] new_observations = [56, 80, 12, 25] . | . We set the null hypothesis to be that the proportions of each category from the recent sample are equal to the previous proportions . \\[H_0: p_A = 0.25\\text{ and }\\ p_B = 0.36\\text{ and }\\ p_C = 0.30\\text{ and }\\ p_D=0.09.\\] We choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. We’ll let $\\alpha$ be 0.05 here. | 1 2 3 . | # Run the Chi-square test, giving the test statistic and p-value from scipy import stats stats.chisquare(f_obs=new_observations, f_exp=old_observations) . | . | 1 . | Power_divergenceResult(statistic=44.98776977898321, pvalue=9.30824439694332e-10) . | . Our $p$-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. It does appear that the proportion of at least one of the four categories is significantly different now from what it was previously. Content last modified on 23 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/#using-scipy-in-python"
  },"614": {
    "doc": "How to do a goodness of fit test for a multinomial experiment",
    "title": "Solution, in R",
    "content": "View this solution alone. Let’s say we have a dataset with the previous population proportions for four categories. (This is contrived data, but the code below can be used on your actual data.) . | Category | Frequency | Proportion | . | A | 43 | 0.25 | . | B | 62 | 0.36 | . | C | 52 | 0.30 | . | D | 16 | 0.09 | . We have also taken a more recent sample and found the number of observations from it that belong to each category. We want to determine if the proportions coming from the recent sample are equal to the previous proportions. R expects that we will have two vectors, one with the expected number of observations in each group (from the previous, or hypothesized proportions) and the other with the actual number of observations in each group (from the more recent sample). R also expects that the total number of observations in each vector is the same. We’ll create two vectors below with the fake data from above, but you can replace them with your real data . | 1 2 3 4 5 6 . | # our fake data: old.observations &lt;- c(43, 62, 52, 16) new.observations &lt;- c(56, 80, 12, 25) # now organized into a data frame: categories &lt;- c(\"A\", \"B\", \"C\", \"D\") data &lt;- data.frame(categories, old.observations, new.observations) . | . We set the null hypothesis to be that the proportions of each category from the recent sample are equal to the previous proportions. \\[H_0: p_A = 0.25\\text{ and }\\ p_B = 0.36\\text{ and }\\ p_C = 0.30\\text{ and }\\ p_D=0.09.\\] We choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. We’ll let $\\alpha$ be 0.05 here. | 1 2 . | # Run the Chi-Square test, giving the test statistic and p-value chisq.test(data$new.observations, p=data$old.observations, rescale.p=TRUE) . | . | 1 2 3 4 . | Chi-squared test for given probabilities data: data$new.observations X-squared = 44.988, df = 3, p-value = 9.308e-10 . | . Our $p$-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. It does appear that the proportion of at least one of the four categories is significantly different now from what it was previously. If instead you provided the population proportions as the old observations, that is, a vector of values that sum to 1, you can omit the rescale.p argument. Content last modified on 23 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/#solution-in-r",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/#solution-in-r"
  },"615": {
    "doc": "How to do a goodness of fit test for a multinomial experiment",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/#topics-that-include-this-task"
  },"616": {
    "doc": "How to do a goodness of fit test for a multinomial experiment",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/#opportunities",
    "relUrl": "/how-to-do-a-goodness-of-fit-test-for-a-multinomial-experiment/#opportunities"
  },"617": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs) (in Python, using SciPy)",
    "title": "How to do a hypothesis test for a mean difference (matched pairs) (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-python-using-scipy/"
  },"618": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs) (in Python, using SciPy)",
    "title": "Task",
    "content": "Say we have two sets of data that are not independent of each other and come from a matched-pairs experiment, $(x_1,x’_1),(x_2,x’_2),\\ldots,(x_n,x’_n)$. We want to perform inference on the mean of the differences between these two samples, that is, the mean of $x_1-x’_1,x_2-x’_2,\\ldots,x_n-x’_n$, called $\\mu_D$. We want to determine if it is significantly different from, greater than, or less than zero (or any other hypothesized value). We can do so with a two-tailed, right-tailed, or left-tailed hypothesis test for matched pairs. Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-python-using-scipy/#task"
  },"619": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs) (in Python, using SciPy)",
    "title": "Solution",
    "content": "We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error rate, and in this case we will set it to be 0.05. We’re going to use fake fata here, but you can replace our fake data with your real data below. Because the data are matched pairs, the samples must be the same size. | 1 2 3 . | # Replace the following example data with your real data sample1 = [15, 10, 7, 22, 17, 14] sample2 = [ 9, 1, 11, 13, 3, 6] . | . Two-tailed test . In a two-sided hypothesis test, the null hypothesis states that the mean difference is equal to 0 (or some other hypothesized value), $H_0: \\mu_D = 0$. | 1 2 . | from scipy import stats stats.ttest_rel(sample1, sample2, alternative = \"two-sided\") . | . | 1 . | Ttest_relResult(statistic=2.8577380332470415, pvalue=0.03550038112896236) . | . Our $p$-value, 0.0355, is smaller than $\\alpha$, so we have sufficient evidence to reject the null hypothesis and conclude that the mean difference between the two samples is significantly different from zero. Note that the function above specifically tests whether the mean of $x_i-x’_i$ is zero. If we want instead to test whether it is some other value $d\\neq0$, then that’s equivalent to testing whether the mean of $(x_i-d)-x’_i$ is zero. We could do so with the code below, which uses an example value of $d$. The null hypothesis is now $H_0: \\mu_D=d$. | 1 2 . | d = 6 # as an example stats.ttest_rel([ x - d for x in sample1 ], sample2, alternative = \"two-sided\") . | . | 1 . | Ttest_relResult(statistic=0.4082482904638631, pvalue=0.6999865427788738) . | . The above $p$-value is greater than $\\alpha=0.05$, so we could not conclude that the mean difference is significantly different from our chosen $d=6$. Right-tailed test . If instead we want to test whether the mean difference is less than or equal to zero, $H_0: \\mu_D\\le0$, we can use a right-tailed test, as follows. | 1 . | stats.ttest_rel(sample1, sample2, alternative = \"greater\") . | . | 1 . | Ttest_relResult(statistic=2.8577380332470415, pvalue=0.01775019056448118) . | . Our $p$-value, 0.01775, is smaller than $\\alpha$, so we have sufficient evidence to reject the null hypothesis and conclude that the mean difference between the two samples is significantly greater than zero. A similar change could be made to the code above to test $H_0:\\mu_D\\le d$, as in the example code further above that uses $d=6$. Left-tailed test . If instead we want to test whether the mean difference is greater than or equal to zero, $H_0: \\mu_D\\ge 0$, we can use a right-tailed test, as follows. | 1 . | stats.ttest_rel(sample1, sample2, alternative = \"less\") . | . | 1 . | Ttest_relResult(statistic=2.8577380332470415, pvalue=0.9822498094355188) . | . Our $p$-value, 0.98225, is larger than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis; we must continue to assume that the mean difference between the two samples is greater than or equal to zero. A similar change could be made to the code above to test $H_0:\\mu_D\\ge d$, as in the example code further above that uses $d=6$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-python-using-scipy/#solution"
  },"620": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs) (in R)",
    "title": "How to do a hypothesis test for a mean difference (matched pairs) (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-r/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-r/"
  },"621": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs) (in R)",
    "title": "Task",
    "content": "Say we have two sets of data that are not independent of each other and come from a matched-pairs experiment, $(x_1,x’_1),(x_2,x’_2),\\ldots,(x_n,x’_n)$. We want to perform inference on the mean of the differences between these two samples, that is, the mean of $x_1-x’_1,x_2-x’_2,\\ldots,x_n-x’_n$, called $\\mu_D$. We want to determine if it is significantly different from, greater than, or less than zero (or any other hypothesized value). We can do so with a two-tailed, right-tailed, or left-tailed hypothesis test for matched pairs. Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-r/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-r/#task"
  },"622": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs) (in R)",
    "title": "Solution",
    "content": "We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error rate, and in this case we will set it to be 0.05. We’re going to use fake fata here, but you can replace our fake data with your real data below. Because the data are matched pairs, the samples must be the same size. | 1 2 3 . | # Replace the following example data with your real data sample.1 &lt;- c(15, 10, 7, 22, 17, 14) sample.2 &lt;- c( 9, 1, 11, 13, 3, 6) . | . Two-tailed test . In a two-sided hypothesis test, the null hypothesis states that the mean difference is equal to 0 (or some other hypothesized value), $H_0: \\mu_D = 0$. | 1 2 3 . | alpha = 0.05 t.test(sample.1, sample.2, alternative = \"two.sided\", mu = 0, paired = TRUE, conf.level = 1-alpha) . | . | 1 2 3 4 5 6 7 8 9 10 . | Paired t-test data: sample.1 and sample.2 t = 2.8577, df = 5, p-value = 0.0355 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 0.7033862 13.2966138 sample estimates: mean of the differences 7 . | . Our $p$-value, 0.0355, appears in the third line of the output. It is smaller than $\\alpha$, so we have sufficient evidence to reject the null hypothesis and conclude that the mean difference between the two samples is significantly different from zero. If we want instead to test whether it is some other value $d\\neq0$, then just use that value as the mu parameter to the t.test function instead of zero. Right-tailed test . If instead we want to test whether the mean difference is less than or equal to zero, $H_0: \\mu_D\\le0$, we can use a right-tailed test, as follows. | 1 2 . | t.test(sample.1, sample.2, alternative = \"greater\", mu = 0, paired = TRUE, conf.level = 1-alpha) . | . | 1 2 3 4 5 6 7 8 9 10 . | Paired t-test data: sample.1 and sample.2 t = 2.8577, df = 5, p-value = 0.01775 alternative hypothesis: true difference in means is greater than 0 95 percent confidence interval: 2.06416 Inf sample estimates: mean of the differences 7 . | . Our $p$-value, 0.01775, is smaller than $\\alpha$, so we have sufficient evidence to reject the null hypothesis and conclude that the mean difference between the two samples is significantly greater than zero. Again, you can use another value $d\\neq0$ in place of mu = 0 in the code. Left-tailed test . If instead we want to test whether the mean difference is greater than or equal to zero, $H_0: \\mu_D\\ge0$, we can use a right-tailed test, as follows. | 1 2 . | t.test(sample.1, sample.2, alternative = \"less\", mu = 0, paired = TRUE, conf.level = 1-alpha) . | . | 1 2 3 4 5 6 7 8 9 10 . | Paired t-test data: sample.1 and sample.2 t = 2.8577, df = 5, p-value = 0.9822 alternative hypothesis: true difference in means is less than 0 95 percent confidence interval: -Inf 11.93584 sample estimates: mean of the differences 7 . | . Our $p$-value, 0.9822, is larger than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis; we must continue to assume that the mean difference between the two samples is greater than or equal to zero. Again, you can use another value $d\\neq0$ in place of mu = 0 in the code. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-r/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs-in-r/#solution"
  },"623": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs)",
    "title": "How to do a hypothesis test for a mean difference (matched pairs)",
    "content": " ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/"
  },"624": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs)",
    "title": "Description",
    "content": "Say we have two sets of data that are not independent of each other and come from a matched-pairs experiment, $(x_1,x’_1),(x_2,x’_2),\\ldots,(x_n,x’_n)$. We want to perform inference on the mean of the differences between these two samples, that is, the mean of $x_1-x’_1,x_2-x’_2,\\ldots,x_n-x’_n$, called $\\mu_D$. We want to determine if it is significantly different from, greater than, or less than zero (or any other hypothesized value). We can do so with a two-tailed, right-tailed, or left-tailed hypothesis test for matched pairs. Related tasks: . | How to compute a confidence interval for a mean difference (matched pairs) | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/#description",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/#description"
  },"625": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs)",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error rate, and in this case we will set it to be 0.05. We’re going to use fake fata here, but you can replace our fake data with your real data below. Because the data are matched pairs, the samples must be the same size. | 1 2 3 . | # Replace the following example data with your real data sample1 = [15, 10, 7, 22, 17, 14] sample2 = [ 9, 1, 11, 13, 3, 6] . | . Two-tailed test . In a two-sided hypothesis test, the null hypothesis states that the mean difference is equal to 0 (or some other hypothesized value), $H_0: \\mu_D = 0$. | 1 2 . | from scipy import stats stats.ttest_rel(sample1, sample2, alternative = \"two-sided\") . | . | 1 . | Ttest_relResult(statistic=2.8577380332470415, pvalue=0.03550038112896236) . | . Our $p$-value, 0.0355, is smaller than $\\alpha$, so we have sufficient evidence to reject the null hypothesis and conclude that the mean difference between the two samples is significantly different from zero. Note that the function above specifically tests whether the mean of $x_i-x’_i$ is zero. If we want instead to test whether it is some other value $d\\neq0$, then that’s equivalent to testing whether the mean of $(x_i-d)-x’_i$ is zero. We could do so with the code below, which uses an example value of $d$. The null hypothesis is now $H_0: \\mu_D=d$. | 1 2 . | d = 6 # as an example stats.ttest_rel([ x - d for x in sample1 ], sample2, alternative = \"two-sided\") . | . | 1 . | Ttest_relResult(statistic=0.4082482904638631, pvalue=0.6999865427788738) . | . The above $p$-value is greater than $\\alpha=0.05$, so we could not conclude that the mean difference is significantly different from our chosen $d=6$. Right-tailed test . If instead we want to test whether the mean difference is less than or equal to zero, $H_0: \\mu_D\\le0$, we can use a right-tailed test, as follows. | 1 . | stats.ttest_rel(sample1, sample2, alternative = \"greater\") . | . | 1 . | Ttest_relResult(statistic=2.8577380332470415, pvalue=0.01775019056448118) . | . Our $p$-value, 0.01775, is smaller than $\\alpha$, so we have sufficient evidence to reject the null hypothesis and conclude that the mean difference between the two samples is significantly greater than zero. A similar change could be made to the code above to test $H_0:\\mu_D\\le d$, as in the example code further above that uses $d=6$. Left-tailed test . If instead we want to test whether the mean difference is greater than or equal to zero, $H_0: \\mu_D\\ge 0$, we can use a right-tailed test, as follows. | 1 . | stats.ttest_rel(sample1, sample2, alternative = \"less\") . | . | 1 . | Ttest_relResult(statistic=2.8577380332470415, pvalue=0.9822498094355188) . | . Our $p$-value, 0.98225, is larger than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis; we must continue to assume that the mean difference between the two samples is greater than or equal to zero. A similar change could be made to the code above to test $H_0:\\mu_D\\ge d$, as in the example code further above that uses $d=6$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/#using-scipy-in-python"
  },"626": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs)",
    "title": "Solution, in R",
    "content": "View this solution alone. We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error rate, and in this case we will set it to be 0.05. We’re going to use fake fata here, but you can replace our fake data with your real data below. Because the data are matched pairs, the samples must be the same size. | 1 2 3 . | # Replace the following example data with your real data sample.1 &lt;- c(15, 10, 7, 22, 17, 14) sample.2 &lt;- c( 9, 1, 11, 13, 3, 6) . | . Two-tailed test . In a two-sided hypothesis test, the null hypothesis states that the mean difference is equal to 0 (or some other hypothesized value), $H_0: \\mu_D = 0$. | 1 2 3 . | alpha = 0.05 t.test(sample.1, sample.2, alternative = \"two.sided\", mu = 0, paired = TRUE, conf.level = 1-alpha) . | . | 1 2 3 4 5 6 7 8 9 10 . | Paired t-test data: sample.1 and sample.2 t = 2.8577, df = 5, p-value = 0.0355 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 0.7033862 13.2966138 sample estimates: mean of the differences 7 . | . Our $p$-value, 0.0355, appears in the third line of the output. It is smaller than $\\alpha$, so we have sufficient evidence to reject the null hypothesis and conclude that the mean difference between the two samples is significantly different from zero. If we want instead to test whether it is some other value $d\\neq0$, then just use that value as the mu parameter to the t.test function instead of zero. Right-tailed test . If instead we want to test whether the mean difference is less than or equal to zero, $H_0: \\mu_D\\le0$, we can use a right-tailed test, as follows. | 1 2 . | t.test(sample.1, sample.2, alternative = \"greater\", mu = 0, paired = TRUE, conf.level = 1-alpha) . | . | 1 2 3 4 5 6 7 8 9 10 . | Paired t-test data: sample.1 and sample.2 t = 2.8577, df = 5, p-value = 0.01775 alternative hypothesis: true difference in means is greater than 0 95 percent confidence interval: 2.06416 Inf sample estimates: mean of the differences 7 . | . Our $p$-value, 0.01775, is smaller than $\\alpha$, so we have sufficient evidence to reject the null hypothesis and conclude that the mean difference between the two samples is significantly greater than zero. Again, you can use another value $d\\neq0$ in place of mu = 0 in the code. Left-tailed test . If instead we want to test whether the mean difference is greater than or equal to zero, $H_0: \\mu_D\\ge0$, we can use a right-tailed test, as follows. | 1 2 . | t.test(sample.1, sample.2, alternative = \"less\", mu = 0, paired = TRUE, conf.level = 1-alpha) . | . | 1 2 3 4 5 6 7 8 9 10 . | Paired t-test data: sample.1 and sample.2 t = 2.8577, df = 5, p-value = 0.9822 alternative hypothesis: true difference in means is less than 0 95 percent confidence interval: -Inf 11.93584 sample estimates: mean of the differences 7 . | . Our $p$-value, 0.9822, is larger than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis; we must continue to assume that the mean difference between the two samples is greater than or equal to zero. Again, you can use another value $d\\neq0$ in place of mu = 0 in the code. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/#solution-in-r",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/#solution-in-r"
  },"627": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs)",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/#topics-that-include-this-task"
  },"628": {
    "doc": "How to do a hypothesis test for a mean difference (matched pairs)",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/#opportunities",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-mean-difference-matched-pairs/#opportunities"
  },"629": {
    "doc": "How to do a hypothesis test for a population proportion (in Python, using SciPy)",
    "title": "How to do a hypothesis test for a population proportion (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-python-using-scipy/"
  },"630": {
    "doc": "How to do a hypothesis test for a population proportion (in Python, using SciPy)",
    "title": "Task",
    "content": "When we have qualitative data, we’re often interested in performing inference on population proportions. That is, the proportion (between 0.0 and 1.0) of the population that is in a certain category with respect to the qualitative variables. Given a sample proportion, $\\bar{p}$, how can we test whether the population proportion is equal to, greater than, or less than some hypothesized value? . Related tasks: . | How to compute a confidence interval for the population proportion | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-python-using-scipy/#task"
  },"631": {
    "doc": "How to do a hypothesis test for a population proportion (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’re going to use fake data here for illustrative purposes, but you can replace our fake data with your real data in the code below. Let’s say that we’ve hypothesized that about one-third of Bostonians are unhappy with the Red Sox’ performance. To test this hypothesis, we surveyed 460 Bostonians and found that 76 of them were unhappy with the Red Sox’ performance. We summarize this situation with the following variables. We will do a test with a Type I error rate of $\\alpha=0.05$. | 1 2 3 4 . | n = 460 # Number of respondents in sample x = 76 # Number of respondents in chosen subset sample_prop = x/n # Proportion of sample in chosen subset population_prop = 1/3 # Hypothesized population proportion . | . Two-tailed test . A two-tailed test is for the null hypothesis $H_0: p = \\frac13$. It can be done by directly computing the test statistic and $p$-value using tools from SciPy’s stats module. | 1 2 3 4 5 . | import numpy as np from scipy import stats test_stat = ( (sample_prop - population_prop) / np.sqrt(population_prop*(1 - population_prop)/n) ) stats.norm.sf(abs(test_stat))*2 # p-value . | . | 1 . | 2.0284218907806657e-14 . | . The $p$-value is less than $\\alpha$, so we can reject the null hypothesis. The proportion of Bostonians unhappy with Red Sox performance is different from $\\frac13$. Right-tailed test . A right-tailed test is for the null hypothesis $H_0: p \\le \\frac13$. Most of the code is the same as above, but the $p$-value is computed differently for a one-sided test. We repeat the re-used code to make it easy to copy and paste. | 1 2 3 4 5 . | import numpy as np from scipy import stats test_stat = ( (sample_prop - population_prop) / np.sqrt(population_prop*(1 - population_prop)/n) ) stats.norm.sf(test_stat) . | . | 1 . | 0.9999999999999899 . | . The $p$-value is greater than $\\alpha$, so we cannot reject the null hypothesis. We continue to assume that the proportion of Bostonians unhappy with Red Sox performance is less than or equal to $\\frac13$. Left-tailed test . A left-tailed test is for the null hypothesis $H_0: p\\ge \\frac13$. Most of the code is the same as above, but the $p$-value is computed differently yet again. We repeat the re-used code to make it easy to copy and paste. | 1 2 3 4 5 . | import numpy as np from scipy import stats test_stat = ( (sample_prop - population_prop) / np.sqrt(population_prop*(1 - population_prop)/n) ) stats.norm.sf(abs(test_stat)) . | . | 1 . | 1.0142109453903328e-14 . | . The $p$-value is less than $\\alpha$, so we can reject the null hypothesis. The proportion of Bostonians unhappy with Red Sox performance is less than $\\frac13$. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-python-using-scipy/#solution"
  },"632": {
    "doc": "How to do a hypothesis test for a population proportion (in R)",
    "title": "How to do a hypothesis test for a population proportion (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-r/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-r/"
  },"633": {
    "doc": "How to do a hypothesis test for a population proportion (in R)",
    "title": "Task",
    "content": "When we have qualitative data, we’re often interested in performing inference on population proportions. That is, the proportion (between 0.0 and 1.0) of the population that is in a certain category with respect to the qualitative variables. Given a sample proportion, $\\bar{p}$, how can we test whether the population proportion is equal to, greater than, or less than some hypothesized value? . Related tasks: . | How to compute a confidence interval for the population proportion | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-r/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-r/#task"
  },"634": {
    "doc": "How to do a hypothesis test for a population proportion (in R)",
    "title": "Solution",
    "content": "We’re going to use fake data here for illustrative purposes, but you can replace our fake data with your real data in the code below. Let’s say that we’ve hypothesized that about one-third of Bostonians are unhappy with the Red Sox’ performance. To test this hypothesis, we surveyed 460 Bostonians and found that 76 of them were unhappy with the Red Sox’ performance. We summarize this situation with the following variables. We will do a test with a Type I error rate of $\\alpha=0.05$. | 1 2 3 . | n &lt;- 460 # Number of respondents in sample x &lt;- 76 # Number of respondents in chosen subset population_prop &lt;- 1/3 # Hypothesized population proportion . | . Two-tailed test . A two-tailed test is for the null hypothesis $H_0: p = \\frac13$. We use R’s prop.test() function and provide it the data from above, requesting a two-tailed test. | 1 . | prop.test(x = x, n = n, p = population_prop, alternative = \"two.sided\") . | . | 1 2 3 4 5 6 7 8 9 10 . | 1-sample proportions test with continuity correction data: x out of n, null probability population_prop X-squared = 57.75, df = 1, p-value = 2.976e-14 alternative hypothesis: true p is not equal to 0.3333333 95 percent confidence interval: 0.1330899 0.2030664 sample estimates: p 0.1652174 . | . The $p$-value (shown at the end of the third line of the output) is less than $\\alpha$, so we can reject the null hypothesis. The proportion of Bostonians unhappy with Red Sox performance is different from $\\frac13$. R also has a binom.test() function that takes the same arguments. Right-tailed test . A right-tailed test is for the null hypothesis $H_0: p \\le \\frac13$. We use R’s prop.test() function and provide it the data from above, requesting a right-tailed test. | 1 . | prop.test(x = x, n = n, p = population_prop, alternative = \"greater\") . | . | 1 2 3 4 5 6 7 8 9 10 . | 1-sample proportions test with continuity correction data: x out of n, null probability population_prop X-squared = 57.75, df = 1, p-value = 1 alternative hypothesis: true p is greater than 0.3333333 95 percent confidence interval: 0.1377034 1.0000000 sample estimates: p 0.1652174 . | . The $p$-value (shown at the end of the third line of the output) is greater than $\\alpha$, so we cannot reject the null hypothesis. We continue to assume that the proportion of Bostonians unhappy with Red Sox performance is less than or equal to $\\frac13$. Again, binom.test() takes the same arguments. Left-tailed test . A left-tailed test is for the null hypothesis $H_0: p\\ge \\frac13$. We use R’s prop.test() function and provide it the data from above, requesting a left-tailed test. | 1 . | prop.test(x = x, n = n, p = population_prop, alternative = \"less\") . | . | 1 2 3 4 5 6 7 8 9 10 . | 1-sample proportions test with continuity correction data: x out of n, null probability population_prop X-squared = 57.75, df = 1, p-value = 1.488e-14 alternative hypothesis: true p is less than 0.3333333 95 percent confidence interval: 0.0000000 0.1967951 sample estimates: p 0.1652174 . | . The $p$-value (shown at the end of the third line of the output) is less than $\\alpha$, so we can reject the null hypothesis. The proportion of Bostonians unhappy with Red Sox performance is less than $\\frac13$. Again, binom.test() takes the same arguments. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-r/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion-in-r/#solution"
  },"635": {
    "doc": "How to do a hypothesis test for a population proportion",
    "title": "How to do a hypothesis test for a population proportion",
    "content": " ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion/"
  },"636": {
    "doc": "How to do a hypothesis test for a population proportion",
    "title": "Description",
    "content": "When we have qualitative data, we’re often interested in performing inference on population proportions. That is, the proportion (between 0.0 and 1.0) of the population that is in a certain category with respect to the qualitative variables. Given a sample proportion, $\\bar{p}$, how can we test whether the population proportion is equal to, greater than, or less than some hypothesized value? . Related tasks: . | How to compute a confidence interval for the population proportion | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion/#description",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion/#description"
  },"637": {
    "doc": "How to do a hypothesis test for a population proportion",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’re going to use fake data here for illustrative purposes, but you can replace our fake data with your real data in the code below. Let’s say that we’ve hypothesized that about one-third of Bostonians are unhappy with the Red Sox’ performance. To test this hypothesis, we surveyed 460 Bostonians and found that 76 of them were unhappy with the Red Sox’ performance. We summarize this situation with the following variables. We will do a test with a Type I error rate of $\\alpha=0.05$. | 1 2 3 4 . | n = 460 # Number of respondents in sample x = 76 # Number of respondents in chosen subset sample_prop = x/n # Proportion of sample in chosen subset population_prop = 1/3 # Hypothesized population proportion . | . Two-tailed test . A two-tailed test is for the null hypothesis $H_0: p = \\frac13$. It can be done by directly computing the test statistic and $p$-value using tools from SciPy’s stats module. | 1 2 3 4 5 . | import numpy as np from scipy import stats test_stat = ( (sample_prop - population_prop) / np.sqrt(population_prop*(1 - population_prop)/n) ) stats.norm.sf(abs(test_stat))*2 # p-value . | . | 1 . | 2.0284218907806657e-14 . | . The $p$-value is less than $\\alpha$, so we can reject the null hypothesis. The proportion of Bostonians unhappy with Red Sox performance is different from $\\frac13$. Right-tailed test . A right-tailed test is for the null hypothesis $H_0: p \\le \\frac13$. Most of the code is the same as above, but the $p$-value is computed differently for a one-sided test. We repeat the re-used code to make it easy to copy and paste. | 1 2 3 4 5 . | import numpy as np from scipy import stats test_stat = ( (sample_prop - population_prop) / np.sqrt(population_prop*(1 - population_prop)/n) ) stats.norm.sf(test_stat) . | . | 1 . | 0.9999999999999899 . | . The $p$-value is greater than $\\alpha$, so we cannot reject the null hypothesis. We continue to assume that the proportion of Bostonians unhappy with Red Sox performance is less than or equal to $\\frac13$. Left-tailed test . A left-tailed test is for the null hypothesis $H_0: p\\ge \\frac13$. Most of the code is the same as above, but the $p$-value is computed differently yet again. We repeat the re-used code to make it easy to copy and paste. | 1 2 3 4 5 . | import numpy as np from scipy import stats test_stat = ( (sample_prop - population_prop) / np.sqrt(population_prop*(1 - population_prop)/n) ) stats.norm.sf(abs(test_stat)) . | . | 1 . | 1.0142109453903328e-14 . | . The $p$-value is less than $\\alpha$, so we can reject the null hypothesis. The proportion of Bostonians unhappy with Red Sox performance is less than $\\frac13$. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion/#using-scipy-in-python"
  },"638": {
    "doc": "How to do a hypothesis test for a population proportion",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use fake data here for illustrative purposes, but you can replace our fake data with your real data in the code below. Let’s say that we’ve hypothesized that about one-third of Bostonians are unhappy with the Red Sox’ performance. To test this hypothesis, we surveyed 460 Bostonians and found that 76 of them were unhappy with the Red Sox’ performance. We summarize this situation with the following variables. We will do a test with a Type I error rate of $\\alpha=0.05$. | 1 2 3 . | n &lt;- 460 # Number of respondents in sample x &lt;- 76 # Number of respondents in chosen subset population_prop &lt;- 1/3 # Hypothesized population proportion . | . Two-tailed test . A two-tailed test is for the null hypothesis $H_0: p = \\frac13$. We use R’s prop.test() function and provide it the data from above, requesting a two-tailed test. | 1 . | prop.test(x = x, n = n, p = population_prop, alternative = \"two.sided\") . | . | 1 2 3 4 5 6 7 8 9 10 . | 1-sample proportions test with continuity correction data: x out of n, null probability population_prop X-squared = 57.75, df = 1, p-value = 2.976e-14 alternative hypothesis: true p is not equal to 0.3333333 95 percent confidence interval: 0.1330899 0.2030664 sample estimates: p 0.1652174 . | . The $p$-value (shown at the end of the third line of the output) is less than $\\alpha$, so we can reject the null hypothesis. The proportion of Bostonians unhappy with Red Sox performance is different from $\\frac13$. R also has a binom.test() function that takes the same arguments. Right-tailed test . A right-tailed test is for the null hypothesis $H_0: p \\le \\frac13$. We use R’s prop.test() function and provide it the data from above, requesting a right-tailed test. | 1 . | prop.test(x = x, n = n, p = population_prop, alternative = \"greater\") . | . | 1 2 3 4 5 6 7 8 9 10 . | 1-sample proportions test with continuity correction data: x out of n, null probability population_prop X-squared = 57.75, df = 1, p-value = 1 alternative hypothesis: true p is greater than 0.3333333 95 percent confidence interval: 0.1377034 1.0000000 sample estimates: p 0.1652174 . | . The $p$-value (shown at the end of the third line of the output) is greater than $\\alpha$, so we cannot reject the null hypothesis. We continue to assume that the proportion of Bostonians unhappy with Red Sox performance is less than or equal to $\\frac13$. Again, binom.test() takes the same arguments. Left-tailed test . A left-tailed test is for the null hypothesis $H_0: p\\ge \\frac13$. We use R’s prop.test() function and provide it the data from above, requesting a left-tailed test. | 1 . | prop.test(x = x, n = n, p = population_prop, alternative = \"less\") . | . | 1 2 3 4 5 6 7 8 9 10 . | 1-sample proportions test with continuity correction data: x out of n, null probability population_prop X-squared = 57.75, df = 1, p-value = 1.488e-14 alternative hypothesis: true p is less than 0.3333333 95 percent confidence interval: 0.0000000 0.1967951 sample estimates: p 0.1652174 . | . The $p$-value (shown at the end of the third line of the output) is less than $\\alpha$, so we can reject the null hypothesis. The proportion of Bostonians unhappy with Red Sox performance is less than $\\frac13$. Again, binom.test() takes the same arguments. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion/#solution-in-r",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion/#solution-in-r"
  },"639": {
    "doc": "How to do a hypothesis test for a population proportion",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion/#topics-that-include-this-task"
  },"640": {
    "doc": "How to do a hypothesis test for a population proportion",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-hypothesis-test-for-a-population-proportion/#opportunities",
    "relUrl": "/how-to-do-a-hypothesis-test-for-a-population-proportion/#opportunities"
  },"641": {
    "doc": "How to do a hypothesis test for population variance (in R)",
    "title": "How to do a hypothesis test for population variance (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-population-variance-in-r/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-population-variance-in-r/"
  },"642": {
    "doc": "How to do a hypothesis test for population variance (in R)",
    "title": "Task",
    "content": "Assume we want to estimate the variability of a quantity across a population, starting from a sample of data, $x_1, x_2, x_3, \\ldots x_k$. How might we test whether the population variance is equal to, greater than, or less than a hypothesized value? . Related tasks: . | How to compute a confidence interval for the population proportion | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-population-variance-in-r/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-population-variance-in-r/#task"
  },"643": {
    "doc": "How to do a hypothesis test for population variance (in R)",
    "title": "Solution",
    "content": "We’ll use R’s dataset EuStockMarkets to do an example. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to look at the variability of Germany’s DAX closing prices. Let’s load the dataset. (See how to quickly load some sample data.) If using your own data, place it into the values variable instead of using the code below. | 1 2 3 4 . | # install.packages(\"datasets\") # If you have not already done this library(datasets) EuStockMarkets &lt;- data.frame(EuStockMarkets) values &lt;- EuStockMarkets$DAX . | . Two-tailed test . We may ask whether the population variance is significantly different from a hypothesized value. Let’s test against a variance of 1,000,000. Our null hypothesis states that the population variance is equal to 1,000,000, $H_0: \\sigma^2 = 1,000,000$. We calculate the test statistic and $p$-value as follows, using a $\\chi^2$ distribution. We can use any $\\alpha$ between 0.0 and 1.0 as our Type I Error Rate; we will use $\\alpha=0.05$ here. | 1 2 3 4 . | hyp.var &lt;- 1000000 # hypothesized variance df &lt;- length(values) - 1 # degrees of freedom test.statistic &lt;- df*var(values)/hyp.var # test statistic 2*pchisq(test.statistic, df=df, lower.tail=FALSE) # two-tailed p-value . | . | 1 . | [1] 3.189769e-07 . | . Our $p$-value, $3.189769\\times10^{-7}$, is smaller than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. The variance of closing prices on Germany’s DAX is signficantly different from 1,000,000. Left-tailed test . What if we wanted to determine if the population variance were significantly less than 1,000,000? Our null hypothesis would therefore be $H_0: \\sigma^2 \\ge 1,000,000$. The computations are very similar to the previous case, but with a different formula for the $p$-value. We repeat the code that’s in common, for ease of use when copying and pasting. | 1 2 3 4 . | hyp.var &lt;- 1000000 # hypothesized variance df &lt;- length(values) - 1 # degrees of freedom test.statistic &lt;- df*var(values)/hyp.var # test statistic pchisq(test.statistic, df=df, lower.tail=TRUE) # left-tailed p-value . | . | 1 . | [1] 0.9999998 . | . Our p-value, 0.9999998, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We should continue to assume that the variance of closing prices on Germany’s DAX is greater than or equal to 1,000,000. Right-tailed test . What if we wanted to determine if the population variance were significantly less than 1,000,000? Our null hypothesis would therefore be $H_0: \\sigma^2 \\ge 1,000,000$. The computations are very similar to the previous case, but with a different formula for the $p$-value. We repeat the code that’s in common, for ease of use when copying and pasting. | 1 2 3 4 . | hyp.var &lt;- 1000000 # hypothesized variance df &lt;- length(values) - 1 # degrees of freedom test.statistic &lt;- df*var(values)/hyp.var # test statistic pchisq(test.statistic, df=df, lower.tail=FALSE) # right-tailed p-value . | . | 1 . | [1] 1.594884e-07 . | . Our p-value, $1.594884\\times10^{-7}$, is smaller than $\\alpha$, so have sufficient evidence to reject the null hypothesis. We conclude that the variance of closing prices on Germany’s DAX is significantly greater than 1,000,000. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-for-population-variance-in-r/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-population-variance-in-r/#solution"
  },"644": {
    "doc": "How to do a hypothesis test for population variance",
    "title": "How to do a hypothesis test for population variance",
    "content": " ",
    "url": "/how-to-do-a-hypothesis-test-for-population-variance/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-population-variance/"
  },"645": {
    "doc": "How to do a hypothesis test for population variance",
    "title": "Description",
    "content": "Assume we want to estimate the variability of a quantity across a population, starting from a sample of data, $x_1, x_2, x_3, \\ldots x_k$. How might we test whether the population variance is equal to, greater than, or less than a hypothesized value? . Related tasks: . | How to compute a confidence interval for the population proportion | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-population-variance/#description",
    "relUrl": "/how-to-do-a-hypothesis-test-for-population-variance/#description"
  },"646": {
    "doc": "How to do a hypothesis test for population variance",
    "title": "Solution, in R",
    "content": "View this solution alone. We’ll use R’s dataset EuStockMarkets to do an example. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to look at the variability of Germany’s DAX closing prices. Let’s load the dataset. (See how to quickly load some sample data.) If using your own data, place it into the values variable instead of using the code below. | 1 2 3 4 . | # install.packages(\"datasets\") # If you have not already done this library(datasets) EuStockMarkets &lt;- data.frame(EuStockMarkets) values &lt;- EuStockMarkets$DAX . | . Two-tailed test . We may ask whether the population variance is significantly different from a hypothesized value. Let’s test against a variance of 1,000,000. Our null hypothesis states that the population variance is equal to 1,000,000, $H_0: \\sigma^2 = 1,000,000$. We calculate the test statistic and $p$-value as follows, using a $\\chi^2$ distribution. We can use any $\\alpha$ between 0.0 and 1.0 as our Type I Error Rate; we will use $\\alpha=0.05$ here. | 1 2 3 4 . | hyp.var &lt;- 1000000 # hypothesized variance df &lt;- length(values) - 1 # degrees of freedom test.statistic &lt;- df*var(values)/hyp.var # test statistic 2*pchisq(test.statistic, df=df, lower.tail=FALSE) # two-tailed p-value . | . | 1 . | [1] 3.189769e-07 . | . Our $p$-value, $3.189769\\times10^{-7}$, is smaller than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. The variance of closing prices on Germany’s DAX is signficantly different from 1,000,000. Left-tailed test . What if we wanted to determine if the population variance were significantly less than 1,000,000? Our null hypothesis would therefore be $H_0: \\sigma^2 \\ge 1,000,000$. The computations are very similar to the previous case, but with a different formula for the $p$-value. We repeat the code that’s in common, for ease of use when copying and pasting. | 1 2 3 4 . | hyp.var &lt;- 1000000 # hypothesized variance df &lt;- length(values) - 1 # degrees of freedom test.statistic &lt;- df*var(values)/hyp.var # test statistic pchisq(test.statistic, df=df, lower.tail=TRUE) # left-tailed p-value . | . | 1 . | [1] 0.9999998 . | . Our p-value, 0.9999998, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We should continue to assume that the variance of closing prices on Germany’s DAX is greater than or equal to 1,000,000. Right-tailed test . What if we wanted to determine if the population variance were significantly less than 1,000,000? Our null hypothesis would therefore be $H_0: \\sigma^2 \\ge 1,000,000$. The computations are very similar to the previous case, but with a different formula for the $p$-value. We repeat the code that’s in common, for ease of use when copying and pasting. | 1 2 3 4 . | hyp.var &lt;- 1000000 # hypothesized variance df &lt;- length(values) - 1 # degrees of freedom test.statistic &lt;- df*var(values)/hyp.var # test statistic pchisq(test.statistic, df=df, lower.tail=FALSE) # right-tailed p-value . | . | 1 . | [1] 1.594884e-07 . | . Our p-value, $1.594884\\times10^{-7}$, is smaller than $\\alpha$, so have sufficient evidence to reject the null hypothesis. We conclude that the variance of closing prices on Germany’s DAX is significantly greater than 1,000,000. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-population-variance/#solution-in-r",
    "relUrl": "/how-to-do-a-hypothesis-test-for-population-variance/#solution-in-r"
  },"647": {
    "doc": "How to do a hypothesis test for population variance",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-hypothesis-test-for-population-variance/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-population-variance/#topics-that-include-this-task"
  },"648": {
    "doc": "How to do a hypothesis test for population variance",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Python | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-hypothesis-test-for-population-variance/#opportunities",
    "relUrl": "/how-to-do-a-hypothesis-test-for-population-variance/#opportunities"
  },"649": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known (in Python, using SciPy)",
    "title": "How to do a hypothesis test for the difference between means when both population variances are known (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-python-using-scipy/"
  },"650": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known (in Python, using SciPy)",
    "title": "Task",
    "content": "Assume we have two samples, $x_1, x_2, \\ldots, x_n$ and $x’_1, x’_2, \\ldots, x’_n$, that come from normally distributed populations with known variances, and the two sample means are $\\bar{x}$ and $\\bar{x}’$, respectively. We might want to ask whether the difference $\\bar{x}-\\bar{x}’$ is significantly different from, greater than, or less than zero. Related tasks: . | How to compute a confidence interval for the difference between two means when both population variances are known | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-python-using-scipy/#task"
  },"651": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’re going to use fake data here, but you can replace our fake data with your real data below. You will need not only the samples but also the known population standard deviations. | 1 2 3 4 . | sample1 = [ 5, 8, 10, 3, 6, 2] sample2 = [13, 20, 16, 12, 18, 15] population1_sd = 2.4 population2_sd = 3 . | . We must compute the sizes and means of the two samples. | 1 2 3 4 5 . | import numpy as np n1 = len(sample1) n2 = len(sample2) sample1_mean = np.mean(sample1) sample2_mean = np.mean(sample2) . | . We choose a value $0 \\le \\alpha \\le 1$ as the probability of a Type I error (a false positive, finding we should reject $H_0$ when it’s actually true). We will use $\\alpha=0.05$ in this example. Two-tailed test . In a two-tailed test, the null hypothesis is that the difference is zero, $H_0: \\bar{x} - \\bar{x}’ = 0$. We compute a test statistic and $p$-value as follows. | 1 2 3 4 . | from scipy import stats test_statistic = ( (sample1_mean - sample2_mean) / np.sqrt(population1_sd**2/n1 + population2_sd**2/n2) ) 2*stats.norm.sf(abs(test_statistic)) # two-tailed p-value . | . | 1 . | 1.8204936819059392e-10 . | . Our p-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. The difference between the means is significantly different from zero. Right-tailed test . In the right-tailed test, the null hypothesis is $H_0: \\bar{x} - \\bar{x}’ \\le 0$. That is, we are testing whether the difference is greater than zero. The code is very similar to the previous, except only in computing the $p$-value. We repeat the code that’s in common, to make it easier to copy and paste the examples. | 1 2 3 4 . | from scipy import stats test_statistic = ( (sample1_mean - sample2_mean) / np.sqrt(population1_sd**2/n1 + population2_sd**2/n2) ) stats.norm.sf(test_statistic) # right-tailed p-value . | . | 1 . | 0.9999999999089754 . | . Our $p$-value is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We would continue to assume that the difference in means is less than or equal to zero. Left-tailed test . In a left-tailed test, the null hypothesis is $H_0: \\bar{x} - \\bar{x}’ \\ge 0$. That is, we are testing whether the difference is less than zero. The code is very similar to the previous, except only in computing the $p$-value. We repeat the code that’s in common, to make it easier to copy and paste the examples. | 1 2 3 4 . | from scipy import stats test_statistic = ( (sample1_mean - sample2_mean) / np.sqrt(population1_sd**2/n1 + population2_sd**2/n2) ) stats.norm.sf(-test_statistic) # left-tailed p-value . | . | 1 . | 9.102468409529696e-11 . | . Our $p$-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. The difference between the means is significantly less than zero. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-python-using-scipy/#solution"
  },"652": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known (in R)",
    "title": "How to do a hypothesis test for the difference between means when both population variances are known (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-r/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-r/"
  },"653": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known (in R)",
    "title": "Task",
    "content": "Assume we have two samples, $x_1, x_2, \\ldots, x_n$ and $x’_1, x’_2, \\ldots, x’_n$, that come from normally distributed populations with known variances, and the two sample means are $\\bar{x}$ and $\\bar{x}’$, respectively. We might want to ask whether the difference $\\bar{x}-\\bar{x}’$ is significantly different from, greater than, or less than zero. Related tasks: . | How to compute a confidence interval for the difference between two means when both population variances are known | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-r/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-r/#task"
  },"654": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known (in R)",
    "title": "Solution",
    "content": "We’re going to use fake data here, but you can replace our fake data with your real data below. You will need not only the samples but also the known population standard deviations. | 1 2 3 4 . | sample1 &lt;- c(5, 8, 10, 3, 6, 2) sample2 &lt;- c(13, 20, 16, 12, 18, 15) population1_sd = 2.4 population2_sd = 3 . | . We must compute the sizes and means of the two samples. | 1 2 3 4 . | n1 &lt;- length(sample1) n2 &lt;- length(sample2) sample1_mean &lt;- mean(sample1) sample2_mean &lt;- mean(sample2) . | . We choose a value $0 \\le \\alpha \\le 1$ as the probability of a Type I error (a false positive, finding we should reject $H_0$ when it’s actually true). We will use $\\alpha=0.05$ in this example. Two-tailed test . In a two-tailed test, the null hypothesis is that the difference is zero, $H_0: \\bar{x} - \\bar{x}’ = 0$. We compute a test statistic and $p$-value as follows. | 1 2 3 . | test_statistic &lt;- (sample1_mean - sample2_mean) / sqrt(population1_sd^2/n1 + population2_sd^2/n2) 2*pnorm(abs(test_statistic), lower.tail = FALSE) # two-tailed p-value . | . | 1 . | [1] 1.820494e-10 . | . Our p-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. The difference between the means is significantly different from zero. Right-tailed test . In the right-tailed test, the null hypothesis is $H_0: \\bar{x} - \\bar{x}’ \\le 0$. That is, we are testing whether the difference is greater than zero. The code is very similar to the previous, except only in computing the $p$-value. We repeat the code that’s in common, to make it easier to copy and paste the examples. | 1 2 3 . | test_statistic &lt;- (sample1_mean - sample2_mean) / sqrt(population1_sd^2/n1 + population2_sd^2/n2) pnorm(test_statistic, lower.tail = FALSE) # right-tailed p-value . | . | 1 . | [1] 1 . | . Our $p$-value is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We would continue to assume that the difference in means is less than or equal to zero. Left-tailed test . In a left-tailed test, the null hypothesis is $H_0: \\bar{x} - \\bar{x}’ \\ge 0$. That is, we are testing whether the difference is less than zero. The code is very similar to the previous, except only in computing the $p$-value. We repeat the code that’s in common, to make it easier to copy and paste the examples. | 1 2 3 . | test_statistic &lt;- (sample1_mean - sample2_mean) / sqrt(population1_sd^2/n1 + population2_sd^2/n2) pnorm(test_statistic, lower.tail = TRUE) # left-tailed p-value . | . | 1 . | [1] 9.102468e-11 . | . Our $p$-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. The difference between the means is significantly less than zero. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-r/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known-in-r/#solution"
  },"655": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known",
    "title": "How to do a hypothesis test for the difference between means when both population variances are known",
    "content": " ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/"
  },"656": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known",
    "title": "Description",
    "content": "Assume we have two samples, $x_1, x_2, \\ldots, x_n$ and $x’_1, x’_2, \\ldots, x’_n$, that come from normally distributed populations with known variances, and the two sample means are $\\bar{x}$ and $\\bar{x}’$, respectively. We might want to ask whether the difference $\\bar{x}-\\bar{x}’$ is significantly different from, greater than, or less than zero. Related tasks: . | How to compute a confidence interval for the difference between two means when both population variances are known | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/#description",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/#description"
  },"657": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’re going to use fake data here, but you can replace our fake data with your real data below. You will need not only the samples but also the known population standard deviations. | 1 2 3 4 . | sample1 = [ 5, 8, 10, 3, 6, 2] sample2 = [13, 20, 16, 12, 18, 15] population1_sd = 2.4 population2_sd = 3 . | . We must compute the sizes and means of the two samples. | 1 2 3 4 5 . | import numpy as np n1 = len(sample1) n2 = len(sample2) sample1_mean = np.mean(sample1) sample2_mean = np.mean(sample2) . | . We choose a value $0 \\le \\alpha \\le 1$ as the probability of a Type I error (a false positive, finding we should reject $H_0$ when it’s actually true). We will use $\\alpha=0.05$ in this example. Two-tailed test . In a two-tailed test, the null hypothesis is that the difference is zero, $H_0: \\bar{x} - \\bar{x}’ = 0$. We compute a test statistic and $p$-value as follows. | 1 2 3 4 . | from scipy import stats test_statistic = ( (sample1_mean - sample2_mean) / np.sqrt(population1_sd**2/n1 + population2_sd**2/n2) ) 2*stats.norm.sf(abs(test_statistic)) # two-tailed p-value . | . | 1 . | 1.8204936819059392e-10 . | . Our p-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. The difference between the means is significantly different from zero. Right-tailed test . In the right-tailed test, the null hypothesis is $H_0: \\bar{x} - \\bar{x}’ \\le 0$. That is, we are testing whether the difference is greater than zero. The code is very similar to the previous, except only in computing the $p$-value. We repeat the code that’s in common, to make it easier to copy and paste the examples. | 1 2 3 4 . | from scipy import stats test_statistic = ( (sample1_mean - sample2_mean) / np.sqrt(population1_sd**2/n1 + population2_sd**2/n2) ) stats.norm.sf(test_statistic) # right-tailed p-value . | . | 1 . | 0.9999999999089754 . | . Our $p$-value is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We would continue to assume that the difference in means is less than or equal to zero. Left-tailed test . In a left-tailed test, the null hypothesis is $H_0: \\bar{x} - \\bar{x}’ \\ge 0$. That is, we are testing whether the difference is less than zero. The code is very similar to the previous, except only in computing the $p$-value. We repeat the code that’s in common, to make it easier to copy and paste the examples. | 1 2 3 4 . | from scipy import stats test_statistic = ( (sample1_mean - sample2_mean) / np.sqrt(population1_sd**2/n1 + population2_sd**2/n2) ) stats.norm.sf(-test_statistic) # left-tailed p-value . | . | 1 . | 9.102468409529696e-11 . | . Our $p$-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. The difference between the means is significantly less than zero. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/#using-scipy-in-python"
  },"658": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use fake data here, but you can replace our fake data with your real data below. You will need not only the samples but also the known population standard deviations. | 1 2 3 4 . | sample1 &lt;- c(5, 8, 10, 3, 6, 2) sample2 &lt;- c(13, 20, 16, 12, 18, 15) population1_sd = 2.4 population2_sd = 3 . | . We must compute the sizes and means of the two samples. | 1 2 3 4 . | n1 &lt;- length(sample1) n2 &lt;- length(sample2) sample1_mean &lt;- mean(sample1) sample2_mean &lt;- mean(sample2) . | . We choose a value $0 \\le \\alpha \\le 1$ as the probability of a Type I error (a false positive, finding we should reject $H_0$ when it’s actually true). We will use $\\alpha=0.05$ in this example. Two-tailed test . In a two-tailed test, the null hypothesis is that the difference is zero, $H_0: \\bar{x} - \\bar{x}’ = 0$. We compute a test statistic and $p$-value as follows. | 1 2 3 . | test_statistic &lt;- (sample1_mean - sample2_mean) / sqrt(population1_sd^2/n1 + population2_sd^2/n2) 2*pnorm(abs(test_statistic), lower.tail = FALSE) # two-tailed p-value . | . | 1 . | [1] 1.820494e-10 . | . Our p-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. The difference between the means is significantly different from zero. Right-tailed test . In the right-tailed test, the null hypothesis is $H_0: \\bar{x} - \\bar{x}’ \\le 0$. That is, we are testing whether the difference is greater than zero. The code is very similar to the previous, except only in computing the $p$-value. We repeat the code that’s in common, to make it easier to copy and paste the examples. | 1 2 3 . | test_statistic &lt;- (sample1_mean - sample2_mean) / sqrt(population1_sd^2/n1 + population2_sd^2/n2) pnorm(test_statistic, lower.tail = FALSE) # right-tailed p-value . | . | 1 . | [1] 1 . | . Our $p$-value is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We would continue to assume that the difference in means is less than or equal to zero. Left-tailed test . In a left-tailed test, the null hypothesis is $H_0: \\bar{x} - \\bar{x}’ \\ge 0$. That is, we are testing whether the difference is less than zero. The code is very similar to the previous, except only in computing the $p$-value. We repeat the code that’s in common, to make it easier to copy and paste the examples. | 1 2 3 . | test_statistic &lt;- (sample1_mean - sample2_mean) / sqrt(population1_sd^2/n1 + population2_sd^2/n2) pnorm(test_statistic, lower.tail = TRUE) # left-tailed p-value . | . | 1 . | [1] 9.102468e-11 . | . Our $p$-value is less than $\\alpha$, so we have sufficient evidence to reject the null hypothesis. The difference between the means is significantly less than zero. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/#solution-in-r",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/#solution-in-r"
  },"659": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/#topics-that-include-this-task"
  },"660": {
    "doc": "How to do a hypothesis test for the difference between means when both population variances are known",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/#opportunities",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-means-when-both-population-variances-are-known/#opportunities"
  },"661": {
    "doc": "How to do a hypothesis test for the difference between two proportions (in Python, using SciPy)",
    "title": "How to do a hypothesis test for the difference between two proportions (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-python-using-scipy/"
  },"662": {
    "doc": "How to do a hypothesis test for the difference between two proportions (in Python, using SciPy)",
    "title": "Task",
    "content": "When dealing with qualitative data, we typically measure what proportion of the population falls into various categories (e.g., which religion a survey respondent adheres to, if any). We might want to compare two proportions by measuring their difference, and asking whether it is equal, greater, or less than zero. How can we perform such a test? . Related tasks: . | How to compute a confidence interval for the difference between two proportions | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-python-using-scipy/#task"
  },"663": {
    "doc": "How to do a hypothesis test for the difference between two proportions (in Python, using SciPy)",
    "title": "Solution",
    "content": "We will use some fake data in this example, but you can replace it with your real data. Imagine we conduct a survey of people in Boston and of people in Nashville and ask them if they prefer chocolate or vanilla ice cream. We get data like the following. | City | Prefer chocolate | Prefer vanilla | Total | . | Boston | 60 | 90 | 150 | . | Nashville | 85 | 50 | 135 | . We want to compare the proportions of people from the two cities who like vanilla. Let $\\bar{p}_1$ represent the proportion of people from Boston who like vanilla and $\\bar{p}_2$ represent the proportion of people from Nashville who like vanilla. | 1 2 3 4 . | n1 = 150 # number of observations in sample 1 n2 = 135 # number of observations in sample 2 p_bar1 = 90/150 # proportion in sample 1 p_bar2 = 50/135 # proportion in sample 2 . | . We choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. For this example, we will use $\\alpha=0.05$. Two-tailed test . In a two-tailed test, the null hypothesis states that the difference between the two proportions equals a hypothesized value; let’s choose zero, $H_0: \\bar{p}_1 - \\bar{p}_2 = 0$. We perform this test by computing a test statistic and $p$-value as shown below, then comparing the $p$-value to our chosen $\\alpha$. | 1 2 3 4 5 6 7 . | import numpy as np p_bar = (90 + 50) / (150 + 135) # overall proportion std_error = np.sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic = (p_bar1 - p_bar2)/std_error # test statistic from scipy import stats 2*stats.norm.sf(abs(test_statistic)) # two-tailed p-value . | . | 1 . | 0.00010802693662804402 . | . Our $p$-value, 0.000108, is smaller than $\\alpha$, so we can reject the null hypothesis and conclude that the difference between the two proportions is different from zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 6 7 8 . | import numpy as np hyp_diff = 0.15 # hypothesized difference std_error = np.sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic = ((p_bar1 - p_bar2) - hyp_diff)/std_error # test statistic from scipy import stats 2*stats.norm.sf(abs(test_statistic)) # two-tailed p-value . | . | 1 . | 0.16744531573658772 . | . Our $p$-value, 0.1674, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly different from 0.15. Right-tailed test . In a right-tailed test, the null hypothesis states that the difference between the two proportions is less than or equal to a hypothesized value. Let’s begin by using zero as our hypothesized value, $H_0: \\bar{p}_1 - \\bar{p}_2 \\le 0$. We repeat some code below that we’ve seen above, just to make it easy to copy and paste the example elsewhere. | 1 2 3 4 5 6 7 . | import numpy as np p_bar = (90 + 50) / (150 + 135) # overall proportion std_error = np.sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic = (p_bar1 - p_bar2)/std_error # test statistic from scipy import stats stats.norm.sf(abs(test_statistic)) # right-tailed p-value . | . | 1 . | 5.401346831402201e-05 . | . Our $p$-value is smaller than $\\alpha$, so we can reject the null hypothesis and conclude that the difference between the two proportions is significantly greater than zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 6 7 8 . | import numpy as np hyp_diff = 0.15 # hypothesized difference std_error = np.sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic = ((p_bar1 - p_bar2) - hyp_diff)/std_error # test statistic from scipy import stats stats.norm.sf(abs(test_statistic)) # right-tailed p-value . | . | 1 . | 0.08372265786829386 . | . Our $p$-value, 0.0837, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly greater than 0.15. Left-tailed test . In a left-tailed test, the null hypothesis states that the difference between the two proportions is greater than or equal to a hypothesized value. Let’s begin by using zero as our hypothesized value, $H_0: \\bar{p}_1 - \\bar{p}_2 \\ge 0$. We repeat some code below that we’ve seen above, just to make it easy to copy and paste the example elsewhere. | 1 2 3 4 5 6 7 . | import numpy as np p_bar = (90 + 50) / (150 + 135) # overall proportion std_error = np.sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic = (p_bar1 - p_bar2)/std_error # test statistic from scipy import stats stats.norm.sf(-test_statistic) # left-tailed p-value . | . | 1 . | 0.999945986531686 . | . Our $p$-value, 0.9999, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between the two proportions is significantly less than zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 6 7 8 . | import numpy as np hyp_diff = 0.15 # hypothesized difference std_error = np.sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic = ((p_bar1 - p_bar2) - hyp_diff)/std_error # test statistic from scipy import stats stats.norm.sf(-test_statistic) # left-tailed p-value . | . | 1 . | 0.9162773421317061 . | . Our $p$-value, 0.91627, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly less than 0.15. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-python-using-scipy/#solution"
  },"664": {
    "doc": "How to do a hypothesis test for the difference between two proportions (in R)",
    "title": "How to do a hypothesis test for the difference between two proportions (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-r/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-r/"
  },"665": {
    "doc": "How to do a hypothesis test for the difference between two proportions (in R)",
    "title": "Task",
    "content": "When dealing with qualitative data, we typically measure what proportion of the population falls into various categories (e.g., which religion a survey respondent adheres to, if any). We might want to compare two proportions by measuring their difference, and asking whether it is equal, greater, or less than zero. How can we perform such a test? . Related tasks: . | How to compute a confidence interval for the difference between two proportions | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-r/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-r/#task"
  },"666": {
    "doc": "How to do a hypothesis test for the difference between two proportions (in R)",
    "title": "Solution",
    "content": "We will use some fake data in this example, but you can replace it with your real data. Imagine we conduct a survey of people in Boston and of people in Nashville and ask them if they prefer chocolate or vanilla ice cream. We get data like the following. | City | Prefer chocolate | Prefer vanilla | Total | . | Boston | 60 | 90 | 150 | . | Nashville | 85 | 50 | 135 | . We want to compare the proportions of people from the two cities who like vanilla. Let $\\bar{p}_1$ represent the proportion of people from Boston who like vanilla and $\\bar{p}_2$ represent the proportion of people from Nashville who like vanilla. | 1 2 3 4 . | n1 &lt;- 150 n2 &lt;- 135 p_bar1 &lt;- 90/150 p_bar2 &lt;- 50/135 . | . We choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. For this example, we will use $\\alpha=0.05$. Two-tailed test . In a two-tailed test, the null hypothesis states that the difference between the two proportions equals a hypothesized value; let’s choose zero, $H_0: \\bar{p}_1 - \\bar{p}_2 = 0$. We perform this test by computing a test statistic and $p$-value as shown below, then comparing the $p$-value to our chosen $\\alpha$. | 1 2 3 4 . | p_bar &lt;- (90 + 50) / (150 + 135) # overall proportion std_error &lt;- sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic &lt;- (p_bar1 - p_bar2)/std_error # test statistic 2*pnorm(q = test_statistic, lower.tail = FALSE) # two-tailed p-value . | . | 1 . | [1] 0.0001080269 . | . Our $p$-value, 0.000108, is smaller than $\\alpha$, so we can reject the null hypothesis and conclude that the difference between the two proportions is different from zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 . | hyp.diff = 0.15 # hypothesized difference std_error &lt;- sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic &lt;- ((p_bar1 - p_bar2) - hyp.diff)/std_error # test statistic 2*pnorm(q = test_statistic, lower.tail = FALSE) # two-tailed p-value . | . | 1 . | [1] 0.1674453 . | . Our $p$-value, 0.1674, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly different from 0.15. Right-tailed test . In a right-tailed test, the null hypothesis states that the difference between the two proportions is less than or equal to a hypothesized value. Let’s begin by using zero as our hypothesized value, $H_0: \\bar{p}_1 - \\bar{p}_2 \\le 0$. We repeat some code below that we’ve seen above, just to make it easy to copy and paste the example elsewhere. | 1 2 3 4 . | p_bar &lt;- (90 + 50) / (150 + 135) # overall proportion std_error &lt;- sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic &lt;- (p_bar1 - p_bar2)/std_error # test statistic pnorm(q = test_statistic, lower.tail = FALSE) # right-tailed p-value . | . | 1 . | [1] 5.401347e-05 . | . Our $p$-value is smaller than $\\alpha$, so we can reject the null hypothesis and conclude that the difference between the two proportions is significantly greater than zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 . | hyp.diff = 0.15 # hypothesized difference std_error &lt;- sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic &lt;- ((p_bar1 - p_bar2) - hyp.diff)/std_error # test statistic pnorm(q = test_statistic, lower.tail = FALSE) # right-tailed p-value . | . | 1 . | [1] 0.08372266 . | . Our $p$-value, 0.0837, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly greater than 0.15. Left-tailed test . In a left-tailed test, the null hypothesis states that the difference between the two proportions is greater than or equal to a hypothesized value. Let’s begin by using zero as our hypothesized value, $H_0: \\bar{p}_1 - \\bar{p}_2 \\ge 0$. We repeat some code below that we’ve seen above, just to make it easy to copy and paste the example elsewhere. | 1 2 3 4 . | p_bar &lt;- (90 + 50) / (150 + 135) # overall proportion std_error &lt;- sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic &lt;- (p_bar1 - p_bar2)/std_error # test statistic pnorm(q = test_statistic, lower.tail = TRUE) # left-tailed p-value . | . | 1 . | [1] 0.999946 . | . Our $p$-value, 0.9999, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between the two proportions is significantly less than zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 . | hyp.diff = 0.15 # hypothesized difference std_error &lt;- sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic &lt;- ((p_bar1 - p_bar2) - hyp.diff)/std_error # test statistic pnorm(q = test_statistic, lower.tail = TRUE) # left-tailed p-value . | . | 1 . | [1] 0.9162773 . | . Our $p$-value, 0.91627, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly less than 0.15. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-r/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions-in-r/#solution"
  },"667": {
    "doc": "How to do a hypothesis test for the difference between two proportions",
    "title": "How to do a hypothesis test for the difference between two proportions",
    "content": " ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/"
  },"668": {
    "doc": "How to do a hypothesis test for the difference between two proportions",
    "title": "Description",
    "content": "When dealing with qualitative data, we typically measure what proportion of the population falls into various categories (e.g., which religion a survey respondent adheres to, if any). We might want to compare two proportions by measuring their difference, and asking whether it is equal, greater, or less than zero. How can we perform such a test? . Related tasks: . | How to compute a confidence interval for the difference between two proportions | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/#description",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/#description"
  },"669": {
    "doc": "How to do a hypothesis test for the difference between two proportions",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We will use some fake data in this example, but you can replace it with your real data. Imagine we conduct a survey of people in Boston and of people in Nashville and ask them if they prefer chocolate or vanilla ice cream. We get data like the following. | City | Prefer chocolate | Prefer vanilla | Total | . | Boston | 60 | 90 | 150 | . | Nashville | 85 | 50 | 135 | . We want to compare the proportions of people from the two cities who like vanilla. Let $\\bar{p}_1$ represent the proportion of people from Boston who like vanilla and $\\bar{p}_2$ represent the proportion of people from Nashville who like vanilla. | 1 2 3 4 . | n1 = 150 # number of observations in sample 1 n2 = 135 # number of observations in sample 2 p_bar1 = 90/150 # proportion in sample 1 p_bar2 = 50/135 # proportion in sample 2 . | . We choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. For this example, we will use $\\alpha=0.05$. Two-tailed test . In a two-tailed test, the null hypothesis states that the difference between the two proportions equals a hypothesized value; let’s choose zero, $H_0: \\bar{p}_1 - \\bar{p}_2 = 0$. We perform this test by computing a test statistic and $p$-value as shown below, then comparing the $p$-value to our chosen $\\alpha$. | 1 2 3 4 5 6 7 . | import numpy as np p_bar = (90 + 50) / (150 + 135) # overall proportion std_error = np.sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic = (p_bar1 - p_bar2)/std_error # test statistic from scipy import stats 2*stats.norm.sf(abs(test_statistic)) # two-tailed p-value . | . | 1 . | 0.00010802693662804402 . | . Our $p$-value, 0.000108, is smaller than $\\alpha$, so we can reject the null hypothesis and conclude that the difference between the two proportions is different from zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 6 7 8 . | import numpy as np hyp_diff = 0.15 # hypothesized difference std_error = np.sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic = ((p_bar1 - p_bar2) - hyp_diff)/std_error # test statistic from scipy import stats 2*stats.norm.sf(abs(test_statistic)) # two-tailed p-value . | . | 1 . | 0.16744531573658772 . | . Our $p$-value, 0.1674, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly different from 0.15. Right-tailed test . In a right-tailed test, the null hypothesis states that the difference between the two proportions is less than or equal to a hypothesized value. Let’s begin by using zero as our hypothesized value, $H_0: \\bar{p}_1 - \\bar{p}_2 \\le 0$. We repeat some code below that we’ve seen above, just to make it easy to copy and paste the example elsewhere. | 1 2 3 4 5 6 7 . | import numpy as np p_bar = (90 + 50) / (150 + 135) # overall proportion std_error = np.sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic = (p_bar1 - p_bar2)/std_error # test statistic from scipy import stats stats.norm.sf(abs(test_statistic)) # right-tailed p-value . | . | 1 . | 5.401346831402201e-05 . | . Our $p$-value is smaller than $\\alpha$, so we can reject the null hypothesis and conclude that the difference between the two proportions is significantly greater than zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 6 7 8 . | import numpy as np hyp_diff = 0.15 # hypothesized difference std_error = np.sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic = ((p_bar1 - p_bar2) - hyp_diff)/std_error # test statistic from scipy import stats stats.norm.sf(abs(test_statistic)) # right-tailed p-value . | . | 1 . | 0.08372265786829386 . | . Our $p$-value, 0.0837, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly greater than 0.15. Left-tailed test . In a left-tailed test, the null hypothesis states that the difference between the two proportions is greater than or equal to a hypothesized value. Let’s begin by using zero as our hypothesized value, $H_0: \\bar{p}_1 - \\bar{p}_2 \\ge 0$. We repeat some code below that we’ve seen above, just to make it easy to copy and paste the example elsewhere. | 1 2 3 4 5 6 7 . | import numpy as np p_bar = (90 + 50) / (150 + 135) # overall proportion std_error = np.sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic = (p_bar1 - p_bar2)/std_error # test statistic from scipy import stats stats.norm.sf(-test_statistic) # left-tailed p-value . | . | 1 . | 0.999945986531686 . | . Our $p$-value, 0.9999, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between the two proportions is significantly less than zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 6 7 8 . | import numpy as np hyp_diff = 0.15 # hypothesized difference std_error = np.sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic = ((p_bar1 - p_bar2) - hyp_diff)/std_error # test statistic from scipy import stats stats.norm.sf(-test_statistic) # left-tailed p-value . | . | 1 . | 0.9162773421317061 . | . Our $p$-value, 0.91627, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly less than 0.15. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/#using-scipy-in-python"
  },"670": {
    "doc": "How to do a hypothesis test for the difference between two proportions",
    "title": "Solution, in R",
    "content": "View this solution alone. We will use some fake data in this example, but you can replace it with your real data. Imagine we conduct a survey of people in Boston and of people in Nashville and ask them if they prefer chocolate or vanilla ice cream. We get data like the following. | City | Prefer chocolate | Prefer vanilla | Total | . | Boston | 60 | 90 | 150 | . | Nashville | 85 | 50 | 135 | . We want to compare the proportions of people from the two cities who like vanilla. Let $\\bar{p}_1$ represent the proportion of people from Boston who like vanilla and $\\bar{p}_2$ represent the proportion of people from Nashville who like vanilla. | 1 2 3 4 . | n1 &lt;- 150 n2 &lt;- 135 p_bar1 &lt;- 90/150 p_bar2 &lt;- 50/135 . | . We choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. For this example, we will use $\\alpha=0.05$. Two-tailed test . In a two-tailed test, the null hypothesis states that the difference between the two proportions equals a hypothesized value; let’s choose zero, $H_0: \\bar{p}_1 - \\bar{p}_2 = 0$. We perform this test by computing a test statistic and $p$-value as shown below, then comparing the $p$-value to our chosen $\\alpha$. | 1 2 3 4 . | p_bar &lt;- (90 + 50) / (150 + 135) # overall proportion std_error &lt;- sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic &lt;- (p_bar1 - p_bar2)/std_error # test statistic 2*pnorm(q = test_statistic, lower.tail = FALSE) # two-tailed p-value . | . | 1 . | [1] 0.0001080269 . | . Our $p$-value, 0.000108, is smaller than $\\alpha$, so we can reject the null hypothesis and conclude that the difference between the two proportions is different from zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 . | hyp.diff = 0.15 # hypothesized difference std_error &lt;- sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic &lt;- ((p_bar1 - p_bar2) - hyp.diff)/std_error # test statistic 2*pnorm(q = test_statistic, lower.tail = FALSE) # two-tailed p-value . | . | 1 . | [1] 0.1674453 . | . Our $p$-value, 0.1674, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly different from 0.15. Right-tailed test . In a right-tailed test, the null hypothesis states that the difference between the two proportions is less than or equal to a hypothesized value. Let’s begin by using zero as our hypothesized value, $H_0: \\bar{p}_1 - \\bar{p}_2 \\le 0$. We repeat some code below that we’ve seen above, just to make it easy to copy and paste the example elsewhere. | 1 2 3 4 . | p_bar &lt;- (90 + 50) / (150 + 135) # overall proportion std_error &lt;- sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic &lt;- (p_bar1 - p_bar2)/std_error # test statistic pnorm(q = test_statistic, lower.tail = FALSE) # right-tailed p-value . | . | 1 . | [1] 5.401347e-05 . | . Our $p$-value is smaller than $\\alpha$, so we can reject the null hypothesis and conclude that the difference between the two proportions is significantly greater than zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 . | hyp.diff = 0.15 # hypothesized difference std_error &lt;- sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic &lt;- ((p_bar1 - p_bar2) - hyp.diff)/std_error # test statistic pnorm(q = test_statistic, lower.tail = FALSE) # right-tailed p-value . | . | 1 . | [1] 0.08372266 . | . Our $p$-value, 0.0837, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly greater than 0.15. Left-tailed test . In a left-tailed test, the null hypothesis states that the difference between the two proportions is greater than or equal to a hypothesized value. Let’s begin by using zero as our hypothesized value, $H_0: \\bar{p}_1 - \\bar{p}_2 \\ge 0$. We repeat some code below that we’ve seen above, just to make it easy to copy and paste the example elsewhere. | 1 2 3 4 . | p_bar &lt;- (90 + 50) / (150 + 135) # overall proportion std_error &lt;- sqrt(p_bar*(1-p_bar)*(1/n1+1/n2)) # standard error test_statistic &lt;- (p_bar1 - p_bar2)/std_error # test statistic pnorm(q = test_statistic, lower.tail = TRUE) # left-tailed p-value . | . | 1 . | [1] 0.999946 . | . Our $p$-value, 0.9999, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between the two proportions is significantly less than zero. But we did not need to compare the difference to zero; we could have used any hypothesized difference for comparison. Let’s repeat the above test, comparing the difference to $0.15$ instead, as an example. | 1 2 3 4 5 . | hyp.diff = 0.15 # hypothesized difference std_error &lt;- sqrt(p_bar1*(1-p_bar1)/n1 + p_bar2*(1-p_bar2)/n2) # standard error test_statistic &lt;- ((p_bar1 - p_bar2) - hyp.diff)/std_error # test statistic pnorm(q = test_statistic, lower.tail = TRUE) # left-tailed p-value . | . | 1 . | [1] 0.9162773 . | . Our $p$-value, 0.91627, is greater than $\\alpha$, so we cannot reject the null hypothesis and cannot conclude that the difference between these two proportions is significantly less than 0.15. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/#solution-in-r",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/#solution-in-r"
  },"671": {
    "doc": "How to do a hypothesis test for the difference between two proportions",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/#topics-that-include-this-task"
  },"672": {
    "doc": "How to do a hypothesis test for the difference between two proportions",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/#opportunities",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-difference-between-two-proportions/#opportunities"
  },"673": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation (in Python, using SciPy)",
    "title": "How to do a hypothesis test for the mean with known standard deviation (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-python-using-scipy/"
  },"674": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation (in Python, using SciPy)",
    "title": "Task",
    "content": "Let’s say we are measuring a variable over a population, and we know its standard deviation $\\sigma$ is known, and assume that the variable is normally distributed. We take a sample, $x_1, x_2, x_3, \\ldots, x_k$, and compute its mean $\\bar{x}$. We want to determine if the sample mean is significantly different from, greater than, or less than some hypothesized value, such as a hypothesized population mean. How do we formulate an appropriate hypothesis test? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-python-using-scipy/#task"
  },"675": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation (in Python, using SciPy)",
    "title": "Solution",
    "content": "We will use the following fake data, but you can insert your actual data in its place. We have a sample of just 5 values and an assumed population standard deviation of 3. | 1 2 . | sample = [31, 44, 28, 25, 40] # sample data pop_std = 3 # population standard deviation . | . We also choose a value $0 \\le \\alpha \\le 1$ as our Type I error rate. We’ll let $\\alpha$ be 0.05 here, but you can change that in the code below. Two-tailed test . In a two-tailed test, we compare the unknown population mean to a hypothesized value $m$ using the null hypothesis $H_0: \\mu=m$. Here we’ll use $m=30$, but you can replace that value in the code below with the hypothesis relevant for your situation. | 1 2 3 4 5 6 7 . | from scipy import stats import numpy as np m = 30 # hypothesized mean n = len(sample) # number of observations xbar = np.mean(sample) # sample mean test_stat = (xbar - m) / (pop_std/np.sqrt(n)) # test statistic 2*stats.norm.sf(abs(test_stat)) # two-tailed p-value . | . | 1 . | 0.007290358091535614 . | . The $p$-value, 0.00729, is less than $\\alpha$, so we have evidence to reject the null hypothesis and conclude that the actual population mean $\\mu$ is significantly different from the hypothesized value of $m=30$. Right-tailed test . In a right-tailed hypothesis test, the null hypothesis is that the population mean is greater than or equal to a chosen value, $H_0: \\mu \\ge m$. Most of the code below is the same as above, but we repeat it to make it easy to copy and paste. Only the computation of the $p$-value changes. | 1 2 3 4 5 6 7 . | from scipy import stats import numpy as np m = 30 # hypothesized mean n = len(sample) # number of observations xbar = np.mean(sample) # sample mean test_stat = (xbar - m) / (pop_std/np.sqrt(n)) # test statistic stats.norm.sf(abs(test_stat)) # right-tailed p-value . | . | 1 . | 0.003645179045767807 . | . The $p$-value, 0.003645, is less than $\\alpha$, so we have evidence to reject the null hypothesis and conclude that the actual population mean $\\mu$ is significantly less than the hypothesized value of $m=30$. Left-tailed test . In a left-tailed hypothesis test, the null hypothesis is that the population mean is less than or equal to a chosen value, $H_0: \\mu \\le m$. Most of the code below is the same as above, but we repeat it to make it easy to copy and paste. Only the computation of the $p$-value changes. | 1 2 3 4 5 6 7 . | from scipy import stats import numpy as np m = 30 # hypothesized mean n = len(sample) # number of observations xbar = np.mean(sample) # sample mean test_stat = (xbar - m) / (pop_std/np.sqrt(n)) # test statistic stats.norm.sf(-abs(test_stat)) # left-tailed p-value . | . | 1 . | 0.9963548209542322 . | . The $p$-value, 0.99635, is greater than $\\alpha$, so wwe do not have sufficient evidence to conclude that $\\mu&gt;m$ and should continue to accept the null hypothesis, that $\\mu\\le m$. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by: . | Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) | Nathan Carter (ncarter@bentley.edu) | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-python-using-scipy/#solution"
  },"676": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation (in R)",
    "title": "How to do a hypothesis test for the mean with known standard deviation (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-r/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-r/"
  },"677": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation (in R)",
    "title": "Task",
    "content": "Let’s say we are measuring a variable over a population, and we know its standard deviation $\\sigma$ is known, and assume that the variable is normally distributed. We take a sample, $x_1, x_2, x_3, \\ldots, x_k$, and compute its mean $\\bar{x}$. We want to determine if the sample mean is significantly different from, greater than, or less than some hypothesized value, such as a hypothesized population mean. How do we formulate an appropriate hypothesis test? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-r/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-r/#task"
  },"678": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation (in R)",
    "title": "Solution",
    "content": "We will use the following fake data, but you can insert your actual data in its place. We have a sample of just 5 values and an assumed population standard deviation of 3. | 1 2 . | sample &lt;- c(31, 44, 28, 25, 40) # sample data pop.std &lt;- 3 # population standard deviation . | . We also choose a value $0 \\le \\alpha \\le 1$ as our Type I error rate. We’ll let $\\alpha$ be 0.05 here, but you can change that in the code below. Two-tailed test . In a two-tailed test, we compare the unknown population mean to a hypothesized value $m$ using the null hypothesis $H_0: \\mu=m$. Here we’ll use $m=30$, but you can replace that value in the code below with the hypothesis relevant for your situation. | 1 2 3 4 5 . | m &lt;- 30 # hypothesized mean n &lt;- length(sample) # number of observations xbar &lt;- mean(sample) # sample mean test.stat &lt;- (xbar - m) / (pop.std/sqrt(n)) # test statistic 2*pnorm(abs(test.stat), 0, 1, lower.tail=FALSE) # two-tailed p-value . | . | 1 . | [1] 0.007290358 . | . The $p$-value, 0.00729, is less than $\\alpha$, so we have evidence to reject the null hypothesis and conclude that the actual population mean $\\mu$ is significantly different from the hypothesized value of $m=30$. Right-tailed test . In a right-tailed hypothesis test, the null hypothesis is that the population mean is greater than or equal to a chosen value, $H_0: \\mu \\ge m$. Most of the code below is the same as above, but we repeat it to make it easy to copy and paste. Only the computation of the $p$-value changes. | 1 2 3 4 5 . | m &lt;- 30 # hypothesized mean n &lt;- length(sample) # number of observations xbar &lt;- mean(sample) # sample mean test.stat &lt;- (xbar - m) / (pop.std/sqrt(n)) # test statistic pnorm(test.stat, 0, 1, lower.tail=FALSE) # right-tailed p-value . | . | 1 . | [1] 0.003645179 . | . The $p$-value, 0.003645, is less than $\\alpha$, so we have evidence to reject the null hypothesis and conclude that the actual population mean $\\mu$ is significantly less than the hypothesized value of $m=30$. Left-tailed test . In a left-tailed hypothesis test, the null hypothesis is that the population mean is less than or equal to a chosen value, $H_0: \\mu \\le m$. Most of the code below is the same as above, but we repeat it to make it easy to copy and paste. Only the computation of the $p$-value changes. | 1 2 3 4 5 . | m &lt;- 30 # hypothesized mean n &lt;- length(sample) # number of observations xbar &lt;- mean(sample) # sample mean test.stat &lt;- (xbar - m) / (pop.std/sqrt(n)) # test statistic pnorm(test.stat, 0, 1, lower.tail=TRUE) # left-tailed p-value . | . | 1 . | [1] 0.9963548 . | . The $p$-value, 0.99635, is greater than $\\alpha$, so wwe do not have sufficient evidence to conclude that $\\mu&gt;m$ and should continue to accept the null hypothesis, that $\\mu\\le m$. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by: . | Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) | Nathan Carter (ncarter@bentley.edu) | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-r/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation-in-r/#solution"
  },"679": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation",
    "title": "How to do a hypothesis test for the mean with known standard deviation",
    "content": " ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/"
  },"680": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation",
    "title": "Description",
    "content": "Let’s say we are measuring a variable over a population, and we know its standard deviation $\\sigma$ is known, and assume that the variable is normally distributed. We take a sample, $x_1, x_2, x_3, \\ldots, x_k$, and compute its mean $\\bar{x}$. We want to determine if the sample mean is significantly different from, greater than, or less than some hypothesized value, such as a hypothesized population mean. How do we formulate an appropriate hypothesis test? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the ratio of two population variances | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/#description",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/#description"
  },"681": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We will use the following fake data, but you can insert your actual data in its place. We have a sample of just 5 values and an assumed population standard deviation of 3. | 1 2 . | sample = [31, 44, 28, 25, 40] # sample data pop_std = 3 # population standard deviation . | . We also choose a value $0 \\le \\alpha \\le 1$ as our Type I error rate. We’ll let $\\alpha$ be 0.05 here, but you can change that in the code below. Two-tailed test . In a two-tailed test, we compare the unknown population mean to a hypothesized value $m$ using the null hypothesis $H_0: \\mu=m$. Here we’ll use $m=30$, but you can replace that value in the code below with the hypothesis relevant for your situation. | 1 2 3 4 5 6 7 . | from scipy import stats import numpy as np m = 30 # hypothesized mean n = len(sample) # number of observations xbar = np.mean(sample) # sample mean test_stat = (xbar - m) / (pop_std/np.sqrt(n)) # test statistic 2*stats.norm.sf(abs(test_stat)) # two-tailed p-value . | . | 1 . | 0.007290358091535614 . | . The $p$-value, 0.00729, is less than $\\alpha$, so we have evidence to reject the null hypothesis and conclude that the actual population mean $\\mu$ is significantly different from the hypothesized value of $m=30$. Right-tailed test . In a right-tailed hypothesis test, the null hypothesis is that the population mean is greater than or equal to a chosen value, $H_0: \\mu \\ge m$. Most of the code below is the same as above, but we repeat it to make it easy to copy and paste. Only the computation of the $p$-value changes. | 1 2 3 4 5 6 7 . | from scipy import stats import numpy as np m = 30 # hypothesized mean n = len(sample) # number of observations xbar = np.mean(sample) # sample mean test_stat = (xbar - m) / (pop_std/np.sqrt(n)) # test statistic stats.norm.sf(abs(test_stat)) # right-tailed p-value . | . | 1 . | 0.003645179045767807 . | . The $p$-value, 0.003645, is less than $\\alpha$, so we have evidence to reject the null hypothesis and conclude that the actual population mean $\\mu$ is significantly less than the hypothesized value of $m=30$. Left-tailed test . In a left-tailed hypothesis test, the null hypothesis is that the population mean is less than or equal to a chosen value, $H_0: \\mu \\le m$. Most of the code below is the same as above, but we repeat it to make it easy to copy and paste. Only the computation of the $p$-value changes. | 1 2 3 4 5 6 7 . | from scipy import stats import numpy as np m = 30 # hypothesized mean n = len(sample) # number of observations xbar = np.mean(sample) # sample mean test_stat = (xbar - m) / (pop_std/np.sqrt(n)) # test statistic stats.norm.sf(-abs(test_stat)) # left-tailed p-value . | . | 1 . | 0.9963548209542322 . | . The $p$-value, 0.99635, is greater than $\\alpha$, so wwe do not have sufficient evidence to conclude that $\\mu&gt;m$ and should continue to accept the null hypothesis, that $\\mu\\le m$. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/#using-scipy-in-python"
  },"682": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation",
    "title": "Solution, in R",
    "content": "View this solution alone. We will use the following fake data, but you can insert your actual data in its place. We have a sample of just 5 values and an assumed population standard deviation of 3. | 1 2 . | sample &lt;- c(31, 44, 28, 25, 40) # sample data pop.std &lt;- 3 # population standard deviation . | . We also choose a value $0 \\le \\alpha \\le 1$ as our Type I error rate. We’ll let $\\alpha$ be 0.05 here, but you can change that in the code below. Two-tailed test . In a two-tailed test, we compare the unknown population mean to a hypothesized value $m$ using the null hypothesis $H_0: \\mu=m$. Here we’ll use $m=30$, but you can replace that value in the code below with the hypothesis relevant for your situation. | 1 2 3 4 5 . | m &lt;- 30 # hypothesized mean n &lt;- length(sample) # number of observations xbar &lt;- mean(sample) # sample mean test.stat &lt;- (xbar - m) / (pop.std/sqrt(n)) # test statistic 2*pnorm(abs(test.stat), 0, 1, lower.tail=FALSE) # two-tailed p-value . | . | 1 . | [1] 0.007290358 . | . The $p$-value, 0.00729, is less than $\\alpha$, so we have evidence to reject the null hypothesis and conclude that the actual population mean $\\mu$ is significantly different from the hypothesized value of $m=30$. Right-tailed test . In a right-tailed hypothesis test, the null hypothesis is that the population mean is greater than or equal to a chosen value, $H_0: \\mu \\ge m$. Most of the code below is the same as above, but we repeat it to make it easy to copy and paste. Only the computation of the $p$-value changes. | 1 2 3 4 5 . | m &lt;- 30 # hypothesized mean n &lt;- length(sample) # number of observations xbar &lt;- mean(sample) # sample mean test.stat &lt;- (xbar - m) / (pop.std/sqrt(n)) # test statistic pnorm(test.stat, 0, 1, lower.tail=FALSE) # right-tailed p-value . | . | 1 . | [1] 0.003645179 . | . The $p$-value, 0.003645, is less than $\\alpha$, so we have evidence to reject the null hypothesis and conclude that the actual population mean $\\mu$ is significantly less than the hypothesized value of $m=30$. Left-tailed test . In a left-tailed hypothesis test, the null hypothesis is that the population mean is less than or equal to a chosen value, $H_0: \\mu \\le m$. Most of the code below is the same as above, but we repeat it to make it easy to copy and paste. Only the computation of the $p$-value changes. | 1 2 3 4 5 . | m &lt;- 30 # hypothesized mean n &lt;- length(sample) # number of observations xbar &lt;- mean(sample) # sample mean test.stat &lt;- (xbar - m) / (pop.std/sqrt(n)) # test statistic pnorm(test.stat, 0, 1, lower.tail=TRUE) # left-tailed p-value . | . | 1 . | [1] 0.9963548 . | . The $p$-value, 0.99635, is greater than $\\alpha$, so wwe do not have sufficient evidence to conclude that $\\mu&gt;m$ and should continue to accept the null hypothesis, that $\\mu\\le m$. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/#solution-in-r",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/#solution-in-r"
  },"683": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/#topics-that-include-this-task"
  },"684": {
    "doc": "How to do a hypothesis test for the mean with known standard deviation",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/#opportunities",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-mean-with-known-standard-deviation/#opportunities"
  },"685": {
    "doc": "How to do a hypothesis test for the ratio of two population variances (in Python, using SciPy)",
    "title": "How to do a hypothesis test for the ratio of two population variances (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-python-using-scipy/"
  },"686": {
    "doc": "How to do a hypothesis test for the ratio of two population variances (in Python, using SciPy)",
    "title": "Task",
    "content": "Let’s say we want to compare the variability of two populations. We take two samples of data, $x_1, x_2, x_3, \\ldots, x_k$ from population 1 and $x’_1, x’_2, x’_3, \\ldots, x’_k$ from population 2. What hypothesis tests can help us compare the population variances? . Related tasks: . | How to compute a confidence interval for the difference between two proportions | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-python-using-scipy/#task"
  },"687": {
    "doc": "How to do a hypothesis test for the ratio of two population variances (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’ll use R’s dataset EuStockMarkets to do an example. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to compare the variability of Germany’s DAX and France’s CAC closing prices. Let’s load the dataset. (See how to quickly load some sample data.) If using your own data, place it into the sample1 and sample2 variables instead of using the code below. | 1 2 3 4 5 6 7 8 9 10 11 . | from rdatasets import data import pandas as pd # Load in the EuStockMarkets data and place it in a pandas DataFrame EuStockMarkets = data('EuStockMarkets') df = pd.DataFrame(EuStockMarkets[['DAX', 'CAC']]) # Choose the two columns we want to analyze # (You can replace the two lines below with your actual data.) sample1 = df['DAX'] sample2 = df['CAC'] . | . For all tests below, we will use $\\alpha=0.05$ as our Type I Error Rate, but any value between 0.0 and 1.0 can be used. Two-tailed test . We can use a two-tailed test to test whether the two population variances are equal. Specifically, the null hypothesis will be: . \\[H_0: \\frac{\\sigma_1^2}{\\sigma_2^2} = 1\\] | 1 2 3 4 5 . | from scipy import stats sample1_df = len(sample1) - 1 # degrees of freedom sample2_df = len(sample2) - 1 # degrees of freedom test_statistic = sample1.var() / sample2.var() # test statistic stats.f.sf(test_statistic, dfn = sample1_df, dfd = sample2_df)*2 # p-value . | . | 1 . | 7.729079251495416e-151 . | . Our $p$-value is smaller than our chosen alpha, so we have sufficient evidence to reject the null hypothesis. The ratio of the variance of the closing prices on Germany’s DAX and France’s CAC is significantly different than 1, so the variances are not equal. Right-tailed test . In a right-tailed test, the null hypothesis is that the ratio is less than or equal to 1. This is equivalent to asking if $\\sigma_1^2 \\le \\sigma_2^2$. \\[H_0: \\frac{\\sigma_1^2}{\\sigma_2^2} \\le 1\\] We repeat below some of the code above to make each example easy to copy and paste. | 1 2 3 4 5 . | from scipy import stats sample1_df = len(sample1) - 1 # degrees of freedom sample2_df = len(sample2) - 1 # degrees of freedom test_statistic = sample1.var() / sample2.var() # test statistic stats.f.sf(test_statistic, dfn = sample1_df, dfd = sample2_df) # p-value . | . | 1 . | 3.864539625747708e-151 . | . Our $p$-value is smaller than our chosen alpha, so we have sufficient evidence to reject the null hypothesis. The ratio of the variance of the closing prices on Germany’s DAX and France’s CAC is significantly greater than 1, so the variance of closing prices on Germany’s DAX is greater than that of closing prices on France’s CAC. To test whether $\\sigma_1^2 \\ge \\sigma_2^2$, simply swap the roles of the two data columns in the above code. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by: . | Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) | Nathan Carter (ncarter@bentley.edu) | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-python-using-scipy/#solution"
  },"688": {
    "doc": "How to do a hypothesis test for the ratio of two population variances (in R)",
    "title": "How to do a hypothesis test for the ratio of two population variances (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-r/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-r/"
  },"689": {
    "doc": "How to do a hypothesis test for the ratio of two population variances (in R)",
    "title": "Task",
    "content": "Let’s say we want to compare the variability of two populations. We take two samples of data, $x_1, x_2, x_3, \\ldots, x_k$ from population 1 and $x’_1, x’_2, x’_3, \\ldots, x’_k$ from population 2. What hypothesis tests can help us compare the population variances? . Related tasks: . | How to compute a confidence interval for the difference between two proportions | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-r/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-r/#task"
  },"690": {
    "doc": "How to do a hypothesis test for the ratio of two population variances (in R)",
    "title": "Solution",
    "content": "We’ll use R’s dataset EuStockMarkets to do an example. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to compare the variability of Germany’s DAX and France’s CAC closing prices. Let’s load the dataset. (See how to quickly load some sample data.) If using your own data, place it into the sample1 and sample2 variables instead of using the code below. | 1 2 3 4 5 6 7 . | # install.packages(\"datasets\") # If you have not already done so library(datasets) # Load the dataset and convert it to a data frame, then extract two columns EuStockMarkets &lt;- data.frame(EuStockMarkets) sample.1 &lt;- EuStockMarkets$DAX sample.2 &lt;- EuStockMarkets$CAC . | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-r/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-r/#solution"
  },"691": {
    "doc": "How to do a hypothesis test for the ratio of two population variances (in R)",
    "title": "Two-tailed test",
    "content": "For all tests below, we will use $\\alpha=0.05$ as our Type I Error Rate, but any value between 0.0 and 1.0 can be used. Two-tailed test . We can use a two-tailed test to test whether the two population variances are equal. Specifically, the null hypothesis will be: . \\[H_0: \\frac{\\sigma_1^2}{\\sigma_2^2} = 1\\] | 1 2 3 4 . | sample.1.df &lt;- length(sample.1) - 1 # degrees of freedom sample.2.df &lt;- length(sample.2) - 1 # degrees of freedom test.statistic &lt;- var(sample.1)/var(sample.2) # test statistic 2*pf(test.statistic, df1=sample.1.df, df2=sample.2.df, lower.tail=FALSE) # p-value . | . | 1 . | [1] 7.729079e-151 . | . Our $p$-value is smaller than our chosen alpha, so we have sufficient evidence to reject the null hypothesis. The ratio of the variance of the closing prices on Germany’s DAX and France’s CAC is significantly different than 1, so the variances are not equal. Right-tailed test . In a right-tailed test, the null hypothesis is that the ratio is less than or equal to 1. This is equivalent to asking if $\\sigma_1^2 \\le \\sigma_2^2$. \\[H_0: \\frac{\\sigma_1^2}{\\sigma_2^2} \\le 1\\] We repeat below some of the code above to make each example easy to copy and paste. | 1 2 3 4 . | sample.1.df &lt;- length(sample.1) - 1 # degrees of freedom sample.2.df &lt;- length(sample.2) - 1 # degrees of freedom test.statistic &lt;- var(sample.1)/var(sample.2) # test statistic pf(test.statistic, df1=sample.1.df, df2=sample.2.df, lower.tail=FALSE) # p-value . | . | 1 . | [1] 3.86454e-151 . | . Our $p$-value is smaller than our chosen alpha, so we have sufficient evidence to reject the null hypothesis. The ratio of the variance of the closing prices on Germany’s DAX and France’s CAC is significantly greater than 1, so the variance of closing prices on Germany’s DAX is greater than that of closing prices on France’s CAC. To test whether $\\sigma_1^2 \\ge \\sigma_2^2$, simply swap the roles of the two data columns in the above code. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-r/#two-tailed-test",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances-in-r/#two-tailed-test"
  },"692": {
    "doc": "How to do a hypothesis test for the ratio of two population variances",
    "title": "How to do a hypothesis test for the ratio of two population variances",
    "content": " ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/"
  },"693": {
    "doc": "How to do a hypothesis test for the ratio of two population variances",
    "title": "Description",
    "content": "Let’s say we want to compare the variability of two populations. We take two samples of data, $x_1, x_2, x_3, \\ldots, x_k$ from population 1 and $x’_1, x’_2, x’_3, \\ldots, x’_k$ from population 2. What hypothesis tests can help us compare the population variances? . Related tasks: . | How to compute a confidence interval for the difference between two proportions | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test of a coefficient’s significance | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#description",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#description"
  },"694": {
    "doc": "How to do a hypothesis test for the ratio of two population variances",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’ll use R’s dataset EuStockMarkets to do an example. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to compare the variability of Germany’s DAX and France’s CAC closing prices. Let’s load the dataset. (See how to quickly load some sample data.) If using your own data, place it into the sample1 and sample2 variables instead of using the code below. | 1 2 3 4 5 6 7 8 9 10 11 . | from rdatasets import data import pandas as pd # Load in the EuStockMarkets data and place it in a pandas DataFrame EuStockMarkets = data('EuStockMarkets') df = pd.DataFrame(EuStockMarkets[['DAX', 'CAC']]) # Choose the two columns we want to analyze # (You can replace the two lines below with your actual data.) sample1 = df['DAX'] sample2 = df['CAC'] . | . For all tests below, we will use $\\alpha=0.05$ as our Type I Error Rate, but any value between 0.0 and 1.0 can be used. Two-tailed test . We can use a two-tailed test to test whether the two population variances are equal. Specifically, the null hypothesis will be: . \\[H_0: \\frac{\\sigma_1^2}{\\sigma_2^2} = 1\\] | 1 2 3 4 5 . | from scipy import stats sample1_df = len(sample1) - 1 # degrees of freedom sample2_df = len(sample2) - 1 # degrees of freedom test_statistic = sample1.var() / sample2.var() # test statistic stats.f.sf(test_statistic, dfn = sample1_df, dfd = sample2_df)*2 # p-value . | . | 1 . | 7.729079251495416e-151 . | . Our $p$-value is smaller than our chosen alpha, so we have sufficient evidence to reject the null hypothesis. The ratio of the variance of the closing prices on Germany’s DAX and France’s CAC is significantly different than 1, so the variances are not equal. Right-tailed test . In a right-tailed test, the null hypothesis is that the ratio is less than or equal to 1. This is equivalent to asking if $\\sigma_1^2 \\le \\sigma_2^2$. \\[H_0: \\frac{\\sigma_1^2}{\\sigma_2^2} \\le 1\\] We repeat below some of the code above to make each example easy to copy and paste. | 1 2 3 4 5 . | from scipy import stats sample1_df = len(sample1) - 1 # degrees of freedom sample2_df = len(sample2) - 1 # degrees of freedom test_statistic = sample1.var() / sample2.var() # test statistic stats.f.sf(test_statistic, dfn = sample1_df, dfd = sample2_df) # p-value . | . | 1 . | 3.864539625747708e-151 . | . Our $p$-value is smaller than our chosen alpha, so we have sufficient evidence to reject the null hypothesis. The ratio of the variance of the closing prices on Germany’s DAX and France’s CAC is significantly greater than 1, so the variance of closing prices on Germany’s DAX is greater than that of closing prices on France’s CAC. To test whether $\\sigma_1^2 \\ge \\sigma_2^2$, simply swap the roles of the two data columns in the above code. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#using-scipy-in-python"
  },"695": {
    "doc": "How to do a hypothesis test for the ratio of two population variances",
    "title": "Solution, in R",
    "content": "View this solution alone. We’ll use R’s dataset EuStockMarkets to do an example. This dataset has information on the daily closing prices of 4 European stock indices. We’re going to compare the variability of Germany’s DAX and France’s CAC closing prices. Let’s load the dataset. (See how to quickly load some sample data.) If using your own data, place it into the sample1 and sample2 variables instead of using the code below. | 1 2 3 4 5 6 7 . | # install.packages(\"datasets\") # If you have not already done so library(datasets) # Load the dataset and convert it to a data frame, then extract two columns EuStockMarkets &lt;- data.frame(EuStockMarkets) sample.1 &lt;- EuStockMarkets$DAX sample.2 &lt;- EuStockMarkets$CAC . | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#solution-in-r",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#solution-in-r"
  },"696": {
    "doc": "How to do a hypothesis test for the ratio of two population variances",
    "title": "Two-tailed test",
    "content": "For all tests below, we will use $\\alpha=0.05$ as our Type I Error Rate, but any value between 0.0 and 1.0 can be used. Two-tailed test . We can use a two-tailed test to test whether the two population variances are equal. Specifically, the null hypothesis will be: . \\[H_0: \\frac{\\sigma_1^2}{\\sigma_2^2} = 1\\] | 1 2 3 4 . | sample.1.df &lt;- length(sample.1) - 1 # degrees of freedom sample.2.df &lt;- length(sample.2) - 1 # degrees of freedom test.statistic &lt;- var(sample.1)/var(sample.2) # test statistic 2*pf(test.statistic, df1=sample.1.df, df2=sample.2.df, lower.tail=FALSE) # p-value . | . | 1 . | [1] 7.729079e-151 . | . Our $p$-value is smaller than our chosen alpha, so we have sufficient evidence to reject the null hypothesis. The ratio of the variance of the closing prices on Germany’s DAX and France’s CAC is significantly different than 1, so the variances are not equal. Right-tailed test . In a right-tailed test, the null hypothesis is that the ratio is less than or equal to 1. This is equivalent to asking if $\\sigma_1^2 \\le \\sigma_2^2$. \\[H_0: \\frac{\\sigma_1^2}{\\sigma_2^2} \\le 1\\] We repeat below some of the code above to make each example easy to copy and paste. | 1 2 3 4 . | sample.1.df &lt;- length(sample.1) - 1 # degrees of freedom sample.2.df &lt;- length(sample.2) - 1 # degrees of freedom test.statistic &lt;- var(sample.1)/var(sample.2) # test statistic pf(test.statistic, df1=sample.1.df, df2=sample.2.df, lower.tail=FALSE) # p-value . | . | 1 . | [1] 3.86454e-151 . | . Our $p$-value is smaller than our chosen alpha, so we have sufficient evidence to reject the null hypothesis. The ratio of the variance of the closing prices on Germany’s DAX and France’s CAC is significantly greater than 1, so the variance of closing prices on Germany’s DAX is greater than that of closing prices on France’s CAC. To test whether $\\sigma_1^2 \\ge \\sigma_2^2$, simply swap the roles of the two data columns in the above code. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#two-tailed-test-1",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#two-tailed-test-1"
  },"697": {
    "doc": "How to do a hypothesis test for the ratio of two population variances",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#topics-that-include-this-task"
  },"698": {
    "doc": "How to do a hypothesis test for the ratio of two population variances",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#opportunities",
    "relUrl": "/how-to-do-a-hypothesis-test-for-the-ratio-of-two-population-variances/#opportunities"
  },"699": {
    "doc": "How to do a hypothesis test of a coefficient's significance (in R)",
    "title": "How to do a hypothesis test of a coefficient’s significance (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance-in-r/#how-to-do-a-hypothesis-test-of-a-coefficients-significance-in-r",
    "relUrl": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance-in-r/#how-to-do-a-hypothesis-test-of-a-coefficients-significance-in-r"
  },"700": {
    "doc": "How to do a hypothesis test of a coefficient's significance (in R)",
    "title": "Task",
    "content": "Let’s say we have a linear model, either one variable or many. How do we conduct a test of significance for the coefficient of a single explanatory variable in the model? Similarly, how can we determine if an explanatory variable has a significant impact on the response variable? . Related tasks: . | How to compute a confidence interval for the difference between two proportions | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance-in-r/#task",
    "relUrl": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance-in-r/#task"
  },"701": {
    "doc": "How to do a hypothesis test of a coefficient's significance (in R)",
    "title": "Solution",
    "content": "We will use the fake data shown below with a single variable model. You can use a model created from your own actual data instead. | 1 2 3 . | x &lt;- c( 34, 9, 78, 60, 22, 45, 83, 59, 25) y &lt;- c(126, 347, 298, 309, 450, 187, 266, 385, 400) model &lt;- lm(y ~ x) . | . We can test whether a coefficient is zero by using that as our null hypothesis, $H_0: \\beta_i = 0$. We can use any value $0 \\le \\alpha \\le 1$ as our Type 1 error rate; we will set $\\alpha$ to be 0.05 here. The answer to our hypothesis test can be obtained by looking at just the coefficients portion of the model summary: . | 1 . | summary(model)$coef . | . | 1 2 3 . | Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 354.082248 76.732772 4.6144853 0.002441995 x -1.009013 1.472939 -0.6850334 0.515358250 . | . The final column of output shows $p$-values for each $\\beta_i$. The $p$-value associated with the $x$ row is therefore for $\\beta_1$, the coefficient on $x$. Because it is 0.515358250, which is greater than $\\alpha$, we cannot reject the null hypothesis, and we should continue to assume that $\\beta_1=0$ and there is no significant relationship between the explanatory and response variable in this situation. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance-in-r/#solution",
    "relUrl": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance-in-r/#solution"
  },"702": {
    "doc": "How to do a hypothesis test of a coefficient's significance (in R)",
    "title": "How to do a hypothesis test of a coefficient's significance (in R)",
    "content": " ",
    "url": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance-in-r/",
    "relUrl": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance-in-r/"
  },"703": {
    "doc": "How to do a hypothesis test of a coefficient's significance",
    "title": "How to do a hypothesis test of a coefficient’s significance",
    "content": " ",
    "url": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/#how-to-do-a-hypothesis-test-of-a-coefficients-significance",
    "relUrl": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/#how-to-do-a-hypothesis-test-of-a-coefficients-significance"
  },"704": {
    "doc": "How to do a hypothesis test of a coefficient's significance",
    "title": "Description",
    "content": "Let’s say we have a linear model, either one variable or many. How do we conduct a test of significance for the coefficient of a single explanatory variable in the model? Similarly, how can we determine if an explanatory variable has a significant impact on the response variable? . Related tasks: . | How to compute a confidence interval for the difference between two proportions | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | How to do a hypothesis test for population variance | How to do a hypothesis test for the difference between means when both population variances are known | How to do a hypothesis test for the difference between two proportions | How to do a hypothesis test for the mean with known standard deviation | How to do a hypothesis test for the ratio of two population variances | How to do a one-sided hypothesis test for two sample means | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | . ",
    "url": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/#description",
    "relUrl": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/#description"
  },"705": {
    "doc": "How to do a hypothesis test of a coefficient's significance",
    "title": "Solution, in R",
    "content": "View this solution alone. We will use the fake data shown below with a single variable model. You can use a model created from your own actual data instead. | 1 2 3 . | x &lt;- c( 34, 9, 78, 60, 22, 45, 83, 59, 25) y &lt;- c(126, 347, 298, 309, 450, 187, 266, 385, 400) model &lt;- lm(y ~ x) . | . We can test whether a coefficient is zero by using that as our null hypothesis, $H_0: \\beta_i = 0$. We can use any value $0 \\le \\alpha \\le 1$ as our Type 1 error rate; we will set $\\alpha$ to be 0.05 here. The answer to our hypothesis test can be obtained by looking at just the coefficients portion of the model summary: . | 1 . | summary(model)$coef . | . | 1 2 3 . | Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 354.082248 76.732772 4.6144853 0.002441995 x -1.009013 1.472939 -0.6850334 0.515358250 . | . The final column of output shows $p$-values for each $\\beta_i$. The $p$-value associated with the $x$ row is therefore for $\\beta_1$, the coefficient on $x$. Because it is 0.515358250, which is greater than $\\alpha$, we cannot reject the null hypothesis, and we should continue to assume that $\\beta_1=0$ and there is no significant relationship between the explanatory and response variable in this situation. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/#solution-in-r",
    "relUrl": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/#solution-in-r"
  },"706": {
    "doc": "How to do a hypothesis test of a coefficient's significance",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/#topics-that-include-this-task"
  },"707": {
    "doc": "How to do a hypothesis test of a coefficient's significance",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Python | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/#opportunities",
    "relUrl": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/#opportunities"
  },"708": {
    "doc": "How to do a hypothesis test of a coefficient's significance",
    "title": "How to do a hypothesis test of a coefficient's significance",
    "content": " ",
    "url": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/",
    "relUrl": "/how-to-do-a-hypothesis-test-of-a-coefficient-s-significance/"
  },"709": {
    "doc": "How to do a Kruskal-Wallis test (in Python, using SciPy)",
    "title": "How to do a Kruskal-Wallis test (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-kruskal-wallis-test-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-kruskal-wallis-test-in-python-using-scipy/"
  },"710": {
    "doc": "How to do a Kruskal-Wallis test (in Python, using SciPy)",
    "title": "Task",
    "content": "If we have samples from several independent populations, we might want to test whether the population medians are equal. We may not be able to assume anything about the populations’ variances, nor whether they are normally distributed, but we do assume that the populations have distributions that are approximately the same shape. The Kruskal-Wallis Test will allow us to test the medians for equality. It is similar to a One-Way ANOVA but using medians instead of means. How do we perform a Kruskal-Wallis Test? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to use Bonferroni’s Correction method | How to do a Wilcoxon rank-sum test | . ",
    "url": "/how-to-do-a-kruskal-wallis-test-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-kruskal-wallis-test-in-python-using-scipy/#task"
  },"711": {
    "doc": "How to do a Kruskal-Wallis test (in Python, using SciPy)",
    "title": "Solution",
    "content": "For the purposes of this example, let’s say we have a sample of GPAs from matriculated students at three Ivy League institutions: Harvard, Dartmouth, and Columbia. This is example data, and you can replace it with your actual data when you re-use this code. SciPy requires our data to be in NumPy arrays, as shown below. Note that pandas Series (e.g., columns in a DataFrame) are also NumPy arrays. | 1 2 3 4 5 . | import numpy as np # Replace the fake data below with your real data harvard = np.array([3.40, 3.66, 3.90, 3.55, 3.90, 3.58]) dartmouth = np.array([3.90, 3.97, 3.92, 3.83, 4.00, 3.68]) columbia = np.array([4.00, 3.75, 3.34]) . | . The Kruskal-Willis Test uses a null hypothesis that the category medians are equal, $H_0: m_C = m_H = m_D \\le 0$. We choose $\\alpha$, or the Type I error rate, as 0.05 and run the test as shown below. | 1 2 . | from scipy import stats stats.kruskal(harvard, dartmouth, columbia) . | . | 1 . | KruskalResult(statistic=3.706006006006005, pvalue=0.15676569090635095) . | . The p-value, 0.1568, is greater than $\\alpha$, so we fail to reject the null hypothesis. We do not have sufficient evidence to conclude that the median GPAs of matriculated students at these three schools are different from each other. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-kruskal-wallis-test-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-kruskal-wallis-test-in-python-using-scipy/#solution"
  },"712": {
    "doc": "How to do a Kruskal-Wallis test (in R)",
    "title": "How to do a Kruskal-Wallis test (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-kruskal-wallis-test-in-r/",
    "relUrl": "/how-to-do-a-kruskal-wallis-test-in-r/"
  },"713": {
    "doc": "How to do a Kruskal-Wallis test (in R)",
    "title": "Task",
    "content": "If we have samples from several independent populations, we might want to test whether the population medians are equal. We may not be able to assume anything about the populations’ variances, nor whether they are normally distributed, but we do assume that the populations have distributions that are approximately the same shape. The Kruskal-Wallis Test will allow us to test the medians for equality. It is similar to a One-Way ANOVA but using medians instead of means. How do we perform a Kruskal-Wallis Test? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to use Bonferroni’s Correction method | How to do a Wilcoxon rank-sum test | . ",
    "url": "/how-to-do-a-kruskal-wallis-test-in-r/#task",
    "relUrl": "/how-to-do-a-kruskal-wallis-test-in-r/#task"
  },"714": {
    "doc": "How to do a Kruskal-Wallis test (in R)",
    "title": "Solution",
    "content": "For the purposes of this example, let’s say we have a sample of GPAs from matriculated students at three Ivy League institutions: Harvard, Dartmouth, and Columbia. This is example data, and you can replace it with your actual data when you re-use this code. R requires that our categories and our numeric sample values be in separate vectors. We could structure our data as follows. | 1 2 3 4 5 6 7 . | gpas &lt;- c( 3.40, 3.66, 3.90, 3.55, 3.90, 3.58, 3.90, 3.97, 3.92, 3.83, 4.00, 3.68, 4.00, 3.75, 3.34 ) schools &lt;- c( \"Harvard\", \"Harvard\", \"Harvard\", \"Harvard\", \"Harvard\", \"Harvard\", \"Dartmouth\", \"Dartmouth\", \"Dartmouth\", \"Dartmouth\", \"Dartmouth\", \"Dartmouth\", \"Columbia\", \"Columbia\", \"Columbia\" ) . | . The Kruskal-Willis Test uses a null hypothesis that the category medians are equal, $H_0: m_C = m_H = m_D \\le 0$. We choose $\\alpha$, or the Type I error rate, as 0.05 and run the test as shown below. | 1 . | kruskal.test(gpas, schools) . | . | 1 2 3 4 . | Kruskal-Wallis rank sum test data: gpas and schools Kruskal-Wallis chi-squared = 3.706, df = 2, p-value = 0.1568 . | . The p-value, 0.1568, is greater than $\\alpha$, so we fail to reject the null hypothesis. We do not have sufficient evidence to conclude that the median GPAs of matriculated students at these three schools are different from each other. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-kruskal-wallis-test-in-r/#solution",
    "relUrl": "/how-to-do-a-kruskal-wallis-test-in-r/#solution"
  },"715": {
    "doc": "How to do a Kruskal-Wallis test",
    "title": "How to do a Kruskal-Wallis test",
    "content": " ",
    "url": "/how-to-do-a-kruskal-wallis-test/",
    "relUrl": "/how-to-do-a-kruskal-wallis-test/"
  },"716": {
    "doc": "How to do a Kruskal-Wallis test",
    "title": "Description",
    "content": "If we have samples from several independent populations, we might want to test whether the population medians are equal. We may not be able to assume anything about the populations’ variances, nor whether they are normally distributed, but we do assume that the populations have distributions that are approximately the same shape. The Kruskal-Wallis Test will allow us to test the medians for equality. It is similar to a One-Way ANOVA but using medians instead of means. How do we perform a Kruskal-Wallis Test? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to use Bonferroni’s Correction method | How to do a Wilcoxon rank-sum test | . ",
    "url": "/how-to-do-a-kruskal-wallis-test/#description",
    "relUrl": "/how-to-do-a-kruskal-wallis-test/#description"
  },"717": {
    "doc": "How to do a Kruskal-Wallis test",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. For the purposes of this example, let’s say we have a sample of GPAs from matriculated students at three Ivy League institutions: Harvard, Dartmouth, and Columbia. This is example data, and you can replace it with your actual data when you re-use this code. SciPy requires our data to be in NumPy arrays, as shown below. Note that pandas Series (e.g., columns in a DataFrame) are also NumPy arrays. | 1 2 3 4 5 . | import numpy as np # Replace the fake data below with your real data harvard = np.array([3.40, 3.66, 3.90, 3.55, 3.90, 3.58]) dartmouth = np.array([3.90, 3.97, 3.92, 3.83, 4.00, 3.68]) columbia = np.array([4.00, 3.75, 3.34]) . | . The Kruskal-Willis Test uses a null hypothesis that the category medians are equal, $H_0: m_C = m_H = m_D \\le 0$. We choose $\\alpha$, or the Type I error rate, as 0.05 and run the test as shown below. | 1 2 . | from scipy import stats stats.kruskal(harvard, dartmouth, columbia) . | . | 1 . | KruskalResult(statistic=3.706006006006005, pvalue=0.15676569090635095) . | . The p-value, 0.1568, is greater than $\\alpha$, so we fail to reject the null hypothesis. We do not have sufficient evidence to conclude that the median GPAs of matriculated students at these three schools are different from each other. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-kruskal-wallis-test/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-kruskal-wallis-test/#using-scipy-in-python"
  },"718": {
    "doc": "How to do a Kruskal-Wallis test",
    "title": "Solution, in R",
    "content": "View this solution alone. For the purposes of this example, let’s say we have a sample of GPAs from matriculated students at three Ivy League institutions: Harvard, Dartmouth, and Columbia. This is example data, and you can replace it with your actual data when you re-use this code. R requires that our categories and our numeric sample values be in separate vectors. We could structure our data as follows. | 1 2 3 4 5 6 7 . | gpas &lt;- c( 3.40, 3.66, 3.90, 3.55, 3.90, 3.58, 3.90, 3.97, 3.92, 3.83, 4.00, 3.68, 4.00, 3.75, 3.34 ) schools &lt;- c( \"Harvard\", \"Harvard\", \"Harvard\", \"Harvard\", \"Harvard\", \"Harvard\", \"Dartmouth\", \"Dartmouth\", \"Dartmouth\", \"Dartmouth\", \"Dartmouth\", \"Dartmouth\", \"Columbia\", \"Columbia\", \"Columbia\" ) . | . The Kruskal-Willis Test uses a null hypothesis that the category medians are equal, $H_0: m_C = m_H = m_D \\le 0$. We choose $\\alpha$, or the Type I error rate, as 0.05 and run the test as shown below. | 1 . | kruskal.test(gpas, schools) . | . | 1 2 3 4 . | Kruskal-Wallis rank sum test data: gpas and schools Kruskal-Wallis chi-squared = 3.706, df = 2, p-value = 0.1568 . | . The p-value, 0.1568, is greater than $\\alpha$, so we fail to reject the null hypothesis. We do not have sufficient evidence to conclude that the median GPAs of matriculated students at these three schools are different from each other. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-kruskal-wallis-test/#solution-in-r",
    "relUrl": "/how-to-do-a-kruskal-wallis-test/#solution-in-r"
  },"719": {
    "doc": "How to do a Kruskal-Wallis test",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-kruskal-wallis-test/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-kruskal-wallis-test/#topics-that-include-this-task"
  },"720": {
    "doc": "How to do a Kruskal-Wallis test",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-kruskal-wallis-test/#opportunities",
    "relUrl": "/how-to-do-a-kruskal-wallis-test/#opportunities"
  },"721": {
    "doc": "How to do a one-sided hypothesis test for two sample means (in Python, using SciPy)",
    "title": "How to do a one-sided hypothesis test for two sample means (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/"
  },"722": {
    "doc": "How to do a one-sided hypothesis test for two sample means (in Python, using SciPy)",
    "title": "Task",
    "content": "If we have two samples, $x_1, \\ldots , x_n$ and $x’_1, \\ldots , x’_n$, and we compute the mean of each one, we might want to ask whether one mean is less than the other. Or more precisely, is their difference significantly less than zero? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | How to do a one-way analysis of variance (ANOVA) | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/#task"
  },"723": {
    "doc": "How to do a one-sided hypothesis test for two sample means (in Python, using SciPy)",
    "title": "Solution",
    "content": "If we call the mean of the first sample $\\bar x_1$ and the mean of the second sample $\\bar x_2$, then this is a two-sided test with the null hypothesis $H_0: \\bar x_1 - \\bar x_2 \\ge 0$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). Let’s use $\\alpha=0.10$ as an example. | 1 2 3 4 5 6 7 8 9 . | from scipy import stats # Replace these first three lines with the values from your situation. sample1 = [ 6, 9, 7, 10, 10, 9 ] sample2 = [ 12, 14, 10, 17, 9 ] # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. stats.ttest_ind( sample1, sample2, equal_var=False, alternative=\"less\" ) . | . | 1 . | Ttest_indResult(statistic=-2.4616581720814326, pvalue=0.025486418709238467) . | . The output says that the $p$-value is about $0.0255$, which is less than $\\alpha=0.10$. Therefore the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.10$ level. That is, the data suggest that $\\bar x_1 &lt; \\bar x_2$. The equal_var parameter tells SciPy not to assume that the two samples have equal variances. If in your case they do, you can omit that parameter, and it will revert to its default value of True. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/#solution"
  },"724": {
    "doc": "How to do a one-sided hypothesis test for two sample means (in R)",
    "title": "How to do a one-sided hypothesis test for two sample means (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-r/",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-r/"
  },"725": {
    "doc": "How to do a one-sided hypothesis test for two sample means (in R)",
    "title": "Task",
    "content": "If we have two samples, $x_1, \\ldots , x_n$ and $x’_1, \\ldots , x’_n$, and we compute the mean of each one, we might want to ask whether one mean is less than the other. Or more precisely, is their difference significantly less than zero? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | How to do a one-way analysis of variance (ANOVA) | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-r/#task",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-r/#task"
  },"726": {
    "doc": "How to do a one-sided hypothesis test for two sample means (in R)",
    "title": "Solution",
    "content": "If we call the mean of the first sample $\\bar x_1$ and the mean of the second sample $\\bar x_2$, then this is a left-tailed test with the null hypothesis $H_0: \\bar x_1 - \\bar x_2 \\ge 0$. We choose a value $0 \\le \\alpha \\le 1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 . | # Replace these first three lines with the values from your situation. alpha &lt;- 0.10 sample1 &lt;- c( 6, 9, 7, 10, 10, 9 ) sample2 &lt;- c( 12, 14, 10, 17, 9 ) # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. t.test( sample1, sample2, conf.level=1-alpha, alternative = \"less\" ) . | . | 1 2 3 4 5 6 7 8 9 10 . | Welch Two Sample t-test data: sample1 and sample2 t = -2.4617, df = 5.7201, p-value = 0.02549 alternative hypothesis: true difference in means is less than 0 90 percent confidence interval: -Inf -1.605229 sample estimates: mean of x mean of y 8.5 12.4 . | . Although we can deduce the answer to our question from the above output, by comparing the $p$-value with $\\alpha$ manually, we can also ask R to do it. | 1 2 3 . | # Is there enough evidence to reject the null hypothesis? result &lt;- t.test( sample1, sample2, conf.level=1-alpha, alternative = \"less\" ) result$p.value &lt; alpha . | . | 1 . | [1] TRUE . | . In this case, the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.10$ level. The data suggest that $\\bar x_1 &lt; \\bar x_2$. Here we did not assume that the two samples had equal variance. If in your case they do, you can pass the parameter var.equal=TRUE to t.test. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-r/#solution",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means-in-r/#solution"
  },"727": {
    "doc": "How to do a one-sided hypothesis test for two sample means",
    "title": "How to do a one-sided hypothesis test for two sample means",
    "content": " ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/"
  },"728": {
    "doc": "How to do a one-sided hypothesis test for two sample means",
    "title": "Description",
    "content": "If we have two samples, $x_1, \\ldots , x_n$ and $x’_1, \\ldots , x’_n$, and we compute the mean of each one, we might want to ask whether one mean is less than the other. Or more precisely, is their difference significantly less than zero? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a sample mean | How to do a two-sided hypothesis test for two sample means | How to do a one-way analysis of variance (ANOVA) | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/#description",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/#description"
  },"729": {
    "doc": "How to do a one-sided hypothesis test for two sample means",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. If we call the mean of the first sample $\\bar x_1$ and the mean of the second sample $\\bar x_2$, then this is a two-sided test with the null hypothesis $H_0: \\bar x_1 - \\bar x_2 \\ge 0$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). Let’s use $\\alpha=0.10$ as an example. | 1 2 3 4 5 6 7 8 9 . | from scipy import stats # Replace these first three lines with the values from your situation. sample1 = [ 6, 9, 7, 10, 10, 9 ] sample2 = [ 12, 14, 10, 17, 9 ] # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. stats.ttest_ind( sample1, sample2, equal_var=False, alternative=\"less\" ) . | . | 1 . | Ttest_indResult(statistic=-2.4616581720814326, pvalue=0.025486418709238467) . | . The output says that the $p$-value is about $0.0255$, which is less than $\\alpha=0.10$. Therefore the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.10$ level. That is, the data suggest that $\\bar x_1 &lt; \\bar x_2$. The equal_var parameter tells SciPy not to assume that the two samples have equal variances. If in your case they do, you can omit that parameter, and it will revert to its default value of True. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/#using-scipy-in-python"
  },"730": {
    "doc": "How to do a one-sided hypothesis test for two sample means",
    "title": "Solution, in R",
    "content": "View this solution alone. If we call the mean of the first sample $\\bar x_1$ and the mean of the second sample $\\bar x_2$, then this is a left-tailed test with the null hypothesis $H_0: \\bar x_1 - \\bar x_2 \\ge 0$. We choose a value $0 \\le \\alpha \\le 1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 . | # Replace these first three lines with the values from your situation. alpha &lt;- 0.10 sample1 &lt;- c( 6, 9, 7, 10, 10, 9 ) sample2 &lt;- c( 12, 14, 10, 17, 9 ) # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. t.test( sample1, sample2, conf.level=1-alpha, alternative = \"less\" ) . | . | 1 2 3 4 5 6 7 8 9 10 . | Welch Two Sample t-test data: sample1 and sample2 t = -2.4617, df = 5.7201, p-value = 0.02549 alternative hypothesis: true difference in means is less than 0 90 percent confidence interval: -Inf -1.605229 sample estimates: mean of x mean of y 8.5 12.4 . | . Although we can deduce the answer to our question from the above output, by comparing the $p$-value with $\\alpha$ manually, we can also ask R to do it. | 1 2 3 . | # Is there enough evidence to reject the null hypothesis? result &lt;- t.test( sample1, sample2, conf.level=1-alpha, alternative = \"less\" ) result$p.value &lt; alpha . | . | 1 . | [1] TRUE . | . In this case, the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.10$ level. The data suggest that $\\bar x_1 &lt; \\bar x_2$. Here we did not assume that the two samples had equal variance. If in your case they do, you can pass the parameter var.equal=TRUE to t.test. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/#solution-in-r",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/#solution-in-r"
  },"731": {
    "doc": "How to do a one-sided hypothesis test for two sample means",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/#topics-that-include-this-task"
  },"732": {
    "doc": "How to do a one-sided hypothesis test for two sample means",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/#opportunities",
    "relUrl": "/how-to-do-a-one-sided-hypothesis-test-for-two-sample-means/#opportunities"
  },"733": {
    "doc": "How to do a one-way analysis of variance (ANOVA) (in Julia)",
    "title": "How to do a one-way analysis of variance (ANOVA) (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova-in-julia/",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova-in-julia/"
  },"734": {
    "doc": "How to do a one-way analysis of variance (ANOVA) (in Julia)",
    "title": "Task",
    "content": "If we have multiple independent samples of the same quantity (such as students’ SAT scores from several different schools), we may want to test whether the means of each of the samples are the same. Analysis of Variance (ANOVA) can determine whether any two of the sample means differ significantly. How can we do an ANOVA? . Related tasks: . | How to do a two-sided hypothesis test for two sample means (which is just an ANOVA with only two samples) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compare two nested linear models | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | How to do a Kruskal-Wallis test | . ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova-in-julia/#task",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova-in-julia/#task"
  },"735": {
    "doc": "How to do a one-way analysis of variance (ANOVA) (in Julia)",
    "title": "Solution",
    "content": "Let’s assume we have our samples in several different Julia arrays. Here I’ll construct some made-up data about SAT scores at four different schools. | 1 2 3 4 . | school1_SATs = [ 1100, 1250, 1390, 970, 1510 ]; school2_SATs = [ 1010, 1050, 1090, 1110 ]; school3_SATs = [ 900, 1550, 1300, 1270, 1210 ]; school4_SATs = [ 900, 850, 1110, 1070, 910, 920 ]; . | . ANOVA tests the null hypothesis that all group means are equal. You choose $\\alpha$, the probability of Type I error (false positive, finding we should reject $H_0$ when it’s actually true). I will use $\\alpha=0.05$ in this example. | 1 2 3 4 5 . | using HypothesisTests alpha = 0.05 p_value = pvalue( OneWayANOVATest( school1_SATs, school2_SATs, school3_SATs, school4_SATs ) ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.03405326535040251, true) . | . The result we see above is to reject $H_0$, and therefore conclude that at least one pair of means is statistically significantly different. If you are using the most common $\\alpha$ value of $0.05$, you can save a few lines of code and get a more detailed printout by just printing out the test itself: . | 1 . | OneWayANOVATest( school1_SATs, school2_SATs, school3_SATs, school4_SATs ) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 . | One-way analysis of variance (ANOVA) test ----------------------------------------- Population details: parameter of interest: Means value under h_0: \"all equal\" point estimate: NaN Test summary: outcome with 95% confidence: reject h_0 p-value: 0.0341 Details: number of observations: [5, 4, 5, 6] F statistic: 3.69513 degrees of freedom: (3, 16) . | . Content last modified on 05 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova-in-julia/#solution",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova-in-julia/#solution"
  },"736": {
    "doc": "How to do a one-way analysis of variance (ANOVA) (in Python, using SciPy)",
    "title": "How to do a one-way analysis of variance (ANOVA) (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova-in-python-using-scipy/"
  },"737": {
    "doc": "How to do a one-way analysis of variance (ANOVA) (in Python, using SciPy)",
    "title": "Task",
    "content": "If we have multiple independent samples of the same quantity (such as students’ SAT scores from several different schools), we may want to test whether the means of each of the samples are the same. Analysis of Variance (ANOVA) can determine whether any two of the sample means differ significantly. How can we do an ANOVA? . Related tasks: . | How to do a two-sided hypothesis test for two sample means (which is just an ANOVA with only two samples) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compare two nested linear models | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | How to do a Kruskal-Wallis test | . ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova-in-python-using-scipy/#task"
  },"738": {
    "doc": "How to do a one-way analysis of variance (ANOVA) (in Python, using SciPy)",
    "title": "Solution",
    "content": "Let’s assume we have our samples in several different Python lists. (Although anything like a list is also supported, including pandas Series.) Here I’ll construct some made-up data about SAT scores at four different schools. | 1 2 3 4 . | school1_SATs = [ 1100, 1250, 1390, 970, 1510 ] school2_SATs = [ 1010, 1050, 1090, 1110 ] school3_SATs = [ 900, 1550, 1300, 1270, 1210 ] school4_SATs = [ 900, 850, 1110, 1070, 910, 920 ] . | . ANOVA tests the null hypothesis that all group means are equal. You choose $\\alpha$, the probability of Type I error (false positive, finding we should reject $H_0$ when it’s actually true). I will use $\\alpha=0.05$ in this example. | 1 2 3 4 5 6 7 8 9 . | alpha = 0.05 # Run a one-way ANOVA and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. from scipy import stats F_statistic, p_value = stats.f_oneway( school1_SATs, school2_SATs, school3_SATs, school4_SATs ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.0342311478489849, True) . | . The result we see above is to reject $H_0$, and therefore conclude that at least one pair of means is statistically significantly different. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova-in-python-using-scipy/#solution"
  },"739": {
    "doc": "How to do a one-way analysis of variance (ANOVA) (in R)",
    "title": "How to do a one-way analysis of variance (ANOVA) (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova-in-r/",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova-in-r/"
  },"740": {
    "doc": "How to do a one-way analysis of variance (ANOVA) (in R)",
    "title": "Task",
    "content": "If we have multiple independent samples of the same quantity (such as students’ SAT scores from several different schools), we may want to test whether the means of each of the samples are the same. Analysis of Variance (ANOVA) can determine whether any two of the sample means differ significantly. How can we do an ANOVA? . Related tasks: . | How to do a two-sided hypothesis test for two sample means (which is just an ANOVA with only two samples) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compare two nested linear models | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | How to do a Kruskal-Wallis test | . ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova-in-r/#task",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova-in-r/#task"
  },"741": {
    "doc": "How to do a one-way analysis of variance (ANOVA) (in R)",
    "title": "Solution",
    "content": "R expects you to have all the samples in one vector, and the groups they came from in a separate, categorical vector. So, for example, if we had SAT scores from four different schools (named A, B, C, and D), then our data might be arranged like this. | 1 2 3 4 5 6 7 8 . | SAT.scores &lt;- c( 1100, 1250, 1390, 970, 1510, 1010, 1050, 1090, 1110, 900, 1550, 1300, 1270, 1210, 900, 850, 1110, 1070, 910, 920 ) school.names &lt;- c( 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'D', 'D', 'D', 'D', 'D', 'D' ) . | . ANOVA tests the null hypothesis that all group means are equal. You choose $\\alpha$, the probability of Type I error (false positive, finding we should reject $H_0$ when it’s actually true). I will use $\\alpha=0.05$ in this example. | 1 2 3 . | # Run a one-way ANOVA and print a summary of all the output result &lt;- aov( SAT.scores ~ school.names ) summary( result ) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) school.names 3 321715 107238 3.689 0.0342 * Residuals 16 465140 29071 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The $p$-value reported in that output is $0.0433$. You could manually check whether $p&lt;\\alpha$. Since it is, we would reject $H_0$, and therefore conclude that at least one pair of means is statistically significantly different. Or you could ask R to do the comparison for you, but getting the $p$-value from the ANOVA summary is fiddly: . | 1 2 3 . | alpha &lt;- 0.05 p.value &lt;- unname( unlist( summary( result ) ) )[9] p.value &lt; alpha . | . | 1 . | [1] TRUE . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova-in-r/#solution",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova-in-r/#solution"
  },"742": {
    "doc": "How to do a one-way analysis of variance (ANOVA)",
    "title": "How to do a one-way analysis of variance (ANOVA)",
    "content": " ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova/",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova/"
  },"743": {
    "doc": "How to do a one-way analysis of variance (ANOVA)",
    "title": "Description",
    "content": "If we have multiple independent samples of the same quantity (such as students’ SAT scores from several different schools), we may want to test whether the means of each of the samples are the same. Analysis of Variance (ANOVA) can determine whether any two of the sample means differ significantly. How can we do an ANOVA? . Related tasks: . | How to do a two-sided hypothesis test for two sample means (which is just an ANOVA with only two samples) | How to do a two-way ANOVA test with interaction | How to do a two-way ANOVA test without interaction | How to compare two nested linear models | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | How to do a Kruskal-Wallis test | . ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova/#description",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova/#description"
  },"744": {
    "doc": "How to do a one-way analysis of variance (ANOVA)",
    "title": "Solution, in Julia",
    "content": "View this solution alone. Let’s assume we have our samples in several different Julia arrays. Here I’ll construct some made-up data about SAT scores at four different schools. | 1 2 3 4 . | school1_SATs = [ 1100, 1250, 1390, 970, 1510 ]; school2_SATs = [ 1010, 1050, 1090, 1110 ]; school3_SATs = [ 900, 1550, 1300, 1270, 1210 ]; school4_SATs = [ 900, 850, 1110, 1070, 910, 920 ]; . | . ANOVA tests the null hypothesis that all group means are equal. You choose $\\alpha$, the probability of Type I error (false positive, finding we should reject $H_0$ when it’s actually true). I will use $\\alpha=0.05$ in this example. | 1 2 3 4 5 . | using HypothesisTests alpha = 0.05 p_value = pvalue( OneWayANOVATest( school1_SATs, school2_SATs, school3_SATs, school4_SATs ) ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.03405326535040251, true) . | . The result we see above is to reject $H_0$, and therefore conclude that at least one pair of means is statistically significantly different. If you are using the most common $\\alpha$ value of $0.05$, you can save a few lines of code and get a more detailed printout by just printing out the test itself: . | 1 . | OneWayANOVATest( school1_SATs, school2_SATs, school3_SATs, school4_SATs ) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 . | One-way analysis of variance (ANOVA) test ----------------------------------------- Population details: parameter of interest: Means value under h_0: \"all equal\" point estimate: NaN Test summary: outcome with 95% confidence: reject h_0 p-value: 0.0341 Details: number of observations: [5, 4, 5, 6] F statistic: 3.69513 degrees of freedom: (3, 16) . | . Content last modified on 05 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova/#solution-in-julia",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova/#solution-in-julia"
  },"745": {
    "doc": "How to do a one-way analysis of variance (ANOVA)",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. Let’s assume we have our samples in several different Python lists. (Although anything like a list is also supported, including pandas Series.) Here I’ll construct some made-up data about SAT scores at four different schools. | 1 2 3 4 . | school1_SATs = [ 1100, 1250, 1390, 970, 1510 ] school2_SATs = [ 1010, 1050, 1090, 1110 ] school3_SATs = [ 900, 1550, 1300, 1270, 1210 ] school4_SATs = [ 900, 850, 1110, 1070, 910, 920 ] . | . ANOVA tests the null hypothesis that all group means are equal. You choose $\\alpha$, the probability of Type I error (false positive, finding we should reject $H_0$ when it’s actually true). I will use $\\alpha=0.05$ in this example. | 1 2 3 4 5 6 7 8 9 . | alpha = 0.05 # Run a one-way ANOVA and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. from scipy import stats F_statistic, p_value = stats.f_oneway( school1_SATs, school2_SATs, school3_SATs, school4_SATs ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.0342311478489849, True) . | . The result we see above is to reject $H_0$, and therefore conclude that at least one pair of means is statistically significantly different. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova/#using-scipy-in-python"
  },"746": {
    "doc": "How to do a one-way analysis of variance (ANOVA)",
    "title": "Solution, in R",
    "content": "View this solution alone. R expects you to have all the samples in one vector, and the groups they came from in a separate, categorical vector. So, for example, if we had SAT scores from four different schools (named A, B, C, and D), then our data might be arranged like this. | 1 2 3 4 5 6 7 8 . | SAT.scores &lt;- c( 1100, 1250, 1390, 970, 1510, 1010, 1050, 1090, 1110, 900, 1550, 1300, 1270, 1210, 900, 850, 1110, 1070, 910, 920 ) school.names &lt;- c( 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C', 'D', 'D', 'D', 'D', 'D', 'D' ) . | . ANOVA tests the null hypothesis that all group means are equal. You choose $\\alpha$, the probability of Type I error (false positive, finding we should reject $H_0$ when it’s actually true). I will use $\\alpha=0.05$ in this example. | 1 2 3 . | # Run a one-way ANOVA and print a summary of all the output result &lt;- aov( SAT.scores ~ school.names ) summary( result ) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) school.names 3 321715 107238 3.689 0.0342 * Residuals 16 465140 29071 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The $p$-value reported in that output is $0.0433$. You could manually check whether $p&lt;\\alpha$. Since it is, we would reject $H_0$, and therefore conclude that at least one pair of means is statistically significantly different. Or you could ask R to do the comparison for you, but getting the $p$-value from the ANOVA summary is fiddly: . | 1 2 3 . | alpha &lt;- 0.05 p.value &lt;- unname( unlist( summary( result ) ) )[9] p.value &lt; alpha . | . | 1 . | [1] TRUE . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova/#solution-in-r",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova/#solution-in-r"
  },"747": {
    "doc": "How to do a one-way analysis of variance (ANOVA)",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR521 | Bentley University MA214 | . ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova/#topics-that-include-this-task"
  },"748": {
    "doc": "How to do a one-way analysis of variance (ANOVA)",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-one-way-analysis-of-variance-anova/#opportunities",
    "relUrl": "/how-to-do-a-one-way-analysis-of-variance-anova/#opportunities"
  },"749": {
    "doc": "How to do a Spearman rank correlation test (in Python, using SciPy)",
    "title": "How to do a Spearman rank correlation test (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-spearman-rank-correlation-test-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test-in-python-using-scipy/"
  },"750": {
    "doc": "How to do a Spearman rank correlation test (in Python, using SciPy)",
    "title": "Task",
    "content": "When we want to determine whether there is a relationship between two variables, but our samples do not come from normally distributed populations, we can use the Spearman Rank Correlation Test. How do we conduct it? . ",
    "url": "/how-to-do-a-spearman-rank-correlation-test-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test-in-python-using-scipy/#task"
  },"751": {
    "doc": "How to do a Spearman rank correlation test (in Python, using SciPy)",
    "title": "Solution",
    "content": "We will use some fake data about height and weight measurements for people. You can replace it with your real data. Our data should be NumPy arrays, as in the example below. (Recall that pandas DataFrame columns are also NumPy arrays.) . | 1 2 3 . | import numpy as np heights = np.array([60, 76, 57, 68, 70, 62, 63]) weights = np.array([145, 178, 120, 143, 174, 130, 137]) . | . Let’s say we want to test the correlation between height (inches) and weight (pounds). Our null hypothesis would state that the Pearson correlation coefficient is equal to zero, or that there is no relationship between height and weight, $H_0: \\rho_s = 0$. We choose $\\alpha$, or the Type I error rate, to be 0.05 and carry out the Spearman Rank Correlation Test to get the test-statistic and $p$-value. | 1 2 3 . | from scipy import stats from scipy.stats import spearmanr spearmanr(heights, weights) . | . | 1 . | SpearmanrResult(correlation=0.7857142857142859, pvalue=0.03623846267982713) . | . Our $p$-value is $0.03624$, which is less than $\\alpha=0.05$, so we reject the null hypothesis. There does appear to be a relationship between height and weight. (This $p$-value is different than the one computed in the solution using R, because different approximation methods are used by the two software packages when the sample size is small.) . Note that for right- or left-tailed tests, the following syntax can be used. | 1 2 . | spearmanr(heights, weights, alternative=\"greater\") # right-tailed spearmanr(heights, weights, alternative=\"less\") # left-talied . | . Content last modified on 05 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-spearman-rank-correlation-test-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test-in-python-using-scipy/#solution"
  },"752": {
    "doc": "How to do a Spearman rank correlation test (in R)",
    "title": "How to do a Spearman rank correlation test (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-spearman-rank-correlation-test-in-r/",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test-in-r/"
  },"753": {
    "doc": "How to do a Spearman rank correlation test (in R)",
    "title": "Task",
    "content": "When we want to determine whether there is a relationship between two variables, but our samples do not come from normally distributed populations, we can use the Spearman Rank Correlation Test. How do we conduct it? . ",
    "url": "/how-to-do-a-spearman-rank-correlation-test-in-r/#task",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test-in-r/#task"
  },"754": {
    "doc": "How to do a Spearman rank correlation test (in R)",
    "title": "Solution",
    "content": "We will use some fake data about height and weight measurements for people. You can replace it with your real data. Our data should be stored in R vectors, as shown below. | 1 2 . | heights &lt;- c(60, 76, 57, 68, 70, 62, 63) weights &lt;- c(145, 178, 120, 143, 174, 130, 137) . | . Let’s say we want to test the correlation between height (inches) and weight (pounds). Our null hypothesis would state that the Pearson correlation coefficient is equal to zero, or that there is no relationship between height and weight, $H_0: \\rho_s = 0$. We choose $\\alpha$, or the Type I error rate, to be 0.05 and carry out the Spearman Rank Correlation Test to get the test-statistic and $p$-value. | 1 2 . | # Run the Spearman Rank Correlation Test to get the test-statistic and p-value cor.test(heights, weights, alternative = \"two.sided\", method = \"spearman\") . | . | 1 2 3 4 5 6 7 8 . | Spearman's rank correlation rho data: heights and weights S = 12, p-value = 0.04802 alternative hypothesis: true rho is not equal to 0 sample estimates: rho 0.7857143 . | . Our $p$-value is $0.04802$, which is less than $\\alpha=0.05$, so we reject the null hypothesis. There does appear to be a relationship between height and weight. (This $p$-value is different than the one computed in the solution using Python, because different approximation methods are used by the two software packages when the sample size is small.) . Note that for a right-tailed test, you can replace “two.sided” with “greater” and for a left-tailed test, you can replace “two.sided” with “less”. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-spearman-rank-correlation-test-in-r/#solution",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test-in-r/#solution"
  },"755": {
    "doc": "How to do a Spearman rank correlation test",
    "title": "How to do a Spearman rank correlation test",
    "content": " ",
    "url": "/how-to-do-a-spearman-rank-correlation-test/",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test/"
  },"756": {
    "doc": "How to do a Spearman rank correlation test",
    "title": "Description",
    "content": "When we want to determine whether there is a relationship between two variables, but our samples do not come from normally distributed populations, we can use the Spearman Rank Correlation Test. How do we conduct it? . ",
    "url": "/how-to-do-a-spearman-rank-correlation-test/#description",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test/#description"
  },"757": {
    "doc": "How to do a Spearman rank correlation test",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We will use some fake data about height and weight measurements for people. You can replace it with your real data. Our data should be NumPy arrays, as in the example below. (Recall that pandas DataFrame columns are also NumPy arrays.) . | 1 2 3 . | import numpy as np heights = np.array([60, 76, 57, 68, 70, 62, 63]) weights = np.array([145, 178, 120, 143, 174, 130, 137]) . | . Let’s say we want to test the correlation between height (inches) and weight (pounds). Our null hypothesis would state that the Pearson correlation coefficient is equal to zero, or that there is no relationship between height and weight, $H_0: \\rho_s = 0$. We choose $\\alpha$, or the Type I error rate, to be 0.05 and carry out the Spearman Rank Correlation Test to get the test-statistic and $p$-value. | 1 2 3 . | from scipy import stats from scipy.stats import spearmanr spearmanr(heights, weights) . | . | 1 . | SpearmanrResult(correlation=0.7857142857142859, pvalue=0.03623846267982713) . | . Our $p$-value is $0.03624$, which is less than $\\alpha=0.05$, so we reject the null hypothesis. There does appear to be a relationship between height and weight. (This $p$-value is different than the one computed in the solution using R, because different approximation methods are used by the two software packages when the sample size is small.) . Note that for right- or left-tailed tests, the following syntax can be used. | 1 2 . | spearmanr(heights, weights, alternative=\"greater\") # right-tailed spearmanr(heights, weights, alternative=\"less\") # left-talied . | . Content last modified on 05 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-spearman-rank-correlation-test/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test/#using-scipy-in-python"
  },"758": {
    "doc": "How to do a Spearman rank correlation test",
    "title": "Solution, in R",
    "content": "View this solution alone. We will use some fake data about height and weight measurements for people. You can replace it with your real data. Our data should be stored in R vectors, as shown below. | 1 2 . | heights &lt;- c(60, 76, 57, 68, 70, 62, 63) weights &lt;- c(145, 178, 120, 143, 174, 130, 137) . | . Let’s say we want to test the correlation between height (inches) and weight (pounds). Our null hypothesis would state that the Pearson correlation coefficient is equal to zero, or that there is no relationship between height and weight, $H_0: \\rho_s = 0$. We choose $\\alpha$, or the Type I error rate, to be 0.05 and carry out the Spearman Rank Correlation Test to get the test-statistic and $p$-value. | 1 2 . | # Run the Spearman Rank Correlation Test to get the test-statistic and p-value cor.test(heights, weights, alternative = \"two.sided\", method = \"spearman\") . | . | 1 2 3 4 5 6 7 8 . | Spearman's rank correlation rho data: heights and weights S = 12, p-value = 0.04802 alternative hypothesis: true rho is not equal to 0 sample estimates: rho 0.7857143 . | . Our $p$-value is $0.04802$, which is less than $\\alpha=0.05$, so we reject the null hypothesis. There does appear to be a relationship between height and weight. (This $p$-value is different than the one computed in the solution using Python, because different approximation methods are used by the two software packages when the sample size is small.) . Note that for a right-tailed test, you can replace “two.sided” with “greater” and for a left-tailed test, you can replace “two.sided” with “less”. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-spearman-rank-correlation-test/#solution-in-r",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test/#solution-in-r"
  },"759": {
    "doc": "How to do a Spearman rank correlation test",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-do-a-spearman-rank-correlation-test/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test/#topics-that-include-this-task"
  },"760": {
    "doc": "How to do a Spearman rank correlation test",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-spearman-rank-correlation-test/#opportunities",
    "relUrl": "/how-to-do-a-spearman-rank-correlation-test/#opportunities"
  },"761": {
    "doc": "How to do a test of joint significance (in Python, using Statsmodels)",
    "title": "How to do a test of joint significance (in Python, using Statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-test-of-joint-significance-in-python-using-statsmodels/",
    "relUrl": "/how-to-do-a-test-of-joint-significance-in-python-using-statsmodels/"
  },"762": {
    "doc": "How to do a test of joint significance (in Python, using Statsmodels)",
    "title": "Task",
    "content": "If we have a multivariate linear model, how do we test the joint significance of all the variables in the model? In other words, how do we test the overall significance of the regression model? . ",
    "url": "/how-to-do-a-test-of-joint-significance-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-do-a-test-of-joint-significance-in-python-using-statsmodels/#task"
  },"763": {
    "doc": "How to do a test of joint significance (in Python, using Statsmodels)",
    "title": "Solution",
    "content": "Let’s assume that you already made your multivariate linear model, similar to the one shown below. If you still need to create one, first see how to fit a multiple linear regression model. We use example data here, but you would use your own data instead. | 1 2 3 4 5 6 7 8 . | import pandas as pd import statsmodels.api as sm data = { 'x1' : [ 2, 7, 4, 3, 11, 18, 6, 15, 9, 12], 'x2' : [ 4, 6, 10, 1, 18, 11, 8, 20, 16, 13], 'x3' : [11, 16, 20, 6, 14, 8, 5, 23, 13, 10], 'y' : [24, 60, 32, 29, 90, 45, 130, 76, 100, 120] } . | . The following code fits the model to the data. | 1 2 3 4 5 . | df = pd.DataFrame(data) xs = df[['x1', 'x2', 'x3']] y = df['y'] xs = sm.add_constant(xs) model = sm.OLS(y, xs).fit() . | . | 1 2 . | /opt/conda/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only x = pd.concat(x[::order], 1) . | . Now we want to test whether the model is significant. We will use a null hypothesis that states that all of the model’s coefficients are equal to zero, that is, they are not jointly significant in predicting $y$. We can write $H_0: \\beta_0 = \\beta_1 = \\beta2 = \\beta_3 = 0$. We also choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. Herer we’ll use $\\alpha=0.05$. The summary output for the model will give us both the F-statistic and the p-value. | 1 . | model.summary() . | . | 1 2 . | /opt/conda/lib/python3.9/site-packages/scipy/stats/stats.py:1541: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=10 warnings.warn(\"kurtosistest only valid for n&gt;=20 ... continuing \" . | . OLS Regression Results | Dep. Variable: | y | R-squared: | 0.594 | . | Model: | OLS | Adj. R-squared: | 0.390 | . | Method: | Least Squares | F-statistic: | 2.921 | . | Date: | Tue, 05 Oct 2021 | Prob (F-statistic): | 0.122 | . | Time: | 20:20:04 | Log-Likelihood: | -45.689 | . | No. Observations: | 10 | AIC: | 99.38 | . | Df Residuals: | 6 | BIC: | 100.6 | . | Df Model: | 3 | | | . | Covariance Type: | nonrobust | | | . | | coef | std err | t | P&gt;|t| | [0.025 | 0.975] | . | const | 77.2443 | 27.366 | 2.823 | 0.030 | 10.282 | 144.206 | . | x1 | -2.7009 | 2.855 | -0.946 | 0.381 | -9.686 | 4.284 | . | x2 | 7.2989 | 2.875 | 2.539 | 0.044 | 0.265 | 14.333 | . | x3 | -4.8607 | 2.187 | -2.223 | 0.068 | -10.211 | 0.490 | . | Omnibus: | 2.691 | Durbin-Watson: | 2.123 | . | Prob(Omnibus): | 0.260 | Jarque-Bera (JB): | 1.251 | . | Skew: | 0.524 | Prob(JB): | 0.535 | . | Kurtosis: | 1.620 | Cond. No. | 58.2 | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. Near the top right of the output, we can see that the F-statistic is 2.921. The corresponding $p$-value immediately below it is 0.1222, which is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We cannot conclude that the independent variables in our model are jointly significant in predicting the response variable. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-test-of-joint-significance-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-do-a-test-of-joint-significance-in-python-using-statsmodels/#solution"
  },"764": {
    "doc": "How to do a test of joint significance (in R)",
    "title": "How to do a test of joint significance (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-test-of-joint-significance-in-r/",
    "relUrl": "/how-to-do-a-test-of-joint-significance-in-r/"
  },"765": {
    "doc": "How to do a test of joint significance (in R)",
    "title": "Task",
    "content": "If we have a multivariate linear model, how do we test the joint significance of all the variables in the model? In other words, how do we test the overall significance of the regression model? . ",
    "url": "/how-to-do-a-test-of-joint-significance-in-r/#task",
    "relUrl": "/how-to-do-a-test-of-joint-significance-in-r/#task"
  },"766": {
    "doc": "How to do a test of joint significance (in R)",
    "title": "Solution",
    "content": "Let’s assume that you already made your multiple regression model, similar to the one shown below. You can visit this task, , to see how to construct a multivariate linear model. Let’s assume that you already made your multivariate linear model, similar to the one shown below. If you still need to create one, first see how to fit a multivariate linear model. We use example data here, but you would use your own data instead. | 1 2 3 4 5 . | x1 &lt;- c( 2, 7, 4, 3, 11, 18, 6, 15, 9, 12) x2 &lt;- c( 4, 6, 10, 1, 18, 11, 8, 20, 16, 13) x3 &lt;- c(11, 16, 20, 6, 14, 8, 5, 23, 13, 10) y &lt;- c(24, 60, 32, 29, 90, 45, 130, 76, 100, 120) model &lt;- lm(y ~ x1 + x2 + x3) . | . Now we want to test whether the model is significant. We will use a null hypothesis that states that all of the model’s coefficients are equal to zero, that is, they are not jointly significant in predicting $y$. We can write $H_0: \\beta_0 = \\beta_1 = \\beta2 = \\beta_3 = 0$. We also choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. Herer we’ll use $\\alpha=0.05$. The summary output for the model will give us both the F-statistic and the p-value. | 1 . | summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 . | Call: lm(formula = y ~ x1 + x2 + x3) Residuals: Min 1Q Median 3Q Max -25.031 -20.218 -8.373 22.937 35.640 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 77.244 27.366 2.823 0.0302 * x1 -2.701 2.855 -0.946 0.3806 x2 7.299 2.875 2.539 0.0441 * x3 -4.861 2.187 -2.223 0.0679 . --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 30.13 on 6 degrees of freedom Multiple R-squared: 0.5936, Adjusted R-squared: 0.3904 F-statistic: 2.921 on 3 and 6 DF, p-value: 0.1222 . | . In the final line of the output, we can see that the F-statistic is 2.921. The corresponding $p$-value in the same line is 0.1222, which is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We cannot conclude that the independent variables in our model are jointly significant in predicting the response variable. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-test-of-joint-significance-in-r/#solution",
    "relUrl": "/how-to-do-a-test-of-joint-significance-in-r/#solution"
  },"767": {
    "doc": "How to do a test of joint significance",
    "title": "How to do a test of joint significance",
    "content": " ",
    "url": "/how-to-do-a-test-of-joint-significance/",
    "relUrl": "/how-to-do-a-test-of-joint-significance/"
  },"768": {
    "doc": "How to do a test of joint significance",
    "title": "Description",
    "content": "If we have a multivariate linear model, how do we test the joint significance of all the variables in the model? In other words, how do we test the overall significance of the regression model? . ",
    "url": "/how-to-do-a-test-of-joint-significance/#description",
    "relUrl": "/how-to-do-a-test-of-joint-significance/#description"
  },"769": {
    "doc": "How to do a test of joint significance",
    "title": "Using Statsmodels, in Python",
    "content": "View this solution alone. Let’s assume that you already made your multivariate linear model, similar to the one shown below. If you still need to create one, first see how to fit a multiple linear regression model. We use example data here, but you would use your own data instead. | 1 2 3 4 5 6 7 8 . | import pandas as pd import statsmodels.api as sm data = { 'x1' : [ 2, 7, 4, 3, 11, 18, 6, 15, 9, 12], 'x2' : [ 4, 6, 10, 1, 18, 11, 8, 20, 16, 13], 'x3' : [11, 16, 20, 6, 14, 8, 5, 23, 13, 10], 'y' : [24, 60, 32, 29, 90, 45, 130, 76, 100, 120] } . | . The following code fits the model to the data. | 1 2 3 4 5 . | df = pd.DataFrame(data) xs = df[['x1', 'x2', 'x3']] y = df['y'] xs = sm.add_constant(xs) model = sm.OLS(y, xs).fit() . | . | 1 2 . | /opt/conda/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only x = pd.concat(x[::order], 1) . | . Now we want to test whether the model is significant. We will use a null hypothesis that states that all of the model’s coefficients are equal to zero, that is, they are not jointly significant in predicting $y$. We can write $H_0: \\beta_0 = \\beta_1 = \\beta2 = \\beta_3 = 0$. We also choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. Herer we’ll use $\\alpha=0.05$. The summary output for the model will give us both the F-statistic and the p-value. | 1 . | model.summary() . | . | 1 2 . | /opt/conda/lib/python3.9/site-packages/scipy/stats/stats.py:1541: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=10 warnings.warn(\"kurtosistest only valid for n&gt;=20 ... continuing \" . | . OLS Regression Results | Dep. Variable: | y | R-squared: | 0.594 | . | Model: | OLS | Adj. R-squared: | 0.390 | . | Method: | Least Squares | F-statistic: | 2.921 | . | Date: | Tue, 05 Oct 2021 | Prob (F-statistic): | 0.122 | . | Time: | 20:20:04 | Log-Likelihood: | -45.689 | . | No. Observations: | 10 | AIC: | 99.38 | . | Df Residuals: | 6 | BIC: | 100.6 | . | Df Model: | 3 | | | . | Covariance Type: | nonrobust | | | . | | coef | std err | t | P&gt;|t| | [0.025 | 0.975] | . | const | 77.2443 | 27.366 | 2.823 | 0.030 | 10.282 | 144.206 | . | x1 | -2.7009 | 2.855 | -0.946 | 0.381 | -9.686 | 4.284 | . | x2 | 7.2989 | 2.875 | 2.539 | 0.044 | 0.265 | 14.333 | . | x3 | -4.8607 | 2.187 | -2.223 | 0.068 | -10.211 | 0.490 | . | Omnibus: | 2.691 | Durbin-Watson: | 2.123 | . | Prob(Omnibus): | 0.260 | Jarque-Bera (JB): | 1.251 | . | Skew: | 0.524 | Prob(JB): | 0.535 | . | Kurtosis: | 1.620 | Cond. No. | 58.2 | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. Near the top right of the output, we can see that the F-statistic is 2.921. The corresponding $p$-value immediately below it is 0.1222, which is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We cannot conclude that the independent variables in our model are jointly significant in predicting the response variable. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-test-of-joint-significance/#using-statsmodels-in-python",
    "relUrl": "/how-to-do-a-test-of-joint-significance/#using-statsmodels-in-python"
  },"770": {
    "doc": "How to do a test of joint significance",
    "title": "Solution, in R",
    "content": "View this solution alone. Let’s assume that you already made your multiple regression model, similar to the one shown below. You can visit this task, , to see how to construct a multivariate linear model. Let’s assume that you already made your multivariate linear model, similar to the one shown below. If you still need to create one, first see how to fit a multivariate linear model. We use example data here, but you would use your own data instead. | 1 2 3 4 5 . | x1 &lt;- c( 2, 7, 4, 3, 11, 18, 6, 15, 9, 12) x2 &lt;- c( 4, 6, 10, 1, 18, 11, 8, 20, 16, 13) x3 &lt;- c(11, 16, 20, 6, 14, 8, 5, 23, 13, 10) y &lt;- c(24, 60, 32, 29, 90, 45, 130, 76, 100, 120) model &lt;- lm(y ~ x1 + x2 + x3) . | . Now we want to test whether the model is significant. We will use a null hypothesis that states that all of the model’s coefficients are equal to zero, that is, they are not jointly significant in predicting $y$. We can write $H_0: \\beta_0 = \\beta_1 = \\beta2 = \\beta_3 = 0$. We also choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. Herer we’ll use $\\alpha=0.05$. The summary output for the model will give us both the F-statistic and the p-value. | 1 . | summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 . | Call: lm(formula = y ~ x1 + x2 + x3) Residuals: Min 1Q Median 3Q Max -25.031 -20.218 -8.373 22.937 35.640 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 77.244 27.366 2.823 0.0302 * x1 -2.701 2.855 -0.946 0.3806 x2 7.299 2.875 2.539 0.0441 * x3 -4.861 2.187 -2.223 0.0679 . --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 30.13 on 6 degrees of freedom Multiple R-squared: 0.5936, Adjusted R-squared: 0.3904 F-statistic: 2.921 on 3 and 6 DF, p-value: 0.1222 . | . In the final line of the output, we can see that the F-statistic is 2.921. The corresponding $p$-value in the same line is 0.1222, which is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We cannot conclude that the independent variables in our model are jointly significant in predicting the response variable. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-test-of-joint-significance/#solution-in-r",
    "relUrl": "/how-to-do-a-test-of-joint-significance/#solution-in-r"
  },"771": {
    "doc": "How to do a test of joint significance",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-do-a-test-of-joint-significance/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-test-of-joint-significance/#topics-that-include-this-task"
  },"772": {
    "doc": "How to do a test of joint significance",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-test-of-joint-significance/#opportunities",
    "relUrl": "/how-to-do-a-test-of-joint-significance/#opportunities"
  },"773": {
    "doc": "How to do a two-sided hypothesis test for a sample mean (in Julia)",
    "title": "How to do a two-sided hypothesis test for a sample mean (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-julia/",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-julia/"
  },"774": {
    "doc": "How to do a two-sided hypothesis test for a sample mean (in Julia)",
    "title": "Task",
    "content": "Say we have a population whose mean $\\mu$ is known. We take a sample $x_1,\\ldots,x_n$ and compute its mean, $\\bar x$. We then ask whether this sample is significantly different from the population at large, that is, is $\\mu=\\bar x$? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for two sample means | How to do a one-sided hypothesis test for two sample means | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-julia/#task",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-julia/#task"
  },"775": {
    "doc": "How to do a two-sided hypothesis test for a sample mean (in Julia)",
    "title": "Solution",
    "content": "This is a two-sided test with the null hypothesis $H_0:\\mu=\\bar x$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 9 10 . | # Replace these first three lines with the values from your situation. alpha = 0.05 pop_mean = 10 sample = [ 9, 12, 14, 8, 13 ] # The following code runs the test for your chosen alpha: using HypothesisTests p_value = pvalue( OneSampleTTest( sample, pop_mean ) ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.35845634462296455, false) . | . In this case, the $p$-value was larger than $\\alpha$, so the sample does not give us enough information to reject the null hypothesis. We would continue to assume that the sample is like the population, $\\mu=\\bar x$. When you are using the most common value for $\\alpha$, which is $0.05$ for the $95\\%$ confidence interval, you can simply print out the test itself and get a detailed printout with all the information you need, thus saving a few lines of code. | 1 . | OneSampleTTest( sample, pop_mean ) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | One sample t-test ----------------- Population details: parameter of interest: Mean value under h_0: 10 point estimate: 11.2 95% confidence interval: (7.986, 14.41) Test summary: outcome with 95% confidence: fail to reject h_0 two-sided p-value: 0.3585 Details: number of observations: 5 t-statistic: 1.0366421106976316 degrees of freedom: 4 empirical standard error: 1.1575836902790224 . | . Content last modified on 05 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-julia/#solution",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-julia/#solution"
  },"776": {
    "doc": "How to do a two-sided hypothesis test for a sample mean (in Python, using SciPy)",
    "title": "How to do a two-sided hypothesis test for a sample mean (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-python-using-scipy/"
  },"777": {
    "doc": "How to do a two-sided hypothesis test for a sample mean (in Python, using SciPy)",
    "title": "Task",
    "content": "Say we have a population whose mean $\\mu$ is known. We take a sample $x_1,\\ldots,x_n$ and compute its mean, $\\bar x$. We then ask whether this sample is significantly different from the population at large, that is, is $\\mu=\\bar x$? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for two sample means | How to do a one-sided hypothesis test for two sample means | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-python-using-scipy/#task"
  },"778": {
    "doc": "How to do a two-sided hypothesis test for a sample mean (in Python, using SciPy)",
    "title": "Solution",
    "content": "This is a two-sided test with the null hypothesis $H_0:\\mu=\\bar x$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 9 10 11 12 . | from scipy import stats # Replace these first three lines with the values from your situation. alpha = 0.05 pop_mean = 10 sample = [ 9, 12, 14, 8, 13 ] # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. t_statistic, p_value = stats.ttest_1samp( sample, pop_mean ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.35845634462296455, False) . | . In this case, the sample does not give us enough information to reject the null hypothesis. We would continue to assume that the sample is like the population, $\\mu=\\bar x$. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-python-using-scipy/#solution"
  },"779": {
    "doc": "How to do a two-sided hypothesis test for a sample mean (in R)",
    "title": "How to do a two-sided hypothesis test for a sample mean (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-r/",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-r/"
  },"780": {
    "doc": "How to do a two-sided hypothesis test for a sample mean (in R)",
    "title": "Task",
    "content": "Say we have a population whose mean $\\mu$ is known. We take a sample $x_1,\\ldots,x_n$ and compute its mean, $\\bar x$. We then ask whether this sample is significantly different from the population at large, that is, is $\\mu=\\bar x$? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for two sample means | How to do a one-sided hypothesis test for two sample means | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-r/#task",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-r/#task"
  },"781": {
    "doc": "How to do a two-sided hypothesis test for a sample mean (in R)",
    "title": "Solution",
    "content": "This is a two-sided test with the null hypothesis $H_0:\\mu=\\bar x$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 . | # Replace these first three lines with the values from your situation. alpha &lt;- 0.05 pop.mean &lt;- 10 sample &lt;- c( 9, 12, 14, 8, 13 ) # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. t.test( sample, mu=pop.mean, conf.level=1-alpha ) . | . | 1 2 3 4 5 6 7 8 9 10 . | One Sample t-test data: sample t = 1.0366, df = 4, p-value = 0.3585 alternative hypothesis: true mean is not equal to 10 95 percent confidence interval: 7.986032 14.413968 sample estimates: mean of x 11.2 . | . Although we can deduce the answer to our question from the above output, by comparing the $p$ value with $\\alpha$ manually, we can also ask R to do it. | 1 2 3 . | # Is there enough evidence to reject the null hypothesis? result &lt;- t.test( sample, mu=pop.mean, conf.level=1-alpha ) result$p.value &lt; alpha . | . | 1 . | [1] FALSE . | . In this case, the sample does not give us enough information to reject the null hypothesis. We would continue to assume that the sample is like the population, $\\mu=\\bar x$. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-r/#solution",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean-in-r/#solution"
  },"782": {
    "doc": "How to do a two-sided hypothesis test for a sample mean",
    "title": "How to do a two-sided hypothesis test for a sample mean",
    "content": " ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/"
  },"783": {
    "doc": "How to do a two-sided hypothesis test for a sample mean",
    "title": "Description",
    "content": "Say we have a population whose mean $\\mu$ is known. We take a sample $x_1,\\ldots,x_n$ and compute its mean, $\\bar x$. We then ask whether this sample is significantly different from the population at large, that is, is $\\mu=\\bar x$? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for two sample means | How to do a one-sided hypothesis test for two sample means | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#description",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#description"
  },"784": {
    "doc": "How to do a two-sided hypothesis test for a sample mean",
    "title": "Solution, in Julia",
    "content": "View this solution alone. This is a two-sided test with the null hypothesis $H_0:\\mu=\\bar x$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 9 10 . | # Replace these first three lines with the values from your situation. alpha = 0.05 pop_mean = 10 sample = [ 9, 12, 14, 8, 13 ] # The following code runs the test for your chosen alpha: using HypothesisTests p_value = pvalue( OneSampleTTest( sample, pop_mean ) ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.35845634462296455, false) . | . In this case, the $p$-value was larger than $\\alpha$, so the sample does not give us enough information to reject the null hypothesis. We would continue to assume that the sample is like the population, $\\mu=\\bar x$. When you are using the most common value for $\\alpha$, which is $0.05$ for the $95\\%$ confidence interval, you can simply print out the test itself and get a detailed printout with all the information you need, thus saving a few lines of code. | 1 . | OneSampleTTest( sample, pop_mean ) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | One sample t-test ----------------- Population details: parameter of interest: Mean value under h_0: 10 point estimate: 11.2 95% confidence interval: (7.986, 14.41) Test summary: outcome with 95% confidence: fail to reject h_0 two-sided p-value: 0.3585 Details: number of observations: 5 t-statistic: 1.0366421106976316 degrees of freedom: 4 empirical standard error: 1.1575836902790224 . | . Content last modified on 05 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#solution-in-julia",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#solution-in-julia"
  },"785": {
    "doc": "How to do a two-sided hypothesis test for a sample mean",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. This is a two-sided test with the null hypothesis $H_0:\\mu=\\bar x$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 9 10 11 12 . | from scipy import stats # Replace these first three lines with the values from your situation. alpha = 0.05 pop_mean = 10 sample = [ 9, 12, 14, 8, 13 ] # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. t_statistic, p_value = stats.ttest_1samp( sample, pop_mean ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.35845634462296455, False) . | . In this case, the sample does not give us enough information to reject the null hypothesis. We would continue to assume that the sample is like the population, $\\mu=\\bar x$. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#using-scipy-in-python"
  },"786": {
    "doc": "How to do a two-sided hypothesis test for a sample mean",
    "title": "Solution, in R",
    "content": "View this solution alone. This is a two-sided test with the null hypothesis $H_0:\\mu=\\bar x$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 . | # Replace these first three lines with the values from your situation. alpha &lt;- 0.05 pop.mean &lt;- 10 sample &lt;- c( 9, 12, 14, 8, 13 ) # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. t.test( sample, mu=pop.mean, conf.level=1-alpha ) . | . | 1 2 3 4 5 6 7 8 9 10 . | One Sample t-test data: sample t = 1.0366, df = 4, p-value = 0.3585 alternative hypothesis: true mean is not equal to 10 95 percent confidence interval: 7.986032 14.413968 sample estimates: mean of x 11.2 . | . Although we can deduce the answer to our question from the above output, by comparing the $p$ value with $\\alpha$ manually, we can also ask R to do it. | 1 2 3 . | # Is there enough evidence to reject the null hypothesis? result &lt;- t.test( sample, mu=pop.mean, conf.level=1-alpha ) result$p.value &lt; alpha . | . | 1 . | [1] FALSE . | . In this case, the sample does not give us enough information to reject the null hypothesis. We would continue to assume that the sample is like the population, $\\mu=\\bar x$. Content last modified on 05 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#solution-in-r",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#solution-in-r"
  },"787": {
    "doc": "How to do a two-sided hypothesis test for a sample mean",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#topics-that-include-this-task"
  },"788": {
    "doc": "How to do a two-sided hypothesis test for a sample mean",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#opportunities",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-a-sample-mean/#opportunities"
  },"789": {
    "doc": "How to do a two-sided hypothesis test for two sample means (in Julia)",
    "title": "How to do a two-sided hypothesis test for two sample means (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-julia/",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-julia/"
  },"790": {
    "doc": "How to do a two-sided hypothesis test for two sample means (in Julia)",
    "title": "Task",
    "content": "If we have two samples, $x_1,\\ldots,x_n$ and $x’_1,\\ldots,x’_m$, and we compute the mean of each one, we might want to ask whether the two means seem approximately equal. Or more precisely, is their difference statistically significant at a given level? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a sample mean | How to do a one-way analysis of variance (ANOVA) | How to do a one-sided hypothesis test for two sample means | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-julia/#task",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-julia/#task"
  },"791": {
    "doc": "How to do a two-sided hypothesis test for two sample means (in Julia)",
    "title": "Solution",
    "content": "If we call the mean of the first sample $\\bar x_1$ and the mean of the second sample $\\bar x_2$, then this is a two-sided test with the null hypothesis $H_0:\\bar x_1=\\bar x_2$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 9 10 11 . | # Replace these first three lines with the values from your situation. alpha = 0.10 sample1 = [ 6, 9, 7, 10, 10, 9 ] sample2 = [ 12, 14, 10, 17, 9 ] # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. using HypothesisTests p_value = pvalue( UnequalVarianceTTest( sample1, sample2 ) ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.1, 0.05097283741847691, true) . | . In this case, the $p$-value was less than $\\alpha$, so the sample gives us enough evidence to reject the null hypothesis at the $\\alpha=0.10$ level. The data suggest that $\\bar x_1\\neq\\bar x_2$. When you are using the most common value for $\\alpha$, which is $0.05$ for the $95\\%$ confidence interval, you can simply print out the test itself and get a detailed printout with all the information you need, thus saving a few lines of code. Note that this gives a different answer below than the one above, because above we chose to use $\\alpha=0.10$, but the default below is $\\alpha=0.05$. | 1 . | UnequalVarianceTTest( sample1, sample2 ) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | Two sample t-test (unequal variance) ------------------------------------ Population details: parameter of interest: Mean difference value under h_0: 0 point estimate: -3.9 95% confidence interval: (-7.823, 0.02309) Test summary: outcome with 95% confidence: fail to reject h_0 two-sided p-value: 0.0510 Details: number of observations: [6,5] t-statistic: -2.4616581720814326 degrees of freedom: 5.720083530052662 empirical standard error: 1.584297951775486 . | . Here we did not assume that the two samples had equal variance. If in your case they do, you can use EqualVarianceTTest() instead of UnequalVarianceTTest(). Content last modified on 05 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-julia/#solution",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-julia/#solution"
  },"792": {
    "doc": "How to do a two-sided hypothesis test for two sample means (in Python, using SciPy)",
    "title": "How to do a two-sided hypothesis test for two sample means (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/"
  },"793": {
    "doc": "How to do a two-sided hypothesis test for two sample means (in Python, using SciPy)",
    "title": "Task",
    "content": "If we have two samples, $x_1,\\ldots,x_n$ and $x’_1,\\ldots,x’_m$, and we compute the mean of each one, we might want to ask whether the two means seem approximately equal. Or more precisely, is their difference statistically significant at a given level? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a sample mean | How to do a one-way analysis of variance (ANOVA) | How to do a one-sided hypothesis test for two sample means | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/#task"
  },"794": {
    "doc": "How to do a two-sided hypothesis test for two sample means (in Python, using SciPy)",
    "title": "Solution",
    "content": "If we call the mean of the first sample $\\bar x_1$ and the mean of the second sample $\\bar x_2$, then this is a two-sided test with the null hypothesis $H_0:\\bar x_1=\\bar x_2$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). Let’s use $\\alpha=0.10$ as an example. | 1 2 3 4 5 6 7 8 9 10 . | from scipy import stats # Replace these first three lines with the values from your situation. alpha = 0.10 sample1 = [ 6, 9, 7, 10, 10, 9 ] sample2 = [ 12, 14, 10, 17, 9 ] # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. stats.ttest_ind( sample1, sample2, equal_var=False ) . | . | 1 . | Ttest_indResult(statistic=-2.4616581720814326, pvalue=0.05097283741847698) . | . The output says that the $p$-value is about $0.05097$, which is less than $\\alpha=0.10$. In this case, the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.10$ level. That is, the data suggest that $\\bar x_1\\neq\\bar x_2$. The equal_var parameter tells SciPy not to assume that the two samples have equal variances. If in your case they do, you can omit that parameter, and it will revert to its default value of True. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-python-using-scipy/#solution"
  },"795": {
    "doc": "How to do a two-sided hypothesis test for two sample means (in R)",
    "title": "How to do a two-sided hypothesis test for two sample means (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-r/",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-r/"
  },"796": {
    "doc": "How to do a two-sided hypothesis test for two sample means (in R)",
    "title": "Task",
    "content": "If we have two samples, $x_1,\\ldots,x_n$ and $x’_1,\\ldots,x’_m$, and we compute the mean of each one, we might want to ask whether the two means seem approximately equal. Or more precisely, is their difference statistically significant at a given level? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a sample mean | How to do a one-way analysis of variance (ANOVA) | How to do a one-sided hypothesis test for two sample means | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-r/#task",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-r/#task"
  },"797": {
    "doc": "How to do a two-sided hypothesis test for two sample means (in R)",
    "title": "Solution",
    "content": "If we call the mean of the first sample $\\bar x_1$ and the mean of the second sample $\\bar x_2$, then this is a two-sided test with the null hypothesis $H_0:\\bar x_1=\\bar x_2$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 . | # Replace these first three lines with the values from your situation. alpha &lt;- 0.10 sample1 &lt;- c( 6, 9, 7, 10, 10, 9 ) sample2 &lt;- c( 12, 14, 10, 17, 9 ) # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. t.test( sample1, sample2, conf.level=1-alpha ) . | . | 1 2 3 4 5 6 7 8 9 10 . | Welch Two Sample t-test data: sample1 and sample2 t = -2.4617, df = 5.7201, p-value = 0.05097 alternative hypothesis: true difference in means is not equal to 0 90 percent confidence interval: -7.0057683 -0.7942317 sample estimates: mean of x mean of y 8.5 12.4 . | . Although we can deduce the answer to our question from the above output, by comparing the $p$ value with $\\alpha$ manually, we can also ask R to do it. | 1 2 3 . | # Is there enough evidence to reject the null hypothesis? result &lt;- t.test( sample1, sample2, conf.level=1-alpha ) result$p.value &lt; alpha . | . | 1 . | [1] TRUE . | . In this case, the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.10$ level. The data suggest that $\\bar x_1\\neq\\bar x_2$. Here we did not assume that the two samples had equal variance. If in your case they do, you can pass the parameter var.equal=TRUE to t.test. Content last modified on 28 May 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-r/#solution",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means-in-r/#solution"
  },"798": {
    "doc": "How to do a two-sided hypothesis test for two sample means",
    "title": "How to do a two-sided hypothesis test for two sample means",
    "content": " ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/"
  },"799": {
    "doc": "How to do a two-sided hypothesis test for two sample means",
    "title": "Description",
    "content": "If we have two samples, $x_1,\\ldots,x_n$ and $x’_1,\\ldots,x’_m$, and we compute the mean of each one, we might want to ask whether the two means seem approximately equal. Or more precisely, is their difference statistically significant at a given level? . Related tasks: . | How to compute a confidence interval for a population mean | How to do a two-sided hypothesis test for a sample mean | How to do a one-way analysis of variance (ANOVA) | How to do a one-sided hypothesis test for two sample means | How to do a hypothesis test for a mean difference (matched pairs) | How to do a hypothesis test for a population proportion | . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#description",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#description"
  },"800": {
    "doc": "How to do a two-sided hypothesis test for two sample means",
    "title": "Solution, in Julia",
    "content": "View this solution alone. If we call the mean of the first sample $\\bar x_1$ and the mean of the second sample $\\bar x_2$, then this is a two-sided test with the null hypothesis $H_0:\\bar x_1=\\bar x_2$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 9 10 11 . | # Replace these first three lines with the values from your situation. alpha = 0.10 sample1 = [ 6, 9, 7, 10, 10, 9 ] sample2 = [ 12, 14, 10, 17, 9 ] # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. using HypothesisTests p_value = pvalue( UnequalVarianceTTest( sample1, sample2 ) ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.1, 0.05097283741847691, true) . | . In this case, the $p$-value was less than $\\alpha$, so the sample gives us enough evidence to reject the null hypothesis at the $\\alpha=0.10$ level. The data suggest that $\\bar x_1\\neq\\bar x_2$. When you are using the most common value for $\\alpha$, which is $0.05$ for the $95\\%$ confidence interval, you can simply print out the test itself and get a detailed printout with all the information you need, thus saving a few lines of code. Note that this gives a different answer below than the one above, because above we chose to use $\\alpha=0.10$, but the default below is $\\alpha=0.05$. | 1 . | UnequalVarianceTTest( sample1, sample2 ) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 . | Two sample t-test (unequal variance) ------------------------------------ Population details: parameter of interest: Mean difference value under h_0: 0 point estimate: -3.9 95% confidence interval: (-7.823, 0.02309) Test summary: outcome with 95% confidence: fail to reject h_0 two-sided p-value: 0.0510 Details: number of observations: [6,5] t-statistic: -2.4616581720814326 degrees of freedom: 5.720083530052662 empirical standard error: 1.584297951775486 . | . Here we did not assume that the two samples had equal variance. If in your case they do, you can use EqualVarianceTTest() instead of UnequalVarianceTTest(). Content last modified on 05 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#solution-in-julia",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#solution-in-julia"
  },"801": {
    "doc": "How to do a two-sided hypothesis test for two sample means",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. If we call the mean of the first sample $\\bar x_1$ and the mean of the second sample $\\bar x_2$, then this is a two-sided test with the null hypothesis $H_0:\\bar x_1=\\bar x_2$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). Let’s use $\\alpha=0.10$ as an example. | 1 2 3 4 5 6 7 8 9 10 . | from scipy import stats # Replace these first three lines with the values from your situation. alpha = 0.10 sample1 = [ 6, 9, 7, 10, 10, 9 ] sample2 = [ 12, 14, 10, 17, 9 ] # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. stats.ttest_ind( sample1, sample2, equal_var=False ) . | . | 1 . | Ttest_indResult(statistic=-2.4616581720814326, pvalue=0.05097283741847698) . | . The output says that the $p$-value is about $0.05097$, which is less than $\\alpha=0.10$. In this case, the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.10$ level. That is, the data suggest that $\\bar x_1\\neq\\bar x_2$. The equal_var parameter tells SciPy not to assume that the two samples have equal variances. If in your case they do, you can omit that parameter, and it will revert to its default value of True. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#using-scipy-in-python"
  },"802": {
    "doc": "How to do a two-sided hypothesis test for two sample means",
    "title": "Solution, in R",
    "content": "View this solution alone. If we call the mean of the first sample $\\bar x_1$ and the mean of the second sample $\\bar x_2$, then this is a two-sided test with the null hypothesis $H_0:\\bar x_1=\\bar x_2$. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 7 8 . | # Replace these first three lines with the values from your situation. alpha &lt;- 0.10 sample1 &lt;- c( 6, 9, 7, 10, 10, 9 ) sample2 &lt;- c( 12, 14, 10, 17, 9 ) # Run a one-sample t-test and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. t.test( sample1, sample2, conf.level=1-alpha ) . | . | 1 2 3 4 5 6 7 8 9 10 . | Welch Two Sample t-test data: sample1 and sample2 t = -2.4617, df = 5.7201, p-value = 0.05097 alternative hypothesis: true difference in means is not equal to 0 90 percent confidence interval: -7.0057683 -0.7942317 sample estimates: mean of x mean of y 8.5 12.4 . | . Although we can deduce the answer to our question from the above output, by comparing the $p$ value with $\\alpha$ manually, we can also ask R to do it. | 1 2 3 . | # Is there enough evidence to reject the null hypothesis? result &lt;- t.test( sample1, sample2, conf.level=1-alpha ) result$p.value &lt; alpha . | . | 1 . | [1] TRUE . | . In this case, the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.10$ level. The data suggest that $\\bar x_1\\neq\\bar x_2$. Here we did not assume that the two samples had equal variance. If in your case they do, you can pass the parameter var.equal=TRUE to t.test. Content last modified on 28 May 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#solution-in-r",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#solution-in-r"
  },"803": {
    "doc": "How to do a two-sided hypothesis test for two sample means",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | . ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#topics-that-include-this-task"
  },"804": {
    "doc": "How to do a two-sided hypothesis test for two sample means",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#opportunities",
    "relUrl": "/how-to-do-a-two-sided-hypothesis-test-for-two-sample-means/#opportunities"
  },"805": {
    "doc": "How to do a two-way ANOVA test with interaction (in Python, using Statsmodels)",
    "title": "How to do a two-way ANOVA test with interaction (in Python, using Statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction-in-python-using-statsmodels/",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction-in-python-using-statsmodels/"
  },"806": {
    "doc": "How to do a two-way ANOVA test with interaction (in Python, using Statsmodels)",
    "title": "Task",
    "content": "When we analyze the impact that two factors have on a response variable, we often consider the possible relationship between the two factors. That is, does their interaction term affect the response variable? A two-way ANOVA test with interaction can answer that question. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction-in-python-using-statsmodels/#task"
  },"807": {
    "doc": "How to do a two-way ANOVA test with interaction (in Python, using Statsmodels)",
    "title": "Solution",
    "content": "We’re going to use R’s esoph dataset, about esophageal cancer cases. We will focus on the impact of age group (agegp) and alcohol consumption (alcgp) on the number of cases of the cancer (ncases). We ask, does the interaction between these two factors affect the number of cases? . First, we load in the dataset. (See how to quickly load some sample data.) . | 1 2 3 . | from rdatasets import data data = data('esoph') data.head() . | . | | agegp | alcgp | tobgp | ncases | ncontrols | . | 0 | 25-34 | 0-39g/day | 0-9g/day | 0 | 40 | . | 1 | 25-34 | 0-39g/day | 10-19 | 0 | 10 | . | 2 | 25-34 | 0-39g/day | 20-29 | 0 | 6 | . | 3 | 25-34 | 0-39g/day | 30+ | 0 | 5 | . | 4 | 25-34 | 40-79 | 0-9g/day | 0 | 27 | . Next, we create a model that includes the response variable we care about, plus the two categorical variables we will be testing, as well as their interaction term. | 1 2 3 4 . | import statsmodels.api as sm from statsmodels.formula.api import ols # C(...) means the variable is categorical, and : means multiplication. model = ols('ncases ~ C(alcgp) + C(agegp) + C(alcgp):C(agegp)', data = data).fit() . | . A two-way ANOVA with interaction tests the following three null hypotheses. | There is no interaction between the two categorical variables. (If we reject this we do not test the other two hypotheses.) | The mean response is the same across all groups of the first factor. (In our example, that says the mean ncases is the same for all age groups.) | The mean response is the same across all groups of the second factor. (In our example, that says the mean ncases is the same for all alcohol consumption groups.) | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. Let’s let $\\alpha=0.05$ here. | 1 . | sm.stats.anova_lm(model, typ=2) . | . | | sum_sq | df | F | PR(&gt;F) | . | C(alcgp) | 52.695287 | 3.0 | 4.723387 | 4.862447e-03 | . | C(agegp) | 267.026108 | 5.0 | 14.361068 | 2.021935e-09 | . | C(alcgp):C(agegp) | 107.557743 | 15.0 | 1.928206 | 3.632710e-02 | . | Residual | 238.000000 | 64.0 | NaN | NaN | . The $p$-value for the interaction of age group and alcohol consumption is in the third row, final column, $3.63271\\times10^{-2}$. It is less than $\\alpha$, so we can reject the null hypothesis that age group and alcohol consumption do not interact with regards to the number of esophageal cancer cases. That is, we have reason to believe that their interaction does effect the outcome. As we stated when we listed the hypotheses to test, since we rejected the first null hypothesis, we will not test the other two. In the case where you failed to reject the first null hypothesis, you could consider each $p$-value in the first two rows of the above table, one for each of the two factors. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction-in-python-using-statsmodels/#solution"
  },"808": {
    "doc": "How to do a two-way ANOVA test with interaction (in R)",
    "title": "How to do a two-way ANOVA test with interaction (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction-in-r/",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction-in-r/"
  },"809": {
    "doc": "How to do a two-way ANOVA test with interaction (in R)",
    "title": "Task",
    "content": "When we analyze the impact that two factors have on a response variable, we often consider the possible relationship between the two factors. That is, does their interaction term affect the response variable? A two-way ANOVA test with interaction can answer that question. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction-in-r/#task",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction-in-r/#task"
  },"810": {
    "doc": "How to do a two-way ANOVA test with interaction (in R)",
    "title": "Solution",
    "content": "We’re going to use R’s esoph dataset, about esophageal cancer cases. We will focus on the impact of age group (agegp) and alcohol consumption (alcgp) on the number of cases of the cancer (ncases). We ask, does the interaction between these two factors affect the number of cases? . First, we load in the dataset. (See how to quickly load some sample data.) . | 1 2 3 4 . | # install.packages(\"datasets\") # if you have not already done this library(datasets) data &lt;- esoph head(data) . | . | 1 2 3 4 5 6 7 . | agegp alcgp tobgp ncases ncontrols 1 25-34 0-39g/day 0-9g/day 0 40 2 25-34 0-39g/day 10-19 0 10 3 25-34 0-39g/day 20-29 0 6 4 25-34 0-39g/day 30+ 0 5 5 25-34 40-79 0-9g/day 0 27 6 25-34 40-79 10-19 0 7 . | . Next, we create a model that includes the response variable we care about, plus the two categorical variables we will be testing, as well as their interaction term. | 1 2 . | # the * below means multiplication, to create an interaction term model &lt;- aov(ncases ~ agegp*alcgp, data = data) . | . A two-way ANOVA with interaction tests the following three null hypotheses. | There is no interaction between the two categorical variables. (If we reject this we do not test the other two hypotheses.) | The mean response is the same across all groups of the first factor. (In our example, that says the mean ncases is the same for all age groups.) | The mean response is the same across all groups of the second factor. (In our example, that says the mean ncases is the same for all alcohol consumption groups.) | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. Let’s let $\\alpha=0.05$ here. | 1 . | summary(model) . | . | 1 2 3 4 5 6 7 . | Df Sum Sq Mean Sq F value Pr(&gt;F) agegp 5 261.2 52.24 14.048 2.89e-09 *** alcgp 3 52.7 17.57 4.723 0.00486 ** agegp:alcgp 15 107.6 7.17 1.928 0.03633 * Residuals 64 238.0 3.72 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The $p$-value for the interaction of age group and alcohol consumption is in the third row, final column, $0.03633$. It is less than $\\alpha$, so we can reject the null hypothesis that age group and alcohol consumption do not interact with regards to the number of esophageal cancer cases. That is, we have reason to believe that their interaction does effect the outcome. As we stated when we listed the hypotheses to test, since we rejected the first null hypothesis, we will not test the other two. In the case where you failed to reject the first null hypothesis, you could consider each $p$-value in the first two rows of the above table, one for each of the two factors. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction-in-r/#solution",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction-in-r/#solution"
  },"811": {
    "doc": "How to do a two-way ANOVA test with interaction",
    "title": "How to do a two-way ANOVA test with interaction",
    "content": " ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction/",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction/"
  },"812": {
    "doc": "How to do a two-way ANOVA test with interaction",
    "title": "Description",
    "content": "When we analyze the impact that two factors have on a response variable, we often consider the possible relationship between the two factors. That is, does their interaction term affect the response variable? A two-way ANOVA test with interaction can answer that question. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction/#description",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction/#description"
  },"813": {
    "doc": "How to do a two-way ANOVA test with interaction",
    "title": "Using Statsmodels, in Python",
    "content": "View this solution alone. We’re going to use R’s esoph dataset, about esophageal cancer cases. We will focus on the impact of age group (agegp) and alcohol consumption (alcgp) on the number of cases of the cancer (ncases). We ask, does the interaction between these two factors affect the number of cases? . First, we load in the dataset. (See how to quickly load some sample data.) . | 1 2 3 . | from rdatasets import data data = data('esoph') data.head() . | . | | agegp | alcgp | tobgp | ncases | ncontrols | . | 0 | 25-34 | 0-39g/day | 0-9g/day | 0 | 40 | . | 1 | 25-34 | 0-39g/day | 10-19 | 0 | 10 | . | 2 | 25-34 | 0-39g/day | 20-29 | 0 | 6 | . | 3 | 25-34 | 0-39g/day | 30+ | 0 | 5 | . | 4 | 25-34 | 40-79 | 0-9g/day | 0 | 27 | . Next, we create a model that includes the response variable we care about, plus the two categorical variables we will be testing, as well as their interaction term. | 1 2 3 4 . | import statsmodels.api as sm from statsmodels.formula.api import ols # C(...) means the variable is categorical, and : means multiplication. model = ols('ncases ~ C(alcgp) + C(agegp) + C(alcgp):C(agegp)', data = data).fit() . | . A two-way ANOVA with interaction tests the following three null hypotheses. | There is no interaction between the two categorical variables. (If we reject this we do not test the other two hypotheses.) | The mean response is the same across all groups of the first factor. (In our example, that says the mean ncases is the same for all age groups.) | The mean response is the same across all groups of the second factor. (In our example, that says the mean ncases is the same for all alcohol consumption groups.) | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. Let’s let $\\alpha=0.05$ here. | 1 . | sm.stats.anova_lm(model, typ=2) . | . | | sum_sq | df | F | PR(&gt;F) | . | C(alcgp) | 52.695287 | 3.0 | 4.723387 | 4.862447e-03 | . | C(agegp) | 267.026108 | 5.0 | 14.361068 | 2.021935e-09 | . | C(alcgp):C(agegp) | 107.557743 | 15.0 | 1.928206 | 3.632710e-02 | . | Residual | 238.000000 | 64.0 | NaN | NaN | . The $p$-value for the interaction of age group and alcohol consumption is in the third row, final column, $3.63271\\times10^{-2}$. It is less than $\\alpha$, so we can reject the null hypothesis that age group and alcohol consumption do not interact with regards to the number of esophageal cancer cases. That is, we have reason to believe that their interaction does effect the outcome. As we stated when we listed the hypotheses to test, since we rejected the first null hypothesis, we will not test the other two. In the case where you failed to reject the first null hypothesis, you could consider each $p$-value in the first two rows of the above table, one for each of the two factors. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction/#using-statsmodels-in-python",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction/#using-statsmodels-in-python"
  },"814": {
    "doc": "How to do a two-way ANOVA test with interaction",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use R’s esoph dataset, about esophageal cancer cases. We will focus on the impact of age group (agegp) and alcohol consumption (alcgp) on the number of cases of the cancer (ncases). We ask, does the interaction between these two factors affect the number of cases? . First, we load in the dataset. (See how to quickly load some sample data.) . | 1 2 3 4 . | # install.packages(\"datasets\") # if you have not already done this library(datasets) data &lt;- esoph head(data) . | . | 1 2 3 4 5 6 7 . | agegp alcgp tobgp ncases ncontrols 1 25-34 0-39g/day 0-9g/day 0 40 2 25-34 0-39g/day 10-19 0 10 3 25-34 0-39g/day 20-29 0 6 4 25-34 0-39g/day 30+ 0 5 5 25-34 40-79 0-9g/day 0 27 6 25-34 40-79 10-19 0 7 . | . Next, we create a model that includes the response variable we care about, plus the two categorical variables we will be testing, as well as their interaction term. | 1 2 . | # the * below means multiplication, to create an interaction term model &lt;- aov(ncases ~ agegp*alcgp, data = data) . | . A two-way ANOVA with interaction tests the following three null hypotheses. | There is no interaction between the two categorical variables. (If we reject this we do not test the other two hypotheses.) | The mean response is the same across all groups of the first factor. (In our example, that says the mean ncases is the same for all age groups.) | The mean response is the same across all groups of the second factor. (In our example, that says the mean ncases is the same for all alcohol consumption groups.) | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. Let’s let $\\alpha=0.05$ here. | 1 . | summary(model) . | . | 1 2 3 4 5 6 7 . | Df Sum Sq Mean Sq F value Pr(&gt;F) agegp 5 261.2 52.24 14.048 2.89e-09 *** alcgp 3 52.7 17.57 4.723 0.00486 ** agegp:alcgp 15 107.6 7.17 1.928 0.03633 * Residuals 64 238.0 3.72 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The $p$-value for the interaction of age group and alcohol consumption is in the third row, final column, $0.03633$. It is less than $\\alpha$, so we can reject the null hypothesis that age group and alcohol consumption do not interact with regards to the number of esophageal cancer cases. That is, we have reason to believe that their interaction does effect the outcome. As we stated when we listed the hypotheses to test, since we rejected the first null hypothesis, we will not test the other two. In the case where you failed to reject the first null hypothesis, you could consider each $p$-value in the first two rows of the above table, one for each of the two factors. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction/#solution-in-r",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction/#solution-in-r"
  },"815": {
    "doc": "How to do a two-way ANOVA test with interaction",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction/#topics-that-include-this-task"
  },"816": {
    "doc": "How to do a two-way ANOVA test with interaction",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-two-way-anova-test-with-interaction/#opportunities",
    "relUrl": "/how-to-do-a-two-way-anova-test-with-interaction/#opportunities"
  },"817": {
    "doc": "How to do a two-way ANOVA test without interaction (in Python, using Statsmodels)",
    "title": "How to do a two-way ANOVA test without interaction (in Python, using Statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction-in-python-using-statsmodels/",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction-in-python-using-statsmodels/"
  },"818": {
    "doc": "How to do a two-way ANOVA test without interaction (in Python, using Statsmodels)",
    "title": "Task",
    "content": "When we analyze the impact that two factors have on a response variable, we may know in advance that the two factors do not interact. How can we use a two-way ANOVA test to test for an effect from each factor without including an interaction term for the two factors? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction-in-python-using-statsmodels/#task"
  },"819": {
    "doc": "How to do a two-way ANOVA test without interaction (in Python, using Statsmodels)",
    "title": "Solution",
    "content": "We’re going to use R’s esoph dataset, about esophageal cancer cases. We will focus on the impact of age group (agegp) and alcohol consumption (alcgp) on the number of cases of the cancer (ncases). We ask, does either of these two factors affect the number of cases? . First, we load in the dataset. (See how to quickly load some sample data.) . | 1 2 3 . | from rdatasets import data data = data('esoph') data.head() . | . | | agegp | alcgp | tobgp | ncases | ncontrols | . | 0 | 25-34 | 0-39g/day | 0-9g/day | 0 | 40 | . | 1 | 25-34 | 0-39g/day | 10-19 | 0 | 10 | . | 2 | 25-34 | 0-39g/day | 20-29 | 0 | 6 | . | 3 | 25-34 | 0-39g/day | 30+ | 0 | 5 | . | 4 | 25-34 | 40-79 | 0-9g/day | 0 | 27 | . Next, we create a model that includes the response variable we care about, plus the two categorical variables we will be testing. We simply omit the interaction term. (If you wish to include it, see how to do a two-way ANOVA test with interaction.) . | 1 2 3 4 . | import statsmodels.api as sm from statsmodels.formula.api import ols # C(...) means the variable is categorical, below model = ols('ncases ~ C(alcgp) + C(agegp)', data = data).fit() . | . A two-way ANOVA with interaction tests the following two null hypotheses. | The mean response is the same across all groups of the first factor. (In our example, that says the mean ncases is the same for all age groups.) | The mean response is the same across all groups of the second factor. (In our example, that says the mean ncases is the same for all alcohol consumption groups.) | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. Let’s let $\\alpha=0.05$ here. | 1 . | sm.stats.anova_lm(model, typ=2) . | . | | sum_sq | df | F | PR(&gt;F) | . | C(alcgp) | 52.695287 | 3.0 | 4.015660 | 1.029452e-02 | . | C(agegp) | 267.026108 | 5.0 | 12.209284 | 8.907998e-09 | . | Residual | 345.557743 | 79.0 | NaN | NaN | . The $p$-value for the alcohol consumption factor is in the first row, final column, $1.029452\\times10^{-2}$. It is less than $\\alpha$, so we can reject the null hypothesis that alcohol consumption does not affect the number of esophageal cancer cases. That is, we have reason to believe that it does affect the number of cases. The $p$-value for the age group factor is in the second row, final column, $8.907998\\times10^{-9}$. It is less than $\\alpha$, so we can reject the null hypothesis that age group does not affect the number of esophageal cancer cases. Again, we have reason to believe that it does affect the number of cases. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction-in-python-using-statsmodels/#solution"
  },"820": {
    "doc": "How to do a two-way ANOVA test without interaction (in R)",
    "title": "How to do a two-way ANOVA test without interaction (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction-in-r/",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction-in-r/"
  },"821": {
    "doc": "How to do a two-way ANOVA test without interaction (in R)",
    "title": "Task",
    "content": "When we analyze the impact that two factors have on a response variable, we may know in advance that the two factors do not interact. How can we use a two-way ANOVA test to test for an effect from each factor without including an interaction term for the two factors? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction-in-r/#task",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction-in-r/#task"
  },"822": {
    "doc": "How to do a two-way ANOVA test without interaction (in R)",
    "title": "Solution",
    "content": "We’re going to use R’s esoph dataset, about esophageal cancer cases. We will focus on the impact of age group (agegp) and alcohol consumption (alcgp) on the number of cases of the cancer (ncases). We ask, does either of these two factors affect the number of cases? . First, we load in the dataset. (See how to quickly load some sample data.) . | 1 2 3 4 . | # install.packages(\"datasets\") # if you have not already done this library(datasets) data &lt;- esoph head(data) . | . | 1 2 3 4 5 6 7 . | agegp alcgp tobgp ncases ncontrols 1 25-34 0-39g/day 0-9g/day 0 40 2 25-34 0-39g/day 10-19 0 10 3 25-34 0-39g/day 20-29 0 6 4 25-34 0-39g/day 30+ 0 5 5 25-34 40-79 0-9g/day 0 27 6 25-34 40-79 10-19 0 7 . | . Next, we create a model that includes the response variable we care about, plus the two categorical variables we will be testing. We simply omit the interaction term. (If you wish to include it, see how to do a two-way ANOVA test with interaction.) . | 1 2 . | # the * below means multiplication, to create an interaction term model &lt;- aov(ncases ~ agegp + alcgp, data = data) . | . A two-way ANOVA with interaction tests the following two null hypotheses. | The mean response is the same across all groups of the first factor. (In our example, that says the mean ncases is the same for all age groups.) | The mean response is the same across all groups of the second factor. (In our example, that says the mean ncases is the same for all alcohol consumption groups.) | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. Let’s let $\\alpha=0.05$ here. | 1 . | summary(model) . | . | 1 2 3 4 5 6 . | Df Sum Sq Mean Sq F value Pr(&gt;F) agegp 5 261.2 52.24 11.943 1.28e-08 *** alcgp 3 52.7 17.57 4.016 0.0103 * Residuals 79 345.6 4.37 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The $p$-value for the alcohol consumption factor is in the first row, final column, $1.029452\\times10^{-2}$. It is less than $\\alpha$, so we can reject the null hypothesis that alcohol consumption does not affect the number of esophageal cancer cases. That is, we have reason to believe that it does affect the number of cases. The $p$-value for the age group factor is in the second row, final column, $8.907998\\times10^{-9}$. It is less than $\\alpha$, so we can reject the null hypothesis that age group does not affect the number of esophageal cancer cases. Again, we have reason to believe that it does affect the number of cases. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction-in-r/#solution",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction-in-r/#solution"
  },"823": {
    "doc": "How to do a two-way ANOVA test without interaction",
    "title": "How to do a two-way ANOVA test without interaction",
    "content": " ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction/",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction/"
  },"824": {
    "doc": "How to do a two-way ANOVA test without interaction",
    "title": "Description",
    "content": "When we analyze the impact that two factors have on a response variable, we may know in advance that the two factors do not interact. How can we use a two-way ANOVA test to test for an effect from each factor without including an interaction term for the two factors? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-way ANOVA test without interaction | How to compare two nested linear models using ANOVA | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | How to perform an analysis of covariance (ANCOVA) | . ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction/#description",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction/#description"
  },"825": {
    "doc": "How to do a two-way ANOVA test without interaction",
    "title": "Using Statsmodels, in Python",
    "content": "View this solution alone. We’re going to use R’s esoph dataset, about esophageal cancer cases. We will focus on the impact of age group (agegp) and alcohol consumption (alcgp) on the number of cases of the cancer (ncases). We ask, does either of these two factors affect the number of cases? . First, we load in the dataset. (See how to quickly load some sample data.) . | 1 2 3 . | from rdatasets import data data = data('esoph') data.head() . | . | | agegp | alcgp | tobgp | ncases | ncontrols | . | 0 | 25-34 | 0-39g/day | 0-9g/day | 0 | 40 | . | 1 | 25-34 | 0-39g/day | 10-19 | 0 | 10 | . | 2 | 25-34 | 0-39g/day | 20-29 | 0 | 6 | . | 3 | 25-34 | 0-39g/day | 30+ | 0 | 5 | . | 4 | 25-34 | 40-79 | 0-9g/day | 0 | 27 | . Next, we create a model that includes the response variable we care about, plus the two categorical variables we will be testing. We simply omit the interaction term. (If you wish to include it, see how to do a two-way ANOVA test with interaction.) . | 1 2 3 4 . | import statsmodels.api as sm from statsmodels.formula.api import ols # C(...) means the variable is categorical, below model = ols('ncases ~ C(alcgp) + C(agegp)', data = data).fit() . | . A two-way ANOVA with interaction tests the following two null hypotheses. | The mean response is the same across all groups of the first factor. (In our example, that says the mean ncases is the same for all age groups.) | The mean response is the same across all groups of the second factor. (In our example, that says the mean ncases is the same for all alcohol consumption groups.) | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. Let’s let $\\alpha=0.05$ here. | 1 . | sm.stats.anova_lm(model, typ=2) . | . | | sum_sq | df | F | PR(&gt;F) | . | C(alcgp) | 52.695287 | 3.0 | 4.015660 | 1.029452e-02 | . | C(agegp) | 267.026108 | 5.0 | 12.209284 | 8.907998e-09 | . | Residual | 345.557743 | 79.0 | NaN | NaN | . The $p$-value for the alcohol consumption factor is in the first row, final column, $1.029452\\times10^{-2}$. It is less than $\\alpha$, so we can reject the null hypothesis that alcohol consumption does not affect the number of esophageal cancer cases. That is, we have reason to believe that it does affect the number of cases. The $p$-value for the age group factor is in the second row, final column, $8.907998\\times10^{-9}$. It is less than $\\alpha$, so we can reject the null hypothesis that age group does not affect the number of esophageal cancer cases. Again, we have reason to believe that it does affect the number of cases. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction/#using-statsmodels-in-python",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction/#using-statsmodels-in-python"
  },"826": {
    "doc": "How to do a two-way ANOVA test without interaction",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use R’s esoph dataset, about esophageal cancer cases. We will focus on the impact of age group (agegp) and alcohol consumption (alcgp) on the number of cases of the cancer (ncases). We ask, does either of these two factors affect the number of cases? . First, we load in the dataset. (See how to quickly load some sample data.) . | 1 2 3 4 . | # install.packages(\"datasets\") # if you have not already done this library(datasets) data &lt;- esoph head(data) . | . | 1 2 3 4 5 6 7 . | agegp alcgp tobgp ncases ncontrols 1 25-34 0-39g/day 0-9g/day 0 40 2 25-34 0-39g/day 10-19 0 10 3 25-34 0-39g/day 20-29 0 6 4 25-34 0-39g/day 30+ 0 5 5 25-34 40-79 0-9g/day 0 27 6 25-34 40-79 10-19 0 7 . | . Next, we create a model that includes the response variable we care about, plus the two categorical variables we will be testing. We simply omit the interaction term. (If you wish to include it, see how to do a two-way ANOVA test with interaction.) . | 1 2 . | # the * below means multiplication, to create an interaction term model &lt;- aov(ncases ~ agegp + alcgp, data = data) . | . A two-way ANOVA with interaction tests the following two null hypotheses. | The mean response is the same across all groups of the first factor. (In our example, that says the mean ncases is the same for all age groups.) | The mean response is the same across all groups of the second factor. (In our example, that says the mean ncases is the same for all alcohol consumption groups.) | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. Let’s let $\\alpha=0.05$ here. | 1 . | summary(model) . | . | 1 2 3 4 5 6 . | Df Sum Sq Mean Sq F value Pr(&gt;F) agegp 5 261.2 52.24 11.943 1.28e-08 *** alcgp 3 52.7 17.57 4.016 0.0103 * Residuals 79 345.6 4.37 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The $p$-value for the alcohol consumption factor is in the first row, final column, $1.029452\\times10^{-2}$. It is less than $\\alpha$, so we can reject the null hypothesis that alcohol consumption does not affect the number of esophageal cancer cases. That is, we have reason to believe that it does affect the number of cases. The $p$-value for the age group factor is in the second row, final column, $8.907998\\times10^{-9}$. It is less than $\\alpha$, so we can reject the null hypothesis that age group does not affect the number of esophageal cancer cases. Again, we have reason to believe that it does affect the number of cases. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction/#solution-in-r",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction/#solution-in-r"
  },"827": {
    "doc": "How to do a two-way ANOVA test without interaction",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction/#topics-that-include-this-task"
  },"828": {
    "doc": "How to do a two-way ANOVA test without interaction",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-two-way-anova-test-without-interaction/#opportunities",
    "relUrl": "/how-to-do-a-two-way-anova-test-without-interaction/#opportunities"
  },"829": {
    "doc": "How to do a Wilcoxon rank-sum test (in Python, using SciPy)",
    "title": "How to do a Wilcoxon rank-sum test (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test-in-python-using-scipy/"
  },"830": {
    "doc": "How to do a Wilcoxon rank-sum test (in Python, using SciPy)",
    "title": "Task",
    "content": "Assume we have two independent samples of data, $x_1, x_2, x_3, \\ldots x_n$ and $x’_1, x’_2, x’_3, \\ldots x’_m$, each from a different population. Also assume that the sample sizes are small or the populations are not normally distributed, but that the two population distributions are approximately the same shape. How can we test whether there is a significant difference between the two medians (or if one is significantly greater than or less than the other)? One method is the Wilcoxon Rank-Sum Test. Related tasks: . | How to do a Kruskal-Wallis test | How to do a Wilcoxon signed-rank test | How to do a Wilcoxon signed-rank test for matched pairs | . ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test-in-python-using-scipy/#task"
  },"831": {
    "doc": "How to do a Wilcoxon rank-sum test (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. Say our first sample, $x_1, x_2, x_3, \\ldots x_n$, has median $m_1$, and our second sample, $x’_1, x’_2, x’_3, \\ldots x’_m$, has median $m_2$. | 1 2 3 4 . | import numpy as np # Replace sample1 and sample2 with your data sample1 = np.array([56, 31, 190, 176, 119, 15, 140, 152, 167]) sample2 = np.array([45, 36, 78, 54, 12, 25, 39, 48, 52, 70, 85]) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. Two-tailed test . To test the null hypothesis $H_0: m_1 - m_2 = 0$, that is, $m_1=m_2$, we use a two-tailed test: . | 1 2 3 . | from scipy import stats from scipy.stats import ranksums ranksums(sample1, sample2) . | . | 1 . | RanksumsResult(statistic=2.0892772350933626, pvalue=0.03668277440246522) . | . Our p-value, $0.03668$, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The population medians are significantly different from each other. (The output above is slightly different from the output you would get by running this test in R, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . Right-tailed test . To test the null hypothesis $H_0: m_1 - m_2 \\le 0$, that is, $m_1\\le m_2$, we use a right-tailed test: . | 1 . | ranksums(sample1, sample2, alternative = 'greater') . | . | 1 . | RanksumsResult(statistic=2.0892772350933626, pvalue=0.01834138720123261) . | . Our p-value, $0.01834$, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The first population medians is significantly greater second. (The output above is slightly different from the output you would get by running this test in R, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . Left-tailed test . To test the null hypothesis $H_0: m_1 - m_2 \\ge 0$, that is, $m_1\\ge m_2$, we use a left-tailed test: . | 1 . | ranksums(sample1, sample2, alternative = 'less') . | . | 1 . | RanksumsResult(statistic=2.0892772350933626, pvalue=0.9816586127987674) . | . Our p-value, $0.98165$, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. The first population median is not significantly smaller than the second population median. (The output above is slightly different from the output you would get by running this test in R, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test-in-python-using-scipy/#solution"
  },"832": {
    "doc": "How to do a Wilcoxon rank-sum test (in R)",
    "title": "How to do a Wilcoxon rank-sum test (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test-in-r/",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test-in-r/"
  },"833": {
    "doc": "How to do a Wilcoxon rank-sum test (in R)",
    "title": "Task",
    "content": "Assume we have two independent samples of data, $x_1, x_2, x_3, \\ldots x_n$ and $x’_1, x’_2, x’_3, \\ldots x’_m$, each from a different population. Also assume that the sample sizes are small or the populations are not normally distributed, but that the two population distributions are approximately the same shape. How can we test whether there is a significant difference between the two medians (or if one is significantly greater than or less than the other)? One method is the Wilcoxon Rank-Sum Test. Related tasks: . | How to do a Kruskal-Wallis test | How to do a Wilcoxon signed-rank test | How to do a Wilcoxon signed-rank test for matched pairs | . ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test-in-r/#task",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test-in-r/#task"
  },"834": {
    "doc": "How to do a Wilcoxon rank-sum test (in R)",
    "title": "Solution",
    "content": "We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. Say our first sample, $x_1, x_2, x_3, \\ldots x_k$, has median $m_1$, and our second sample, $x’_1, x’_2, x’_3, \\ldots x’_k$, has median $m_2$. | 1 2 3 . | # Replace sample1 and sample2 with your data sample1 &lt;- c(56, 31, 190, 176, 119, 15, 140, 152, 167) sample2 &lt;- c(45, 36, 78, 54, 12, 25, 39, 48, 52, 70, 85) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. Two-tailed test . To test the null hypothesis $H_0: m_1 - m_2 = 0$, that is, $m_1=m_2$, we use a two-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"two.sided\", mu = 0, paired = FALSE) . | . | 1 2 3 4 5 . | Wilcoxon rank sum exact test data: sample1 and sample2 W = 77, p-value = 0.03813 alternative hypothesis: true location shift is not equal to 0 . | . Our p-value, $0.03813$, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The population medians are significantly different from each other. (The output above is slightly different than the output you would get by running this test in Python, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . Right-tailed test . To test the null hypothesis $H_0: m_1 - m_2 \\le 0$, that is, $m_1\\le m_2$, we use a right-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"greater\", mu = 0, paired = FALSE) . | . | 1 2 3 4 5 . | Wilcoxon rank sum exact test data: sample1 and sample2 W = 77, p-value = 0.01906 alternative hypothesis: true location shift is greater than 0 . | . Our p-value, $0.01906$, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The first population medians is significantly greater second. (The output above is slightly different from the output you would get by running this test in Python, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . Left-tailed test . To test the null hypothesis $H_0: m_1 - m_2 \\ge 0$, that is, $m_1\\ge m_2$, we use a left-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"less\", mu = 0, paired = FALSE) . | . | 1 2 3 4 5 . | Wilcoxon rank sum exact test data: sample1 and sample2 W = 77, p-value = 0.9845 alternative hypothesis: true location shift is less than 0 . | . Our p-value, $0.9845$, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. The first population median is not significantly smaller than the second population median. (The output above is slightly different from the output you would get by running this test in Python, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . NOTE: If there are ties in the data and there are fewer than 50 observations in each sample, then R will compute a $p$-value using the normal approximation, and there will be an error message indicating that the exact $p$-value cannot be calculated. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test-in-r/#solution",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test-in-r/#solution"
  },"835": {
    "doc": "How to do a Wilcoxon rank-sum test",
    "title": "How to do a Wilcoxon rank-sum test",
    "content": " ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test/",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test/"
  },"836": {
    "doc": "How to do a Wilcoxon rank-sum test",
    "title": "Description",
    "content": "Assume we have two independent samples of data, $x_1, x_2, x_3, \\ldots x_n$ and $x’_1, x’_2, x’_3, \\ldots x’_m$, each from a different population. Also assume that the sample sizes are small or the populations are not normally distributed, but that the two population distributions are approximately the same shape. How can we test whether there is a significant difference between the two medians (or if one is significantly greater than or less than the other)? One method is the Wilcoxon Rank-Sum Test. Related tasks: . | How to do a Kruskal-Wallis test | How to do a Wilcoxon signed-rank test | How to do a Wilcoxon signed-rank test for matched pairs | . ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test/#description",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test/#description"
  },"837": {
    "doc": "How to do a Wilcoxon rank-sum test",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. Say our first sample, $x_1, x_2, x_3, \\ldots x_n$, has median $m_1$, and our second sample, $x’_1, x’_2, x’_3, \\ldots x’_m$, has median $m_2$. | 1 2 3 4 . | import numpy as np # Replace sample1 and sample2 with your data sample1 = np.array([56, 31, 190, 176, 119, 15, 140, 152, 167]) sample2 = np.array([45, 36, 78, 54, 12, 25, 39, 48, 52, 70, 85]) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. Two-tailed test . To test the null hypothesis $H_0: m_1 - m_2 = 0$, that is, $m_1=m_2$, we use a two-tailed test: . | 1 2 3 . | from scipy import stats from scipy.stats import ranksums ranksums(sample1, sample2) . | . | 1 . | RanksumsResult(statistic=2.0892772350933626, pvalue=0.03668277440246522) . | . Our p-value, $0.03668$, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The population medians are significantly different from each other. (The output above is slightly different from the output you would get by running this test in R, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . Right-tailed test . To test the null hypothesis $H_0: m_1 - m_2 \\le 0$, that is, $m_1\\le m_2$, we use a right-tailed test: . | 1 . | ranksums(sample1, sample2, alternative = 'greater') . | . | 1 . | RanksumsResult(statistic=2.0892772350933626, pvalue=0.01834138720123261) . | . Our p-value, $0.01834$, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The first population medians is significantly greater second. (The output above is slightly different from the output you would get by running this test in R, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . Left-tailed test . To test the null hypothesis $H_0: m_1 - m_2 \\ge 0$, that is, $m_1\\ge m_2$, we use a left-tailed test: . | 1 . | ranksums(sample1, sample2, alternative = 'less') . | . | 1 . | RanksumsResult(statistic=2.0892772350933626, pvalue=0.9816586127987674) . | . Our p-value, $0.98165$, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. The first population median is not significantly smaller than the second population median. (The output above is slightly different from the output you would get by running this test in R, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test/#using-scipy-in-python"
  },"838": {
    "doc": "How to do a Wilcoxon rank-sum test",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. Say our first sample, $x_1, x_2, x_3, \\ldots x_k$, has median $m_1$, and our second sample, $x’_1, x’_2, x’_3, \\ldots x’_k$, has median $m_2$. | 1 2 3 . | # Replace sample1 and sample2 with your data sample1 &lt;- c(56, 31, 190, 176, 119, 15, 140, 152, 167) sample2 &lt;- c(45, 36, 78, 54, 12, 25, 39, 48, 52, 70, 85) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. Two-tailed test . To test the null hypothesis $H_0: m_1 - m_2 = 0$, that is, $m_1=m_2$, we use a two-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"two.sided\", mu = 0, paired = FALSE) . | . | 1 2 3 4 5 . | Wilcoxon rank sum exact test data: sample1 and sample2 W = 77, p-value = 0.03813 alternative hypothesis: true location shift is not equal to 0 . | . Our p-value, $0.03813$, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The population medians are significantly different from each other. (The output above is slightly different than the output you would get by running this test in Python, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . Right-tailed test . To test the null hypothesis $H_0: m_1 - m_2 \\le 0$, that is, $m_1\\le m_2$, we use a right-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"greater\", mu = 0, paired = FALSE) . | . | 1 2 3 4 5 . | Wilcoxon rank sum exact test data: sample1 and sample2 W = 77, p-value = 0.01906 alternative hypothesis: true location shift is greater than 0 . | . Our p-value, $0.01906$, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The first population medians is significantly greater second. (The output above is slightly different from the output you would get by running this test in Python, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . Left-tailed test . To test the null hypothesis $H_0: m_1 - m_2 \\ge 0$, that is, $m_1\\ge m_2$, we use a left-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"less\", mu = 0, paired = FALSE) . | . | 1 2 3 4 5 . | Wilcoxon rank sum exact test data: sample1 and sample2 W = 77, p-value = 0.9845 alternative hypothesis: true location shift is less than 0 . | . Our p-value, $0.9845$, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. The first population median is not significantly smaller than the second population median. (The output above is slightly different from the output you would get by running this test in Python, because SciPy uses a normal distribution internally, but R uses a Wilcoxon distribution.) . NOTE: If there are ties in the data and there are fewer than 50 observations in each sample, then R will compute a $p$-value using the normal approximation, and there will be an error message indicating that the exact $p$-value cannot be calculated. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test/#solution-in-r",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test/#solution-in-r"
  },"839": {
    "doc": "How to do a Wilcoxon rank-sum test",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test/#topics-that-include-this-task"
  },"840": {
    "doc": "How to do a Wilcoxon rank-sum test",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-wilcoxon-rank-sum-test/#opportunities",
    "relUrl": "/how-to-do-a-wilcoxon-rank-sum-test/#opportunities"
  },"841": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs (in Python, using SciPy)",
    "title": "How to do a Wilcoxon signed-rank test for matched pairs (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-python-using-scipy/"
  },"842": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs (in Python, using SciPy)",
    "title": "Task",
    "content": "Assume we have two samples of data that come in matched pairs, $x_1, x_2, x_3, \\ldots x_k$ and $x’_1, x’_2, x’_3, \\ldots x’_k$, which we might pair up as $(x_1,x’_1),(x_2,x’_2),\\ldots,(x_k,x’_k)$. The two samples may be from different populations. Also assume that the sample sizes are small or the populations are not normally distributed. Consider measuring the difference in each pair, $x_1-x’_1,x_2-x’_2,\\ldots,x_k-x’_k$. We want to perform tests that compare the median of those differences, $m_D$, to a hypothesized value (equal, greater, or less). One method is the Wilcoxon Signed-Rank Test for Matched Pairs. Related tasks: . | How to do a Kruskal-Wallis test | How to do a Wilcoxon rank-sum test | How to do a Wilcoxon signed-rank test | . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-python-using-scipy/#task"
  },"843": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs (in Python, using SciPy)",
    "title": "Solution",
    "content": "The method we will use is equivalent to subtracting the two samples and then performing the signed-rank test. See how to do a Wilcoxon signed-rank test to compare the two methods. We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. | 1 2 3 4 . | import numpy as np # Replace sample1 and sample2 with your data sample1 = np.array([156, 133, 90, 176, 119, 120, 40, 52, 167, 80]) sample2 = np.array([45, 36, 78, 54, 12, 25, 39, 48, 52, 70]) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. Two-tailed test . To test the null hypothesis $H_0: m_D = 0$, we use a two-tailed test: . | 1 2 3 . | from scipy import stats from scipy.stats import wilcoxon wilcoxon(sample1 - sample2) . | . | 1 . | WilcoxonResult(statistic=0.0, pvalue=0.001953125) . | . Our p-value, 0.001953125, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The median difference is significantly different from zero. Right-tailed test . To test the null hypothesis $H_0: m_D \\le 0$, we use a right-tailed test: . | 1 . | wilcoxon(sample1 - sample2, alternative = 'greater') . | . | 1 . | WilcoxonResult(statistic=55.0, pvalue=0.0009765625) . | . Our p-value, 0.0009765625, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The median difference is significantly greater than zero. Left-tailed test . To test the null hypothesis $H_0: m_D \\ge 0$, we use a left-tailed test: . | 1 . | wilcoxon(sample1 - sample2, alternative = 'less') . | . | 1 . | WilcoxonResult(statistic=55.0, pvalue=1.0) . | . Our p-value, 1.0, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We should continue to assume that the mean difference may be less than (or equal to) zero. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-python-using-scipy/#solution"
  },"844": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs (in R)",
    "title": "How to do a Wilcoxon signed-rank test for matched pairs (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-r/",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-r/"
  },"845": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs (in R)",
    "title": "Task",
    "content": "Assume we have two samples of data that come in matched pairs, $x_1, x_2, x_3, \\ldots x_k$ and $x’_1, x’_2, x’_3, \\ldots x’_k$, which we might pair up as $(x_1,x’_1),(x_2,x’_2),\\ldots,(x_k,x’_k)$. The two samples may be from different populations. Also assume that the sample sizes are small or the populations are not normally distributed. Consider measuring the difference in each pair, $x_1-x’_1,x_2-x’_2,\\ldots,x_k-x’_k$. We want to perform tests that compare the median of those differences, $m_D$, to a hypothesized value (equal, greater, or less). One method is the Wilcoxon Signed-Rank Test for Matched Pairs. Related tasks: . | How to do a Kruskal-Wallis test | How to do a Wilcoxon rank-sum test | How to do a Wilcoxon signed-rank test | . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-r/#task",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-r/#task"
  },"846": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs (in R)",
    "title": "Solution",
    "content": "The method we will use is equivalent to subtracting the two samples and then performing the signed-rank test. See how to do a Wilcoxon signed-rank test to compare the two methods. We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. | 1 2 3 . | # Replace sample1 and sample2 with your data sample1 &lt;- c(156, 133, 90, 176, 119, 120, 40, 52, 167, 80) sample2 &lt;- c(45, 36, 78, 54, 12, 25, 39, 48, 52, 70) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. Two-tailed test . To test the null hypothesis $H_0: m_D = 0$, we use a two-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"two.sided\", mu = 0, paired = TRUE) . | . | 1 2 3 4 5 . | Wilcoxon signed rank exact test data: sample1 and sample2 V = 55, p-value = 0.001953 alternative hypothesis: true location shift is not equal to 0 . | . Our p-value, 0.00195, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The median difference is significantly different from zero. Right-tailed test . To test the null hypothesis $H_0: m_D \\le 0$, we use a right-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"greater\", mu = 0, paired = TRUE) . | . | 1 2 3 4 5 . | Wilcoxon signed rank exact test data: sample1 and sample2 V = 55, p-value = 0.0009766 alternative hypothesis: true location shift is greater than 0 . | . Our p-value, 0.0009766, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The median difference is significantly greater than zero. Left-tailed test . To test the null hypothesis $H_0: m_D \\ge 0$, we use a left-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"less\", mu = 0, paired = TRUE) . | . | 1 2 3 4 5 . | Wilcoxon signed rank exact test data: sample1 and sample2 V = 55, p-value = 1 alternative hypothesis: true location shift is less than 0 . | . Our p-value, 1.0, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We should continue to assume that the mean difference may be less than (or equal to) zero. NOTE: If there are ties in the data and there are fewer than 50 observations in each sample, then R will compute a $p$-value using the normal approximation, and there will be an error message indicating that the exact $p$-value cannot be calculated. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-r/#solution",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs-in-r/#solution"
  },"847": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs",
    "title": "How to do a Wilcoxon signed-rank test for matched pairs",
    "content": " ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/"
  },"848": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs",
    "title": "Description",
    "content": "Assume we have two samples of data that come in matched pairs, $x_1, x_2, x_3, \\ldots x_k$ and $x’_1, x’_2, x’_3, \\ldots x’_k$, which we might pair up as $(x_1,x’_1),(x_2,x’_2),\\ldots,(x_k,x’_k)$. The two samples may be from different populations. Also assume that the sample sizes are small or the populations are not normally distributed. Consider measuring the difference in each pair, $x_1-x’_1,x_2-x’_2,\\ldots,x_k-x’_k$. We want to perform tests that compare the median of those differences, $m_D$, to a hypothesized value (equal, greater, or less). One method is the Wilcoxon Signed-Rank Test for Matched Pairs. Related tasks: . | How to do a Kruskal-Wallis test | How to do a Wilcoxon rank-sum test | How to do a Wilcoxon signed-rank test | . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/#description",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/#description"
  },"849": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. The method we will use is equivalent to subtracting the two samples and then performing the signed-rank test. See how to do a Wilcoxon signed-rank test to compare the two methods. We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. | 1 2 3 4 . | import numpy as np # Replace sample1 and sample2 with your data sample1 = np.array([156, 133, 90, 176, 119, 120, 40, 52, 167, 80]) sample2 = np.array([45, 36, 78, 54, 12, 25, 39, 48, 52, 70]) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. Two-tailed test . To test the null hypothesis $H_0: m_D = 0$, we use a two-tailed test: . | 1 2 3 . | from scipy import stats from scipy.stats import wilcoxon wilcoxon(sample1 - sample2) . | . | 1 . | WilcoxonResult(statistic=0.0, pvalue=0.001953125) . | . Our p-value, 0.001953125, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The median difference is significantly different from zero. Right-tailed test . To test the null hypothesis $H_0: m_D \\le 0$, we use a right-tailed test: . | 1 . | wilcoxon(sample1 - sample2, alternative = 'greater') . | . | 1 . | WilcoxonResult(statistic=55.0, pvalue=0.0009765625) . | . Our p-value, 0.0009765625, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The median difference is significantly greater than zero. Left-tailed test . To test the null hypothesis $H_0: m_D \\ge 0$, we use a left-tailed test: . | 1 . | wilcoxon(sample1 - sample2, alternative = 'less') . | . | 1 . | WilcoxonResult(statistic=55.0, pvalue=1.0) . | . Our p-value, 1.0, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We should continue to assume that the mean difference may be less than (or equal to) zero. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/#using-scipy-in-python"
  },"850": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs",
    "title": "Solution, in R",
    "content": "View this solution alone. The method we will use is equivalent to subtracting the two samples and then performing the signed-rank test. See how to do a Wilcoxon signed-rank test to compare the two methods. We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. | 1 2 3 . | # Replace sample1 and sample2 with your data sample1 &lt;- c(156, 133, 90, 176, 119, 120, 40, 52, 167, 80) sample2 &lt;- c(45, 36, 78, 54, 12, 25, 39, 48, 52, 70) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. Two-tailed test . To test the null hypothesis $H_0: m_D = 0$, we use a two-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"two.sided\", mu = 0, paired = TRUE) . | . | 1 2 3 4 5 . | Wilcoxon signed rank exact test data: sample1 and sample2 V = 55, p-value = 0.001953 alternative hypothesis: true location shift is not equal to 0 . | . Our p-value, 0.00195, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The median difference is significantly different from zero. Right-tailed test . To test the null hypothesis $H_0: m_D \\le 0$, we use a right-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"greater\", mu = 0, paired = TRUE) . | . | 1 2 3 4 5 . | Wilcoxon signed rank exact test data: sample1 and sample2 V = 55, p-value = 0.0009766 alternative hypothesis: true location shift is greater than 0 . | . Our p-value, 0.0009766, is less than $\\alpha=0.05$, so we have sufficient evidence to reject the null hypothesis. The median difference is significantly greater than zero. Left-tailed test . To test the null hypothesis $H_0: m_D \\ge 0$, we use a left-tailed test: . | 1 . | wilcox.test(sample1, sample2, alternative = \"less\", mu = 0, paired = TRUE) . | . | 1 2 3 4 5 . | Wilcoxon signed rank exact test data: sample1 and sample2 V = 55, p-value = 1 alternative hypothesis: true location shift is less than 0 . | . Our p-value, 1.0, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We should continue to assume that the mean difference may be less than (or equal to) zero. NOTE: If there are ties in the data and there are fewer than 50 observations in each sample, then R will compute a $p$-value using the normal approximation, and there will be an error message indicating that the exact $p$-value cannot be calculated. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/#solution-in-r",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/#solution-in-r"
  },"851": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/#topics-that-include-this-task"
  },"852": {
    "doc": "How to do a Wilcoxon signed-rank test for matched pairs",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/#opportunities",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-for-matched-pairs/#opportunities"
  },"853": {
    "doc": "How to do a Wilcoxon signed-rank test (in Python, using SciPy)",
    "title": "How to do a Wilcoxon signed-rank test (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-in-python-using-scipy/",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-in-python-using-scipy/"
  },"854": {
    "doc": "How to do a Wilcoxon signed-rank test (in Python, using SciPy)",
    "title": "Task",
    "content": "Assume we a sample of data, $x_1, x_2, x_3, \\ldots x_k$ and either the sample size is small or the population is not normally distributed. But we still want to perform tests that compare the sample median to a hypothesized value (equal, greater, or less). One method is the Wilcoxon Signed-Rank Test. Related tasks: . | How to do a Kruskal-Wallis test | How to do a Wilcoxon rank-sum test | How to do a Wilcoxon signed-rank test for matched pairs | . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-in-python-using-scipy/#task",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-in-python-using-scipy/#task"
  },"855": {
    "doc": "How to do a Wilcoxon signed-rank test (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. Say our sample, $x_1, x_2, x_3, \\ldots x_k$, has median $m$. | 1 2 3 . | import numpy as np # Replace the next line with your data sample = np.array([19, 4, 23, 16, 1, 8, 30, 25, 13]) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. In the examples below, we will be comparing the median $m$ to a hypothesized value of $a=10$, but you can use any value for $a$. Two-tailed test . To test the null hypothesis $H_0: m=a$, we use a two-tailed test: . | 1 2 3 4 . | from scipy import stats from scipy.stats import wilcoxon a = 10 # or your chosen value for comparison wilcoxon(sample - a) . | . | 1 . | WilcoxonResult(statistic=10.0, pvalue=0.1640625) . | . Our p-value, 0.1640625, is greater than $\\alpha=0.05$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is equal to 10. Right-tailed test . To test the null hypothesis $H_0: m\\ge a$, we use a right-tailed test: . | 1 . | wilcoxon(sample - a, alternative = 'less') . | . | 1 . | WilcoxonResult(statistic=35.0, pvalue=0.935546875) . | . Our p-value, 0.935546875, is greater than $\\alpha=0.05$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is less than (or equal to) 10. Left-tailed test . To test the null hypothesis $H_0: m\\le a$, we use a left-tailed test: . | 1 . | wilcoxon(sample - a, alternative = 'greater') . | . | 1 . | WilcoxonResult(statistic=35.0, pvalue=0.08203125) . | . Our p-value, 0.08203125, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is greater than (or equal to) 10. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-in-python-using-scipy/#solution",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-in-python-using-scipy/#solution"
  },"856": {
    "doc": "How to do a Wilcoxon signed-rank test (in R)",
    "title": "How to do a Wilcoxon signed-rank test (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-in-r/",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-in-r/"
  },"857": {
    "doc": "How to do a Wilcoxon signed-rank test (in R)",
    "title": "Task",
    "content": "Assume we a sample of data, $x_1, x_2, x_3, \\ldots x_k$ and either the sample size is small or the population is not normally distributed. But we still want to perform tests that compare the sample median to a hypothesized value (equal, greater, or less). One method is the Wilcoxon Signed-Rank Test. Related tasks: . | How to do a Kruskal-Wallis test | How to do a Wilcoxon rank-sum test | How to do a Wilcoxon signed-rank test for matched pairs | . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-in-r/#task",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-in-r/#task"
  },"858": {
    "doc": "How to do a Wilcoxon signed-rank test (in R)",
    "title": "Solution",
    "content": "We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. Say our sample, $x_1, x_2, x_3, \\ldots x_k$, has median $m$. | 1 2 . | # Replace the next line with your data sample &lt;- c(19, 4, 23, 16, 1, 8, 30, 25, 13) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. In the examples below, we will be comparing the median $m$ to a hypothesized value of $a=10$, but you can use any value for $a$. Two-tailed test . To test the null hypothesis $H_0: m=a$, we use a two-tailed test: . | 1 2 . | a &lt;- 10 wilcox.test(sample, mu = a, alternative = \"two.sided\") . | . | 1 2 3 4 5 6 7 8 9 10 11 . | Warning message in wilcox.test.default(sample, mu = a, alternative = \"two.sided\"): “cannot compute exact p-value with ties” Wilcoxon signed rank test with continuity correction data: sample V = 35, p-value = 0.1544 alternative hypothesis: true location is not equal to 10 . | . Our p-value, 0.1544, is greater than $\\alpha=0.05$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is equal to 10. Right-tailed test . To test the null hypothesis $H_0: m\\ge a$, we use a right-tailed test: . | 1 . | wilcox.test(sample, mu = a, alternative = \"less\") . | . | 1 2 3 4 5 6 7 8 9 10 11 . | Warning message in wilcox.test.default(sample, mu = a, alternative = \"less\"): “cannot compute exact p-value with ties” Wilcoxon signed rank test with continuity correction data: sample V = 35, p-value = 0.9386 alternative hypothesis: true location is less than 10 . | . Our p-value, 0.9386, is greater than $\\alpha=0.05$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is less than (or equal to) 10. Left-tailed test . To test the null hypothesis $H_0: m\\le a$, we use a left-tailed test: . | 1 . | wilcox.test(sample, mu = a, alternative = \"greater\") . | . | 1 2 3 4 5 6 7 8 9 10 11 . | Warning message in wilcox.test.default(sample, mu = a, alternative = \"greater\"): “cannot compute exact p-value with ties” Wilcoxon signed rank test with continuity correction data: sample V = 35, p-value = 0.0772 alternative hypothesis: true location is greater than 10 . | . Our p-value, 0.0772, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is greater than (or equal to) 10. NOTE: If there are ties in the data and there are fewer than 50 observations in each sample, then R will compute a $p$-value using the normal approximation, and there will be an error message indicating that the exact $p$-value cannot be calculated. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test-in-r/#solution",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test-in-r/#solution"
  },"859": {
    "doc": "How to do a Wilcoxon signed-rank test",
    "title": "How to do a Wilcoxon signed-rank test",
    "content": " ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test/",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test/"
  },"860": {
    "doc": "How to do a Wilcoxon signed-rank test",
    "title": "Description",
    "content": "Assume we a sample of data, $x_1, x_2, x_3, \\ldots x_k$ and either the sample size is small or the population is not normally distributed. But we still want to perform tests that compare the sample median to a hypothesized value (equal, greater, or less). One method is the Wilcoxon Signed-Rank Test. Related tasks: . | How to do a Kruskal-Wallis test | How to do a Wilcoxon rank-sum test | How to do a Wilcoxon signed-rank test for matched pairs | . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test/#description",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test/#description"
  },"861": {
    "doc": "How to do a Wilcoxon signed-rank test",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. Say our sample, $x_1, x_2, x_3, \\ldots x_k$, has median $m$. | 1 2 3 . | import numpy as np # Replace the next line with your data sample = np.array([19, 4, 23, 16, 1, 8, 30, 25, 13]) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. In the examples below, we will be comparing the median $m$ to a hypothesized value of $a=10$, but you can use any value for $a$. Two-tailed test . To test the null hypothesis $H_0: m=a$, we use a two-tailed test: . | 1 2 3 4 . | from scipy import stats from scipy.stats import wilcoxon a = 10 # or your chosen value for comparison wilcoxon(sample - a) . | . | 1 . | WilcoxonResult(statistic=10.0, pvalue=0.1640625) . | . Our p-value, 0.1640625, is greater than $\\alpha=0.05$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is equal to 10. Right-tailed test . To test the null hypothesis $H_0: m\\ge a$, we use a right-tailed test: . | 1 . | wilcoxon(sample - a, alternative = 'less') . | . | 1 . | WilcoxonResult(statistic=35.0, pvalue=0.935546875) . | . Our p-value, 0.935546875, is greater than $\\alpha=0.05$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is less than (or equal to) 10. Left-tailed test . To test the null hypothesis $H_0: m\\le a$, we use a left-tailed test: . | 1 . | wilcoxon(sample - a, alternative = 'greater') . | . | 1 . | WilcoxonResult(statistic=35.0, pvalue=0.08203125) . | . Our p-value, 0.08203125, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is greater than (or equal to) 10. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test/#using-scipy-in-python",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test/#using-scipy-in-python"
  },"862": {
    "doc": "How to do a Wilcoxon signed-rank test",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use fake data for illustrative purposes, but you can replace our fake data with your real data. Say our sample, $x_1, x_2, x_3, \\ldots x_k$, has median $m$. | 1 2 . | # Replace the next line with your data sample &lt;- c(19, 4, 23, 16, 1, 8, 30, 25, 13) . | . We choose a value, $0 \\le \\alpha \\le 1$, as the Type I Error Rate. We’ll let $\\alpha$ be 0.05. In the examples below, we will be comparing the median $m$ to a hypothesized value of $a=10$, but you can use any value for $a$. Two-tailed test . To test the null hypothesis $H_0: m=a$, we use a two-tailed test: . | 1 2 . | a &lt;- 10 wilcox.test(sample, mu = a, alternative = \"two.sided\") . | . | 1 2 3 4 5 6 7 8 9 10 11 . | Warning message in wilcox.test.default(sample, mu = a, alternative = \"two.sided\"): “cannot compute exact p-value with ties” Wilcoxon signed rank test with continuity correction data: sample V = 35, p-value = 0.1544 alternative hypothesis: true location is not equal to 10 . | . Our p-value, 0.1544, is greater than $\\alpha=0.05$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is equal to 10. Right-tailed test . To test the null hypothesis $H_0: m\\ge a$, we use a right-tailed test: . | 1 . | wilcox.test(sample, mu = a, alternative = \"less\") . | . | 1 2 3 4 5 6 7 8 9 10 11 . | Warning message in wilcox.test.default(sample, mu = a, alternative = \"less\"): “cannot compute exact p-value with ties” Wilcoxon signed rank test with continuity correction data: sample V = 35, p-value = 0.9386 alternative hypothesis: true location is less than 10 . | . Our p-value, 0.9386, is greater than $\\alpha=0.05$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is less than (or equal to) 10. Left-tailed test . To test the null hypothesis $H_0: m\\le a$, we use a left-tailed test: . | 1 . | wilcox.test(sample, mu = a, alternative = \"greater\") . | . | 1 2 3 4 5 6 7 8 9 10 11 . | Warning message in wilcox.test.default(sample, mu = a, alternative = \"greater\"): “cannot compute exact p-value with ties” Wilcoxon signed rank test with continuity correction data: sample V = 35, p-value = 0.0772 alternative hypothesis: true location is greater than 10 . | . Our p-value, 0.0772, is greater than $\\alpha$, so we do not have sufficient evidence to reject the null hypothesis. We may continue to assume the population median is greater than (or equal to) 10. NOTE: If there are ties in the data and there are fewer than 50 observations in each sample, then R will compute a $p$-value using the normal approximation, and there will be an error message indicating that the exact $p$-value cannot be calculated. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test/#solution-in-r",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test/#solution-in-r"
  },"863": {
    "doc": "How to do a Wilcoxon signed-rank test",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test/#topics-that-include-this-task",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test/#topics-that-include-this-task"
  },"864": {
    "doc": "How to do a Wilcoxon signed-rank test",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-a-wilcoxon-signed-rank-test/#opportunities",
    "relUrl": "/how-to-do-a-wilcoxon-signed-rank-test/#opportunities"
  },"865": {
    "doc": "How to do basic mathematical computations (in Excel)",
    "title": "How to do basic mathematical computations (in Excel)",
    "content": "See all solutions. ",
    "url": "/how-to-do-basic-mathematical-computations-in-excel/",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-excel/"
  },"866": {
    "doc": "How to do basic mathematical computations (in Excel)",
    "title": "Task",
    "content": "How do we write the most common mathematical operations in a given piece of software? For example, how do we write multiplication, or exponentiation, or logarithms, in Python vs. R vs. Excel, and so on? . ",
    "url": "/how-to-do-basic-mathematical-computations-in-excel/#task",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-excel/#task"
  },"867": {
    "doc": "How to do basic mathematical computations (in Excel)",
    "title": "Solution",
    "content": "Each of the formulas shown on the right of the table below is valid code for use in Excel formulas, in cells in a worksheet. | Mathematical notation | Excel notation | Example | . | $x+y$ | x+y | =A1+B1 | . | $x-y$ | x-y | =A1-B1 | . | $xy$ | x*y | =A1*B1 | . | $\\frac xy$ | x/y | =A1/B1 | . | $x^y$ | x^y | =A1^B1 | . | $\\vert x\\vert$ | ABS(x) | =ABS(A1) | . | $\\ln x$ | LN(x) | =LN(A1) | . | $\\log_a b$ | LOG(b,a) | =LOG(A1,B1) | . | $e^x$ | EXP(x) | =EXP(A1) | . | $\\pi$ | PI() | =PI() | . | $\\sin x$ | SIN(x) | =SIN(A1) | . | $\\sin^{-1} x$ | ASIN(x) | =ASIN(A1) | . | $\\sqrt x$ | SQRT(x) | =SQRT(A1) | . Other trigonometric functions are also available besides just SIN, including COS, TAN, etc. Content last modified on 09 December 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-basic-mathematical-computations-in-excel/#solution",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-excel/#solution"
  },"868": {
    "doc": "How to do basic mathematical computations (in Julia)",
    "title": "How to do basic mathematical computations (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-do-basic-mathematical-computations-in-julia/",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-julia/"
  },"869": {
    "doc": "How to do basic mathematical computations (in Julia)",
    "title": "Task",
    "content": "How do we write the most common mathematical operations in a given piece of software? For example, how do we write multiplication, or exponentiation, or logarithms, in Python vs. R vs. Excel, and so on? . ",
    "url": "/how-to-do-basic-mathematical-computations-in-julia/#task",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-julia/#task"
  },"870": {
    "doc": "How to do basic mathematical computations (in Julia)",
    "title": "Solution",
    "content": "| Mathematical notation | Julia code | . | $x+y$ | x+y | . | $x-y$ | x-y | . | $xy$ | x*y | . | $\\frac xy$ | x/y (or y\\x) | . | $\\left\\lfloor\\frac xy\\right\\rfloor$ | x÷y | . | remainder of $x\\div y$ | x%y | . | $x^y$ | x^y | . | $\\vert x\\vert$ | abs(x) | . | $\\ln x$ | log(x) | . | $\\log_a b$ | log(a,b) | . | $e^x$ | exp(x) | . | $\\pi$ | pi | . | $\\sin x$ | sin(x) | . | $\\sin^{-1} x$ | asin(x) | . | $\\sqrt x$ | sqrt(x) | . Other trigonometric functions are also available besides just sin including cos, tan, etc. Content last modified on 04 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-basic-mathematical-computations-in-julia/#solution",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-julia/#solution"
  },"871": {
    "doc": "How to do basic mathematical computations (in Python, using NumPy)",
    "title": "How to do basic mathematical computations (in Python, using NumPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-basic-mathematical-computations-in-python-using-numpy/",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-python-using-numpy/"
  },"872": {
    "doc": "How to do basic mathematical computations (in Python, using NumPy)",
    "title": "Task",
    "content": "How do we write the most common mathematical operations in a given piece of software? For example, how do we write multiplication, or exponentiation, or logarithms, in Python vs. R vs. Excel, and so on? . ",
    "url": "/how-to-do-basic-mathematical-computations-in-python-using-numpy/#task",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-python-using-numpy/#task"
  },"873": {
    "doc": "How to do basic mathematical computations (in Python, using NumPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported NumPy as follows. | 1 . | import numpy as np . | . | Mathematical notation | Python code | Requires NumPy? | . | $x+y$ | x+y | no | . | $x-y$ | x-y | no | . | $xy$ | x*y | no | . | $\\frac xy$ | x/y | no | . | $\\left\\lfloor\\frac xy\\right\\rfloor$ | x//y | no | . | $\\left\\lfloor\\frac xy\\right\\rfloor$ | np.floor_divide(x,y) | yes | . | remainder of $x\\div y$ | x%y | no | . | remainder of $x\\div y$ | np.remainder(x,y) | yes | . | $x^y$ | x**y | no | . | $\\vert x\\vert$ | abs(x) | no | . | $\\vert x\\vert$ | np.abs(x) | yes | . | $\\ln x$ | np.log(x) | yes | . | $\\log_a b$ | np.log(b)/np.log(a) | yes | . | $e^x$ | np.exp(x) | yes | . | $\\pi$ | np.pi | yes | . | $\\sin x$ | np.sin(x) | yes | . | $\\sin^{-1} x$ | np.asin(x) | yes | . | $\\sqrt x$ | x**0.5 | no | . | $\\sqrt x$ | np.sqrt(x) | yes | . Other trigonometric functions are also available besides just np.sin, including np.cos, np.tan, etc. NumPy automatically applies any of these functions to all entries of a NumPy array or pandas Series, but the built-in Python functions do not have this feature. For example, to square all numbers in an array, see below. | 1 2 3 . | import numpy as np example_array = np.array( [ -3, 2, 0.5, -1, 10, 9.2, -3.3 ] ) example_array ** 2 . | . | 1 . | array([ 9. , 4. , 0.25, 1. , 100. , 84.64, 10.89]) . | . Content last modified on 14 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-basic-mathematical-computations-in-python-using-numpy/#solution",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-python-using-numpy/#solution"
  },"874": {
    "doc": "How to do basic mathematical computations (in Python, using SymPy)",
    "title": "How to do basic mathematical computations (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-basic-mathematical-computations-in-python-using-sympy/",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-python-using-sympy/"
  },"875": {
    "doc": "How to do basic mathematical computations (in Python, using SymPy)",
    "title": "Task",
    "content": "How do we write the most common mathematical operations in a given piece of software? For example, how do we write multiplication, or exponentiation, or logarithms, in Python vs. R vs. Excel, and so on? . ",
    "url": "/how-to-do-basic-mathematical-computations-in-python-using-sympy/#task",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-python-using-sympy/#task"
  },"876": {
    "doc": "How to do basic mathematical computations (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . | Mathematical notation | Python code | Requires SymPy? | . | $x+y$ | x+y | no | . | $x-y$ | x-y | no | . | $xy$ | x*y | no | . | $\\frac xy$ | x/y | no | . | $\\left\\lfloor\\frac xy\\right\\rfloor$ | x//y | no | . | remainder of $x\\div y$ | x%y | no | . | $x^y$ | x**y | no | . | $\\vert x\\vert$ | abs(x) | no | . | $\\ln x$ | log(x) | yes | . | $\\log_a b$ | log(b,a) | yes | . | $e^x$ | E | yes | . | $\\pi$ | pi | yes | . | $\\sin x$ | sin(x) | yes | . | $\\sin^{-1} x$ | asin(x) | yes | . | $\\sqrt x$ | sqrt(x) | yes | . Other trigonometric functions are also available besides just sin, including cos, tan, etc. Note that SymPy gives precise answers to mathematical queries, which may not be what you want. | 1 . | sqrt(2) . | . $\\displaystyle \\sqrt{2}$ . If you want a decimal approximation instead, you can use the N function. | 1 . | N(sqrt(2)) . | . $\\displaystyle 1.4142135623731$ . Or you can use the evalf function. | 1 . | sqrt(2).evalf() . | . $\\displaystyle 1.4142135623731$ . By contrast, if you need an exact rational number when Python gives you an approximation, you can use the Rational function to build one. Note the differences below: . | 1 . | 1/3 . | . $\\displaystyle 0.333333333333333$ . | 1 . | Rational(1,3) . | . $\\displaystyle \\frac{1}{3}$ . Content last modified on 14 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-basic-mathematical-computations-in-python-using-sympy/#solution",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-python-using-sympy/#solution"
  },"877": {
    "doc": "How to do basic mathematical computations (in Python)",
    "title": "How to do basic mathematical computations (in Python)",
    "content": "See all solutions. ",
    "url": "/how-to-do-basic-mathematical-computations-in-python/",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-python/"
  },"878": {
    "doc": "How to do basic mathematical computations (in Python)",
    "title": "Task",
    "content": "How do we write the most common mathematical operations in a given piece of software? For example, how do we write multiplication, or exponentiation, or logarithms, in Python vs. R vs. Excel, and so on? . ",
    "url": "/how-to-do-basic-mathematical-computations-in-python/#task",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-python/#task"
  },"879": {
    "doc": "How to do basic mathematical computations (in Python)",
    "title": "Solution",
    "content": "For those expressions that need the Python math package, use the code import math beforehand to ensure that package is loaded. Alternatively, you can write from math import * and thus drop the math prefixes in the table below. | Mathematical notation | Python code | Requires math package? | . | $x+y$ | x+y | no | . | $x-y$ | x-y | no | . | $xy$ | x*y | no | . | $\\frac xy$ | x/y | no | . | $\\left\\lfloor\\frac xy\\right\\rfloor$ | x//y | no | . | remainder of $x\\div y$ | x%y | no | . | $x^y$ | x**y | no | . | $\\vert x\\vert$ | abs(x) | no | . | $\\ln x$ | math.log(x) | yes | . | $\\log_a b$ | math.log(b,a) | yes | . | $e^x$ | math.exp(x) | yes | . | $\\pi$ | math.pi | yes | . | $\\sin x$ | math.sin(x) | yes | . | $\\sin^{-1} x$ | math.asin(x) | yes | . | $\\sqrt x$ | x**0.5 | no | . | $\\sqrt x$ | math.sqrt(x) | yes | . Other trigonometric functions are also available besides just math.sin, including math.cos, math.tan, etc. Content last modified on 14 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-basic-mathematical-computations-in-python/#solution",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-python/#solution"
  },"880": {
    "doc": "How to do basic mathematical computations (in R)",
    "title": "How to do basic mathematical computations (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-do-basic-mathematical-computations-in-r/",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-r/"
  },"881": {
    "doc": "How to do basic mathematical computations (in R)",
    "title": "Task",
    "content": "How do we write the most common mathematical operations in a given piece of software? For example, how do we write multiplication, or exponentiation, or logarithms, in Python vs. R vs. Excel, and so on? . ",
    "url": "/how-to-do-basic-mathematical-computations-in-r/#task",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-r/#task"
  },"882": {
    "doc": "How to do basic mathematical computations (in R)",
    "title": "Solution",
    "content": "For those expressions that need the Python math package, use the code import math beforehand to ensure that package is loaded. Alternatively, you can write from math import * and thus drop the math prefixes in the table below. | Mathematical notation | R code | . | $x+y$ | x+y | . | $x-y$ | x-y | . | $xy$ | x*y | . | $\\frac xy$ | x/y | . | $x^y$ | x^y | . | $\\vert x\\vert$ | abs(x) | . | $\\ln x$ | log(x) | . | $\\log_a b$ | log(b,a) | . | $e^x$ | exp(x) | . | $\\pi$ | pi | . | $\\sin x$ | sin(x) | . | $\\sin^{-1} x$ | asin(x) | . | $\\sqrt x$ | sqrt(x) | . Other trigonometric functions are also available besides just sin, including cos, tan, etc. R naturally applies these functions across vectors. For example, you can square all the entries in a vector as in the example below. | 1 2 . | example.vector &lt;- c( -3, 2, 0.5, -1, 10, 9.2, -3.3 ) example.vector ^ 2 . | . | 1 . | [1] 9.00 4.00 0.25 1.00 100.00 84.64 10.89 . | . Content last modified on 23 November 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-basic-mathematical-computations-in-r/#solution",
    "relUrl": "/how-to-do-basic-mathematical-computations-in-r/#solution"
  },"883": {
    "doc": "How to do basic mathematical computations",
    "title": "How to do basic mathematical computations",
    "content": " ",
    "url": "/how-to-do-basic-mathematical-computations/",
    "relUrl": "/how-to-do-basic-mathematical-computations/"
  },"884": {
    "doc": "How to do basic mathematical computations",
    "title": "Description",
    "content": "How do we write the most common mathematical operations in a given piece of software? For example, how do we write multiplication, or exponentiation, or logarithms, in Python vs. R vs. Excel, and so on? . ",
    "url": "/how-to-do-basic-mathematical-computations/#description",
    "relUrl": "/how-to-do-basic-mathematical-computations/#description"
  },"885": {
    "doc": "How to do basic mathematical computations",
    "title": "Solution, in Excel",
    "content": "View this solution alone. Each of the formulas shown on the right of the table below is valid code for use in Excel formulas, in cells in a worksheet. | Mathematical notation | Excel notation | Example | . | $x+y$ | x+y | =A1+B1 | . | $x-y$ | x-y | =A1-B1 | . | $xy$ | x*y | =A1*B1 | . | $\\frac xy$ | x/y | =A1/B1 | . | $x^y$ | x^y | =A1^B1 | . | $\\vert x\\vert$ | ABS(x) | =ABS(A1) | . | $\\ln x$ | LN(x) | =LN(A1) | . | $\\log_a b$ | LOG(b,a) | =LOG(A1,B1) | . | $e^x$ | EXP(x) | =EXP(A1) | . | $\\pi$ | PI() | =PI() | . | $\\sin x$ | SIN(x) | =SIN(A1) | . | $\\sin^{-1} x$ | ASIN(x) | =ASIN(A1) | . | $\\sqrt x$ | SQRT(x) | =SQRT(A1) | . Other trigonometric functions are also available besides just SIN, including COS, TAN, etc. Content last modified on 09 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-basic-mathematical-computations/#solution-in-excel",
    "relUrl": "/how-to-do-basic-mathematical-computations/#solution-in-excel"
  },"886": {
    "doc": "How to do basic mathematical computations",
    "title": "Solution, in Julia",
    "content": "View this solution alone. | Mathematical notation | Julia code | . | $x+y$ | x+y | . | $x-y$ | x-y | . | $xy$ | x*y | . | $\\frac xy$ | x/y (or y\\x) | . | $\\left\\lfloor\\frac xy\\right\\rfloor$ | x÷y | . | remainder of $x\\div y$ | x%y | . | $x^y$ | x^y | . | $\\vert x\\vert$ | abs(x) | . | $\\ln x$ | log(x) | . | $\\log_a b$ | log(a,b) | . | $e^x$ | exp(x) | . | $\\pi$ | pi | . | $\\sin x$ | sin(x) | . | $\\sin^{-1} x$ | asin(x) | . | $\\sqrt x$ | sqrt(x) | . Other trigonometric functions are also available besides just sin including cos, tan, etc. Content last modified on 04 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-basic-mathematical-computations/#solution-in-julia",
    "relUrl": "/how-to-do-basic-mathematical-computations/#solution-in-julia"
  },"887": {
    "doc": "How to do basic mathematical computations",
    "title": "Using NumPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported NumPy as follows. | 1 . | import numpy as np . | . | Mathematical notation | Python code | Requires NumPy? | . | $x+y$ | x+y | no | . | $x-y$ | x-y | no | . | $xy$ | x*y | no | . | $\\frac xy$ | x/y | no | . | $\\left\\lfloor\\frac xy\\right\\rfloor$ | x//y | no | . | $\\left\\lfloor\\frac xy\\right\\rfloor$ | np.floor_divide(x,y) | yes | . | remainder of $x\\div y$ | x%y | no | . | remainder of $x\\div y$ | np.remainder(x,y) | yes | . | $x^y$ | x**y | no | . | $\\vert x\\vert$ | abs(x) | no | . | $\\vert x\\vert$ | np.abs(x) | yes | . | $\\ln x$ | np.log(x) | yes | . | $\\log_a b$ | np.log(b)/np.log(a) | yes | . | $e^x$ | np.exp(x) | yes | . | $\\pi$ | np.pi | yes | . | $\\sin x$ | np.sin(x) | yes | . | $\\sin^{-1} x$ | np.asin(x) | yes | . | $\\sqrt x$ | x**0.5 | no | . | $\\sqrt x$ | np.sqrt(x) | yes | . Other trigonometric functions are also available besides just np.sin, including np.cos, np.tan, etc. NumPy automatically applies any of these functions to all entries of a NumPy array or pandas Series, but the built-in Python functions do not have this feature. For example, to square all numbers in an array, see below. | 1 2 3 . | import numpy as np example_array = np.array( [ -3, 2, 0.5, -1, 10, 9.2, -3.3 ] ) example_array ** 2 . | . | 1 . | array([ 9. , 4. , 0.25, 1. , 100. , 84.64, 10.89]) . | . Content last modified on 14 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-basic-mathematical-computations/#using-numpy-in-python",
    "relUrl": "/how-to-do-basic-mathematical-computations/#using-numpy-in-python"
  },"888": {
    "doc": "How to do basic mathematical computations",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . | Mathematical notation | Python code | Requires SymPy? | . | $x+y$ | x+y | no | . | $x-y$ | x-y | no | . | $xy$ | x*y | no | . | $\\frac xy$ | x/y | no | . | $\\left\\lfloor\\frac xy\\right\\rfloor$ | x//y | no | . | remainder of $x\\div y$ | x%y | no | . | $x^y$ | x**y | no | . | $\\vert x\\vert$ | abs(x) | no | . | $\\ln x$ | log(x) | yes | . | $\\log_a b$ | log(b,a) | yes | . | $e^x$ | E | yes | . | $\\pi$ | pi | yes | . | $\\sin x$ | sin(x) | yes | . | $\\sin^{-1} x$ | asin(x) | yes | . | $\\sqrt x$ | sqrt(x) | yes | . Other trigonometric functions are also available besides just sin, including cos, tan, etc. Note that SymPy gives precise answers to mathematical queries, which may not be what you want. | 1 . | sqrt(2) . | . $\\displaystyle \\sqrt{2}$ . If you want a decimal approximation instead, you can use the N function. | 1 . | N(sqrt(2)) . | . $\\displaystyle 1.4142135623731$ . Or you can use the evalf function. | 1 . | sqrt(2).evalf() . | . $\\displaystyle 1.4142135623731$ . By contrast, if you need an exact rational number when Python gives you an approximation, you can use the Rational function to build one. Note the differences below: . | 1 . | 1/3 . | . $\\displaystyle 0.333333333333333$ . | 1 . | Rational(1,3) . | . $\\displaystyle \\frac{1}{3}$ . Content last modified on 14 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-basic-mathematical-computations/#using-sympy-in-python",
    "relUrl": "/how-to-do-basic-mathematical-computations/#using-sympy-in-python"
  },"889": {
    "doc": "How to do basic mathematical computations",
    "title": "Solution, in Python",
    "content": "View this solution alone. For those expressions that need the Python math package, use the code import math beforehand to ensure that package is loaded. Alternatively, you can write from math import * and thus drop the math prefixes in the table below. | Mathematical notation | Python code | Requires math package? | . | $x+y$ | x+y | no | . | $x-y$ | x-y | no | . | $xy$ | x*y | no | . | $\\frac xy$ | x/y | no | . | $\\left\\lfloor\\frac xy\\right\\rfloor$ | x//y | no | . | remainder of $x\\div y$ | x%y | no | . | $x^y$ | x**y | no | . | $\\vert x\\vert$ | abs(x) | no | . | $\\ln x$ | math.log(x) | yes | . | $\\log_a b$ | math.log(b,a) | yes | . | $e^x$ | math.exp(x) | yes | . | $\\pi$ | math.pi | yes | . | $\\sin x$ | math.sin(x) | yes | . | $\\sin^{-1} x$ | math.asin(x) | yes | . | $\\sqrt x$ | x**0.5 | no | . | $\\sqrt x$ | math.sqrt(x) | yes | . Other trigonometric functions are also available besides just math.sin, including math.cos, math.tan, etc. Content last modified on 14 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-basic-mathematical-computations/#solution-in-python",
    "relUrl": "/how-to-do-basic-mathematical-computations/#solution-in-python"
  },"890": {
    "doc": "How to do basic mathematical computations",
    "title": "Solution, in R",
    "content": "View this solution alone. For those expressions that need the Python math package, use the code import math beforehand to ensure that package is loaded. Alternatively, you can write from math import * and thus drop the math prefixes in the table below. | Mathematical notation | R code | . | $x+y$ | x+y | . | $x-y$ | x-y | . | $xy$ | x*y | . | $\\frac xy$ | x/y | . | $x^y$ | x^y | . | $\\vert x\\vert$ | abs(x) | . | $\\ln x$ | log(x) | . | $\\log_a b$ | log(b,a) | . | $e^x$ | exp(x) | . | $\\pi$ | pi | . | $\\sin x$ | sin(x) | . | $\\sin^{-1} x$ | asin(x) | . | $\\sqrt x$ | sqrt(x) | . Other trigonometric functions are also available besides just sin, including cos, tan, etc. R naturally applies these functions across vectors. For example, you can square all the entries in a vector as in the example below. | 1 2 . | example.vector &lt;- c( -3, 2, 0.5, -1, 10, 9.2, -3.3 ) example.vector ^ 2 . | . | 1 . | [1] 9.00 4.00 0.25 1.00 100.00 84.64 10.89 . | . Content last modified on 23 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-basic-mathematical-computations/#solution-in-r",
    "relUrl": "/how-to-do-basic-mathematical-computations/#solution-in-r"
  },"891": {
    "doc": "How to do basic mathematical computations",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | Bentley University GR526 | Bentley University MA346 | . ",
    "url": "/how-to-do-basic-mathematical-computations/#topics-that-include-this-task",
    "relUrl": "/how-to-do-basic-mathematical-computations/#topics-that-include-this-task"
  },"892": {
    "doc": "How to do implicit differentiation (in Python, using SymPy)",
    "title": "How to do implicit differentiation (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-do-implicit-differentiation-in-python-using-sympy/",
    "relUrl": "/how-to-do-implicit-differentiation-in-python-using-sympy/"
  },"893": {
    "doc": "How to do implicit differentiation (in Python, using SymPy)",
    "title": "Task",
    "content": "Assume we have an equation in which $y$ cannot be isolated as a function of $x$. (The standard example is the formula for the unit circle, $x^2+y^2=1$.) We would still like to be able to compute the derivative of $y$ with respect to $x$. Related tasks: . | How to graph curves that are not functions | . ",
    "url": "/how-to-do-implicit-differentiation-in-python-using-sympy/#task",
    "relUrl": "/how-to-do-implicit-differentiation-in-python-using-sympy/#task"
  },"894": {
    "doc": "How to do implicit differentiation (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s consider the example of the unit circle, $x^2+y^2=1$. To plot it, SymPy first expects us to move everything to the left-hand side of the equation, so in this case, we would have $x^2+y^2-1=0$. We then use that left hand side to represent the equation as a single formula, and computue $\\frac{dy}{dx}$ using the idiff function (standing for “implicit differentiation”). | 1 2 3 . | var( 'x y' ) formula = x**2 + y**2 - 1 # to represent x^2+y^2=1 idiff( formula, y, x ) . | . $\\displaystyle - \\frac{x}{y}$ . So in this case, $\\frac{dy}{dx}=-\\frac xy$. Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-do-implicit-differentiation-in-python-using-sympy/#solution",
    "relUrl": "/how-to-do-implicit-differentiation-in-python-using-sympy/#solution"
  },"895": {
    "doc": "How to do implicit differentiation",
    "title": "How to do implicit differentiation",
    "content": " ",
    "url": "/how-to-do-implicit-differentiation/",
    "relUrl": "/how-to-do-implicit-differentiation/"
  },"896": {
    "doc": "How to do implicit differentiation",
    "title": "Description",
    "content": "Assume we have an equation in which $y$ cannot be isolated as a function of $x$. (The standard example is the formula for the unit circle, $x^2+y^2=1$.) We would still like to be able to compute the derivative of $y$ with respect to $x$. Related tasks: . | How to graph curves that are not functions | . ",
    "url": "/how-to-do-implicit-differentiation/#description",
    "relUrl": "/how-to-do-implicit-differentiation/#description"
  },"897": {
    "doc": "How to do implicit differentiation",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s consider the example of the unit circle, $x^2+y^2=1$. To plot it, SymPy first expects us to move everything to the left-hand side of the equation, so in this case, we would have $x^2+y^2-1=0$. We then use that left hand side to represent the equation as a single formula, and computue $\\frac{dy}{dx}$ using the idiff function (standing for “implicit differentiation”). | 1 2 3 . | var( 'x y' ) formula = x**2 + y**2 - 1 # to represent x^2+y^2=1 idiff( formula, y, x ) . | . $\\displaystyle - \\frac{x}{y}$ . So in this case, $\\frac{dy}{dx}=-\\frac xy$. Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-do-implicit-differentiation/#using-sympy-in-python",
    "relUrl": "/how-to-do-implicit-differentiation/#using-sympy-in-python"
  },"898": {
    "doc": "How to do implicit differentiation",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-do-implicit-differentiation/#topics-that-include-this-task",
    "relUrl": "/how-to-do-implicit-differentiation/#topics-that-include-this-task"
  },"899": {
    "doc": "How to do implicit differentiation",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-do-implicit-differentiation/#opportunities",
    "relUrl": "/how-to-do-implicit-differentiation/#opportunities"
  },"900": {
    "doc": "How to find critical values and p-values from the normal distribution (in Julia)",
    "title": "How to find critical values and p-values from the normal distribution (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-julia/",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-julia/"
  },"901": {
    "doc": "How to find critical values and p-values from the normal distribution (in Julia)",
    "title": "Task",
    "content": "Some statistical techniques require computing critical values or $p$-values from the normal distribution. For example, we need to do this when constructing a confidence interval or conducting a hypothesis test. How do we compute such values? . Related tasks: . | How to find critical values and p-values from the t-distribution | . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-julia/#task",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-julia/#task"
  },"902": {
    "doc": "How to find critical values and p-values from the normal distribution (in Julia)",
    "title": "Solution",
    "content": "If we choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate, then we can find the critical value from the normal distribution using the quantile() function in Julia’s Distributions package. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. The code below shows how to do this for left-tailed, right-tailed, and two-tailed hypothesis tests. | 1 2 3 4 . | using Distributions alpha = 0.05 # Replace with your alpha value standard_normal = Normal( 0, 1 ) quantile( standard_normal, alpha ) # Critical value for a left-tailed test . | . | 1 . | -1.6448536269514724 . | . | 1 . | quantile( standard_normal, 1 - alpha ) # Critical value for a right-tailed test . | . | 1 . | 1.6448536269514717 . | . | 1 . | quantile( standard_normal, alpha / 2 ) # Critical value for a two-tailed test . | . | 1 . | -1.9599639845400592 . | . We can also compute $p$-values from the normal distribution to compare to a test statistic. As an example, we’ll use a test statistic of 2.67, but you can substitute your test statistic’s value instead. We can find the $p$-value for this test statistic using the cdf() function in Julia’s Distributions package. Again, we show code for left-tailed, right-tailed, and two-tailed tests. | 1 2 . | test_statistic = 2.67 # Replace with your test statistic cdf( standard_normal, test_statistic ) # p-value for a left-tailed test . | . | 1 . | 0.9962074376523146 . | . | 1 . | 1 - cdf( standard_normal, test_statistic ) # p-value for a right-tailed test . | . | 1 . | 0.0037925623476854353 . | . | 1 . | 2 * ( 1 - cdf( standard_normal, test_statistic ) ) # p-value for a two-tailed test . | . | 1 . | 0.007585124695370871 . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-julia/#solution",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-julia/#solution"
  },"903": {
    "doc": "How to find critical values and p-values from the normal distribution (in R)",
    "title": "How to find critical values and p-values from the normal distribution (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-r/",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-r/"
  },"904": {
    "doc": "How to find critical values and p-values from the normal distribution (in R)",
    "title": "Task",
    "content": "Some statistical techniques require computing critical values or $p$-values from the normal distribution. For example, we need to do this when constructing a confidence interval or conducting a hypothesis test. How do we compute such values? . Related tasks: . | How to find critical values and p-values from the t-distribution | . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-r/#task",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-r/#task"
  },"905": {
    "doc": "How to find critical values and p-values from the normal distribution (in R)",
    "title": "Solution",
    "content": "If we choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate, then we can find the critical value from the normal distribution using R’s qnorm() function. The code below shows how to do this for left-tailed, right-tailed, and two-tailed hypothesis tests. | 1 2 3 4 . | alpha &lt;- 0.05 # Replace with your alpha value qnorm(p = alpha, lower.tail = TRUE) # Critical value for a left-tailed test qnorm(p = alpha, lower.tail = FALSE) # Critical value for a right-tailed test qnorm(p = alpha/2, lower.tail = FALSE) # Critical value for a two-tailed test . | . | 1 2 3 4 5 6 7 8 9 . | [1] -1.644854 [1] 1.644854 [1] 1.959964 . | . We can also compute $p$-values from the normal distribution to compare to a test statistic. As an example, we’ll use a test statistic of 2.67, but you can substitute your test statistic’s value instead. We can find the $p$-value for this test statistic using R’s pnorm() function. Again, we show code for left-tailed, right-tailed, and two-tailed tests. | 1 2 3 4 . | test_statistic &lt;- 2.67 # Replace with your test statistic pnorm(test_statistic, lower.tail = TRUE) # p-value for a left-tailed test pnorm(test_statistic, lower.tail = FALSE) # p-value for a right-tailed test 2*pnorm(test_statistic, lower.tail = FALSE) # p-value for a two-tailed test . | . | 1 2 3 4 5 6 7 8 9 . | [1] 0.9962074 [1] 0.003792562 [1] 0.007585125 . | . Content last modified on 05 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-r/#solution",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution-in-r/#solution"
  },"906": {
    "doc": "How to find critical values and p-values from the normal distribution",
    "title": "How to find critical values and p-values from the normal distribution",
    "content": " ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/"
  },"907": {
    "doc": "How to find critical values and p-values from the normal distribution",
    "title": "Description",
    "content": "Some statistical techniques require computing critical values or $p$-values from the normal distribution. For example, we need to do this when constructing a confidence interval or conducting a hypothesis test. How do we compute such values? . Related tasks: . | How to find critical values and p-values from the t-distribution | . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/#description",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/#description"
  },"908": {
    "doc": "How to find critical values and p-values from the normal distribution",
    "title": "Solution, in Julia",
    "content": "View this solution alone. If we choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate, then we can find the critical value from the normal distribution using the quantile() function in Julia’s Distributions package. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. The code below shows how to do this for left-tailed, right-tailed, and two-tailed hypothesis tests. | 1 2 3 4 . | using Distributions alpha = 0.05 # Replace with your alpha value standard_normal = Normal( 0, 1 ) quantile( standard_normal, alpha ) # Critical value for a left-tailed test . | . | 1 . | -1.6448536269514724 . | . | 1 . | quantile( standard_normal, 1 - alpha ) # Critical value for a right-tailed test . | . | 1 . | 1.6448536269514717 . | . | 1 . | quantile( standard_normal, alpha / 2 ) # Critical value for a two-tailed test . | . | 1 . | -1.9599639845400592 . | . We can also compute $p$-values from the normal distribution to compare to a test statistic. As an example, we’ll use a test statistic of 2.67, but you can substitute your test statistic’s value instead. We can find the $p$-value for this test statistic using the cdf() function in Julia’s Distributions package. Again, we show code for left-tailed, right-tailed, and two-tailed tests. | 1 2 . | test_statistic = 2.67 # Replace with your test statistic cdf( standard_normal, test_statistic ) # p-value for a left-tailed test . | . | 1 . | 0.9962074376523146 . | . | 1 . | 1 - cdf( standard_normal, test_statistic ) # p-value for a right-tailed test . | . | 1 . | 0.0037925623476854353 . | . | 1 . | 2 * ( 1 - cdf( standard_normal, test_statistic ) ) # p-value for a two-tailed test . | . | 1 . | 0.007585124695370871 . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/#solution-in-julia",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/#solution-in-julia"
  },"909": {
    "doc": "How to find critical values and p-values from the normal distribution",
    "title": "Solution, in R",
    "content": "View this solution alone. If we choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate, then we can find the critical value from the normal distribution using R’s qnorm() function. The code below shows how to do this for left-tailed, right-tailed, and two-tailed hypothesis tests. | 1 2 3 4 . | alpha &lt;- 0.05 # Replace with your alpha value qnorm(p = alpha, lower.tail = TRUE) # Critical value for a left-tailed test qnorm(p = alpha, lower.tail = FALSE) # Critical value for a right-tailed test qnorm(p = alpha/2, lower.tail = FALSE) # Critical value for a two-tailed test . | . | 1 2 3 4 5 6 7 8 9 . | [1] -1.644854 [1] 1.644854 [1] 1.959964 . | . We can also compute $p$-values from the normal distribution to compare to a test statistic. As an example, we’ll use a test statistic of 2.67, but you can substitute your test statistic’s value instead. We can find the $p$-value for this test statistic using R’s pnorm() function. Again, we show code for left-tailed, right-tailed, and two-tailed tests. | 1 2 3 4 . | test_statistic &lt;- 2.67 # Replace with your test statistic pnorm(test_statistic, lower.tail = TRUE) # p-value for a left-tailed test pnorm(test_statistic, lower.tail = FALSE) # p-value for a right-tailed test 2*pnorm(test_statistic, lower.tail = FALSE) # p-value for a two-tailed test . | . | 1 2 3 4 5 6 7 8 9 . | [1] 0.9962074 [1] 0.003792562 [1] 0.007585125 . | . Content last modified on 05 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/#solution-in-r",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/#solution-in-r"
  },"910": {
    "doc": "How to find critical values and p-values from the normal distribution",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/#topics-that-include-this-task",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/#topics-that-include-this-task"
  },"911": {
    "doc": "How to find critical values and p-values from the normal distribution",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Python | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/#opportunities",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-normal-distribution/#opportunities"
  },"912": {
    "doc": "How to find critical values and p-values from the t-distribution (in Julia)",
    "title": "How to find critical values and p-values from the t-distribution (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-julia/",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-julia/"
  },"913": {
    "doc": "How to find critical values and p-values from the t-distribution (in Julia)",
    "title": "Task",
    "content": "If we have a test statistic and need to find the corresponding p-value from the t-distribution, how do we do that? If we need to find a p-value from the t distribution, given that we know the significance level and degrees of freedom, how do we do that? . Related tasks: . | How to find critical values and p-values from the normal distribution | . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-julia/#task",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-julia/#task"
  },"914": {
    "doc": "How to find critical values and p-values from the t-distribution (in Julia)",
    "title": "Solution",
    "content": "If we choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate, then we can find the critical value from the normal distribution using the quantile() function in Julia’s Distributions package. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. The code below shows how to do this for left-tailed, right-tailed, and two-tailed hypothesis tests. | 1 2 3 4 5 . | using Distributions alpha = 0.05 # Replace with your alpha value n = 68 # Replace with your sample size tdist = TDist( n - 1 ) quantile( tdist, alpha ) # Critical value for a left-tailed test . | . | 1 . | -1.6679161141074252 . | . | 1 . | quantile( tdist, 1 - alpha ) # Critical value for a right-tailed test . | . | 1 . | 1.6679161141074246 . | . | 1 . | quantile( tdist, alpha / 2 ) # Critical value for a two-tailed test . | . | 1 . | -1.996008354025297 . | . We can also compute $p$-values from the normal distribution to compare to a test statistic. As an example, we’ll use a test statistic of 2.67, but you can substitute your test statistic’s value instead. We can find the $p$-value for this test statistic using the cdf() function in Julia’s Distributions package. Again, we show code for left-tailed, right-tailed, and two-tailed tests. | 1 2 . | test_statistic = 2.67 # Replace with your test statistic cdf( tdist, test_statistic ) # p-value for a left-tailed test . | . | 1 . | 0.9952454518351646 . | . | 1 . | 1 - cdf( tdist, test_statistic ) # p-value for a right-tailed test . | . | 1 . | 0.004754548164835448 . | . | 1 . | 2 * ( 1 - cdf( tdist, test_statistic ) ) # p-value for a two-tailed test . | . | 1 . | 0.009509096329670896 . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-julia/#solution",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-julia/#solution"
  },"915": {
    "doc": "How to find critical values and p-values from the t-distribution (in R)",
    "title": "How to find critical values and p-values from the t-distribution (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-r/",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-r/"
  },"916": {
    "doc": "How to find critical values and p-values from the t-distribution (in R)",
    "title": "Task",
    "content": "If we have a test statistic and need to find the corresponding p-value from the t-distribution, how do we do that? If we need to find a p-value from the t distribution, given that we know the significance level and degrees of freedom, how do we do that? . Related tasks: . | How to find critical values and p-values from the normal distribution | . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-r/#task",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-r/#task"
  },"917": {
    "doc": "How to find critical values and p-values from the t-distribution (in R)",
    "title": "Solution",
    "content": "If we choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate, and we know the sample size of our data, then we can find the critical value from the $t$-distribution using R’s qt() function. The code below shows how to do this for left-tailed, right-tailed, and two-tailed hypothesis tests. | 1 2 3 4 5 . | alpha &lt;- 0.05 # Replace with your alpha value n &lt;- 68 # Replace with your sample size qt(p = alpha, df = n-1, lower.tail = TRUE) # Critical value for a left-tailed test qt(p = alpha, df = n-1, lower.tail = FALSE) # Critical value for a right-tailed test qt(p = alpha/2, df = n-1, lower.tail = FALSE) # Critical value for a two-tailed test . | . | 1 2 3 4 5 6 7 8 9 . | [1] -1.667916 [1] 1.667916 [1] 1.996008 . | . We can also compute $p$-values from the $t$-distribution to compare to a test statistic. As an example, we’ll use a test statistic of 2.67, but you can substitute your test statistic’s value instead. We can find the $p$-value for this test statistic using R’s pt() function. We will use the same example sample size as above. Again, we show code for left-tailed, right-tailed, and two-tailed tests. | 1 2 3 4 5 . | test_statistic &lt;- 2.67 # Replace with your test statistic n &lt;- 68 # Replace with your sample size pt(test_statistic, df = n-1, lower.tail = TRUE) # p-value for a left-tailed test pt(test_statistic, df = n-1, lower.tail = FALSE) # p-value for a right-tailed test 2*pt(test_statistic, df = n-1, lower.tail = FALSE) # p-value for a two-tailed test . | . | 1 2 3 4 5 6 7 8 9 . | [1] 0.9952455 [1] 0.004754548 [1] 0.009509096 . | . Content last modified on 05 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-r/#solution",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution-in-r/#solution"
  },"918": {
    "doc": "How to find critical values and p-values from the t-distribution",
    "title": "How to find critical values and p-values from the t-distribution",
    "content": " ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/"
  },"919": {
    "doc": "How to find critical values and p-values from the t-distribution",
    "title": "Description",
    "content": "If we have a test statistic and need to find the corresponding p-value from the t-distribution, how do we do that? If we need to find a p-value from the t distribution, given that we know the significance level and degrees of freedom, how do we do that? . Related tasks: . | How to find critical values and p-values from the normal distribution | . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/#description",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/#description"
  },"920": {
    "doc": "How to find critical values and p-values from the t-distribution",
    "title": "Solution, in Julia",
    "content": "View this solution alone. If we choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate, then we can find the critical value from the normal distribution using the quantile() function in Julia’s Distributions package. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. The code below shows how to do this for left-tailed, right-tailed, and two-tailed hypothesis tests. | 1 2 3 4 5 . | using Distributions alpha = 0.05 # Replace with your alpha value n = 68 # Replace with your sample size tdist = TDist( n - 1 ) quantile( tdist, alpha ) # Critical value for a left-tailed test . | . | 1 . | -1.6679161141074252 . | . | 1 . | quantile( tdist, 1 - alpha ) # Critical value for a right-tailed test . | . | 1 . | 1.6679161141074246 . | . | 1 . | quantile( tdist, alpha / 2 ) # Critical value for a two-tailed test . | . | 1 . | -1.996008354025297 . | . We can also compute $p$-values from the normal distribution to compare to a test statistic. As an example, we’ll use a test statistic of 2.67, but you can substitute your test statistic’s value instead. We can find the $p$-value for this test statistic using the cdf() function in Julia’s Distributions package. Again, we show code for left-tailed, right-tailed, and two-tailed tests. | 1 2 . | test_statistic = 2.67 # Replace with your test statistic cdf( tdist, test_statistic ) # p-value for a left-tailed test . | . | 1 . | 0.9952454518351646 . | . | 1 . | 1 - cdf( tdist, test_statistic ) # p-value for a right-tailed test . | . | 1 . | 0.004754548164835448 . | . | 1 . | 2 * ( 1 - cdf( tdist, test_statistic ) ) # p-value for a two-tailed test . | . | 1 . | 0.009509096329670896 . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/#solution-in-julia",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/#solution-in-julia"
  },"921": {
    "doc": "How to find critical values and p-values from the t-distribution",
    "title": "Solution, in R",
    "content": "View this solution alone. If we choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate, and we know the sample size of our data, then we can find the critical value from the $t$-distribution using R’s qt() function. The code below shows how to do this for left-tailed, right-tailed, and two-tailed hypothesis tests. | 1 2 3 4 5 . | alpha &lt;- 0.05 # Replace with your alpha value n &lt;- 68 # Replace with your sample size qt(p = alpha, df = n-1, lower.tail = TRUE) # Critical value for a left-tailed test qt(p = alpha, df = n-1, lower.tail = FALSE) # Critical value for a right-tailed test qt(p = alpha/2, df = n-1, lower.tail = FALSE) # Critical value for a two-tailed test . | . | 1 2 3 4 5 6 7 8 9 . | [1] -1.667916 [1] 1.667916 [1] 1.996008 . | . We can also compute $p$-values from the $t$-distribution to compare to a test statistic. As an example, we’ll use a test statistic of 2.67, but you can substitute your test statistic’s value instead. We can find the $p$-value for this test statistic using R’s pt() function. We will use the same example sample size as above. Again, we show code for left-tailed, right-tailed, and two-tailed tests. | 1 2 3 4 5 . | test_statistic &lt;- 2.67 # Replace with your test statistic n &lt;- 68 # Replace with your sample size pt(test_statistic, df = n-1, lower.tail = TRUE) # p-value for a left-tailed test pt(test_statistic, df = n-1, lower.tail = FALSE) # p-value for a right-tailed test 2*pt(test_statistic, df = n-1, lower.tail = FALSE) # p-value for a two-tailed test . | . | 1 2 3 4 5 6 7 8 9 . | [1] 0.9952455 [1] 0.004754548 [1] 0.009509096 . | . Content last modified on 05 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/#solution-in-r",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/#solution-in-r"
  },"922": {
    "doc": "How to find critical values and p-values from the t-distribution",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | . ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/#topics-that-include-this-task",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/#topics-that-include-this-task"
  },"923": {
    "doc": "How to find critical values and p-values from the t-distribution",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Python | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/#opportunities",
    "relUrl": "/how-to-find-critical-values-and-p-values-from-the-t-distribution/#opportunities"
  },"924": {
    "doc": "How to find the critical numbers of a function (in Python, using SymPy)",
    "title": "How to find the critical numbers of a function (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-find-the-critical-numbers-of-a-function-in-python-using-sympy/",
    "relUrl": "/how-to-find-the-critical-numbers-of-a-function-in-python-using-sympy/"
  },"925": {
    "doc": "How to find the critical numbers of a function (in Python, using SymPy)",
    "title": "Task",
    "content": "When trying to find the maximum and minimum values of a function, one of the main techniques in calculus is to use the “critical numbers” of the function, which are the most important $x$ values to examine to find maxima and minima. Can we find critical numbers for a single-variable function using software? . Related tasks: . | How to compute the domain of a function | . ",
    "url": "/how-to-find-the-critical-numbers-of-a-function-in-python-using-sympy/#task",
    "relUrl": "/how-to-find-the-critical-numbers-of-a-function-in-python-using-sympy/#task"
  },"926": {
    "doc": "How to find the critical numbers of a function (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s create an example function to work with. | 1 2 3 . | var( 'x' ) formula = sqrt( x - 1 ) - x formula . | . $\\displaystyle - x + \\sqrt{x - 1}$ . Critical numbers come in two kinds. First, where is the derivative zero? Second, where is the derivative undefined but the function is defined? . Let’s begin by finding where the derivative is zero. We’ll use the same techniques introduced in how to write symbolic equations and how to solve symbolic equations. | 1 2 . | derivative = diff( formula ) derivative . | . $\\displaystyle -1 + \\frac{1}{2 \\sqrt{x - 1}}$ . | 1 . | solve( Eq( derivative, 0 ) ) . | . $\\displaystyle \\left[ \\frac{5}{4}\\right]$ . So one critical number, where the derivative is zero, is $x=\\frac54$. Now where is the derivative defined but the function undefined? We compute the domain of both functions and subtract them, using the techniques from how to compute the domain of a function. | 1 2 3 4 . | from sympy.calculus.util import continuous_domain f_domain = continuous_domain( formula, x, S.Reals ) deriv_domain = continuous_domain( derivative, x, S.Reals ) Complement( f_domain, deriv_domain ) . | . $\\displaystyle \\left\\{1\\right\\}$ . So another critical number, where the function is defined but the derivative is not, is $x=1$. Thus the full set of critical numbers for this function is $\\left{1,\\frac54\\right}$. Content last modified on 13 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-find-the-critical-numbers-of-a-function-in-python-using-sympy/#solution",
    "relUrl": "/how-to-find-the-critical-numbers-of-a-function-in-python-using-sympy/#solution"
  },"927": {
    "doc": "How to find the critical numbers of a function",
    "title": "How to find the critical numbers of a function",
    "content": " ",
    "url": "/how-to-find-the-critical-numbers-of-a-function/",
    "relUrl": "/how-to-find-the-critical-numbers-of-a-function/"
  },"928": {
    "doc": "How to find the critical numbers of a function",
    "title": "Description",
    "content": "When trying to find the maximum and minimum values of a function, one of the main techniques in calculus is to use the “critical numbers” of the function, which are the most important $x$ values to examine to find maxima and minima. Can we find critical numbers for a single-variable function using software? . Related tasks: . | How to compute the domain of a function | . ",
    "url": "/how-to-find-the-critical-numbers-of-a-function/#description",
    "relUrl": "/how-to-find-the-critical-numbers-of-a-function/#description"
  },"929": {
    "doc": "How to find the critical numbers of a function",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s create an example function to work with. | 1 2 3 . | var( 'x' ) formula = sqrt( x - 1 ) - x formula . | . $\\displaystyle - x + \\sqrt{x - 1}$ . Critical numbers come in two kinds. First, where is the derivative zero? Second, where is the derivative undefined but the function is defined? . Let’s begin by finding where the derivative is zero. We’ll use the same techniques introduced in how to write symbolic equations and how to solve symbolic equations. | 1 2 . | derivative = diff( formula ) derivative . | . $\\displaystyle -1 + \\frac{1}{2 \\sqrt{x - 1}}$ . | 1 . | solve( Eq( derivative, 0 ) ) . | . $\\displaystyle \\left[ \\frac{5}{4}\\right]$ . So one critical number, where the derivative is zero, is $x=\\frac54$. Now where is the derivative defined but the function undefined? We compute the domain of both functions and subtract them, using the techniques from how to compute the domain of a function. | 1 2 3 4 . | from sympy.calculus.util import continuous_domain f_domain = continuous_domain( formula, x, S.Reals ) deriv_domain = continuous_domain( derivative, x, S.Reals ) Complement( f_domain, deriv_domain ) . | . $\\displaystyle \\left\\{1\\right\\}$ . So another critical number, where the function is defined but the derivative is not, is $x=1$. Thus the full set of critical numbers for this function is $\\left{1,\\frac54\\right}$. Content last modified on 13 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-find-the-critical-numbers-of-a-function/#using-sympy-in-python",
    "relUrl": "/how-to-find-the-critical-numbers-of-a-function/#using-sympy-in-python"
  },"930": {
    "doc": "How to find the critical numbers of a function",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-find-the-critical-numbers-of-a-function/#topics-that-include-this-task",
    "relUrl": "/how-to-find-the-critical-numbers-of-a-function/#topics-that-include-this-task"
  },"931": {
    "doc": "How to find the critical numbers of a function",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-find-the-critical-numbers-of-a-function/#opportunities",
    "relUrl": "/how-to-find-the-critical-numbers-of-a-function/#opportunities"
  },"932": {
    "doc": "How to fit a linear model to two columns of data (in Julia)",
    "title": "How to fit a linear model to two columns of data (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-julia/",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-julia/"
  },"933": {
    "doc": "How to fit a linear model to two columns of data (in Julia)",
    "title": "Task",
    "content": "Let’s say we have two columns of data, one for a single independent variable $x$ and the other for a single dependent variable $y$. How can I find the best fit linear model that predicts $y$ based on $x$? . In other words, what are the model coefficients $\\beta_0$ and $\\beta_1$ that give me the best linear model $\\hat y=\\beta_0+\\beta_1x$ based on my data? . Related tasks: . | How to compute R-squared for a simple linear model | How to fit a multivariate linear model | How to predict the response variable in a linear model | . ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-julia/#task",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-julia/#task"
  },"934": {
    "doc": "How to fit a linear model to two columns of data (in Julia)",
    "title": "Solution",
    "content": "This solution uses fake example data. When using this code, replace our fake data with your real data. | 1 2 3 4 5 6 7 8 9 10 11 . | # Here is the fake data you should replace with your real data. xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] # Place the data into a DataFrame, because that's what Julia's modeling tools expect: using DataFrames data = DataFrame( xs=xs, ys=ys ) # Or you can name the columns whatever you like # Create the linear model: using GLM lm( @formula( ys ~ xs ), data ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}} ys ~ 1 + xs Coefficients: ─────────────────────────────────────────────────────────────────────────── Coef. Std. Error t Pr(&gt;|t|) Lower 95% Upper 95% ─────────────────────────────────────────────────────────────────────────── (Intercept) -37.3214 18.9954 -1.96 0.1066 -86.1508 11.5079 xs 0.13272 0.029589 4.49 0.0065 0.0566587 0.20878 ─────────────────────────────────────────────────────────────────────────── . | . The linear model in this example is approximately $y=0.13272x-37.3214$. Content last modified on 05 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-julia/#solution",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-julia/#solution"
  },"935": {
    "doc": "How to fit a linear model to two columns of data (in Python, using SciPy)",
    "title": "How to fit a linear model to two columns of data (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-scipy/",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-scipy/"
  },"936": {
    "doc": "How to fit a linear model to two columns of data (in Python, using SciPy)",
    "title": "Task",
    "content": "Let’s say we have two columns of data, one for a single independent variable $x$ and the other for a single dependent variable $y$. How can I find the best fit linear model that predicts $y$ based on $x$? . In other words, what are the model coefficients $\\beta_0$ and $\\beta_1$ that give me the best linear model $\\hat y=\\beta_0+\\beta_1x$ based on my data? . Related tasks: . | How to compute R-squared for a simple linear model | How to fit a multivariate linear model | How to predict the response variable in a linear model | . ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-scipy/#task",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-scipy/#task"
  },"937": {
    "doc": "How to fit a linear model to two columns of data (in Python, using SciPy)",
    "title": "Solution",
    "content": "This solution uses a pandas DataFrame of fake example data. When using this code, replace our fake data with your real data. Although the solution below uses plain Python lists of data, it also works if the data are stored in NumPy arrays or pandas Series. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 . | # Here is the fake data you should replace with your real data. xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] # We will use SciPy to build the model import scipy.stats as stats # If you need the model coefficients stored in variables for later use, do: model = stats.linregress( xs, ys ) beta0 = model.intercept beta1 = model.slope # If you just need to see the coefficients (and some other related data), # do this alone: stats.linregress( xs, ys ) . | . | 1 . | LinregressResult(slope=0.1327195637885226, intercept=-37.32141898334582, rvalue=0.8949574425541466, pvalue=0.006486043236692156, stderr=0.029588975845594334, intercept_stderr=18.995444317768097) . | . The linear model in this example is approximately $\\hat y=0.133x-37.32$. Content last modified on 08 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-scipy/#solution",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-scipy/#solution"
  },"938": {
    "doc": "How to fit a linear model to two columns of data (in Python, using statsmodels)",
    "title": "How to fit a linear model to two columns of data (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-statsmodels/",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-statsmodels/"
  },"939": {
    "doc": "How to fit a linear model to two columns of data (in Python, using statsmodels)",
    "title": "Task",
    "content": "Let’s say we have two columns of data, one for a single independent variable $x$ and the other for a single dependent variable $y$. How can I find the best fit linear model that predicts $y$ based on $x$? . In other words, what are the model coefficients $\\beta_0$ and $\\beta_1$ that give me the best linear model $\\hat y=\\beta_0+\\beta_1x$ based on my data? . Related tasks: . | How to compute R-squared for a simple linear model | How to fit a multivariate linear model | How to predict the response variable in a linear model | . ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-statsmodels/#task"
  },"940": {
    "doc": "How to fit a linear model to two columns of data (in Python, using statsmodels)",
    "title": "Solution",
    "content": "This solution uses fake example data. When using this code, replace our fake data with your real data. Although the solution below uses plain Python lists of data, it also works if the data are stored in NumPy arrays or pandas Series. | 1 2 3 4 5 6 7 8 9 10 11 12 13 . | # Here is the fake data you should replace with your real data. xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] # We will use statsmodels to build the model import statsmodels.api as sm # statsmodels does not add a constant term to the model unless you request it: xs = sm.add_constant( xs ) # Fit the model and tell us all about it: model = sm.OLS( ys, xs ).fit() model.summary() . | . | 1 2 . | /opt/conda/lib/python3.10/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 7 samples were given. warn(\"omni_normtest is not valid with less than 8 observations; %i \" . | . OLS Regression Results | Dep. Variable: | y | R-squared: | 0.801 | . | Model: | OLS | Adj. R-squared: | 0.761 | . | Method: | Least Squares | F-statistic: | 20.12 | . | Date: | Tue, 08 Nov 2022 | Prob (F-statistic): | 0.00649 | . | Time: | 21:35:13 | Log-Likelihood: | -25.926 | . | No. Observations: | 7 | AIC: | 55.85 | . | Df Residuals: | 5 | BIC: | 55.74 | . | Df Model: | 1 | | | . | Covariance Type: | nonrobust | | | . | | coef | std err | t | P&gt;|t| | [0.025 | 0.975] | . | const | -37.3214 | 18.995 | -1.965 | 0.107 | -86.151 | 11.508 | . | x1 | 0.1327 | 0.030 | 4.485 | 0.006 | 0.057 | 0.209 | . | Omnibus: | nan | Durbin-Watson: | 0.806 | . | Prob(Omnibus): | nan | Jarque-Bera (JB): | 0.520 | . | Skew: | -0.366 | Prob(JB): | 0.771 | . | Kurtosis: | 1.883 | Cond. No. | 2.78e+03 | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 2.78e+03. This might indicate that there arestrong multicollinearity or other numerical problems. The linear model in this example is approximately $\\hat y=0.1327x-37.3214$. Content last modified on 08 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-python-using-statsmodels/#solution"
  },"941": {
    "doc": "How to fit a linear model to two columns of data (in R)",
    "title": "How to fit a linear model to two columns of data (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-r/",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-r/"
  },"942": {
    "doc": "How to fit a linear model to two columns of data (in R)",
    "title": "Task",
    "content": "Let’s say we have two columns of data, one for a single independent variable $x$ and the other for a single dependent variable $y$. How can I find the best fit linear model that predicts $y$ based on $x$? . In other words, what are the model coefficients $\\beta_0$ and $\\beta_1$ that give me the best linear model $\\hat y=\\beta_0+\\beta_1x$ based on my data? . Related tasks: . | How to compute R-squared for a simple linear model | How to fit a multivariate linear model | How to predict the response variable in a linear model | . ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-r/#task",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-r/#task"
  },"943": {
    "doc": "How to fit a linear model to two columns of data (in R)",
    "title": "Solution",
    "content": "This solution uses fake example data. When using this code, replace our fake data with your real data. | 1 2 3 4 5 6 7 8 9 10 11 . | # Here is the fake data you should replace with your real data. xs &lt;- c( 393, 453, 553, 679, 729, 748, 817 ) ys &lt;- c( 24, 25, 27, 36, 55, 68, 84 ) # If you need the model coefficients stored in variables for later use, do: model &lt;- lm( ys ~ xs ) beta0 = model$coefficients[1] beta1 = model$coefficients[2] # If you just need to see the coefficients, do this alone: lm( ys ~ xs ) . | . | 1 2 3 4 5 6 . | Call: lm(formula = ys ~ xs) Coefficients: (Intercept) xs -37.3214 0.1327 . | . The linear model in this example is approximately $y=0.133x-37.32$. Content last modified on 28 May 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-r/#solution",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data-in-r/#solution"
  },"944": {
    "doc": "How to fit a linear model to two columns of data",
    "title": "How to fit a linear model to two columns of data",
    "content": " ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data/",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data/"
  },"945": {
    "doc": "How to fit a linear model to two columns of data",
    "title": "Description",
    "content": "Let’s say we have two columns of data, one for a single independent variable $x$ and the other for a single dependent variable $y$. How can I find the best fit linear model that predicts $y$ based on $x$? . In other words, what are the model coefficients $\\beta_0$ and $\\beta_1$ that give me the best linear model $\\hat y=\\beta_0+\\beta_1x$ based on my data? . Related tasks: . | How to compute R-squared for a simple linear model | How to fit a multivariate linear model | How to predict the response variable in a linear model | . ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data/#description",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data/#description"
  },"946": {
    "doc": "How to fit a linear model to two columns of data",
    "title": "Solution, in Julia",
    "content": "View this solution alone. This solution uses fake example data. When using this code, replace our fake data with your real data. | 1 2 3 4 5 6 7 8 9 10 11 . | # Here is the fake data you should replace with your real data. xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] # Place the data into a DataFrame, because that's what Julia's modeling tools expect: using DataFrames data = DataFrame( xs=xs, ys=ys ) # Or you can name the columns whatever you like # Create the linear model: using GLM lm( @formula( ys ~ xs ), data ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}} ys ~ 1 + xs Coefficients: ─────────────────────────────────────────────────────────────────────────── Coef. Std. Error t Pr(&gt;|t|) Lower 95% Upper 95% ─────────────────────────────────────────────────────────────────────────── (Intercept) -37.3214 18.9954 -1.96 0.1066 -86.1508 11.5079 xs 0.13272 0.029589 4.49 0.0065 0.0566587 0.20878 ─────────────────────────────────────────────────────────────────────────── . | . The linear model in this example is approximately $y=0.13272x-37.3214$. Content last modified on 05 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data/#solution-in-julia",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data/#solution-in-julia"
  },"947": {
    "doc": "How to fit a linear model to two columns of data",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. This solution uses a pandas DataFrame of fake example data. When using this code, replace our fake data with your real data. Although the solution below uses plain Python lists of data, it also works if the data are stored in NumPy arrays or pandas Series. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 . | # Here is the fake data you should replace with your real data. xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] # We will use SciPy to build the model import scipy.stats as stats # If you need the model coefficients stored in variables for later use, do: model = stats.linregress( xs, ys ) beta0 = model.intercept beta1 = model.slope # If you just need to see the coefficients (and some other related data), # do this alone: stats.linregress( xs, ys ) . | . | 1 . | LinregressResult(slope=0.1327195637885226, intercept=-37.32141898334582, rvalue=0.8949574425541466, pvalue=0.006486043236692156, stderr=0.029588975845594334, intercept_stderr=18.995444317768097) . | . The linear model in this example is approximately $\\hat y=0.133x-37.32$. Content last modified on 08 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data/#using-scipy-in-python",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data/#using-scipy-in-python"
  },"948": {
    "doc": "How to fit a linear model to two columns of data",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. This solution uses fake example data. When using this code, replace our fake data with your real data. Although the solution below uses plain Python lists of data, it also works if the data are stored in NumPy arrays or pandas Series. | 1 2 3 4 5 6 7 8 9 10 11 12 13 . | # Here is the fake data you should replace with your real data. xs = [ 393, 453, 553, 679, 729, 748, 817 ] ys = [ 24, 25, 27, 36, 55, 68, 84 ] # We will use statsmodels to build the model import statsmodels.api as sm # statsmodels does not add a constant term to the model unless you request it: xs = sm.add_constant( xs ) # Fit the model and tell us all about it: model = sm.OLS( ys, xs ).fit() model.summary() . | . | 1 2 . | /opt/conda/lib/python3.10/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 7 samples were given. warn(\"omni_normtest is not valid with less than 8 observations; %i \" . | . OLS Regression Results | Dep. Variable: | y | R-squared: | 0.801 | . | Model: | OLS | Adj. R-squared: | 0.761 | . | Method: | Least Squares | F-statistic: | 20.12 | . | Date: | Tue, 08 Nov 2022 | Prob (F-statistic): | 0.00649 | . | Time: | 21:35:13 | Log-Likelihood: | -25.926 | . | No. Observations: | 7 | AIC: | 55.85 | . | Df Residuals: | 5 | BIC: | 55.74 | . | Df Model: | 1 | | | . | Covariance Type: | nonrobust | | | . | | coef | std err | t | P&gt;|t| | [0.025 | 0.975] | . | const | -37.3214 | 18.995 | -1.965 | 0.107 | -86.151 | 11.508 | . | x1 | 0.1327 | 0.030 | 4.485 | 0.006 | 0.057 | 0.209 | . | Omnibus: | nan | Durbin-Watson: | 0.806 | . | Prob(Omnibus): | nan | Jarque-Bera (JB): | 0.520 | . | Skew: | -0.366 | Prob(JB): | 0.771 | . | Kurtosis: | 1.883 | Cond. No. | 2.78e+03 | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 2.78e+03. This might indicate that there arestrong multicollinearity or other numerical problems. The linear model in this example is approximately $\\hat y=0.1327x-37.3214$. Content last modified on 08 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data/#using-statsmodels-in-python",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data/#using-statsmodels-in-python"
  },"949": {
    "doc": "How to fit a linear model to two columns of data",
    "title": "Solution, in R",
    "content": "View this solution alone. This solution uses fake example data. When using this code, replace our fake data with your real data. | 1 2 3 4 5 6 7 8 9 10 11 . | # Here is the fake data you should replace with your real data. xs &lt;- c( 393, 453, 553, 679, 729, 748, 817 ) ys &lt;- c( 24, 25, 27, 36, 55, 68, 84 ) # If you need the model coefficients stored in variables for later use, do: model &lt;- lm( ys ~ xs ) beta0 = model$coefficients[1] beta1 = model$coefficients[2] # If you just need to see the coefficients, do this alone: lm( ys ~ xs ) . | . | 1 2 3 4 5 6 . | Call: lm(formula = ys ~ xs) Coefficients: (Intercept) xs -37.3214 0.1327 . | . The linear model in this example is approximately $y=0.133x-37.32$. Content last modified on 28 May 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data/#solution-in-r",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data/#solution-in-r"
  },"950": {
    "doc": "How to fit a linear model to two columns of data",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | Bentley University MA214 | Bentley University MA252 | . ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data/#topics-that-include-this-task",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data/#topics-that-include-this-task"
  },"951": {
    "doc": "How to fit a linear model to two columns of data",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-fit-a-linear-model-to-two-columns-of-data/#opportunities",
    "relUrl": "/how-to-fit-a-linear-model-to-two-columns-of-data/#opportunities"
  },"952": {
    "doc": "How to fit a multivariate linear model (in Python, using statsmodels)",
    "title": "How to fit a multivariate linear model (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-fit-a-multivariate-linear-model-in-python-using-statsmodels/",
    "relUrl": "/how-to-fit-a-multivariate-linear-model-in-python-using-statsmodels/"
  },"953": {
    "doc": "How to fit a multivariate linear model (in Python, using statsmodels)",
    "title": "Task",
    "content": "Let’s say we have several independent variables, $x_1, x_2, \\ldots, x_k$, and a dependent variable $y$. How can I fit a linear model that uses these independent variables to best predict the dependent variable? . In other words, what are the model coefficients $\\beta_0, \\beta_1, \\beta_2, \\ldots, \\beta_k$ that give me the best linear model $\\hat{y}=\\beta_0 + \\beta_1x + \\beta_2x + \\cdots + \\beta_kx$ based on my data? . Related tasks: . | How to fit a linear model to two columns of data | How to predict the response variable in a linear model | . ",
    "url": "/how-to-fit-a-multivariate-linear-model-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-fit-a-multivariate-linear-model-in-python-using-statsmodels/#task"
  },"954": {
    "doc": "How to fit a multivariate linear model (in Python, using statsmodels)",
    "title": "Solution",
    "content": "We’re going to use fake data here for illustrative purposes. You can replace our fake data with your real data in the code below. We’ll put the data into a dataframe and then make a variable with a list of the independent variables and a variable with the outcome variable. | 1 2 3 4 5 6 7 8 9 10 11 12 . | import pandas as pd # Replace this fake data with your real data df = pd.DataFrame( { 'x1':[2, 7, 4, 3, 11, 18, 6, 15, 9, 12], 'x2':[4, 6, 10, 1, 18, 11, 8, 20, 16, 13], 'x3':[11, 16, 20, 6, 14, 8, 5, 23, 13, 10], 'y':[24, 60, 32, 29, 90, 45, 130, 76, 100, 120] } ) xs = df[['x1', 'x2', 'x3']] # list of independent variables y = df['y'] # dependent variable . | . We can use StatsModels’ OLS to build our multivariate linear model. We’ll print out the coefficients and the intercept, and the coefficients will be in the form of an array when we print them. | 1 2 3 4 5 6 7 8 9 10 . | import statsmodels.api as sm # Add a constant to the dependent variables first xs = sm.add_constant(xs) # Build the model model = sm.OLS(y, xs).fit() # Show the model summary to get the coefficients and the intercept model.summary() . | . | 1 2 3 4 . | /opt/conda/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only x = pd.concat(x[::order], 1) /opt/conda/lib/python3.9/site-packages/scipy/stats/stats.py:1541: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=10 warnings.warn(\"kurtosistest only valid for n&gt;=20 ... continuing \" . | . OLS Regression Results | Dep. Variable: | y | R-squared: | 0.594 | . | Model: | OLS | Adj. R-squared: | 0.390 | . | Method: | Least Squares | F-statistic: | 2.921 | . | Date: | Tue, 07 Dec 2021 | Prob (F-statistic): | 0.122 | . | Time: | 15:07:00 | Log-Likelihood: | -45.689 | . | No. Observations: | 10 | AIC: | 99.38 | . | Df Residuals: | 6 | BIC: | 100.6 | . | Df Model: | 3 | | | . | Covariance Type: | nonrobust | | | . | | coef | std err | t | P&gt;|t| | [0.025 | 0.975] | . | const | 77.2443 | 27.366 | 2.823 | 0.030 | 10.282 | 144.206 | . | x1 | -2.7009 | 2.855 | -0.946 | 0.381 | -9.686 | 4.284 | . | x2 | 7.2989 | 2.875 | 2.539 | 0.044 | 0.265 | 14.333 | . | x3 | -4.8607 | 2.187 | -2.223 | 0.068 | -10.211 | 0.490 | . | Omnibus: | 2.691 | Durbin-Watson: | 2.123 | . | Prob(Omnibus): | 0.260 | Jarque-Bera (JB): | 1.251 | . | Skew: | 0.524 | Prob(JB): | 0.535 | . | Kurtosis: | 1.620 | Cond. No. | 58.2 | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. The coefficients and intercept appear on the left hand side of the output, about half way down, under the heading “coef.” . Thus the multivariate linear model from the example data is $\\hat y = 77.2443 - 2.7009x_1 + 7.2989x_2 - 4.8607x_3$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-fit-a-multivariate-linear-model-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-fit-a-multivariate-linear-model-in-python-using-statsmodels/#solution"
  },"955": {
    "doc": "How to fit a multivariate linear model (in R)",
    "title": "How to fit a multivariate linear model (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-fit-a-multivariate-linear-model-in-r/",
    "relUrl": "/how-to-fit-a-multivariate-linear-model-in-r/"
  },"956": {
    "doc": "How to fit a multivariate linear model (in R)",
    "title": "Task",
    "content": "Let’s say we have several independent variables, $x_1, x_2, \\ldots, x_k$, and a dependent variable $y$. How can I fit a linear model that uses these independent variables to best predict the dependent variable? . In other words, what are the model coefficients $\\beta_0, \\beta_1, \\beta_2, \\ldots, \\beta_k$ that give me the best linear model $\\hat{y}=\\beta_0 + \\beta_1x + \\beta_2x + \\cdots + \\beta_kx$ based on my data? . Related tasks: . | How to fit a linear model to two columns of data | How to predict the response variable in a linear model | . ",
    "url": "/how-to-fit-a-multivariate-linear-model-in-r/#task",
    "relUrl": "/how-to-fit-a-multivariate-linear-model-in-r/#task"
  },"957": {
    "doc": "How to fit a multivariate linear model (in R)",
    "title": "Solution",
    "content": "We’re going to use fake data here for illustrative purposes. You can replace our fake data with your real data in the code below. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 . | # Replace this fake data with your real data x1 &lt;- c(2, 7, 4, 3, 11, 18, 6, 15, 9, 12) x2 &lt;- c(4, 6, 10, 1, 18, 11, 8, 20, 16, 13) x3 &lt;- c(11, 16, 20, 6, 14, 8, 5, 23, 13, 10) y &lt;- c(24, 60, 32, 29, 90, 45, 130, 76, 100, 120) # If you'll need the model coefficients later, store them as variables like this: model &lt;- lm(y ~ x1 + x2 + x3) beta0 &lt;- model$coefficients[1] beta1 &lt;- model$coefficients[2] beta2 &lt;- model$coefficients[3] beta3 &lt;- model$coefficients[4] # To see the model summary, which includes the coefficients and much more, do this: summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 . | Call: lm(formula = y ~ x1 + x2 + x3) Residuals: Min 1Q Median 3Q Max -25.031 -20.218 -8.373 22.937 35.640 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 77.244 27.366 2.823 0.0302 * x1 -2.701 2.855 -0.946 0.3806 x2 7.299 2.875 2.539 0.0441 * x3 -4.861 2.187 -2.223 0.0679 . --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 30.13 on 6 degrees of freedom Multiple R-squared: 0.5936, Adjusted R-squared: 0.3904 F-statistic: 2.921 on 3 and 6 DF, p-value: 0.1222 . | . The coefficients and intercept appear on the left hand side of the output, about half way down, under the heading “Estimate.” . Thus the multivariate linear model from the example data is $\\hat y = 77.244 - 2.701x_1 + 7.299x_2 - 4.861x_3$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-fit-a-multivariate-linear-model-in-r/#solution",
    "relUrl": "/how-to-fit-a-multivariate-linear-model-in-r/#solution"
  },"958": {
    "doc": "How to fit a multivariate linear model",
    "title": "How to fit a multivariate linear model",
    "content": " ",
    "url": "/how-to-fit-a-multivariate-linear-model/",
    "relUrl": "/how-to-fit-a-multivariate-linear-model/"
  },"959": {
    "doc": "How to fit a multivariate linear model",
    "title": "Description",
    "content": "Let’s say we have several independent variables, $x_1, x_2, \\ldots, x_k$, and a dependent variable $y$. How can I fit a linear model that uses these independent variables to best predict the dependent variable? . In other words, what are the model coefficients $\\beta_0, \\beta_1, \\beta_2, \\ldots, \\beta_k$ that give me the best linear model $\\hat{y}=\\beta_0 + \\beta_1x + \\beta_2x + \\cdots + \\beta_kx$ based on my data? . Related tasks: . | How to fit a linear model to two columns of data | How to predict the response variable in a linear model | . ",
    "url": "/how-to-fit-a-multivariate-linear-model/#description",
    "relUrl": "/how-to-fit-a-multivariate-linear-model/#description"
  },"960": {
    "doc": "How to fit a multivariate linear model",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. We’re going to use fake data here for illustrative purposes. You can replace our fake data with your real data in the code below. We’ll put the data into a dataframe and then make a variable with a list of the independent variables and a variable with the outcome variable. | 1 2 3 4 5 6 7 8 9 10 11 12 . | import pandas as pd # Replace this fake data with your real data df = pd.DataFrame( { 'x1':[2, 7, 4, 3, 11, 18, 6, 15, 9, 12], 'x2':[4, 6, 10, 1, 18, 11, 8, 20, 16, 13], 'x3':[11, 16, 20, 6, 14, 8, 5, 23, 13, 10], 'y':[24, 60, 32, 29, 90, 45, 130, 76, 100, 120] } ) xs = df[['x1', 'x2', 'x3']] # list of independent variables y = df['y'] # dependent variable . | . We can use StatsModels’ OLS to build our multivariate linear model. We’ll print out the coefficients and the intercept, and the coefficients will be in the form of an array when we print them. | 1 2 3 4 5 6 7 8 9 10 . | import statsmodels.api as sm # Add a constant to the dependent variables first xs = sm.add_constant(xs) # Build the model model = sm.OLS(y, xs).fit() # Show the model summary to get the coefficients and the intercept model.summary() . | . | 1 2 3 4 . | /opt/conda/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only x = pd.concat(x[::order], 1) /opt/conda/lib/python3.9/site-packages/scipy/stats/stats.py:1541: UserWarning: kurtosistest only valid for n&gt;=20 ... continuing anyway, n=10 warnings.warn(\"kurtosistest only valid for n&gt;=20 ... continuing \" . | . OLS Regression Results | Dep. Variable: | y | R-squared: | 0.594 | . | Model: | OLS | Adj. R-squared: | 0.390 | . | Method: | Least Squares | F-statistic: | 2.921 | . | Date: | Tue, 07 Dec 2021 | Prob (F-statistic): | 0.122 | . | Time: | 15:07:00 | Log-Likelihood: | -45.689 | . | No. Observations: | 10 | AIC: | 99.38 | . | Df Residuals: | 6 | BIC: | 100.6 | . | Df Model: | 3 | | | . | Covariance Type: | nonrobust | | | . | | coef | std err | t | P&gt;|t| | [0.025 | 0.975] | . | const | 77.2443 | 27.366 | 2.823 | 0.030 | 10.282 | 144.206 | . | x1 | -2.7009 | 2.855 | -0.946 | 0.381 | -9.686 | 4.284 | . | x2 | 7.2989 | 2.875 | 2.539 | 0.044 | 0.265 | 14.333 | . | x3 | -4.8607 | 2.187 | -2.223 | 0.068 | -10.211 | 0.490 | . | Omnibus: | 2.691 | Durbin-Watson: | 2.123 | . | Prob(Omnibus): | 0.260 | Jarque-Bera (JB): | 1.251 | . | Skew: | 0.524 | Prob(JB): | 0.535 | . | Kurtosis: | 1.620 | Cond. No. | 58.2 | . Notes:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. The coefficients and intercept appear on the left hand side of the output, about half way down, under the heading “coef.” . Thus the multivariate linear model from the example data is $\\hat y = 77.2443 - 2.7009x_1 + 7.2989x_2 - 4.8607x_3$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-fit-a-multivariate-linear-model/#using-statsmodels-in-python",
    "relUrl": "/how-to-fit-a-multivariate-linear-model/#using-statsmodels-in-python"
  },"961": {
    "doc": "How to fit a multivariate linear model",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use fake data here for illustrative purposes. You can replace our fake data with your real data in the code below. | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 . | # Replace this fake data with your real data x1 &lt;- c(2, 7, 4, 3, 11, 18, 6, 15, 9, 12) x2 &lt;- c(4, 6, 10, 1, 18, 11, 8, 20, 16, 13) x3 &lt;- c(11, 16, 20, 6, 14, 8, 5, 23, 13, 10) y &lt;- c(24, 60, 32, 29, 90, 45, 130, 76, 100, 120) # If you'll need the model coefficients later, store them as variables like this: model &lt;- lm(y ~ x1 + x2 + x3) beta0 &lt;- model$coefficients[1] beta1 &lt;- model$coefficients[2] beta2 &lt;- model$coefficients[3] beta3 &lt;- model$coefficients[4] # To see the model summary, which includes the coefficients and much more, do this: summary(model) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 . | Call: lm(formula = y ~ x1 + x2 + x3) Residuals: Min 1Q Median 3Q Max -25.031 -20.218 -8.373 22.937 35.640 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 77.244 27.366 2.823 0.0302 * x1 -2.701 2.855 -0.946 0.3806 x2 7.299 2.875 2.539 0.0441 * x3 -4.861 2.187 -2.223 0.0679 . --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 30.13 on 6 degrees of freedom Multiple R-squared: 0.5936, Adjusted R-squared: 0.3904 F-statistic: 2.921 on 3 and 6 DF, p-value: 0.1222 . | . The coefficients and intercept appear on the left hand side of the output, about half way down, under the heading “Estimate.” . Thus the multivariate linear model from the example data is $\\hat y = 77.244 - 2.701x_1 + 7.299x_2 - 4.861x_3$. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-fit-a-multivariate-linear-model/#solution-in-r",
    "relUrl": "/how-to-fit-a-multivariate-linear-model/#solution-in-r"
  },"962": {
    "doc": "How to fit a multivariate linear model",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA252 | . ",
    "url": "/how-to-fit-a-multivariate-linear-model/#topics-that-include-this-task",
    "relUrl": "/how-to-fit-a-multivariate-linear-model/#topics-that-include-this-task"
  },"963": {
    "doc": "How to fit a multivariate linear model",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-fit-a-multivariate-linear-model/#opportunities",
    "relUrl": "/how-to-fit-a-multivariate-linear-model/#opportunities"
  },"964": {
    "doc": "How to generate random values from a distribution (in Excel)",
    "title": "How to generate random values from a distribution (in Excel)",
    "content": "See all solutions. ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-excel/",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-excel/"
  },"965": {
    "doc": "How to generate random values from a distribution (in Excel)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to generate random values from a chosen distribution? . Related tasks: . | How to compute probabilities from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-excel/#task",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-excel/#task"
  },"966": {
    "doc": "How to generate random values from a distribution (in Excel)",
    "title": "Solution",
    "content": "You can generate random numbers from many common distributions easily using the Data Analysis Toolpak. (Below we cover another method that does not use the Data Analysis Toolpak.) If you’ve never enabled it before, see these instructions from Microsoft on how to do so. On the Data tab, click the Data Analysis button, shown below. From the list of tools it provides, choose Random Number Generation, as shown below, then click OK. Choose a number of variables (that is, columns of output) and of random numbers (that is, rows of output) and a distribution. Once you select a distribution, you can also select its parameters (e.g., the mean and standard deviation for a normal distribution). Choose where you want the output and then click OK. Here is example data generated for 3 variables, 20 random numbers per variable, using a standard normal distribution. It’s also possible to generate random numbers using Excel formulas in place of the Data Analysis Toolpak. Here’s how: . No matter what distribution you want to draw from, begin by generating random values from the uniform distribution on the interval [0,1] using the =RAND() function. For example, if you’ll want 10 random values, place the =RAND() formula into 10 cells in a single column, like so: . Then in an adjacent column, apply one of the built-in inverse CDF functions from Excel’s statistics function set. For example, to generate values from a normal distribution with mean 5 and standard deviation 2, apply =NORM.INV(_,5,2) to each random number in the first column. The NORM.INV function converts uniform random values into random values chosen from the specified distribution. Excel also has built-in functions for several other distributions, including BETA.INV, BINOM.INV, CHISQ.INV, F.INV, GAMMA.INV, LOGNORM.INV, and T.INV. Excel recomputes random values every time a formula or cell changes. If you do not want this behavior, simply copy all the random cells and then paste them back into the exact same locations, but using the “Paste Values” functionality of Excel, which removes the original formulas, leaving only their final results. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-excel/#solution",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-excel/#solution"
  },"967": {
    "doc": "How to generate random values from a distribution (in Julia)",
    "title": "How to generate random values from a distribution (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-julia/",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-julia/"
  },"968": {
    "doc": "How to generate random values from a distribution (in Julia)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to generate random values from a chosen distribution? . Related tasks: . | How to compute probabilities from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-julia/#task",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-julia/#task"
  },"969": {
    "doc": "How to generate random values from a distribution (in Julia)",
    "title": "Solution",
    "content": "You can import many different random variables from Julia’s Distributions package. The full list of them is online here. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. Regardless of whether the distribution is discrete or continuous, the appropriate function to call is rand. Here are two examples. Using a normal distribution: . | 1 2 3 . | using Distributions X = Normal( 5, 3 ) rand( X, 10 ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | 10-element Vector{Float64}: 3.2984814947222136 3.8868925858958496 11.054518475291347 2.151820027715916 6.288103699884755 4.207026557133198 2.957553317891313 7.192469043513352 4.440336885361706 4.809597919062985 . | . Using a uniform distribution: . In this example, we generate the random values in one line of code, without giving the random variable a name. | 1 2 . | using Distributions rand( Uniform( 100, 200 ), 5 ) . | . | 1 2 3 4 5 6 . | 5-element Vector{Float64}: 147.77637653948742 139.5897785099046 154.48524776533654 141.81989321071512 116.27699388606632 . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-julia/#solution",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-julia/#solution"
  },"970": {
    "doc": "How to generate random values from a distribution (in Python, using SciPy)",
    "title": "How to generate random values from a distribution (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-python-using-scipy/",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-python-using-scipy/"
  },"971": {
    "doc": "How to generate random values from a distribution (in Python, using SciPy)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to generate random values from a chosen distribution? . Related tasks: . | How to compute probabilities from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-python-using-scipy/#task",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-python-using-scipy/#task"
  },"972": {
    "doc": "How to generate random values from a distribution (in Python, using SciPy)",
    "title": "Solution",
    "content": "You can import many different random variables from SciPy’s stats module. The full list of them is online here. Regardless of whether the distribution is discrete or continuous, the appropriate function to call is rvs, which stands for “random values.” Here are two examples. Using a normal distribution: . | 1 2 3 . | from scipy import stats X = stats.norm( 10, 5 ) # normal random variable with μ=10 and σ=5 X.rvs( 20 ) # 20 random values from X . | . | 1 2 3 4 . | array([ 1.13692807, -3.09919844, 13.79356131, 17.84684953, 7.34652953, 5.96476561, 6.23576219, 12.28853107, 10.27890569, 2.09501497, 17.00005655, 4.48580115, 13.15019787, 5.88702913, 0.69611227, 3.91977886, 7.94029598, 17.89184954, 5.30894695, 4.85143363]) . | . Using a uniform distribution: . (Note that in SciPy, the uniform distribution needs a “location,” which is where the sample space begins—in this case 50—and a “scale,” which is the width of the sample space—in this case 10.) . | 1 2 3 . | from scipy import stats X = stats.uniform( 50, 10 ) # uniform random variable on the interval [50,60] X.rvs( 20 ) # 20 random values from X . | . | 1 2 3 4 . | array([55.91662278, 51.49011128, 52.01391463, 50.2982162 , 57.60499819, 53.57351348, 55.85305281, 51.26367314, 56.40196614, 52.4686033 , 55.2603163 , 57.10813614, 54.95842753, 52.03184066, 50.18116328, 51.52196773, 55.10236943, 59.15484043, 56.90184757, 58.04909252]) . | . Content last modified on 27 May 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-python-using-scipy/#solution",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-python-using-scipy/#solution"
  },"973": {
    "doc": "How to generate random values from a distribution (in R)",
    "title": "How to generate random values from a distribution (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-r/",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-r/"
  },"974": {
    "doc": "How to generate random values from a distribution (in R)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to generate random values from a chosen distribution? . Related tasks: . | How to compute probabilities from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-r/#task",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-r/#task"
  },"975": {
    "doc": "How to generate random values from a distribution (in R)",
    "title": "Solution",
    "content": "Because R is designed for use in statistics, it comes with many probability distributions built in. A list of them is online here. Regardless of whether the distribution is discrete or continuous, prefix the name of the distribution with r, which stands for “random values.” Here are two examples. Using a normal distribution: . | 1 2 . | # 20 random values from the normal distribution with μ=10 and σ=5 rnorm( 20, mean=10, sd=5 ) . | . | 1 2 3 . | [1] 10.900996 11.976357 10.050084 12.659541 9.213338 10.347917 7.532614 [8] 11.563255 15.942300 13.378527 8.029759 5.707103 16.132197 -1.686346 [15] 5.930778 5.099380 8.945254 13.480151 18.683996 1.714144 . | . Using a uniform distribution: . | 1 2 . | # 20 random values from the uniform distribution on the interval [50,60] runif( 20, min=50, max=60 ) . | . | 1 2 3 . | [1] 57.95825 50.30892 59.89443 58.67946 59.24075 58.61541 52.79747 51.46903 [9] 54.59619 52.78599 54.41834 55.62009 51.94706 54.79693 55.33611 59.67543 [17] 56.80342 50.73818 59.68497 58.63296 . | . Content last modified on 27 May 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-generate-random-values-from-a-distribution-in-r/#solution",
    "relUrl": "/how-to-generate-random-values-from-a-distribution-in-r/#solution"
  },"976": {
    "doc": "How to generate random values from a distribution",
    "title": "How to generate random values from a distribution",
    "content": " ",
    "url": "/how-to-generate-random-values-from-a-distribution/",
    "relUrl": "/how-to-generate-random-values-from-a-distribution/"
  },"977": {
    "doc": "How to generate random values from a distribution",
    "title": "Description",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to generate random values from a chosen distribution? . Related tasks: . | How to compute probabilities from a distribution | How to plot continuous probability distributions | How to plot discrete probability distributions | . ",
    "url": "/how-to-generate-random-values-from-a-distribution/#description",
    "relUrl": "/how-to-generate-random-values-from-a-distribution/#description"
  },"978": {
    "doc": "How to generate random values from a distribution",
    "title": "Solution, in Excel",
    "content": "View this solution alone. You can generate random numbers from many common distributions easily using the Data Analysis Toolpak. (Below we cover another method that does not use the Data Analysis Toolpak.) If you’ve never enabled it before, see these instructions from Microsoft on how to do so. On the Data tab, click the Data Analysis button, shown below. From the list of tools it provides, choose Random Number Generation, as shown below, then click OK. Choose a number of variables (that is, columns of output) and of random numbers (that is, rows of output) and a distribution. Once you select a distribution, you can also select its parameters (e.g., the mean and standard deviation for a normal distribution). Choose where you want the output and then click OK. Here is example data generated for 3 variables, 20 random numbers per variable, using a standard normal distribution. It’s also possible to generate random numbers using Excel formulas in place of the Data Analysis Toolpak. Here’s how: . No matter what distribution you want to draw from, begin by generating random values from the uniform distribution on the interval [0,1] using the =RAND() function. For example, if you’ll want 10 random values, place the =RAND() formula into 10 cells in a single column, like so: . Then in an adjacent column, apply one of the built-in inverse CDF functions from Excel’s statistics function set. For example, to generate values from a normal distribution with mean 5 and standard deviation 2, apply =NORM.INV(_,5,2) to each random number in the first column. The NORM.INV function converts uniform random values into random values chosen from the specified distribution. Excel also has built-in functions for several other distributions, including BETA.INV, BINOM.INV, CHISQ.INV, F.INV, GAMMA.INV, LOGNORM.INV, and T.INV. Excel recomputes random values every time a formula or cell changes. If you do not want this behavior, simply copy all the random cells and then paste them back into the exact same locations, but using the “Paste Values” functionality of Excel, which removes the original formulas, leaving only their final results. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-generate-random-values-from-a-distribution/#solution-in-excel",
    "relUrl": "/how-to-generate-random-values-from-a-distribution/#solution-in-excel"
  },"979": {
    "doc": "How to generate random values from a distribution",
    "title": "Solution, in Julia",
    "content": "View this solution alone. You can import many different random variables from Julia’s Distributions package. The full list of them is online here. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. Regardless of whether the distribution is discrete or continuous, the appropriate function to call is rand. Here are two examples. Using a normal distribution: . | 1 2 3 . | using Distributions X = Normal( 5, 3 ) rand( X, 10 ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | 10-element Vector{Float64}: 3.2984814947222136 3.8868925858958496 11.054518475291347 2.151820027715916 6.288103699884755 4.207026557133198 2.957553317891313 7.192469043513352 4.440336885361706 4.809597919062985 . | . Using a uniform distribution: . In this example, we generate the random values in one line of code, without giving the random variable a name. | 1 2 . | using Distributions rand( Uniform( 100, 200 ), 5 ) . | . | 1 2 3 4 5 6 . | 5-element Vector{Float64}: 147.77637653948742 139.5897785099046 154.48524776533654 141.81989321071512 116.27699388606632 . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-generate-random-values-from-a-distribution/#solution-in-julia",
    "relUrl": "/how-to-generate-random-values-from-a-distribution/#solution-in-julia"
  },"980": {
    "doc": "How to generate random values from a distribution",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. You can import many different random variables from SciPy’s stats module. The full list of them is online here. Regardless of whether the distribution is discrete or continuous, the appropriate function to call is rvs, which stands for “random values.” Here are two examples. Using a normal distribution: . | 1 2 3 . | from scipy import stats X = stats.norm( 10, 5 ) # normal random variable with μ=10 and σ=5 X.rvs( 20 ) # 20 random values from X . | . | 1 2 3 4 . | array([ 1.13692807, -3.09919844, 13.79356131, 17.84684953, 7.34652953, 5.96476561, 6.23576219, 12.28853107, 10.27890569, 2.09501497, 17.00005655, 4.48580115, 13.15019787, 5.88702913, 0.69611227, 3.91977886, 7.94029598, 17.89184954, 5.30894695, 4.85143363]) . | . Using a uniform distribution: . (Note that in SciPy, the uniform distribution needs a “location,” which is where the sample space begins—in this case 50—and a “scale,” which is the width of the sample space—in this case 10.) . | 1 2 3 . | from scipy import stats X = stats.uniform( 50, 10 ) # uniform random variable on the interval [50,60] X.rvs( 20 ) # 20 random values from X . | . | 1 2 3 4 . | array([55.91662278, 51.49011128, 52.01391463, 50.2982162 , 57.60499819, 53.57351348, 55.85305281, 51.26367314, 56.40196614, 52.4686033 , 55.2603163 , 57.10813614, 54.95842753, 52.03184066, 50.18116328, 51.52196773, 55.10236943, 59.15484043, 56.90184757, 58.04909252]) . | . Content last modified on 27 May 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-generate-random-values-from-a-distribution/#using-scipy-in-python",
    "relUrl": "/how-to-generate-random-values-from-a-distribution/#using-scipy-in-python"
  },"981": {
    "doc": "How to generate random values from a distribution",
    "title": "Solution, in R",
    "content": "View this solution alone. Because R is designed for use in statistics, it comes with many probability distributions built in. A list of them is online here. Regardless of whether the distribution is discrete or continuous, prefix the name of the distribution with r, which stands for “random values.” Here are two examples. Using a normal distribution: . | 1 2 . | # 20 random values from the normal distribution with μ=10 and σ=5 rnorm( 20, mean=10, sd=5 ) . | . | 1 2 3 . | [1] 10.900996 11.976357 10.050084 12.659541 9.213338 10.347917 7.532614 [8] 11.563255 15.942300 13.378527 8.029759 5.707103 16.132197 -1.686346 [15] 5.930778 5.099380 8.945254 13.480151 18.683996 1.714144 . | . Using a uniform distribution: . | 1 2 . | # 20 random values from the uniform distribution on the interval [50,60] runif( 20, min=50, max=60 ) . | . | 1 2 3 . | [1] 57.95825 50.30892 59.89443 58.67946 59.24075 58.61541 52.79747 51.46903 [9] 54.59619 52.78599 54.41834 55.62009 51.94706 54.79693 55.33611 59.67543 [17] 56.80342 50.73818 59.68497 58.63296 . | . Content last modified on 27 May 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-generate-random-values-from-a-distribution/#solution-in-r",
    "relUrl": "/how-to-generate-random-values-from-a-distribution/#solution-in-r"
  },"982": {
    "doc": "How to generate random values from a distribution",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | . ",
    "url": "/how-to-generate-random-values-from-a-distribution/#topics-that-include-this-task",
    "relUrl": "/how-to-generate-random-values-from-a-distribution/#topics-that-include-this-task"
  },"983": {
    "doc": "How to graph a two-variable function as a surface (in Python, using SymPy)",
    "title": "How to graph a two-variable function as a surface (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-graph-a-two-variable-function-as-a-surface-in-python-using-sympy/",
    "relUrl": "/how-to-graph-a-two-variable-function-as-a-surface-in-python-using-sympy/"
  },"984": {
    "doc": "How to graph a two-variable function as a surface (in Python, using SymPy)",
    "title": "Task",
    "content": "Assume we have a mathematical formula in the variables $x$ and $y$ and we would like to plot a graph of it using a 3D coordinate system. Related tasks: . | How to graph mathematical functions | How to graph mathematical sequences | . ",
    "url": "/how-to-graph-a-two-variable-function-as-a-surface-in-python-using-sympy/#task",
    "relUrl": "/how-to-graph-a-two-variable-function-as-a-surface-in-python-using-sympy/#task"
  },"985": {
    "doc": "How to graph a two-variable function as a surface (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . First, we need a two-variable function that we wish to plot. | 1 2 3 . | var( 'x y' ) formula = sin( x**2 + y**2 ) formula . | . $\\displaystyle \\sin{\\left(x^{2} + y^{2} \\right)}$ . You can use plot3d, but you have to import it specifically, because it is not imported by default with the rest of SymPy. | 1 2 . | from sympy.plotting.plot import plot3d plot3d( formula ) . | . | 1 . | &lt;sympy.plotting.plot.Plot at 0x7f76ca409280&gt; . | . Specify the minimum and maximum values for both $x$ and $y$ as follows. In this example, I keep $-\\pi\\leq x\\leq\\pi$ and $-\\frac\\pi2\\leq y\\leq\\frac\\pi2$. | 1 . | plot3d( formula, (x,-pi,pi), (y,-pi/2,pi/2) ) . | . | 1 . | &lt;sympy.plotting.plot.Plot at 0x7f763acebd30&gt; . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-graph-a-two-variable-function-as-a-surface-in-python-using-sympy/#solution",
    "relUrl": "/how-to-graph-a-two-variable-function-as-a-surface-in-python-using-sympy/#solution"
  },"986": {
    "doc": "How to graph a two-variable function as a surface",
    "title": "How to graph a two-variable function as a surface",
    "content": " ",
    "url": "/how-to-graph-a-two-variable-function-as-a-surface/",
    "relUrl": "/how-to-graph-a-two-variable-function-as-a-surface/"
  },"987": {
    "doc": "How to graph a two-variable function as a surface",
    "title": "Description",
    "content": "Assume we have a mathematical formula in the variables $x$ and $y$ and we would like to plot a graph of it using a 3D coordinate system. Related tasks: . | How to graph mathematical functions | How to graph mathematical sequences | . ",
    "url": "/how-to-graph-a-two-variable-function-as-a-surface/#description",
    "relUrl": "/how-to-graph-a-two-variable-function-as-a-surface/#description"
  },"988": {
    "doc": "How to graph a two-variable function as a surface",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . First, we need a two-variable function that we wish to plot. | 1 2 3 . | var( 'x y' ) formula = sin( x**2 + y**2 ) formula . | . $\\displaystyle \\sin{\\left(x^{2} + y^{2} \\right)}$ . You can use plot3d, but you have to import it specifically, because it is not imported by default with the rest of SymPy. | 1 2 . | from sympy.plotting.plot import plot3d plot3d( formula ) . | . | 1 . | &lt;sympy.plotting.plot.Plot at 0x7f76ca409280&gt; . | . Specify the minimum and maximum values for both $x$ and $y$ as follows. In this example, I keep $-\\pi\\leq x\\leq\\pi$ and $-\\frac\\pi2\\leq y\\leq\\frac\\pi2$. | 1 . | plot3d( formula, (x,-pi,pi), (y,-pi/2,pi/2) ) . | . | 1 . | &lt;sympy.plotting.plot.Plot at 0x7f763acebd30&gt; . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-graph-a-two-variable-function-as-a-surface/#using-sympy-in-python",
    "relUrl": "/how-to-graph-a-two-variable-function-as-a-surface/#using-sympy-in-python"
  },"989": {
    "doc": "How to graph a two-variable function as a surface",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-graph-a-two-variable-function-as-a-surface/#topics-that-include-this-task",
    "relUrl": "/how-to-graph-a-two-variable-function-as-a-surface/#topics-that-include-this-task"
  },"990": {
    "doc": "How to graph a two-variable function as a surface",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-graph-a-two-variable-function-as-a-surface/#opportunities",
    "relUrl": "/how-to-graph-a-two-variable-function-as-a-surface/#opportunities"
  },"991": {
    "doc": "How to graph curves that are not functions (in Python, using SymPy)",
    "title": "How to graph curves that are not functions (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-graph-curves-that-are-not-functions-in-python-using-sympy/",
    "relUrl": "/how-to-graph-curves-that-are-not-functions-in-python-using-sympy/"
  },"992": {
    "doc": "How to graph curves that are not functions (in Python, using SymPy)",
    "title": "Task",
    "content": "Assume we have an equation in which $y$ cannot be isolated as a function of $x$. (The standard example is the formula for the unit circle, $x^2+y^2=1$.) We would still like to be able to use software to plot such curves. How? . Related tasks: . | How to graph mathematical functions | How to do implicit differentiation | . ",
    "url": "/how-to-graph-curves-that-are-not-functions-in-python-using-sympy/#task",
    "relUrl": "/how-to-graph-curves-that-are-not-functions-in-python-using-sympy/#task"
  },"993": {
    "doc": "How to graph curves that are not functions (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s consider the example of the unit circle, $x^2+y^2=1$. To plot it, SymPy first expects us to move everything to the left-hand side of the equation, so in this case, we would have $x^2+y^2-1=0$. We then use that left hand side to represent the equation as a single formula, and we can plot it with SymPy’s plot_implicit function. | 1 2 3 . | var( 'x y' ) formula = x**2 + y**2 - 1 # to represent x^2+y^2=1 plot_implicit( formula ) . | . | 1 . | &lt;sympy.plotting.plot.Plot at 0x7f10dbd7d130&gt; . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-graph-curves-that-are-not-functions-in-python-using-sympy/#solution",
    "relUrl": "/how-to-graph-curves-that-are-not-functions-in-python-using-sympy/#solution"
  },"994": {
    "doc": "How to graph curves that are not functions",
    "title": "How to graph curves that are not functions",
    "content": " ",
    "url": "/how-to-graph-curves-that-are-not-functions/",
    "relUrl": "/how-to-graph-curves-that-are-not-functions/"
  },"995": {
    "doc": "How to graph curves that are not functions",
    "title": "Description",
    "content": "Assume we have an equation in which $y$ cannot be isolated as a function of $x$. (The standard example is the formula for the unit circle, $x^2+y^2=1$.) We would still like to be able to use software to plot such curves. How? . Related tasks: . | How to graph mathematical functions | How to do implicit differentiation | . ",
    "url": "/how-to-graph-curves-that-are-not-functions/#description",
    "relUrl": "/how-to-graph-curves-that-are-not-functions/#description"
  },"996": {
    "doc": "How to graph curves that are not functions",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s consider the example of the unit circle, $x^2+y^2=1$. To plot it, SymPy first expects us to move everything to the left-hand side of the equation, so in this case, we would have $x^2+y^2-1=0$. We then use that left hand side to represent the equation as a single formula, and we can plot it with SymPy’s plot_implicit function. | 1 2 3 . | var( 'x y' ) formula = x**2 + y**2 - 1 # to represent x^2+y^2=1 plot_implicit( formula ) . | . | 1 . | &lt;sympy.plotting.plot.Plot at 0x7f10dbd7d130&gt; . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-graph-curves-that-are-not-functions/#using-sympy-in-python",
    "relUrl": "/how-to-graph-curves-that-are-not-functions/#using-sympy-in-python"
  },"997": {
    "doc": "How to graph curves that are not functions",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-graph-curves-that-are-not-functions/#topics-that-include-this-task",
    "relUrl": "/how-to-graph-curves-that-are-not-functions/#topics-that-include-this-task"
  },"998": {
    "doc": "How to graph curves that are not functions",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-graph-curves-that-are-not-functions/#opportunities",
    "relUrl": "/how-to-graph-curves-that-are-not-functions/#opportunities"
  },"999": {
    "doc": "How to graph mathematical functions (in Python, using NumPy and Matplotlib)",
    "title": "How to graph mathematical functions (in Python, using NumPy and Matplotlib)",
    "content": "See all solutions. ",
    "url": "/how-to-graph-mathematical-functions-in-python-using-numpy-and-matplotlib/",
    "relUrl": "/how-to-graph-mathematical-functions-in-python-using-numpy-and-matplotlib/"
  },"1000": {
    "doc": "How to graph mathematical functions (in Python, using NumPy and Matplotlib)",
    "title": "Task",
    "content": "Assume we have a mathematical formula and we would like to plot a graph of it using the standard Cartesian coordinate system. Related tasks: . | How to graph curves that are not functions | How to graph mathematical sequences | How to graph a two-variable function as a surface | . ",
    "url": "/how-to-graph-mathematical-functions-in-python-using-numpy-and-matplotlib/#task",
    "relUrl": "/how-to-graph-mathematical-functions-in-python-using-numpy-and-matplotlib/#task"
  },"1001": {
    "doc": "How to graph mathematical functions (in Python, using NumPy and Matplotlib)",
    "title": "Solution",
    "content": "Let’s assume we want to graph the function $x^2-5x+9$ from $x=-10$ to $x=10$. Let’s import NumPy for the mathematics and Matplotlib for the graph. | 1 2 . | import numpy as np import matplotlib.pyplot as plt . | . We compute a series of $(x,y)$ pairs to generate the plot. Notice how NumPy automatically computes a $y$ value for each $x$ value if we just include all the $x$s in the formula we wish to graph. | 1 2 3 4 . | xs = np.linspace( -10, 10, 100 ) # 100 values from x=-10 to x=10 ys = xs**2 - 5*xs + 9 # compute all corresponding ys plt.plot( xs, ys ) plt.show() . | . You can also plot more than one function on the same graph. | 1 2 3 4 . | ys2 = 10*np.sin(xs) + 20 # ys for the formula y=10sin(x)+20 plt.plot( xs, ys ) # make the original plot plt.plot( xs, ys2 ) # add the second plot to it plt.show() . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-graph-mathematical-functions-in-python-using-numpy-and-matplotlib/#solution",
    "relUrl": "/how-to-graph-mathematical-functions-in-python-using-numpy-and-matplotlib/#solution"
  },"1002": {
    "doc": "How to graph mathematical functions (in Python, using SymPy)",
    "title": "How to graph mathematical functions (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-graph-mathematical-functions-in-python-using-sympy/",
    "relUrl": "/how-to-graph-mathematical-functions-in-python-using-sympy/"
  },"1003": {
    "doc": "How to graph mathematical functions (in Python, using SymPy)",
    "title": "Task",
    "content": "Assume we have a mathematical formula and we would like to plot a graph of it using the standard Cartesian coordinate system. Related tasks: . | How to graph curves that are not functions | How to graph mathematical sequences | How to graph a two-variable function as a surface | . ",
    "url": "/how-to-graph-mathematical-functions-in-python-using-sympy/#task",
    "relUrl": "/how-to-graph-mathematical-functions-in-python-using-sympy/#task"
  },"1004": {
    "doc": "How to graph mathematical functions (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . You can write a formula and plot it in just a few lines of code. | 1 2 3 . | var( 'x' ) formula = x**2 - 5*x + 9 plot( formula ) . | . | 1 . | &lt;sympy.plotting.plot.Plot at 0x7f42e07651c0&gt; . | . If you want to elimiate the extra bit of text after the graph, just assign the plot to a variable, as in p = plot( formula ). You can also plot more than one function on the same graph. | 1 2 . | formula2 = 10*sin(x) + 20 plot( formula, formula2 ) . | . | 1 . | &lt;sympy.plotting.plot.Plot at 0x7f42f06383d0&gt; . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-graph-mathematical-functions-in-python-using-sympy/#solution",
    "relUrl": "/how-to-graph-mathematical-functions-in-python-using-sympy/#solution"
  },"1005": {
    "doc": "How to graph mathematical functions (in R)",
    "title": "How to graph mathematical functions (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-graph-mathematical-functions-in-r/",
    "relUrl": "/how-to-graph-mathematical-functions-in-r/"
  },"1006": {
    "doc": "How to graph mathematical functions (in R)",
    "title": "Task",
    "content": "Assume we have a mathematical formula and we would like to plot a graph of it using the standard Cartesian coordinate system. Related tasks: . | How to graph curves that are not functions | How to graph mathematical sequences | How to graph a two-variable function as a surface | . ",
    "url": "/how-to-graph-mathematical-functions-in-r/#task",
    "relUrl": "/how-to-graph-mathematical-functions-in-r/#task"
  },"1007": {
    "doc": "How to graph mathematical functions (in R)",
    "title": "Solution",
    "content": "Let’s assume we want to graph the function $x^2-5x+9$ from $x=-10$ to $x=10$. We compute a series of $(x,y)$ pairs to generate the plot. Notice how R automatically computes a $y$ value for each $x$ value if we just include all the $x$s in the formula we wish to graph. | 1 2 3 . | xs &lt;- seq(-10,10,length.out=100) # 100 values from x=-10 to x=10 ys &lt;- xs^2 - 5*xs + 9 # compute all corresponding ys plot( xs, ys, type='l' ) . | . You can also plot more than one function on the same graph. | 1 2 3 . | ys2 &lt;- 10*sin(xs) + 20 # ys for the formula y=10sin(x)+20 plot( xs, ys, type='l' ) # make the original plot lines( xs, ys2 ) # add the second plot to it . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-graph-mathematical-functions-in-r/#solution",
    "relUrl": "/how-to-graph-mathematical-functions-in-r/#solution"
  },"1008": {
    "doc": "How to graph mathematical functions",
    "title": "How to graph mathematical functions",
    "content": " ",
    "url": "/how-to-graph-mathematical-functions/",
    "relUrl": "/how-to-graph-mathematical-functions/"
  },"1009": {
    "doc": "How to graph mathematical functions",
    "title": "Description",
    "content": "Assume we have a mathematical formula and we would like to plot a graph of it using the standard Cartesian coordinate system. Related tasks: . | How to graph curves that are not functions | How to graph mathematical sequences | How to graph a two-variable function as a surface | . ",
    "url": "/how-to-graph-mathematical-functions/#description",
    "relUrl": "/how-to-graph-mathematical-functions/#description"
  },"1010": {
    "doc": "How to graph mathematical functions",
    "title": "Using NumPy and Matplotlib, in Python",
    "content": "View this solution alone. Let’s assume we want to graph the function $x^2-5x+9$ from $x=-10$ to $x=10$. Let’s import NumPy for the mathematics and Matplotlib for the graph. | 1 2 . | import numpy as np import matplotlib.pyplot as plt . | . We compute a series of $(x,y)$ pairs to generate the plot. Notice how NumPy automatically computes a $y$ value for each $x$ value if we just include all the $x$s in the formula we wish to graph. | 1 2 3 4 . | xs = np.linspace( -10, 10, 100 ) # 100 values from x=-10 to x=10 ys = xs**2 - 5*xs + 9 # compute all corresponding ys plt.plot( xs, ys ) plt.show() . | . You can also plot more than one function on the same graph. | 1 2 3 4 . | ys2 = 10*np.sin(xs) + 20 # ys for the formula y=10sin(x)+20 plt.plot( xs, ys ) # make the original plot plt.plot( xs, ys2 ) # add the second plot to it plt.show() . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-graph-mathematical-functions/#using-numpy-and-matplotlib-in-python",
    "relUrl": "/how-to-graph-mathematical-functions/#using-numpy-and-matplotlib-in-python"
  },"1011": {
    "doc": "How to graph mathematical functions",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . You can write a formula and plot it in just a few lines of code. | 1 2 3 . | var( 'x' ) formula = x**2 - 5*x + 9 plot( formula ) . | . | 1 . | &lt;sympy.plotting.plot.Plot at 0x7f42e07651c0&gt; . | . If you want to elimiate the extra bit of text after the graph, just assign the plot to a variable, as in p = plot( formula ). You can also plot more than one function on the same graph. | 1 2 . | formula2 = 10*sin(x) + 20 plot( formula, formula2 ) . | . | 1 . | &lt;sympy.plotting.plot.Plot at 0x7f42f06383d0&gt; . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-graph-mathematical-functions/#using-sympy-in-python",
    "relUrl": "/how-to-graph-mathematical-functions/#using-sympy-in-python"
  },"1012": {
    "doc": "How to graph mathematical functions",
    "title": "Solution, in R",
    "content": "View this solution alone. Let’s assume we want to graph the function $x^2-5x+9$ from $x=-10$ to $x=10$. We compute a series of $(x,y)$ pairs to generate the plot. Notice how R automatically computes a $y$ value for each $x$ value if we just include all the $x$s in the formula we wish to graph. | 1 2 3 . | xs &lt;- seq(-10,10,length.out=100) # 100 values from x=-10 to x=10 ys &lt;- xs^2 - 5*xs + 9 # compute all corresponding ys plot( xs, ys, type='l' ) . | . You can also plot more than one function on the same graph. | 1 2 3 . | ys2 &lt;- 10*sin(xs) + 20 # ys for the formula y=10sin(x)+20 plot( xs, ys, type='l' ) # make the original plot lines( xs, ys2 ) # add the second plot to it . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-graph-mathematical-functions/#solution-in-r",
    "relUrl": "/how-to-graph-mathematical-functions/#solution-in-r"
  },"1013": {
    "doc": "How to graph mathematical functions",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-graph-mathematical-functions/#topics-that-include-this-task",
    "relUrl": "/how-to-graph-mathematical-functions/#topics-that-include-this-task"
  },"1014": {
    "doc": "How to graph mathematical functions",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-graph-mathematical-functions/#opportunities",
    "relUrl": "/how-to-graph-mathematical-functions/#opportunities"
  },"1015": {
    "doc": "How to graph mathematical sequences (in Python, using SymPy and Matplotlib)",
    "title": "How to graph mathematical sequences (in Python, using SymPy and Matplotlib)",
    "content": "See all solutions. ",
    "url": "/how-to-graph-mathematical-sequences-in-python-using-sympy-and-matplotlib/",
    "relUrl": "/how-to-graph-mathematical-sequences-in-python-using-sympy-and-matplotlib/"
  },"1016": {
    "doc": "How to graph mathematical sequences (in Python, using SymPy and Matplotlib)",
    "title": "Task",
    "content": "Assume we have a mathematical sequence $a_0,a_1,a_2,\\ldots$ and we would like to plot a graph of it using the standard Cartesian coordinate system. The result will not look like a curve, because a sequence is separate points instead of a smooth curve. Related tasks: . | How to graph mathematical functions | How to define a mathematical sequence | . ",
    "url": "/how-to-graph-mathematical-sequences-in-python-using-sympy-and-matplotlib/#task",
    "relUrl": "/how-to-graph-mathematical-sequences-in-python-using-sympy-and-matplotlib/#task"
  },"1017": {
    "doc": "How to graph mathematical sequences (in Python, using SymPy and Matplotlib)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . We will re-use the sequence defined in the task how to define a mathematical sequence. | 1 2 3 4 . | var( 'n' ) a_n = 1 / ( n + 1 ) seq = sequence( a_n, (n,0,oo) ) seq . | . $\\displaystyle \\left[1, \\frac{1}{2}, \\frac{1}{3}, \\frac{1}{4}, \\ldots\\right]$ . We can graph any finite range of any sequence as follows. | 1 2 3 4 5 . | start = 0 stop = 10 import matplotlib.pyplot as plt plt.plot( range(start,stop+1), seq[start:stop+1], '.' ) plt.show() . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-graph-mathematical-sequences-in-python-using-sympy-and-matplotlib/#solution",
    "relUrl": "/how-to-graph-mathematical-sequences-in-python-using-sympy-and-matplotlib/#solution"
  },"1018": {
    "doc": "How to graph mathematical sequences",
    "title": "How to graph mathematical sequences",
    "content": " ",
    "url": "/how-to-graph-mathematical-sequences/",
    "relUrl": "/how-to-graph-mathematical-sequences/"
  },"1019": {
    "doc": "How to graph mathematical sequences",
    "title": "Description",
    "content": "Assume we have a mathematical sequence $a_0,a_1,a_2,\\ldots$ and we would like to plot a graph of it using the standard Cartesian coordinate system. The result will not look like a curve, because a sequence is separate points instead of a smooth curve. Related tasks: . | How to graph mathematical functions | How to define a mathematical sequence | . ",
    "url": "/how-to-graph-mathematical-sequences/#description",
    "relUrl": "/how-to-graph-mathematical-sequences/#description"
  },"1020": {
    "doc": "How to graph mathematical sequences",
    "title": "Using SymPy and Matplotlib, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . We will re-use the sequence defined in the task how to define a mathematical sequence. | 1 2 3 4 . | var( 'n' ) a_n = 1 / ( n + 1 ) seq = sequence( a_n, (n,0,oo) ) seq . | . $\\displaystyle \\left[1, \\frac{1}{2}, \\frac{1}{3}, \\frac{1}{4}, \\ldots\\right]$ . We can graph any finite range of any sequence as follows. | 1 2 3 4 5 . | start = 0 stop = 10 import matplotlib.pyplot as plt plt.plot( range(start,stop+1), seq[start:stop+1], '.' ) plt.show() . | . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-graph-mathematical-sequences/#using-sympy-and-matplotlib-in-python",
    "relUrl": "/how-to-graph-mathematical-sequences/#using-sympy-and-matplotlib-in-python"
  },"1021": {
    "doc": "How to graph mathematical sequences",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-graph-mathematical-sequences/#topics-that-include-this-task",
    "relUrl": "/how-to-graph-mathematical-sequences/#topics-that-include-this-task"
  },"1022": {
    "doc": "How to graph mathematical sequences",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-graph-mathematical-sequences/#opportunities",
    "relUrl": "/how-to-graph-mathematical-sequences/#opportunities"
  },"1023": {
    "doc": "How to isolate one variable in an equation (in Python, using SymPy)",
    "title": "How to isolate one variable in an equation (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-isolate-one-variable-in-an-equation-in-python-using-sympy/",
    "relUrl": "/how-to-isolate-one-variable-in-an-equation-in-python-using-sympy/"
  },"1024": {
    "doc": "How to isolate one variable in an equation (in Python, using SymPy)",
    "title": "Task",
    "content": "Once we’ve expressed an equation or system of equations using the technique from how to write symbolic equations, we often want the software to isolate one variable in terms of all the others. Related tasks: . | How to solve symbolic equations | . ",
    "url": "/how-to-isolate-one-variable-in-an-equation-in-python-using-sympy/#task",
    "relUrl": "/how-to-isolate-one-variable-in-an-equation-in-python-using-sympy/#task"
  },"1025": {
    "doc": "How to isolate one variable in an equation (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s create an equation with many variables. | 1 2 3 . | var('P V n R T') ideal_gas_law = Eq( P*V, n*R*T ) ideal_gas_law . | . $\\displaystyle P V = R T n$ . To isolate one variable, call the solve function, and pass that variable as the second argument. | 1 . | solve( ideal_gas_law, R ) . | . $\\displaystyle \\left[ \\frac{P V}{T n}\\right]$ . The brackets surround a list of all solutions—in this case, just one. That solution is that $R=\\frac{PV}{Tn}$. Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-isolate-one-variable-in-an-equation-in-python-using-sympy/#solution",
    "relUrl": "/how-to-isolate-one-variable-in-an-equation-in-python-using-sympy/#solution"
  },"1026": {
    "doc": "How to isolate one variable in an equation",
    "title": "How to isolate one variable in an equation",
    "content": " ",
    "url": "/how-to-isolate-one-variable-in-an-equation/",
    "relUrl": "/how-to-isolate-one-variable-in-an-equation/"
  },"1027": {
    "doc": "How to isolate one variable in an equation",
    "title": "Description",
    "content": "Once we’ve expressed an equation or system of equations using the technique from how to write symbolic equations, we often want the software to isolate one variable in terms of all the others. Related tasks: . | How to solve symbolic equations | . ",
    "url": "/how-to-isolate-one-variable-in-an-equation/#description",
    "relUrl": "/how-to-isolate-one-variable-in-an-equation/#description"
  },"1028": {
    "doc": "How to isolate one variable in an equation",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s create an equation with many variables. | 1 2 3 . | var('P V n R T') ideal_gas_law = Eq( P*V, n*R*T ) ideal_gas_law . | . $\\displaystyle P V = R T n$ . To isolate one variable, call the solve function, and pass that variable as the second argument. | 1 . | solve( ideal_gas_law, R ) . | . $\\displaystyle \\left[ \\frac{P V}{T n}\\right]$ . The brackets surround a list of all solutions—in this case, just one. That solution is that $R=\\frac{PV}{Tn}$. Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-isolate-one-variable-in-an-equation/#using-sympy-in-python",
    "relUrl": "/how-to-isolate-one-variable-in-an-equation/#using-sympy-in-python"
  },"1029": {
    "doc": "How to isolate one variable in an equation",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-isolate-one-variable-in-an-equation/#topics-that-include-this-task",
    "relUrl": "/how-to-isolate-one-variable-in-an-equation/#topics-that-include-this-task"
  },"1030": {
    "doc": "How to isolate one variable in an equation",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-isolate-one-variable-in-an-equation/#opportunities",
    "relUrl": "/how-to-isolate-one-variable-in-an-equation/#opportunities"
  },"1031": {
    "doc": "How to perform a chi-squared test on a contingency table (in Julia)",
    "title": "How to perform a chi-squared test on a contingency table (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-julia/",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-julia/"
  },"1032": {
    "doc": "How to perform a chi-squared test on a contingency table (in Julia)",
    "title": "Task",
    "content": "If we have a contingency table showing the frequencies observed in two categorical variables, how can we run a $\\chi^2$ test to see if the two variables are independent? . ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-julia/#task",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-julia/#task"
  },"1033": {
    "doc": "How to perform a chi-squared test on a contingency table (in Julia)",
    "title": "Solution",
    "content": "Here we will use a two-dimensional Julia array to store a contingency table of education vs. gender, taken from Penn State University’s online stats review website. You should use your own data. | 1 2 3 4 5 . | data = [ # HS BS MS Phd 60 54 46 41 # females 40 44 53 57 # males ] . | . | 1 2 3 . | 2×4 Matrix{Int64}: 60 54 46 41 40 44 53 57 . | . The $\\chi^2$ test’s null hypothesis is that the two variables are independent. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 . | alpha = 0.05 # or choose your own alpha here using HypothesisTests p_value = pvalue( ChisqTest( data ) ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.04588650089174742, true) . | . In this case, the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.05$ level. The data suggest that the two categorical variables are not independent. If you are using the most common $\\alpha$ value of $0.05$, you can save a few lines of code and get more output by just writing the test itself: . | 1 . | ChisqTest( data ) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 . | Pearson's Chi-square Test ------------------------- Population details: parameter of interest: Multinomial Probabilities value under h_0: [0.128826, 0.124339, 0.126249, 0.121852, 0.127537, 0.123096, 0.126249, 0.121852] point estimate: [0.151899, 0.101266, 0.136709, 0.111392, 0.116456, 0.134177, 0.103797, 0.144304] 95% confidence interval: [(0.1089, 0.1978), (0.05823, 0.1472), (0.09367, 0.1826), (0.06835, 0.1573), (0.07342, 0.1624), (0.09114, 0.1801), (0.06076, 0.1497), (0.1013, 0.1902)] Test summary: outcome with 95% confidence: reject h_0 one-sided p-value: 0.0459 Details: Sample size: 395 statistic: 8.006066246262527 degrees of freedom: 3 residuals: [1.27763, -1.30048, 0.585074, -0.595536, -0.61671, 0.627737, -1.25583, 1.27828] std. residuals: [2.10956, -2.10956, 0.962783, -0.962783, -1.01656, 1.01656, -2.06656, 2.06656] . | . Content last modified on 05 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-julia/#solution",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-julia/#solution"
  },"1034": {
    "doc": "How to perform a chi-squared test on a contingency table (in Python, using SciPy)",
    "title": "How to perform a chi-squared test on a contingency table (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-python-using-scipy/",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-python-using-scipy/"
  },"1035": {
    "doc": "How to perform a chi-squared test on a contingency table (in Python, using SciPy)",
    "title": "Task",
    "content": "If we have a contingency table showing the frequencies observed in two categorical variables, how can we run a $\\chi^2$ test to see if the two variables are independent? . ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-python-using-scipy/#task",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-python-using-scipy/#task"
  },"1036": {
    "doc": "How to perform a chi-squared test on a contingency table (in Python, using SciPy)",
    "title": "Solution",
    "content": "Here we will use nested Python lists to store a contingency table of education vs. gender, taken from Penn State University’s online stats review website. You should use your own data, and it can be in Python lists or NumPy arrays or a pandas DataFrame. | 1 2 3 4 5 . | data = [ # HS BS MS Phd [ 60, 54, 46, 41 ], # females [ 40, 44, 53, 57 ] # males ] . | . The $\\chi^2$ test’s null hypothesis is that the two variables are independent. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). SciPy’s stats package provides a chi2_contingency function that does exactly what we need. | 1 2 3 4 5 6 7 8 9 . | alpha = 0.05 # or choose your own alpha here from scipy import stats # Run a chi-squared and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. # (The dof and ex variables are values we don't need here.) chi2_statistic, p_value, dof, ex = stats.chi2_contingency( data ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.045886500891747214, True) . | . In this case, the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.05$ level. The data suggest that the two categorical variables are not independent. Content last modified on 28 May 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-python-using-scipy/#solution",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-python-using-scipy/#solution"
  },"1037": {
    "doc": "How to perform a chi-squared test on a contingency table (in R)",
    "title": "How to perform a chi-squared test on a contingency table (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-r/",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-r/"
  },"1038": {
    "doc": "How to perform a chi-squared test on a contingency table (in R)",
    "title": "Task",
    "content": "If we have a contingency table showing the frequencies observed in two categorical variables, how can we run a $\\chi^2$ test to see if the two variables are independent? . ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-r/#task",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-r/#task"
  },"1039": {
    "doc": "How to perform a chi-squared test on a contingency table (in R)",
    "title": "Solution",
    "content": "Here we will use a $2\\times4$ matrix to store a contingency table of education vs. gender, taken from Penn State University’s online stats review website. You should use your own data. (Note: R’s table function is useful for creating contingency tables from data.) . | 1 2 3 4 . | data &lt;- matrix( c( 60, 54, 46, 41, 40, 44, 53, 57 ), ncol = 4, dimnames=list( c('F','M'), c('HS','BS','MS','PhD') ), byrow =TRUE) data . | . | 1 2 3 . | HS BS MS PhD F 60 54 46 41 M 40 44 53 57 . | . The $\\chi^2$ test’s null hypothesis is that the two variables are independent. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). R provides a chisq.test function that does exactly what we need. | 1 2 . | results &lt;- chisq.test( data ) results . | . | 1 2 3 4 . | Pearson's Chi-squared test data: data X-squared = 8.0061, df = 3, p-value = 0.04589 . | . We can manually compare the $p$-value to an $\\alpha$ we’ve chosen, or ask R to do it. | 1 2 . | alpha &lt;- 0.05 # or choose your own alpha here results$p.value &lt; alpha # reject the null hypothesis? . | . | 1 . | [1] TRUE . | . Content last modified on 16 September 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-r/#solution",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table-in-r/#solution"
  },"1040": {
    "doc": "How to perform a chi-squared test on a contingency table",
    "title": "How to perform a chi-squared test on a contingency table",
    "content": " ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/"
  },"1041": {
    "doc": "How to perform a chi-squared test on a contingency table",
    "title": "Description",
    "content": "If we have a contingency table showing the frequencies observed in two categorical variables, how can we run a $\\chi^2$ test to see if the two variables are independent? . ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#description",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#description"
  },"1042": {
    "doc": "How to perform a chi-squared test on a contingency table",
    "title": "Solution, in Julia",
    "content": "View this solution alone. Here we will use a two-dimensional Julia array to store a contingency table of education vs. gender, taken from Penn State University’s online stats review website. You should use your own data. | 1 2 3 4 5 . | data = [ # HS BS MS Phd 60 54 46 41 # females 40 44 53 57 # males ] . | . | 1 2 3 . | 2×4 Matrix{Int64}: 60 54 46 41 40 44 53 57 . | . The $\\chi^2$ test’s null hypothesis is that the two variables are independent. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). | 1 2 3 4 5 6 . | alpha = 0.05 # or choose your own alpha here using HypothesisTests p_value = pvalue( ChisqTest( data ) ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.04588650089174742, true) . | . In this case, the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.05$ level. The data suggest that the two categorical variables are not independent. If you are using the most common $\\alpha$ value of $0.05$, you can save a few lines of code and get more output by just writing the test itself: . | 1 . | ChisqTest( data ) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 . | Pearson's Chi-square Test ------------------------- Population details: parameter of interest: Multinomial Probabilities value under h_0: [0.128826, 0.124339, 0.126249, 0.121852, 0.127537, 0.123096, 0.126249, 0.121852] point estimate: [0.151899, 0.101266, 0.136709, 0.111392, 0.116456, 0.134177, 0.103797, 0.144304] 95% confidence interval: [(0.1089, 0.1978), (0.05823, 0.1472), (0.09367, 0.1826), (0.06835, 0.1573), (0.07342, 0.1624), (0.09114, 0.1801), (0.06076, 0.1497), (0.1013, 0.1902)] Test summary: outcome with 95% confidence: reject h_0 one-sided p-value: 0.0459 Details: Sample size: 395 statistic: 8.006066246262527 degrees of freedom: 3 residuals: [1.27763, -1.30048, 0.585074, -0.595536, -0.61671, 0.627737, -1.25583, 1.27828] std. residuals: [2.10956, -2.10956, 0.962783, -0.962783, -1.01656, 1.01656, -2.06656, 2.06656] . | . Content last modified on 05 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#solution-in-julia",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#solution-in-julia"
  },"1043": {
    "doc": "How to perform a chi-squared test on a contingency table",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. Here we will use nested Python lists to store a contingency table of education vs. gender, taken from Penn State University’s online stats review website. You should use your own data, and it can be in Python lists or NumPy arrays or a pandas DataFrame. | 1 2 3 4 5 . | data = [ # HS BS MS Phd [ 60, 54, 46, 41 ], # females [ 40, 44, 53, 57 ] # males ] . | . The $\\chi^2$ test’s null hypothesis is that the two variables are independent. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). SciPy’s stats package provides a chi2_contingency function that does exactly what we need. | 1 2 3 4 5 6 7 8 9 . | alpha = 0.05 # or choose your own alpha here from scipy import stats # Run a chi-squared and print out alpha, the p value, # and whether the comparison says to reject the null hypothesis. # (The dof and ex variables are values we don't need here.) chi2_statistic, p_value, dof, ex = stats.chi2_contingency( data ) reject_H0 = p_value &lt; alpha alpha, p_value, reject_H0 . | . | 1 . | (0.05, 0.045886500891747214, True) . | . In this case, the samples give us enough evidence to reject the null hypothesis at the $\\alpha=0.05$ level. The data suggest that the two categorical variables are not independent. Content last modified on 28 May 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#using-scipy-in-python",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#using-scipy-in-python"
  },"1044": {
    "doc": "How to perform a chi-squared test on a contingency table",
    "title": "Solution, in R",
    "content": "View this solution alone. Here we will use a $2\\times4$ matrix to store a contingency table of education vs. gender, taken from Penn State University’s online stats review website. You should use your own data. (Note: R’s table function is useful for creating contingency tables from data.) . | 1 2 3 4 . | data &lt;- matrix( c( 60, 54, 46, 41, 40, 44, 53, 57 ), ncol = 4, dimnames=list( c('F','M'), c('HS','BS','MS','PhD') ), byrow =TRUE) data . | . | 1 2 3 . | HS BS MS PhD F 60 54 46 41 M 40 44 53 57 . | . The $\\chi^2$ test’s null hypothesis is that the two variables are independent. We choose a value $0\\leq\\alpha\\leq1$ as the probability of a Type I error (false positive, finding we should reject $H_0$ when it’s actually true). R provides a chisq.test function that does exactly what we need. | 1 2 . | results &lt;- chisq.test( data ) results . | . | 1 2 3 4 . | Pearson's Chi-squared test data: data X-squared = 8.0061, df = 3, p-value = 0.04589 . | . We can manually compare the $p$-value to an $\\alpha$ we’ve chosen, or ask R to do it. | 1 2 . | alpha &lt;- 0.05 # or choose your own alpha here results$p.value &lt; alpha # reject the null hypothesis? . | . | 1 . | [1] TRUE . | . Content last modified on 16 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#solution-in-r",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#solution-in-r"
  },"1045": {
    "doc": "How to perform a chi-squared test on a contingency table",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR521 | Bentley University MA214 | . ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#topics-that-include-this-task",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#topics-that-include-this-task"
  },"1046": {
    "doc": "How to perform a chi-squared test on a contingency table",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#opportunities",
    "relUrl": "/how-to-perform-a-chi-squared-test-on-a-contingency-table/#opportunities"
  },"1047": {
    "doc": "How to perform a planned comparison test (in R, using gmodels)",
    "title": "How to perform a planned comparison test (in R, using gmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-a-planned-comparison-test-in-r-using-gmodels/",
    "relUrl": "/how-to-perform-a-planned-comparison-test-in-r-using-gmodels/"
  },"1048": {
    "doc": "How to perform a planned comparison test (in R, using gmodels)",
    "title": "Task",
    "content": "Suppose that ANOVA reveals a significant difference between treatment levels, and you wish to explore further through post hoc analysis by comparing two specific treatment levels. How can we perform perform planned comparisons, also called a contrast test? . ",
    "url": "/how-to-perform-a-planned-comparison-test-in-r-using-gmodels/#task",
    "relUrl": "/how-to-perform-a-planned-comparison-test-in-r-using-gmodels/#task"
  },"1049": {
    "doc": "How to perform a planned comparison test (in R, using gmodels)",
    "title": "Solution",
    "content": "Usually, you have data you wish to compare, but we will use example data here. We load the “oats” dataset from R’s MASS package, about the yield of oats from a split-plot field trial using three varieties (V) and four levels of manurial treatment (N). The experiment was laid out in 6 blocks (B) of 3 main plots, each split into 4 sub-plots. The varieties were applied to the main plots and the manurial treatments to the sub-plots. | 1 2 3 . | # install.package('MASS') # if you have not already done so, and want this data library(MASS) df &lt;- oats . | . Before we perform the contrast test, let’s verify that the yield of oats Y depends on the nitrogen manurial treatment given to it N. | 1 2 . | aov1 &lt;- aov(Y ~ N, data = df) summary(aov1) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) N 3 20020 6673 14.2 2.78e-07 *** Residuals 68 31965 470 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The $p$-value in the Pr(&gt;F) column is below $\\alpha=0.05$. So at the 5% significance level, the yield differs according to the nitrogen manurial treatment. We assume that the model assumptions are met but do not verify them here. We now want to perform a planned comparison test (or contrast test) on the data to see whether there is a difference between the $N&lt;0.5$ levels and the $N&gt;0.5$ levels. We will use the fit.contrast function in the gmodels package. Since the order of the levels is 0, 0.2, 0.4 and 0.6, the contrast coefficients will be $-0.5$, $-0.5$, $0.5$, $0.5$, respectively. | 1 2 3 . | # install.package('gmodels') # if you have not already done so library(gmodels) fit.contrast(aov1, \"N\", coeff=c(-1/2,-1/2,1/2,1/2)) . | . | 1 2 3 4 . | Estimate Std. Error t value Pr(&gt;|t|) N c=( -0.5 -0.5 0.5 0.5 ) 29.66667 5.110338 5.805225 1.855598e-07 attr(,\"class\") [1] \"fit_contrast\" . | . The $p$-value in the Pr(&gt;|t|) column is below $\\alpha=0.05$. This tells us that there is a significant difference between the average yields of the $N&lt;0.5$ and $N&gt;0.5$ levels. Content last modified on 10 November 2022. See a problem? Tell us or edit the source. Contributed by: . | Krtin Juneja (KJUNEJA@falcon.bentley.edu) | Nathan Carter (ncarter@bentley.edu) | . ",
    "url": "/how-to-perform-a-planned-comparison-test-in-r-using-gmodels/#solution",
    "relUrl": "/how-to-perform-a-planned-comparison-test-in-r-using-gmodels/#solution"
  },"1050": {
    "doc": "How to perform a planned comparison test",
    "title": "How to perform a planned comparison test",
    "content": " ",
    "url": "/how-to-perform-a-planned-comparison-test/",
    "relUrl": "/how-to-perform-a-planned-comparison-test/"
  },"1051": {
    "doc": "How to perform a planned comparison test",
    "title": "Description",
    "content": "Suppose that ANOVA reveals a significant difference between treatment levels, and you wish to explore further through post hoc analysis by comparing two specific treatment levels. How can we perform perform planned comparisons, also called a contrast test? . ",
    "url": "/how-to-perform-a-planned-comparison-test/#description",
    "relUrl": "/how-to-perform-a-planned-comparison-test/#description"
  },"1052": {
    "doc": "How to perform a planned comparison test",
    "title": "Using gmodels, in R",
    "content": "View this solution alone. Usually, you have data you wish to compare, but we will use example data here. We load the “oats” dataset from R’s MASS package, about the yield of oats from a split-plot field trial using three varieties (V) and four levels of manurial treatment (N). The experiment was laid out in 6 blocks (B) of 3 main plots, each split into 4 sub-plots. The varieties were applied to the main plots and the manurial treatments to the sub-plots. | 1 2 3 . | # install.package('MASS') # if you have not already done so, and want this data library(MASS) df &lt;- oats . | . Before we perform the contrast test, let’s verify that the yield of oats Y depends on the nitrogen manurial treatment given to it N. | 1 2 . | aov1 &lt;- aov(Y ~ N, data = df) summary(aov1) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) N 3 20020 6673 14.2 2.78e-07 *** Residuals 68 31965 470 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The $p$-value in the Pr(&gt;F) column is below $\\alpha=0.05$. So at the 5% significance level, the yield differs according to the nitrogen manurial treatment. We assume that the model assumptions are met but do not verify them here. We now want to perform a planned comparison test (or contrast test) on the data to see whether there is a difference between the $N&lt;0.5$ levels and the $N&gt;0.5$ levels. We will use the fit.contrast function in the gmodels package. Since the order of the levels is 0, 0.2, 0.4 and 0.6, the contrast coefficients will be $-0.5$, $-0.5$, $0.5$, $0.5$, respectively. | 1 2 3 . | # install.package('gmodels') # if you have not already done so library(gmodels) fit.contrast(aov1, \"N\", coeff=c(-1/2,-1/2,1/2,1/2)) . | . | 1 2 3 4 . | Estimate Std. Error t value Pr(&gt;|t|) N c=( -0.5 -0.5 0.5 0.5 ) 29.66667 5.110338 5.805225 1.855598e-07 attr(,\"class\") [1] \"fit_contrast\" . | . The $p$-value in the Pr(&gt;|t|) column is below $\\alpha=0.05$. This tells us that there is a significant difference between the average yields of the $N&lt;0.5$ and $N&gt;0.5$ levels. Content last modified on 10 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-a-planned-comparison-test/#using-gmodels-in-r",
    "relUrl": "/how-to-perform-a-planned-comparison-test/#using-gmodels-in-r"
  },"1053": {
    "doc": "How to perform a planned comparison test",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-perform-a-planned-comparison-test/#topics-that-include-this-task",
    "relUrl": "/how-to-perform-a-planned-comparison-test/#topics-that-include-this-task"
  },"1054": {
    "doc": "How to perform a planned comparison test",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Python | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-perform-a-planned-comparison-test/#opportunities",
    "relUrl": "/how-to-perform-a-planned-comparison-test/#opportunities"
  },"1055": {
    "doc": "How to perform an analysis of covariance (ANCOVA) (in Python, using pingouin)",
    "title": "How to perform an analysis of covariance (ANCOVA) (in Python, using pingouin)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova-in-python-using-pingouin/",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova-in-python-using-pingouin/"
  },"1056": {
    "doc": "How to perform an analysis of covariance (ANCOVA) (in Python, using pingouin)",
    "title": "Task",
    "content": "Recall that covariates are variables that may be related to the outcome but are unaffected by treatment assignment. In a randomized experiment with one or more observed covariates, an analysis of covariance (ANCOVA) addresses this question: How would the mean outcome in each treatment group change if all groups were equal with respect to the covariate? The goal is to remove any variability in the outcome associated with the covariate from the unexplained variability used to determine statistical significance. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to compare two nested linear models | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | . ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova-in-python-using-pingouin/#task",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova-in-python-using-pingouin/#task"
  },"1057": {
    "doc": "How to perform an analysis of covariance (ANCOVA) (in Python, using pingouin)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('mtcars') . | . Let’s use ANCOVA to check the effect of the engine type (0 = V-shaped, 1 = straight, in the variable vs) on the miles per gallon when considering the weight of the car as a covariate. We will use the ancova function from the pingouin package to conduct the test. | 1 2 . | from pingouin import ancova ancova(data=df, dv='mpg', covar='wt', between='vs') . | . | | Source | SS | DF | F | p-unc | np2 | . | 0 | vs | 54.228061 | 1 | 7.017656 | 1.292580e-02 | 0.194839 | . | 1 | wt | 405.425409 | 1 | 52.466123 | 5.632548e-08 | 0.644024 | . | 2 | Residual | 224.093877 | 29 | NaN | NaN | NaN | . | 1 2 3 . | /opt/conda/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.4.0, the latest is 0.5.0. Set the environment variable OUTDATED_IGNORE=1 to disable these warnings. return warn( . | . The $p$-value for each variable is in the p-unc column. The $p$-value for the wt variable tests the null hypothesis, “The quantities wt and mpg are not related.” Since it is below 0.05, we reject the null hypothesis, and conclude that wt is significant in predicting mpg. The $p$-value for the vs variable tests the null hypothesis, “The quantities vs and mpg are not related if we hold wt constant.” Since it is below 0.05, we reject the null hypothesis, and conclude that vs is significant in predicting mpg even among cars with equal weight (wt). Note: Unfortunately, a two-factor ANCOVA is not possible in pingouin. However, a model with more than one covariate is possible, as you can provide a list as the covar parameter when calling ancova. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova-in-python-using-pingouin/#solution",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova-in-python-using-pingouin/#solution"
  },"1058": {
    "doc": "How to perform an analysis of covariance (ANCOVA) (in R)",
    "title": "How to perform an analysis of covariance (ANCOVA) (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova-in-r/",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova-in-r/"
  },"1059": {
    "doc": "How to perform an analysis of covariance (ANCOVA) (in R)",
    "title": "Task",
    "content": "Recall that covariates are variables that may be related to the outcome but are unaffected by treatment assignment. In a randomized experiment with one or more observed covariates, an analysis of covariance (ANCOVA) addresses this question: How would the mean outcome in each treatment group change if all groups were equal with respect to the covariate? The goal is to remove any variability in the outcome associated with the covariate from the unexplained variability used to determine statistical significance. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to compare two nested linear models | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | . ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova-in-r/#task",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova-in-r/#task"
  },"1060": {
    "doc": "How to perform an analysis of covariance (ANCOVA) (in R)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) . | 1 2 . | df &lt;- mtcars df$vs &lt;- as.factor(df$vs) . | . Let’s use ANCOVA to check the effect of the engine type (0 = V-shaped, 1 = straight, in the variable vs) on the miles per gallon when considering the weight of the car as a covariate. We will use the ancova function from the pingouin package to conduct the test. | 1 2 . | cov.model &lt;- lm(mpg ~ wt + vs, data = df) anova(cov.model) . | . | 1 2 3 4 . | Df Sum Sq Mean Sq F value Pr(&gt;F) wt 1 847.72525 847.725250 109.704168 2.284396e-11 vs 1 54.22806 54.228061 7.017656 1.292580e-02 Residuals 29 224.09388 7.727375 NA NA . | . The $p$-value for each variable can be found in the final column of the output, called Pr(&gt;F). The $p$-value for the wt variable tests the null hypothesis, “The quantities wt and mpg are not related.” Since it is below 0.05, we reject the null hypothesis, and conclude that wt is significant in predicting mpg. The $p$-value for the vs variable tests the null hypothesis, “The quantities vs and mpg are not related if we hold wt constant.” Since it is below 0.05, we reject the null hypothesis, and conclude that vs is significant in predicting mpg even among cars with equal weight (wt). If we wish to create a 2-factor ANCOVA model, we can test to see if the engine type (0 = V-shaped, 1 = straight) and transmission type (0 = automatic, 1 = manual) have an effect on the Miles/gallon per car when considering the weight of the car as a covariate. | 1 2 . | cov.model.2 &lt;- lm(mpg ~ wt + vs + am, data = df) anova(cov.model.2) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) wt 1 847.725250 847.725250 109.729918 3.420018e-11 vs 1 54.228061 54.228061 7.019303 1.310627e-02 am 1 7.778149 7.778149 1.006807 3.242621e-01 Residuals 28 216.315728 7.725562 NA NA . | . The $p$-values are again in the final column of output. They show that at the 5% significance level, we would conclude that engine type (vs) significantly impacts the Miles/gallon per car while accounting for the weight of the car (wt) but the transmission type (am) does not. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova-in-r/#solution",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova-in-r/#solution"
  },"1061": {
    "doc": "How to perform an analysis of covariance (ANCOVA)",
    "title": "How to perform an analysis of covariance (ANCOVA)",
    "content": " ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova/",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova/"
  },"1062": {
    "doc": "How to perform an analysis of covariance (ANCOVA)",
    "title": "Description",
    "content": "Recall that covariates are variables that may be related to the outcome but are unaffected by treatment assignment. In a randomized experiment with one or more observed covariates, an analysis of covariance (ANCOVA) addresses this question: How would the mean outcome in each treatment group change if all groups were equal with respect to the covariate? The goal is to remove any variability in the outcome associated with the covariate from the unexplained variability used to determine statistical significance. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to compare two nested linear models | How to conduct a mixed designs ANOVA | How to conduct a repeated measures ANOVA | . ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova/#description",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova/#description"
  },"1063": {
    "doc": "How to perform an analysis of covariance (ANCOVA)",
    "title": "Using pingouin, in Python",
    "content": "View this solution alone. The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('mtcars') . | . Let’s use ANCOVA to check the effect of the engine type (0 = V-shaped, 1 = straight, in the variable vs) on the miles per gallon when considering the weight of the car as a covariate. We will use the ancova function from the pingouin package to conduct the test. | 1 2 . | from pingouin import ancova ancova(data=df, dv='mpg', covar='wt', between='vs') . | . | | Source | SS | DF | F | p-unc | np2 | . | 0 | vs | 54.228061 | 1 | 7.017656 | 1.292580e-02 | 0.194839 | . | 1 | wt | 405.425409 | 1 | 52.466123 | 5.632548e-08 | 0.644024 | . | 2 | Residual | 224.093877 | 29 | NaN | NaN | NaN | . | 1 2 3 . | /opt/conda/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.4.0, the latest is 0.5.0. Set the environment variable OUTDATED_IGNORE=1 to disable these warnings. return warn( . | . The $p$-value for each variable is in the p-unc column. The $p$-value for the wt variable tests the null hypothesis, “The quantities wt and mpg are not related.” Since it is below 0.05, we reject the null hypothesis, and conclude that wt is significant in predicting mpg. The $p$-value for the vs variable tests the null hypothesis, “The quantities vs and mpg are not related if we hold wt constant.” Since it is below 0.05, we reject the null hypothesis, and conclude that vs is significant in predicting mpg even among cars with equal weight (wt). Note: Unfortunately, a two-factor ANCOVA is not possible in pingouin. However, a model with more than one covariate is possible, as you can provide a list as the covar parameter when calling ancova. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova/#using-pingouin-in-python",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova/#using-pingouin-in-python"
  },"1064": {
    "doc": "How to perform an analysis of covariance (ANCOVA)",
    "title": "Solution, in R",
    "content": "View this solution alone. The solution below uses an example dataset about car design and fuel consumption from a 1974 Motor Trend magazine. (See how to quickly load some sample data.) . | 1 2 . | df &lt;- mtcars df$vs &lt;- as.factor(df$vs) . | . Let’s use ANCOVA to check the effect of the engine type (0 = V-shaped, 1 = straight, in the variable vs) on the miles per gallon when considering the weight of the car as a covariate. We will use the ancova function from the pingouin package to conduct the test. | 1 2 . | cov.model &lt;- lm(mpg ~ wt + vs, data = df) anova(cov.model) . | . | 1 2 3 4 . | Df Sum Sq Mean Sq F value Pr(&gt;F) wt 1 847.72525 847.725250 109.704168 2.284396e-11 vs 1 54.22806 54.228061 7.017656 1.292580e-02 Residuals 29 224.09388 7.727375 NA NA . | . The $p$-value for each variable can be found in the final column of the output, called Pr(&gt;F). The $p$-value for the wt variable tests the null hypothesis, “The quantities wt and mpg are not related.” Since it is below 0.05, we reject the null hypothesis, and conclude that wt is significant in predicting mpg. The $p$-value for the vs variable tests the null hypothesis, “The quantities vs and mpg are not related if we hold wt constant.” Since it is below 0.05, we reject the null hypothesis, and conclude that vs is significant in predicting mpg even among cars with equal weight (wt). If we wish to create a 2-factor ANCOVA model, we can test to see if the engine type (0 = V-shaped, 1 = straight) and transmission type (0 = automatic, 1 = manual) have an effect on the Miles/gallon per car when considering the weight of the car as a covariate. | 1 2 . | cov.model.2 &lt;- lm(mpg ~ wt + vs + am, data = df) anova(cov.model.2) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) wt 1 847.725250 847.725250 109.729918 3.420018e-11 vs 1 54.228061 54.228061 7.019303 1.310627e-02 am 1 7.778149 7.778149 1.006807 3.242621e-01 Residuals 28 216.315728 7.725562 NA NA . | . The $p$-values are again in the final column of output. They show that at the 5% significance level, we would conclude that engine type (vs) significantly impacts the Miles/gallon per car while accounting for the weight of the car (wt) but the transmission type (am) does not. Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova/#solution-in-r",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova/#solution-in-r"
  },"1065": {
    "doc": "How to perform an analysis of covariance (ANCOVA)",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | Bentley University MA255 | . ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova/#topics-that-include-this-task",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova/#topics-that-include-this-task"
  },"1066": {
    "doc": "How to perform an analysis of covariance (ANCOVA)",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-perform-an-analysis-of-covariance-ancova/#opportunities",
    "relUrl": "/how-to-perform-an-analysis-of-covariance-ancova/#opportunities"
  },"1067": {
    "doc": "How to perform pairwise comparisons (in Python, using statsmodels, Matplotlib and scikit)",
    "title": "How to perform pairwise comparisons (in Python, using statsmodels, Matplotlib and scikit)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-pairwise-comparisons-in-python-using-statsmodels-matplotlib-and-scikit/",
    "relUrl": "/how-to-perform-pairwise-comparisons-in-python-using-statsmodels-matplotlib-and-scikit/"
  },"1068": {
    "doc": "How to perform pairwise comparisons (in Python, using statsmodels, Matplotlib and scikit)",
    "title": "Task",
    "content": "When analyzing data from a completely randomized single-factor design, suppose that you have performed an ANOVA and noticed that there’s a significant difference between at least one pair of treatment levels. How can pairwise comparisons help us explore which pairs of treatment levels are different? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to perform post-hoc analysis with Tukey’s HSD test | . ",
    "url": "/how-to-perform-pairwise-comparisons-in-python-using-statsmodels-matplotlib-and-scikit/#task",
    "relUrl": "/how-to-perform-pairwise-comparisons-in-python-using-statsmodels-matplotlib-and-scikit/#task"
  },"1069": {
    "doc": "How to perform pairwise comparisons (in Python, using statsmodels, Matplotlib and scikit)",
    "title": "Solution",
    "content": "The solution below uses an example dataset that details the counts of insects in an agricultural experiment with six types of insecticides, labeled A through F. (See how to quickly load some sample data.) . | 1 2 3 . | from rdatasets import data df = data('InsectSprays') df . | . | | count | spray | . | 0 | 10 | A | . | 1 | 7 | A | . | 2 | 20 | A | . | 3 | 14 | A | . | 4 | 14 | A | . | ... | ... | ... | . | 67 | 10 | F | . | 68 | 26 | F | . | 69 | 26 | F | . | 70 | 24 | F | . | 71 | 13 | F | . 72 rows × 2 columns . Before we perform any post hoc analysis, we need to see if the count of insects depends on the type of insecticide given by conducting a one way ANOVA. (See also how to do a one-way analysis of variance (ANOVA).) . | 1 2 3 4 . | from statsmodels.formula.api import ols model = ols('count ~ spray', data = df).fit() import statsmodels.api as sm sm.stats.anova_lm(model, typ=1) . | . | | df | sum_sq | mean_sq | F | PR(&gt;F) | . | spray | 5.0 | 2668.833333 | 533.766667 | 34.702282 | 3.182584e-17 | . | Residual | 66.0 | 1015.166667 | 15.381313 | NaN | NaN | . At the 5% significance level, we see that the count differs according to the type of insecticide used. We assume that the model assumptions are met, but do not verify that here. If we would like to compare the pairs without any corrections, we can use the ‘pairwise t test’ in the scikit_posthocs package. | 1 2 . | import scikit_posthocs as sp sp.posthoc_ttest(df, val_col='count', group_col='spray', p_adjust=None, pool_sd=True ) . | . | | A | B | C | D | E | F | . | A | 1.000000e+00 | 6.044761e-01 | 7.266893e-11 | 9.816910e-08 | 2.753922e-09 | 1.805998e-01 | . | B | 6.044761e-01 | 1.000000e+00 | 8.509776e-12 | 1.212803e-08 | 3.257986e-10 | 4.079858e-01 | . | C | 7.266893e-11 | 8.509776e-12 | 1.000000e+00 | 8.141205e-02 | 3.794750e-01 | 2.794343e-13 | . | D | 9.816910e-08 | 1.212803e-08 | 8.141205e-02 | 1.000000e+00 | 3.794750e-01 | 4.035610e-10 | . | E | 2.753922e-09 | 3.257986e-10 | 3.794750e-01 | 3.794750e-01 | 1.000000e+00 | 1.054387e-11 | . | F | 1.805998e-01 | 4.079858e-01 | 2.794343e-13 | 4.035610e-10 | 1.054387e-11 | 1.000000e+00 | . Techniques to adjust the above table for multiple comparisons include the Bonferroni correction, Fisher’s Least Significant Difference (LSD) method, Dunnett’s procedure, and Scheffe’s method. These can be used in place of ‘None’ for the p.adjust argument; see details here. You can also determine the magnitude of these differences; see how to perform post-hoc analysis with Tukey’s HSD test. Content last modified on 16 September 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-perform-pairwise-comparisons-in-python-using-statsmodels-matplotlib-and-scikit/#solution",
    "relUrl": "/how-to-perform-pairwise-comparisons-in-python-using-statsmodels-matplotlib-and-scikit/#solution"
  },"1070": {
    "doc": "How to perform pairwise comparisons (in R)",
    "title": "How to perform pairwise comparisons (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-pairwise-comparisons-in-r/",
    "relUrl": "/how-to-perform-pairwise-comparisons-in-r/"
  },"1071": {
    "doc": "How to perform pairwise comparisons (in R)",
    "title": "Task",
    "content": "When analyzing data from a completely randomized single-factor design, suppose that you have performed an ANOVA and noticed that there’s a significant difference between at least one pair of treatment levels. How can pairwise comparisons help us explore which pairs of treatment levels are different? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to perform post-hoc analysis with Tukey’s HSD test | . ",
    "url": "/how-to-perform-pairwise-comparisons-in-r/#task",
    "relUrl": "/how-to-perform-pairwise-comparisons-in-r/#task"
  },"1072": {
    "doc": "How to perform pairwise comparisons (in R)",
    "title": "Solution",
    "content": "The solution below uses an example dataset that details the counts of insects in an agricultural experiment with six types of insecticides, labeled A through F. (This is one of the datasets built into R for use in examples like this one.) . | 1 2 . | df &lt;- InsectSprays head( df, 10 ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | count spray 1 10 A 2 7 A 3 20 A 4 14 A 5 14 A 6 12 A 7 10 A 8 23 A 9 17 A 10 20 A . | . Before we perform any post hoc analysis, we need to see if the count of insects depends on the type of insecticide given by conducting a one way ANOVA. (See also how to do a one-way analysis of variance (ANOVA).) . | 1 2 . | aov1 = aov(count ~ spray, data = df) summary(aov1) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) spray 5 2669 533.8 34.7 &lt;2e-16 *** Residuals 66 1015 15.4 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . At the 5% significance level, we see that the count differs according to the type of insecticide used. We assume that the model assumptions are met, but do not verify that here. If we would like to compare the pairs without any corrections, we can use the pairwise.t.test function built into R. | 1 . | pairwise.t.test(df$count, df$spray, p.adj=\"none\") . | . | 1 2 3 4 5 6 7 8 9 10 11 12 . | Pairwise comparisons using t tests with pooled SD data: df$count and df$spray A B C D E B 0.604 - - - - C 7.3e-11 8.5e-12 - - - D 9.8e-08 1.2e-08 0.081 - - E 2.8e-09 3.3e-10 0.379 0.379 - F 0.181 0.408 2.8e-13 4.0e-10 1.1e-11 P value adjustment method: none . | . Techniques to adjust the above table for multiple comparisons include the Bonferroni correction, Fisher’s Least Significant Difference (LSD) method, Dunnett’s procedure, and Scheffe’s method. These can be used in place of “none” for the p.adj argument; see details here. You can also determine the magnitude of these differences; see how to perform post-hoc analysis with Tukey’s HSD test. Content last modified on 10 September 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-perform-pairwise-comparisons-in-r/#solution",
    "relUrl": "/how-to-perform-pairwise-comparisons-in-r/#solution"
  },"1073": {
    "doc": "How to perform pairwise comparisons",
    "title": "How to perform pairwise comparisons",
    "content": " ",
    "url": "/how-to-perform-pairwise-comparisons/",
    "relUrl": "/how-to-perform-pairwise-comparisons/"
  },"1074": {
    "doc": "How to perform pairwise comparisons",
    "title": "Description",
    "content": "When analyzing data from a completely randomized single-factor design, suppose that you have performed an ANOVA and noticed that there’s a significant difference between at least one pair of treatment levels. How can pairwise comparisons help us explore which pairs of treatment levels are different? . Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to perform post-hoc analysis with Tukey’s HSD test | . ",
    "url": "/how-to-perform-pairwise-comparisons/#description",
    "relUrl": "/how-to-perform-pairwise-comparisons/#description"
  },"1075": {
    "doc": "How to perform pairwise comparisons",
    "title": "Using statsmodels, Matplotlib and scikit, in Python",
    "content": "View this solution alone. The solution below uses an example dataset that details the counts of insects in an agricultural experiment with six types of insecticides, labeled A through F. (See how to quickly load some sample data.) . | 1 2 3 . | from rdatasets import data df = data('InsectSprays') df . | . | | count | spray | . | 0 | 10 | A | . | 1 | 7 | A | . | 2 | 20 | A | . | 3 | 14 | A | . | 4 | 14 | A | . | ... | ... | ... | . | 67 | 10 | F | . | 68 | 26 | F | . | 69 | 26 | F | . | 70 | 24 | F | . | 71 | 13 | F | . 72 rows × 2 columns . Before we perform any post hoc analysis, we need to see if the count of insects depends on the type of insecticide given by conducting a one way ANOVA. (See also how to do a one-way analysis of variance (ANOVA).) . | 1 2 3 4 . | from statsmodels.formula.api import ols model = ols('count ~ spray', data = df).fit() import statsmodels.api as sm sm.stats.anova_lm(model, typ=1) . | . | | df | sum_sq | mean_sq | F | PR(&gt;F) | . | spray | 5.0 | 2668.833333 | 533.766667 | 34.702282 | 3.182584e-17 | . | Residual | 66.0 | 1015.166667 | 15.381313 | NaN | NaN | . At the 5% significance level, we see that the count differs according to the type of insecticide used. We assume that the model assumptions are met, but do not verify that here. If we would like to compare the pairs without any corrections, we can use the ‘pairwise t test’ in the scikit_posthocs package. | 1 2 . | import scikit_posthocs as sp sp.posthoc_ttest(df, val_col='count', group_col='spray', p_adjust=None, pool_sd=True ) . | . | | A | B | C | D | E | F | . | A | 1.000000e+00 | 6.044761e-01 | 7.266893e-11 | 9.816910e-08 | 2.753922e-09 | 1.805998e-01 | . | B | 6.044761e-01 | 1.000000e+00 | 8.509776e-12 | 1.212803e-08 | 3.257986e-10 | 4.079858e-01 | . | C | 7.266893e-11 | 8.509776e-12 | 1.000000e+00 | 8.141205e-02 | 3.794750e-01 | 2.794343e-13 | . | D | 9.816910e-08 | 1.212803e-08 | 8.141205e-02 | 1.000000e+00 | 3.794750e-01 | 4.035610e-10 | . | E | 2.753922e-09 | 3.257986e-10 | 3.794750e-01 | 3.794750e-01 | 1.000000e+00 | 1.054387e-11 | . | F | 1.805998e-01 | 4.079858e-01 | 2.794343e-13 | 4.035610e-10 | 1.054387e-11 | 1.000000e+00 | . Techniques to adjust the above table for multiple comparisons include the Bonferroni correction, Fisher’s Least Significant Difference (LSD) method, Dunnett’s procedure, and Scheffe’s method. These can be used in place of ‘None’ for the p.adjust argument; see details here. You can also determine the magnitude of these differences; see how to perform post-hoc analysis with Tukey’s HSD test. Content last modified on 16 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-pairwise-comparisons/#using-statsmodels-matplotlib-and-scikit-in-python",
    "relUrl": "/how-to-perform-pairwise-comparisons/#using-statsmodels-matplotlib-and-scikit-in-python"
  },"1076": {
    "doc": "How to perform pairwise comparisons",
    "title": "Solution, in R",
    "content": "View this solution alone. The solution below uses an example dataset that details the counts of insects in an agricultural experiment with six types of insecticides, labeled A through F. (This is one of the datasets built into R for use in examples like this one.) . | 1 2 . | df &lt;- InsectSprays head( df, 10 ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | count spray 1 10 A 2 7 A 3 20 A 4 14 A 5 14 A 6 12 A 7 10 A 8 23 A 9 17 A 10 20 A . | . Before we perform any post hoc analysis, we need to see if the count of insects depends on the type of insecticide given by conducting a one way ANOVA. (See also how to do a one-way analysis of variance (ANOVA).) . | 1 2 . | aov1 = aov(count ~ spray, data = df) summary(aov1) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) spray 5 2669 533.8 34.7 &lt;2e-16 *** Residuals 66 1015 15.4 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . At the 5% significance level, we see that the count differs according to the type of insecticide used. We assume that the model assumptions are met, but do not verify that here. If we would like to compare the pairs without any corrections, we can use the pairwise.t.test function built into R. | 1 . | pairwise.t.test(df$count, df$spray, p.adj=\"none\") . | . | 1 2 3 4 5 6 7 8 9 10 11 12 . | Pairwise comparisons using t tests with pooled SD data: df$count and df$spray A B C D E B 0.604 - - - - C 7.3e-11 8.5e-12 - - - D 9.8e-08 1.2e-08 0.081 - - E 2.8e-09 3.3e-10 0.379 0.379 - F 0.181 0.408 2.8e-13 4.0e-10 1.1e-11 P value adjustment method: none . | . Techniques to adjust the above table for multiple comparisons include the Bonferroni correction, Fisher’s Least Significant Difference (LSD) method, Dunnett’s procedure, and Scheffe’s method. These can be used in place of “none” for the p.adj argument; see details here. You can also determine the magnitude of these differences; see how to perform post-hoc analysis with Tukey’s HSD test. Content last modified on 10 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-pairwise-comparisons/#solution-in-r",
    "relUrl": "/how-to-perform-pairwise-comparisons/#solution-in-r"
  },"1077": {
    "doc": "How to perform pairwise comparisons",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-perform-pairwise-comparisons/#topics-that-include-this-task",
    "relUrl": "/how-to-perform-pairwise-comparisons/#topics-that-include-this-task"
  },"1078": {
    "doc": "How to perform pairwise comparisons",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-perform-pairwise-comparisons/#opportunities",
    "relUrl": "/how-to-perform-pairwise-comparisons/#opportunities"
  },"1079": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in Python, using statsmodels, Matplotlib and scikit)",
    "title": "How to perform post-hoc analysis with Tukey’s HSD test (in Python, using statsmodels, Matplotlib and scikit)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-python-using-statsmodels-matplotlib-and-scikit/#how-to-perform-post-hoc-analysis-with-tukeys-hsd-test-in-python-using-statsmodels-matplotlib-and-scikit",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-python-using-statsmodels-matplotlib-and-scikit/#how-to-perform-post-hoc-analysis-with-tukeys-hsd-test-in-python-using-statsmodels-matplotlib-and-scikit"
  },"1080": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in Python, using statsmodels, Matplotlib and scikit)",
    "title": "Task",
    "content": "If we run a one-way ANOVA test and find that there is a significant difference between population means, we might want to know which means are actually different from each other. One way to do so is with Tukey’s Honestly Significant Differences (HSD) method. It creates confidence intervals for each pair of samples, while controlling for Type I error rate across all pairs. Thus the resulting intervals are a little wider than those produced using Fisher’s LSD method. How do we make these confidence intervals, with an appropriate visualization? . ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-python-using-statsmodels-matplotlib-and-scikit/#task",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-python-using-statsmodels-matplotlib-and-scikit/#task"
  },"1081": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in Python, using statsmodels, Matplotlib and scikit)",
    "title": "Solution",
    "content": "We load here the same data that appears in the solution for how to perform pairwise comparisons. That solution used ANOVA to determine which pairs of groups have significant differences in their means; follow its link for more details. | 1 2 3 . | from rdatasets import data df = data('InsectSprays') df . | . | | count | spray | . | 0 | 10 | A | . | 1 | 7 | A | . | 2 | 20 | A | . | 3 | 14 | A | . | 4 | 14 | A | . | ... | ... | ... | . | 67 | 10 | F | . | 68 | 26 | F | . | 69 | 26 | F | . | 70 | 24 | F | . | 71 | 13 | F | . 72 rows × 2 columns . We now want to perform an unplanned comparison test on the data to determine the magnitudes of the differences between pairs of groups. We do this by applying Tukey’s HSD approach to perform pairwise comparisons and generate confidence intervals that maintain a specified experiment-wide error rate. Before that, the pairwise_tukeyhsd module needs to be imported from the statsmodels package. | 1 2 3 . | from statsmodels.stats.multicomp import pairwise_tukeyhsd tukey = pairwise_tukeyhsd(endog=df['count'], groups=df['spray'], alpha=0.05) print(tukey) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 . | Multiple Comparison of Means - Tukey HSD, FWER=0.05 ===================================================== group1 group2 meandiff p-adj lower upper reject ----------------------------------------------------- A B 0.8333 0.9 -3.8659 5.5326 False A C -12.4167 0.001 -17.1159 -7.7174 True A D -9.5833 0.001 -14.2826 -4.8841 True A E -11.0 0.001 -15.6992 -6.3008 True A F 2.1667 0.728 -2.5326 6.8659 False B C -13.25 0.001 -17.9492 -8.5508 True B D -10.4167 0.001 -15.1159 -5.7174 True B E -11.8333 0.001 -16.5326 -7.1341 True B F 1.3333 0.9 -3.3659 6.0326 False C D 2.8333 0.4921 -1.8659 7.5326 False C E 1.4167 0.9 -3.2826 6.1159 False C F 14.5833 0.001 9.8841 19.2826 True D E -1.4167 0.9 -6.1159 3.2826 False D F 11.75 0.001 7.0508 16.4492 True E F 13.1667 0.001 8.4674 17.8659 True ----------------------------------------------------- . | . Because the above table contains a lot of information, it’s often helpful to visualize these intervals. Python’s statsmodels package does not have a built-in way to do so, but we can create our own as follows. | 1 2 3 4 5 6 7 . | import matplotlib.pyplot as plt rows = tukey.summary().data[1:] plt.hlines( range(len(rows)), [row[4] for row in rows], [row[5] for row in rows] ) plt.vlines( 0, -1, len( rows )-1, linestyles='dashed' ) plt.gca().set_yticks( range( len( rows ) ) ) plt.gca().set_yticklabels( [ f'{x[0]}-{x[1]}' for x in rows ] ) plt.show() . | . Confidence intervals that cross the vertical, dashed line at $x=0$ are those in which the means across those groups may be equal. Other intervals have mean differences whose 95% confidence intervals do not include zero. Content last modified on 10 September 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-python-using-statsmodels-matplotlib-and-scikit/#solution",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-python-using-statsmodels-matplotlib-and-scikit/#solution"
  },"1082": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in Python, using statsmodels, Matplotlib and scikit)",
    "title": "How to perform post-hoc analysis with Tukey's HSD test (in Python, using statsmodels, Matplotlib and scikit)",
    "content": " ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-python-using-statsmodels-matplotlib-and-scikit/",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-python-using-statsmodels-matplotlib-and-scikit/"
  },"1083": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in R, using agricolae)",
    "title": "How to perform post-hoc analysis with Tukey’s HSD test (in R, using agricolae)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r-using-agricolae/#how-to-perform-post-hoc-analysis-with-tukeys-hsd-test-in-r-using-agricolae",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r-using-agricolae/#how-to-perform-post-hoc-analysis-with-tukeys-hsd-test-in-r-using-agricolae"
  },"1084": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in R, using agricolae)",
    "title": "Task",
    "content": "If we run a one-way ANOVA test and find that there is a significant difference between population means, we might want to know which means are actually different from each other. One way to do so is with Tukey’s Honestly Significant Differences (HSD) method. It creates confidence intervals for each pair of samples, while controlling for Type I error rate across all pairs. Thus the resulting intervals are a little wider than those produced using Fisher’s LSD method. How do we make these confidence intervals, with an appropriate visualization? . ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r-using-agricolae/#task",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r-using-agricolae/#task"
  },"1085": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in R, using agricolae)",
    "title": "Solution",
    "content": "We load here the same data that appears in the solution for how to perform pairwise comparisons. That solution used ANOVA to determine which pairs of groups have significant differences in their means; follow its link for more details. | 1 2 3 . | # Load an inbuilt data set called InsectSprays and assign it to the variable df df &lt;- InsectSprays head( df, 10 ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | count spray 1 10 A 2 7 A 3 20 A 4 14 A 5 14 A 6 12 A 7 10 A 8 23 A 9 17 A 10 20 A . | . We now want to perform an unplanned comparison test on the data to determine the magnitudes of the differences between pairs of groups. Although R has a built-in TukeyHSD function, its output is not as complete as the HSD.test function in the agricolae package, so here we will use that latter function. We provide it the same ANOVA results that we computed in the solution to how to perform pairwise comparisons. | 1 2 3 4 . | # install.packages( \"agricolae\" ) # if you have not already done this library(agricolae) aov1 &lt;- aov(count ~ spray, data = df) HSD.test(aov1, \"spray\", group=FALSE, console=TRUE) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 . | Study: aov1 ~ \"spray\" HSD Test for count Mean Square Error: 15.38131 spray, means count std r Min Max A 14.500000 4.719399 12 7 23 B 15.333333 4.271115 12 7 21 C 2.083333 1.975225 12 0 7 D 4.916667 2.503028 12 2 12 E 3.500000 1.732051 12 1 6 F 16.666667 6.213378 12 9 26 Alpha: 0.05 ; DF Error: 66 Critical Value of Studentized Range: 4.150851 Comparison between treatments means difference pvalue signif. LCL UCL A - B -0.8333333 0.9952 -5.532742 3.866075 A - C 12.4166667 0.0000 *** 7.717258 17.116075 A - D 9.5833333 0.0000 *** 4.883925 14.282742 A - E 11.0000000 0.0000 *** 6.300591 15.699409 A - F -2.1666667 0.7542 -6.866075 2.532742 B - C 13.2500000 0.0000 *** 8.550591 17.949409 B - D 10.4166667 0.0000 *** 5.717258 15.116075 B - E 11.8333333 0.0000 *** 7.133925 16.532742 B - F -1.3333333 0.9603 -6.032742 3.366075 C - D -2.8333333 0.4921 -7.532742 1.866075 C - E -1.4166667 0.9489 -6.116075 3.282742 C - F -14.5833333 0.0000 *** -19.282742 -9.883925 D - E 1.4166667 0.9489 -3.282742 6.116075 D - F -11.7500000 0.0000 *** -16.449409 -7.050591 E - F -13.1666667 0.0000 *** -17.866075 -8.467258 . | . The table above highlights for us those confidence intervals whose means are significantly different from zero, and provides other information as well. To see if there is any statistical different between the pairs, look at the “signif” column. The more asterisks appear there, the more significant the difference. Content last modified on 14 September 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r-using-agricolae/#solution",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r-using-agricolae/#solution"
  },"1086": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in R, using agricolae)",
    "title": "How to perform post-hoc analysis with Tukey's HSD test (in R, using agricolae)",
    "content": " ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r-using-agricolae/",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r-using-agricolae/"
  },"1087": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in R)",
    "title": "How to perform post-hoc analysis with Tukey’s HSD test (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r/#how-to-perform-post-hoc-analysis-with-tukeys-hsd-test-in-r",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r/#how-to-perform-post-hoc-analysis-with-tukeys-hsd-test-in-r"
  },"1088": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in R)",
    "title": "Task",
    "content": "If we run a one-way ANOVA test and find that there is a significant difference between population means, we might want to know which means are actually different from each other. One way to do so is with Tukey’s Honestly Significant Differences (HSD) method. It creates confidence intervals for each pair of samples, while controlling for Type I error rate across all pairs. Thus the resulting intervals are a little wider than those produced using Fisher’s LSD method. How do we make these confidence intervals, with an appropriate visualization? . ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r/#task",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r/#task"
  },"1089": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in R)",
    "title": "Solution",
    "content": "We load here the same data that appears in the solution for how to perform pairwise comparisons. That solution used ANOVA to determine which pairs of groups have significant differences in their means; follow its link for more details. | 1 2 3 . | # Load an inbuilt data set called InsectSprays and assign it to the variable df df &lt;- InsectSprays head( df, 10 ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | count spray 1 10 A 2 7 A 3 20 A 4 14 A 5 14 A 6 12 A 7 10 A 8 23 A 9 17 A 10 20 A . | . We now want to perform an unplanned comparison test on the data to determine the magnitudes of the differences between pairs of groups. We do this by applying Tukey’s HSD approach to perform pairwise comparisons and generate confidence intervals that maintain a specified experiment-wide error rate. We use R’s built-in TukeyHSD function, and we give it the same ANOVA results that we computed in the solution for how to perform pairwise comparisons. | 1 2 . | aov1 &lt;- aov(count ~ spray, data = df) TukeyHSD(aov1, \"spray\", ordered=TRUE, conf.level = 0.95) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 . | Tukey multiple comparisons of means 95% family-wise confidence level factor levels have been ordered Fit: aov(formula = count ~ spray, data = df) $spray diff lwr upr p adj E-C 1.4166667 -3.282742 6.116075 0.9488669 D-C 2.8333333 -1.866075 7.532742 0.4920707 A-C 12.4166667 7.717258 17.116075 0.0000000 B-C 13.2500000 8.550591 17.949409 0.0000000 F-C 14.5833333 9.883925 19.282742 0.0000000 D-E 1.4166667 -3.282742 6.116075 0.9488669 A-E 11.0000000 6.300591 15.699409 0.0000000 B-E 11.8333333 7.133925 16.532742 0.0000000 F-E 13.1666667 8.467258 17.866075 0.0000000 A-D 9.5833333 4.883925 14.282742 0.0000014 B-D 10.4166667 5.717258 15.116075 0.0000002 F-D 11.7500000 7.050591 16.449409 0.0000000 B-A 0.8333333 -3.866075 5.532742 0.9951810 F-A 2.1666667 -2.532742 6.866075 0.7542147 F-B 1.3333333 -3.366075 6.032742 0.9603075 . | . Because the above table contains a lot of information, it’s often helpful to visualize these intervals. R lets us do so by simply calling plot on the above table. We add a few plotting parameters to improve its appearance. | 1 2 . | plot( TukeyHSD(aov1, \"spray\", ordered=TRUE, conf.level = 0.95), las=1, cex.axis=0.9 ) . | . Confidence intervals that cross the vertical, dashed line at $x=0$ are those in which the means across those groups may be equal. Other intervals have mean differences whose 95% confidence intervals do not include zero. Content last modified on 14 September 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r/#solution",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r/#solution"
  },"1090": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test (in R)",
    "title": "How to perform post-hoc analysis with Tukey's HSD test (in R)",
    "content": " ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r/",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test-in-r/"
  },"1091": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test",
    "title": "How to perform post-hoc analysis with Tukey’s HSD test",
    "content": " ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#how-to-perform-post-hoc-analysis-with-tukeys-hsd-test",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#how-to-perform-post-hoc-analysis-with-tukeys-hsd-test"
  },"1092": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test",
    "title": "Description",
    "content": "If we run a one-way ANOVA test and find that there is a significant difference between population means, we might want to know which means are actually different from each other. One way to do so is with Tukey’s Honestly Significant Differences (HSD) method. It creates confidence intervals for each pair of samples, while controlling for Type I error rate across all pairs. Thus the resulting intervals are a little wider than those produced using Fisher’s LSD method. How do we make these confidence intervals, with an appropriate visualization? . ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#description",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#description"
  },"1093": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test",
    "title": "Using statsmodels, Matplotlib and scikit, in Python",
    "content": "View this solution alone. We load here the same data that appears in the solution for how to perform pairwise comparisons. That solution used ANOVA to determine which pairs of groups have significant differences in their means; follow its link for more details. | 1 2 3 . | from rdatasets import data df = data('InsectSprays') df . | . | | count | spray | . | 0 | 10 | A | . | 1 | 7 | A | . | 2 | 20 | A | . | 3 | 14 | A | . | 4 | 14 | A | . | ... | ... | ... | . | 67 | 10 | F | . | 68 | 26 | F | . | 69 | 26 | F | . | 70 | 24 | F | . | 71 | 13 | F | . 72 rows × 2 columns . We now want to perform an unplanned comparison test on the data to determine the magnitudes of the differences between pairs of groups. We do this by applying Tukey’s HSD approach to perform pairwise comparisons and generate confidence intervals that maintain a specified experiment-wide error rate. Before that, the pairwise_tukeyhsd module needs to be imported from the statsmodels package. | 1 2 3 . | from statsmodels.stats.multicomp import pairwise_tukeyhsd tukey = pairwise_tukeyhsd(endog=df['count'], groups=df['spray'], alpha=0.05) print(tukey) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 . | Multiple Comparison of Means - Tukey HSD, FWER=0.05 ===================================================== group1 group2 meandiff p-adj lower upper reject ----------------------------------------------------- A B 0.8333 0.9 -3.8659 5.5326 False A C -12.4167 0.001 -17.1159 -7.7174 True A D -9.5833 0.001 -14.2826 -4.8841 True A E -11.0 0.001 -15.6992 -6.3008 True A F 2.1667 0.728 -2.5326 6.8659 False B C -13.25 0.001 -17.9492 -8.5508 True B D -10.4167 0.001 -15.1159 -5.7174 True B E -11.8333 0.001 -16.5326 -7.1341 True B F 1.3333 0.9 -3.3659 6.0326 False C D 2.8333 0.4921 -1.8659 7.5326 False C E 1.4167 0.9 -3.2826 6.1159 False C F 14.5833 0.001 9.8841 19.2826 True D E -1.4167 0.9 -6.1159 3.2826 False D F 11.75 0.001 7.0508 16.4492 True E F 13.1667 0.001 8.4674 17.8659 True ----------------------------------------------------- . | . Because the above table contains a lot of information, it’s often helpful to visualize these intervals. Python’s statsmodels package does not have a built-in way to do so, but we can create our own as follows. | 1 2 3 4 5 6 7 . | import matplotlib.pyplot as plt rows = tukey.summary().data[1:] plt.hlines( range(len(rows)), [row[4] for row in rows], [row[5] for row in rows] ) plt.vlines( 0, -1, len( rows )-1, linestyles='dashed' ) plt.gca().set_yticks( range( len( rows ) ) ) plt.gca().set_yticklabels( [ f'{x[0]}-{x[1]}' for x in rows ] ) plt.show() . | . Confidence intervals that cross the vertical, dashed line at $x=0$ are those in which the means across those groups may be equal. Other intervals have mean differences whose 95% confidence intervals do not include zero. Content last modified on 10 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#using-statsmodels-matplotlib-and-scikit-in-python",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#using-statsmodels-matplotlib-and-scikit-in-python"
  },"1094": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test",
    "title": "Using agricolae, in R",
    "content": "View this solution alone. We load here the same data that appears in the solution for how to perform pairwise comparisons. That solution used ANOVA to determine which pairs of groups have significant differences in their means; follow its link for more details. | 1 2 3 . | # Load an inbuilt data set called InsectSprays and assign it to the variable df df &lt;- InsectSprays head( df, 10 ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | count spray 1 10 A 2 7 A 3 20 A 4 14 A 5 14 A 6 12 A 7 10 A 8 23 A 9 17 A 10 20 A . | . We now want to perform an unplanned comparison test on the data to determine the magnitudes of the differences between pairs of groups. Although R has a built-in TukeyHSD function, its output is not as complete as the HSD.test function in the agricolae package, so here we will use that latter function. We provide it the same ANOVA results that we computed in the solution to how to perform pairwise comparisons. | 1 2 3 4 . | # install.packages( \"agricolae\" ) # if you have not already done this library(agricolae) aov1 &lt;- aov(count ~ spray, data = df) HSD.test(aov1, \"spray\", group=FALSE, console=TRUE) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 . | Study: aov1 ~ \"spray\" HSD Test for count Mean Square Error: 15.38131 spray, means count std r Min Max A 14.500000 4.719399 12 7 23 B 15.333333 4.271115 12 7 21 C 2.083333 1.975225 12 0 7 D 4.916667 2.503028 12 2 12 E 3.500000 1.732051 12 1 6 F 16.666667 6.213378 12 9 26 Alpha: 0.05 ; DF Error: 66 Critical Value of Studentized Range: 4.150851 Comparison between treatments means difference pvalue signif. LCL UCL A - B -0.8333333 0.9952 -5.532742 3.866075 A - C 12.4166667 0.0000 *** 7.717258 17.116075 A - D 9.5833333 0.0000 *** 4.883925 14.282742 A - E 11.0000000 0.0000 *** 6.300591 15.699409 A - F -2.1666667 0.7542 -6.866075 2.532742 B - C 13.2500000 0.0000 *** 8.550591 17.949409 B - D 10.4166667 0.0000 *** 5.717258 15.116075 B - E 11.8333333 0.0000 *** 7.133925 16.532742 B - F -1.3333333 0.9603 -6.032742 3.366075 C - D -2.8333333 0.4921 -7.532742 1.866075 C - E -1.4166667 0.9489 -6.116075 3.282742 C - F -14.5833333 0.0000 *** -19.282742 -9.883925 D - E 1.4166667 0.9489 -3.282742 6.116075 D - F -11.7500000 0.0000 *** -16.449409 -7.050591 E - F -13.1666667 0.0000 *** -17.866075 -8.467258 . | . The table above highlights for us those confidence intervals whose means are significantly different from zero, and provides other information as well. To see if there is any statistical different between the pairs, look at the “signif” column. The more asterisks appear there, the more significant the difference. Content last modified on 14 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#using-agricolae-in-r",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#using-agricolae-in-r"
  },"1095": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test",
    "title": "Solution, in R",
    "content": "View this solution alone. We load here the same data that appears in the solution for how to perform pairwise comparisons. That solution used ANOVA to determine which pairs of groups have significant differences in their means; follow its link for more details. | 1 2 3 . | # Load an inbuilt data set called InsectSprays and assign it to the variable df df &lt;- InsectSprays head( df, 10 ) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | count spray 1 10 A 2 7 A 3 20 A 4 14 A 5 14 A 6 12 A 7 10 A 8 23 A 9 17 A 10 20 A . | . We now want to perform an unplanned comparison test on the data to determine the magnitudes of the differences between pairs of groups. We do this by applying Tukey’s HSD approach to perform pairwise comparisons and generate confidence intervals that maintain a specified experiment-wide error rate. We use R’s built-in TukeyHSD function, and we give it the same ANOVA results that we computed in the solution for how to perform pairwise comparisons. | 1 2 . | aov1 &lt;- aov(count ~ spray, data = df) TukeyHSD(aov1, \"spray\", ordered=TRUE, conf.level = 0.95) . | . | 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 . | Tukey multiple comparisons of means 95% family-wise confidence level factor levels have been ordered Fit: aov(formula = count ~ spray, data = df) $spray diff lwr upr p adj E-C 1.4166667 -3.282742 6.116075 0.9488669 D-C 2.8333333 -1.866075 7.532742 0.4920707 A-C 12.4166667 7.717258 17.116075 0.0000000 B-C 13.2500000 8.550591 17.949409 0.0000000 F-C 14.5833333 9.883925 19.282742 0.0000000 D-E 1.4166667 -3.282742 6.116075 0.9488669 A-E 11.0000000 6.300591 15.699409 0.0000000 B-E 11.8333333 7.133925 16.532742 0.0000000 F-E 13.1666667 8.467258 17.866075 0.0000000 A-D 9.5833333 4.883925 14.282742 0.0000014 B-D 10.4166667 5.717258 15.116075 0.0000002 F-D 11.7500000 7.050591 16.449409 0.0000000 B-A 0.8333333 -3.866075 5.532742 0.9951810 F-A 2.1666667 -2.532742 6.866075 0.7542147 F-B 1.3333333 -3.366075 6.032742 0.9603075 . | . Because the above table contains a lot of information, it’s often helpful to visualize these intervals. R lets us do so by simply calling plot on the above table. We add a few plotting parameters to improve its appearance. | 1 2 . | plot( TukeyHSD(aov1, \"spray\", ordered=TRUE, conf.level = 0.95), las=1, cex.axis=0.9 ) . | . Confidence intervals that cross the vertical, dashed line at $x=0$ are those in which the means across those groups may be equal. Other intervals have mean differences whose 95% confidence intervals do not include zero. Content last modified on 14 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#solution-in-r",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#solution-in-r"
  },"1096": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | Bentley University MA255 | . ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#topics-that-include-this-task",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#topics-that-include-this-task"
  },"1097": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#opportunities",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/#opportunities"
  },"1098": {
    "doc": "How to perform post-hoc analysis with Tukey's HSD test",
    "title": "How to perform post-hoc analysis with Tukey's HSD test",
    "content": " ",
    "url": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/",
    "relUrl": "/how-to-perform-post-hoc-analysis-with-tukey-s-hsd-test/"
  },"1099": {
    "doc": "How to plot continuous probability distributions (in Excel)",
    "title": "How to plot continuous probability distributions (in Excel)",
    "content": "See all solutions. ",
    "url": "/how-to-plot-continuous-probability-distributions-in-excel/",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-excel/"
  },"1100": {
    "doc": "How to plot continuous probability distributions (in Excel)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to plot the distribution as a curve? . Related tasks: . | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot discrete probability distributions | . ",
    "url": "/how-to-plot-continuous-probability-distributions-in-excel/#task",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-excel/#task"
  },"1101": {
    "doc": "How to plot continuous probability distributions (in Excel)",
    "title": "Solution",
    "content": "We begin by creating the values that will be shown on the $x$-axis. These values depend not only on the distribution, but on which portion of it you wish to see. For example, for an exponential distribution, the sample space is $(0,\\infty)$, but for a standard normal distribution, it is the whole real line, and you may wish to view just $( - 5,5)$, or some other range. In the example below, we will use a Gamma distribution with $\\alpha = 5$ and $\\beta = 5$, plotted on the range $\\lbrack 0,50\\rbrack$, but the particular example doesn’t matter; you can use the procedure below for any distribution. To generate the $x$ values from 0 to 50, begin with just the first two values in the sequence, in this case 0 and 1, as shown below. Drag the small green square in the bottom right of the selection downward, to create a sequence that goes all the way up to 50. (Only the beginning of it is shown here.) . If your sample spaces were a smaller range (say, just from -2 to 2), you would need to use smaller steps to get a smooth plot. For example, you might begin with -2 and -1.9 to tell Excel to take steps of size 0.1. In the adjacent column, we put the formula for the distribution, based on the $x$ values in the first column. In this example, recall that we’ll plot a Gamma distribution with $\\alpha = 5$ and $\\beta = 5$, so we use the formula shown below. The final parameter for the distribution should always be FALSE, to indicate that we are not asking Excel for a cumulative distribution function, but just the usual probability density function. After typing your probability density function’s formula, drag it down the column. Highlight just column B and insert a line chart from the Insert tab on the Ribbon, as shown below. This will create a chart that does not yet include your desired $x$-axis labels; rather, the horizontal axis markings will be 1, 2, 3, 4, etc. To get the correct labels on the $x$-axis, right-click the chart and choose “Select Data…” This will bring up the window shown below. Click the Edit button for the Horizontal (Category) Axis Labels and select column A. Click OK twice to return to your plot, which should then have the correct $x$-axis labels. You can then update the chart title and axis labels to be more descriptive if desired, as shown in the final result, below. Although we used the GAMMA.DIST function in Excel, you can use any of the built-in continuous probability distribution functions, such as BETA.DIST, CHISQ.DIST, F.DIST, NORM.DIST, LOGNORM.DIST, or T.DIST. Content last modified on 14 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-plot-continuous-probability-distributions-in-excel/#solution",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-excel/#solution"
  },"1102": {
    "doc": "How to plot continuous probability distributions (in Julia)",
    "title": "How to plot continuous probability distributions (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-plot-continuous-probability-distributions-in-julia/",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-julia/"
  },"1103": {
    "doc": "How to plot continuous probability distributions (in Julia)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to plot the distribution as a curve? . Related tasks: . | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot discrete probability distributions | . ",
    "url": "/how-to-plot-continuous-probability-distributions-in-julia/#task",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-julia/#task"
  },"1104": {
    "doc": "How to plot continuous probability distributions (in Julia)",
    "title": "Solution",
    "content": "You can import many different random variables from Julia’s Distributions package. The full list of them is online here. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. But we can just ask Julia to show us the central 99.98% of a continuous distribution, which is almost always indistinguishable to the human eye from the entire distribution. We style the plot below so that it is clear the sample space is continuous. | 1 2 3 4 5 6 7 8 9 . | using Distributions X = Normal( 10, 5 ) # use a normal distribution with μ=10 and σ=5 xmin = quantile( X, 0.0001 ) # compute min x as the 0.0001 quantile xmax = quantile( X, 0.9999 ) # compute max x as the 0.9999 quantile xs = range( xmin, xmax, length=100 ) # create 100 x values in that range using Plots plot( xs, pdf.( X, xs ) ) # plot the shape of the distribution . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-plot-continuous-probability-distributions-in-julia/#solution",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-julia/#solution"
  },"1105": {
    "doc": "How to plot continuous probability distributions (in Python, using SciPy)",
    "title": "How to plot continuous probability distributions (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-plot-continuous-probability-distributions-in-python-using-scipy/",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-python-using-scipy/"
  },"1106": {
    "doc": "How to plot continuous probability distributions (in Python, using SciPy)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to plot the distribution as a curve? . Related tasks: . | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot discrete probability distributions | . ",
    "url": "/how-to-plot-continuous-probability-distributions-in-python-using-scipy/#task",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-python-using-scipy/#task"
  },"1107": {
    "doc": "How to plot continuous probability distributions (in Python, using SciPy)",
    "title": "Solution",
    "content": "You can import many different random variables from SciPy’s stats module. The full list of them is online here. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. But we can just ask SciPy to show us the central 99.98% of a continuous distribution, which is almost always indistinguishable to the human eye from the entire distribution. We style the plot below so that it is clear the sample space is continuous. | 1 2 3 4 5 6 7 8 9 10 11 . | from scipy import stats X = stats.norm( 10, 5 ) # use a normal distribution with μ=10 and σ=5 xmin = X.ppf( 0.0001 ) # compute min x as the 0.0001 quantile xmax = X.ppf( 0.9999 ) # compute max x as the 0.9999 quantile import numpy as np xs = np.linspace( xmin, xmax, 100 ) # create 100 x values in that range import matplotlib.pyplot as plt plt.plot( xs, X.pdf( xs ) ) # plot the shape of the distribution plt.show() . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-plot-continuous-probability-distributions-in-python-using-scipy/#solution",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-python-using-scipy/#solution"
  },"1108": {
    "doc": "How to plot continuous probability distributions (in R)",
    "title": "How to plot continuous probability distributions (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-plot-continuous-probability-distributions-in-r/",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-r/"
  },"1109": {
    "doc": "How to plot continuous probability distributions (in R)",
    "title": "Task",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to plot the distribution as a curve? . Related tasks: . | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot discrete probability distributions | . ",
    "url": "/how-to-plot-continuous-probability-distributions-in-r/#task",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-r/#task"
  },"1110": {
    "doc": "How to plot continuous probability distributions (in R)",
    "title": "Solution",
    "content": "Because R is designed for use in statistics, it comes with many probability distributions built in. A list of them is online here. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. But we can just ask R to show us the central 99.98% of a continuous distribution, which is almost always indistinguishable to the human eye from the entire distribution. We will use a normal distribution with $\\mu=10$ and $\\sigma=5$, but if you wanted to use a different distribution, you could replace qnorm and dnorm with, for example, qchisq and dchisq (for the $\\chi^2$ distribution), adjusting the named parameters as appropriate. (For a list of supported distributions, see the link above.) . We style the plot below so that it is clear the sample space is continuous. | 1 2 3 4 5 . | xmin &lt;- qnorm( 0.0001, mean=10, sd=5 ) # compute min x as the 0.0001 quantile xmax &lt;- qnorm( 0.9999, mean=10, sd=5 ) # compute max x as the 0.9999 quantile xs &lt;- seq( xmin, xmax, length.out=100 ) # create 100 values in that range ys &lt;- dnorm( xs, mean=10, sd=5 ) # compute the shape of the distribution plot( xs, ys, type='l' ) # plot that shape as a smooth line . | . Content last modified on 28 May 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-plot-continuous-probability-distributions-in-r/#solution",
    "relUrl": "/how-to-plot-continuous-probability-distributions-in-r/#solution"
  },"1111": {
    "doc": "How to plot continuous probability distributions",
    "title": "How to plot continuous probability distributions",
    "content": " ",
    "url": "/how-to-plot-continuous-probability-distributions/",
    "relUrl": "/how-to-plot-continuous-probability-distributions/"
  },"1112": {
    "doc": "How to plot continuous probability distributions",
    "title": "Description",
    "content": "There are many famous continuous probability distributions, such as the normal and exponential distributions. How can we get access to them in software, to plot the distribution as a curve? . Related tasks: . | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot discrete probability distributions | . ",
    "url": "/how-to-plot-continuous-probability-distributions/#description",
    "relUrl": "/how-to-plot-continuous-probability-distributions/#description"
  },"1113": {
    "doc": "How to plot continuous probability distributions",
    "title": "Solution, in Excel",
    "content": "View this solution alone. We begin by creating the values that will be shown on the $x$-axis. These values depend not only on the distribution, but on which portion of it you wish to see. For example, for an exponential distribution, the sample space is $(0,\\infty)$, but for a standard normal distribution, it is the whole real line, and you may wish to view just $( - 5,5)$, or some other range. In the example below, we will use a Gamma distribution with $\\alpha = 5$ and $\\beta = 5$, plotted on the range $\\lbrack 0,50\\rbrack$, but the particular example doesn’t matter; you can use the procedure below for any distribution. To generate the $x$ values from 0 to 50, begin with just the first two values in the sequence, in this case 0 and 1, as shown below. Drag the small green square in the bottom right of the selection downward, to create a sequence that goes all the way up to 50. (Only the beginning of it is shown here.) . If your sample spaces were a smaller range (say, just from -2 to 2), you would need to use smaller steps to get a smooth plot. For example, you might begin with -2 and -1.9 to tell Excel to take steps of size 0.1. In the adjacent column, we put the formula for the distribution, based on the $x$ values in the first column. In this example, recall that we’ll plot a Gamma distribution with $\\alpha = 5$ and $\\beta = 5$, so we use the formula shown below. The final parameter for the distribution should always be FALSE, to indicate that we are not asking Excel for a cumulative distribution function, but just the usual probability density function. After typing your probability density function’s formula, drag it down the column. Highlight just column B and insert a line chart from the Insert tab on the Ribbon, as shown below. This will create a chart that does not yet include your desired $x$-axis labels; rather, the horizontal axis markings will be 1, 2, 3, 4, etc. To get the correct labels on the $x$-axis, right-click the chart and choose “Select Data…” This will bring up the window shown below. Click the Edit button for the Horizontal (Category) Axis Labels and select column A. Click OK twice to return to your plot, which should then have the correct $x$-axis labels. You can then update the chart title and axis labels to be more descriptive if desired, as shown in the final result, below. Although we used the GAMMA.DIST function in Excel, you can use any of the built-in continuous probability distribution functions, such as BETA.DIST, CHISQ.DIST, F.DIST, NORM.DIST, LOGNORM.DIST, or T.DIST. Content last modified on 14 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-plot-continuous-probability-distributions/#solution-in-excel",
    "relUrl": "/how-to-plot-continuous-probability-distributions/#solution-in-excel"
  },"1114": {
    "doc": "How to plot continuous probability distributions",
    "title": "Solution, in Julia",
    "content": "View this solution alone. You can import many different random variables from Julia’s Distributions package. The full list of them is online here. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. But we can just ask Julia to show us the central 99.98% of a continuous distribution, which is almost always indistinguishable to the human eye from the entire distribution. We style the plot below so that it is clear the sample space is continuous. | 1 2 3 4 5 6 7 8 9 . | using Distributions X = Normal( 10, 5 ) # use a normal distribution with μ=10 and σ=5 xmin = quantile( X, 0.0001 ) # compute min x as the 0.0001 quantile xmax = quantile( X, 0.9999 ) # compute max x as the 0.9999 quantile xs = range( xmin, xmax, length=100 ) # create 100 x values in that range using Plots plot( xs, pdf.( X, xs ) ) # plot the shape of the distribution . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-plot-continuous-probability-distributions/#solution-in-julia",
    "relUrl": "/how-to-plot-continuous-probability-distributions/#solution-in-julia"
  },"1115": {
    "doc": "How to plot continuous probability distributions",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. You can import many different random variables from SciPy’s stats module. The full list of them is online here. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. But we can just ask SciPy to show us the central 99.98% of a continuous distribution, which is almost always indistinguishable to the human eye from the entire distribution. We style the plot below so that it is clear the sample space is continuous. | 1 2 3 4 5 6 7 8 9 10 11 . | from scipy import stats X = stats.norm( 10, 5 ) # use a normal distribution with μ=10 and σ=5 xmin = X.ppf( 0.0001 ) # compute min x as the 0.0001 quantile xmax = X.ppf( 0.9999 ) # compute max x as the 0.9999 quantile import numpy as np xs = np.linspace( xmin, xmax, 100 ) # create 100 x values in that range import matplotlib.pyplot as plt plt.plot( xs, X.pdf( xs ) ) # plot the shape of the distribution plt.show() . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-plot-continuous-probability-distributions/#using-scipy-in-python",
    "relUrl": "/how-to-plot-continuous-probability-distributions/#using-scipy-in-python"
  },"1116": {
    "doc": "How to plot continuous probability distributions",
    "title": "Solution, in R",
    "content": "View this solution alone. Because R is designed for use in statistics, it comes with many probability distributions built in. A list of them is online here. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. But we can just ask R to show us the central 99.98% of a continuous distribution, which is almost always indistinguishable to the human eye from the entire distribution. We will use a normal distribution with $\\mu=10$ and $\\sigma=5$, but if you wanted to use a different distribution, you could replace qnorm and dnorm with, for example, qchisq and dchisq (for the $\\chi^2$ distribution), adjusting the named parameters as appropriate. (For a list of supported distributions, see the link above.) . We style the plot below so that it is clear the sample space is continuous. | 1 2 3 4 5 . | xmin &lt;- qnorm( 0.0001, mean=10, sd=5 ) # compute min x as the 0.0001 quantile xmax &lt;- qnorm( 0.9999, mean=10, sd=5 ) # compute max x as the 0.9999 quantile xs &lt;- seq( xmin, xmax, length.out=100 ) # create 100 values in that range ys &lt;- dnorm( xs, mean=10, sd=5 ) # compute the shape of the distribution plot( xs, ys, type='l' ) # plot that shape as a smooth line . | . Content last modified on 28 May 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-plot-continuous-probability-distributions/#solution-in-r",
    "relUrl": "/how-to-plot-continuous-probability-distributions/#solution-in-r"
  },"1117": {
    "doc": "How to plot continuous probability distributions",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | . ",
    "url": "/how-to-plot-continuous-probability-distributions/#topics-that-include-this-task",
    "relUrl": "/how-to-plot-continuous-probability-distributions/#topics-that-include-this-task"
  },"1118": {
    "doc": "How to plot discrete probability distributions (in Julia)",
    "title": "How to plot discrete probability distributions (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-plot-discrete-probability-distributions-in-julia/",
    "relUrl": "/how-to-plot-discrete-probability-distributions-in-julia/"
  },"1119": {
    "doc": "How to plot discrete probability distributions (in Julia)",
    "title": "Task",
    "content": "There are many famous discrete probability distributions, such as the binomial and geometric distributions. How can we get access to them in software, to plot the distribution as a series of points? . Related tasks: . | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot continuous probability distributions | . ",
    "url": "/how-to-plot-discrete-probability-distributions-in-julia/#task",
    "relUrl": "/how-to-plot-discrete-probability-distributions-in-julia/#task"
  },"1120": {
    "doc": "How to plot discrete probability distributions (in Julia)",
    "title": "Solution",
    "content": "You can import many different random variables from Julia’s Distributions package. The full list of them is online here. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. The example below uses a geometric distribution, whose sample space is $\\{1,2,3,\\ldots\\}$. We specify that we just want to use $x$ values in the set $\\{1,2,\\ldots,10\\}$. (In some software, the geometric distribution’s sample space begins at 0, but not in SciPy.) . We style the plot below so that it is clear the sample space is discrete. | 1 2 3 4 5 6 . | using Distributions X = Geometric( 0.5 ) # use a geometric distribution with p=0.5 xs = 1:10 # specify the range to be 1,2,3,...,10 using Plots bar( xs, pdf.( X, xs ) ) # plot the shape of the distribution . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-plot-discrete-probability-distributions-in-julia/#solution",
    "relUrl": "/how-to-plot-discrete-probability-distributions-in-julia/#solution"
  },"1121": {
    "doc": "How to plot discrete probability distributions (in Python, using SciPy)",
    "title": "How to plot discrete probability distributions (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-plot-discrete-probability-distributions-in-python-using-scipy/",
    "relUrl": "/how-to-plot-discrete-probability-distributions-in-python-using-scipy/"
  },"1122": {
    "doc": "How to plot discrete probability distributions (in Python, using SciPy)",
    "title": "Task",
    "content": "There are many famous discrete probability distributions, such as the binomial and geometric distributions. How can we get access to them in software, to plot the distribution as a series of points? . Related tasks: . | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot continuous probability distributions | . ",
    "url": "/how-to-plot-discrete-probability-distributions-in-python-using-scipy/#task",
    "relUrl": "/how-to-plot-discrete-probability-distributions-in-python-using-scipy/#task"
  },"1123": {
    "doc": "How to plot discrete probability distributions (in Python, using SciPy)",
    "title": "Solution",
    "content": "You can import many different random variables from SciPy’s stats module. The full list of them is online here. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. The example below uses a geometric distribution, whose sample space is $\\{1,2,3,\\ldots\\}$. We specify that we just want to use $x$ values in the set $\\{1,2,\\ldots,10\\}$. (In some software, the geometric distribution’s sample space begins at 0, but not in SciPy.) . We style the plot below so that it is clear the sample space is discrete. | 1 2 3 4 5 6 7 8 9 10 11 12 . | from scipy import stats X = stats.geom( 0.5 ) # use a geometric distribution with p=0.5 import numpy as np xs = np.arange( 1, 11 ) # specify the range to be 1,2,3,...,10 import matplotlib.pyplot as plt ys = X.pmf( xs ) # compute the shape of the distribution plt.plot( xs, ys, 'o' ) # plot circles... plt.vlines( xs, 0, ys ) # ...and lines plt.ylim( bottom=0 ) # ensure sensible bottom border plt.show() . | . Content last modified on 28 May 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-plot-discrete-probability-distributions-in-python-using-scipy/#solution",
    "relUrl": "/how-to-plot-discrete-probability-distributions-in-python-using-scipy/#solution"
  },"1124": {
    "doc": "How to plot discrete probability distributions (in R)",
    "title": "How to plot discrete probability distributions (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-plot-discrete-probability-distributions-in-r/",
    "relUrl": "/how-to-plot-discrete-probability-distributions-in-r/"
  },"1125": {
    "doc": "How to plot discrete probability distributions (in R)",
    "title": "Task",
    "content": "There are many famous discrete probability distributions, such as the binomial and geometric distributions. How can we get access to them in software, to plot the distribution as a series of points? . Related tasks: . | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot continuous probability distributions | . ",
    "url": "/how-to-plot-discrete-probability-distributions-in-r/#task",
    "relUrl": "/how-to-plot-discrete-probability-distributions-in-r/#task"
  },"1126": {
    "doc": "How to plot discrete probability distributions (in R)",
    "title": "Solution",
    "content": "Because R is designed for use in statistics, it comes with many probability distributions built in. A list of them is online here. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. The example below uses a geometric distribution (with $p=0.5$), whose sample space is $\\{0,1,2,3,\\ldots\\}$. We specify that we just want to use $x$ values in the set $\\{0,1,2,\\ldots,10\\}$. (In some software, the geometric distribution’s sample space begins at 1, but not in R.) . If you wanted to use a different distribution, you could replace dgeom with, for example, dbinom, adjusting the named parameters as appropriate. We style the plot below so that it is clear the sample space is discrete. | 1 2 3 4 5 . | xs = 0:8 # choose the sample space (here, it's 0,1,2,...,10) ys = dgeom( xs, prob=0.5 ) # compute the shape of the distribution plot( xs, ys, type='p', # plot circles... xlab='sample space', ylab='probability' ) segments( xs, 0, xs, ys ) # ...and lines . | . Content last modified on 28 May 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-plot-discrete-probability-distributions-in-r/#solution",
    "relUrl": "/how-to-plot-discrete-probability-distributions-in-r/#solution"
  },"1127": {
    "doc": "How to plot discrete probability distributions",
    "title": "How to plot discrete probability distributions",
    "content": " ",
    "url": "/how-to-plot-discrete-probability-distributions/",
    "relUrl": "/how-to-plot-discrete-probability-distributions/"
  },"1128": {
    "doc": "How to plot discrete probability distributions",
    "title": "Description",
    "content": "There are many famous discrete probability distributions, such as the binomial and geometric distributions. How can we get access to them in software, to plot the distribution as a series of points? . Related tasks: . | How to generate random values from a distribution | How to compute probabilities from a distribution | How to plot continuous probability distributions | . ",
    "url": "/how-to-plot-discrete-probability-distributions/#description",
    "relUrl": "/how-to-plot-discrete-probability-distributions/#description"
  },"1129": {
    "doc": "How to plot discrete probability distributions",
    "title": "Solution, in Julia",
    "content": "View this solution alone. You can import many different random variables from Julia’s Distributions package. The full list of them is online here. If you don’t have that package installed, first run using Pkg and then Pkg.add( \"Distributions\" ) from within Julia. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. The example below uses a geometric distribution, whose sample space is $\\{1,2,3,\\ldots\\}$. We specify that we just want to use $x$ values in the set $\\{1,2,\\ldots,10\\}$. (In some software, the geometric distribution’s sample space begins at 0, but not in SciPy.) . We style the plot below so that it is clear the sample space is discrete. | 1 2 3 4 5 6 . | using Distributions X = Geometric( 0.5 ) # use a geometric distribution with p=0.5 xs = 1:10 # specify the range to be 1,2,3,...,10 using Plots bar( xs, pdf.( X, xs ) ) # plot the shape of the distribution . | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-plot-discrete-probability-distributions/#solution-in-julia",
    "relUrl": "/how-to-plot-discrete-probability-distributions/#solution-in-julia"
  },"1130": {
    "doc": "How to plot discrete probability distributions",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. You can import many different random variables from SciPy’s stats module. The full list of them is online here. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. The example below uses a geometric distribution, whose sample space is $\\{1,2,3,\\ldots\\}$. We specify that we just want to use $x$ values in the set $\\{1,2,\\ldots,10\\}$. (In some software, the geometric distribution’s sample space begins at 0, but not in SciPy.) . We style the plot below so that it is clear the sample space is discrete. | 1 2 3 4 5 6 7 8 9 10 11 12 . | from scipy import stats X = stats.geom( 0.5 ) # use a geometric distribution with p=0.5 import numpy as np xs = np.arange( 1, 11 ) # specify the range to be 1,2,3,...,10 import matplotlib.pyplot as plt ys = X.pmf( xs ) # compute the shape of the distribution plt.plot( xs, ys, 'o' ) # plot circles... plt.vlines( xs, 0, ys ) # ...and lines plt.ylim( bottom=0 ) # ensure sensible bottom border plt.show() . | . Content last modified on 28 May 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-plot-discrete-probability-distributions/#using-scipy-in-python",
    "relUrl": "/how-to-plot-discrete-probability-distributions/#using-scipy-in-python"
  },"1131": {
    "doc": "How to plot discrete probability distributions",
    "title": "Solution, in R",
    "content": "View this solution alone. Because R is designed for use in statistics, it comes with many probability distributions built in. A list of them is online here. The challenge with plotting a random variable is knowing the appropriate sample space, because some random variables have sample spaces of infinite width, which cannot be plotted. The example below uses a geometric distribution (with $p=0.5$), whose sample space is $\\{0,1,2,3,\\ldots\\}$. We specify that we just want to use $x$ values in the set $\\{0,1,2,\\ldots,10\\}$. (In some software, the geometric distribution’s sample space begins at 1, but not in R.) . If you wanted to use a different distribution, you could replace dgeom with, for example, dbinom, adjusting the named parameters as appropriate. We style the plot below so that it is clear the sample space is discrete. | 1 2 3 4 5 . | xs = 0:8 # choose the sample space (here, it's 0,1,2,...,10) ys = dgeom( xs, prob=0.5 ) # compute the shape of the distribution plot( xs, ys, type='p', # plot circles... xlab='sample space', ylab='probability' ) segments( xs, 0, xs, ys ) # ...and lines . | . Content last modified on 28 May 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-plot-discrete-probability-distributions/#solution-in-r",
    "relUrl": "/how-to-plot-discrete-probability-distributions/#solution-in-r"
  },"1132": {
    "doc": "How to plot discrete probability distributions",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | . ",
    "url": "/how-to-plot-discrete-probability-distributions/#topics-that-include-this-task",
    "relUrl": "/how-to-plot-discrete-probability-distributions/#topics-that-include-this-task"
  },"1133": {
    "doc": "How to plot discrete probability distributions",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-plot-discrete-probability-distributions/#opportunities",
    "relUrl": "/how-to-plot-discrete-probability-distributions/#opportunities"
  },"1134": {
    "doc": "How to plot interaction effects of treatments (in Python, using Matplotlib and Seaborn)",
    "title": "How to plot interaction effects of treatments (in Python, using Matplotlib and Seaborn)",
    "content": "See all solutions. ",
    "url": "/how-to-plot-interaction-effects-of-treatments-in-python-using-matplotlib-and-seaborn/",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments-in-python-using-matplotlib-and-seaborn/"
  },"1135": {
    "doc": "How to plot interaction effects of treatments (in Python, using Matplotlib and Seaborn)",
    "title": "Task",
    "content": "When there are multiple treatment conditions with multiple levels and you wish to undertsand the interaction effects of each of them, a plot can be useful. How can we create the right kind of plot for that situation? . | How to create basic plots | How to add details to a plot | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | . ",
    "url": "/how-to-plot-interaction-effects-of-treatments-in-python-using-matplotlib-and-seaborn/#task",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments-in-python-using-matplotlib-and-seaborn/#task"
  },"1136": {
    "doc": "How to plot interaction effects of treatments (in Python, using Matplotlib and Seaborn)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . To plot the interaction effects among tooth length, supplement, and dosage, we can use the pointplot function in the Seaborn package. | 1 2 3 4 5 . | import seaborn as sns import matplotlib.pyplot as plt sns.pointplot(x='dose',y='len',hue='supp',data=df) plt.legend(loc='lower right') # Default is upper right, which overlaps the data here. plt.show() . | . Looking at the output, we first see that there is an interaction effect because the two supp lines intersect. We also see that there is a difference in length when giving 0.5mg and 1mg dosage of either of the two delivery methods. However, there is barely any difference between the delivery methods when the dosage level is 2mg. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-plot-interaction-effects-of-treatments-in-python-using-matplotlib-and-seaborn/#solution",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments-in-python-using-matplotlib-and-seaborn/#solution"
  },"1137": {
    "doc": "How to plot interaction effects of treatments (in R, using ggpubr)",
    "title": "How to plot interaction effects of treatments (in R, using ggpubr)",
    "content": "See all solutions. ",
    "url": "/how-to-plot-interaction-effects-of-treatments-in-r-using-ggpubr/",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments-in-r-using-ggpubr/"
  },"1138": {
    "doc": "How to plot interaction effects of treatments (in R, using ggpubr)",
    "title": "Task",
    "content": "When there are multiple treatment conditions with multiple levels and you wish to undertsand the interaction effects of each of them, a plot can be useful. How can we create the right kind of plot for that situation? . | How to create basic plots | How to add details to a plot | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | . ",
    "url": "/how-to-plot-interaction-effects-of-treatments-in-r-using-ggpubr/#task",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments-in-r-using-ggpubr/#task"
  },"1139": {
    "doc": "How to plot interaction effects of treatments (in R, using ggpubr)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 . | df &lt;- ToothGrowth . | . To plot the interaction effects among tooth length, supplement, and dosage, we can use the ggline function in the ggpubr package. You can change the x and color inputs below depending on your goals, but the y input should always be the dependent variable. | 1 2 3 . | # install.packages(\"ggpubr\") # If you have not already installed it library(ggpubr) ggline(df, x=\"dose\", y=\"len\", color=\"supp\", add=c(\"mean\")) . | . | 1 . | Loading required package: ggplot2 . | . Looking at the output, we first see that there is an interaction effect because the two supp lines intersect. We also see that there is a difference in length when giving 0.5mg and 1mg dosage of either of the two delivery methods. However, there is barely any difference between the delivery methods when the dosage level is 2mg. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-plot-interaction-effects-of-treatments-in-r-using-ggpubr/#solution",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments-in-r-using-ggpubr/#solution"
  },"1140": {
    "doc": "How to plot interaction effects of treatments",
    "title": "How to plot interaction effects of treatments",
    "content": " ",
    "url": "/how-to-plot-interaction-effects-of-treatments/",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments/"
  },"1141": {
    "doc": "How to plot interaction effects of treatments",
    "title": "Description",
    "content": "When there are multiple treatment conditions with multiple levels and you wish to undertsand the interaction effects of each of them, a plot can be useful. How can we create the right kind of plot for that situation? . | How to create basic plots | How to add details to a plot | How to create a histogram | How to create a box (and whisker) plot | How to change axes, ticks, and scale in a plot | How to create bivariate plots to compare groups | . ",
    "url": "/how-to-plot-interaction-effects-of-treatments/#description",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments/#description"
  },"1142": {
    "doc": "How to plot interaction effects of treatments",
    "title": "Using Matplotlib and Seaborn, in Python",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . To plot the interaction effects among tooth length, supplement, and dosage, we can use the pointplot function in the Seaborn package. | 1 2 3 4 5 . | import seaborn as sns import matplotlib.pyplot as plt sns.pointplot(x='dose',y='len',hue='supp',data=df) plt.legend(loc='lower right') # Default is upper right, which overlaps the data here. plt.show() . | . Looking at the output, we first see that there is an interaction effect because the two supp lines intersect. We also see that there is a difference in length when giving 0.5mg and 1mg dosage of either of the two delivery methods. However, there is barely any difference between the delivery methods when the dosage level is 2mg. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-plot-interaction-effects-of-treatments/#using-matplotlib-and-seaborn-in-python",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments/#using-matplotlib-and-seaborn-in-python"
  },"1143": {
    "doc": "How to plot interaction effects of treatments",
    "title": "Using ggpubr, in R",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 . | df &lt;- ToothGrowth . | . To plot the interaction effects among tooth length, supplement, and dosage, we can use the ggline function in the ggpubr package. You can change the x and color inputs below depending on your goals, but the y input should always be the dependent variable. | 1 2 3 . | # install.packages(\"ggpubr\") # If you have not already installed it library(ggpubr) ggline(df, x=\"dose\", y=\"len\", color=\"supp\", add=c(\"mean\")) . | . | 1 . | Loading required package: ggplot2 . | . Looking at the output, we first see that there is an interaction effect because the two supp lines intersect. We also see that there is a difference in length when giving 0.5mg and 1mg dosage of either of the two delivery methods. However, there is barely any difference between the delivery methods when the dosage level is 2mg. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-plot-interaction-effects-of-treatments/#using-ggpubr-in-r",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments/#using-ggpubr-in-r"
  },"1144": {
    "doc": "How to plot interaction effects of treatments",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-plot-interaction-effects-of-treatments/#topics-that-include-this-task",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments/#topics-that-include-this-task"
  },"1145": {
    "doc": "How to plot interaction effects of treatments",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-plot-interaction-effects-of-treatments/#opportunities",
    "relUrl": "/how-to-plot-interaction-effects-of-treatments/#opportunities"
  },"1146": {
    "doc": "How to predict the response variable in a linear model (in Python, using statsmodels)",
    "title": "How to predict the response variable in a linear model (in Python, using statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model-in-python-using-statsmodels/",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model-in-python-using-statsmodels/"
  },"1147": {
    "doc": "How to predict the response variable in a linear model (in Python, using statsmodels)",
    "title": "Task",
    "content": "If we have a linear model and a value for each explanatory variable, how do we predict the corresponding value of the response variable? . Related tasks: . | How to fit a linear model to two columns of data | How to fit a multivariate linear model | . ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model-in-python-using-statsmodels/#task",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model-in-python-using-statsmodels/#task"
  },"1148": {
    "doc": "How to predict the response variable in a linear model (in Python, using statsmodels)",
    "title": "Solution",
    "content": "Let’s assume that you’ve already built a linear model. We do an example below with fake data, but you can use your own actual data. For more information on the following code, see how to fit a multivariate linear model. | 1 2 3 4 5 6 7 8 9 10 . | import pandas as pd df = pd.DataFrame( { 'x1' : [ 2, 7, 4, 3, 11, 18, 6, 15, 9, 12], 'x2' : [ 4, 6, 10, 1, 18, 11, 8, 20, 16, 13], 'x3' : [11, 16, 20, 6, 14, 8, 5, 23, 13, 10], 'y' : [24, 60, 32, 29, 90, 45, 130, 76, 100, 120] } ) import statsmodels.api as sm model = sm.OLS( df['y'], sm.add_constant( df[['x1','x2','x3']] ) ).fit() . | . Let’s say we want to estimate $y$ given that $x_1 = 5$, $x_2 = 12$, and $x_3=50$. We can use the model’s predict() function as shown below, but we must add an entry for the constant term in the model—we can use any value, but we choose 1. | 1 . | model.predict( [ 1, 5, 12, 50 ] ) . | . | 1 . | array([-91.71014402]) . | . For the given values of the explanatory variables, our predicted response variable is $-91.71014402$. Note that if you want to compute the predicted values for all the data on which the model was trained, simply call model.predict() with no arguments, and it defaults to using the training data. | 1 . | model.predict() . | . | 1 2 3 . | array([ 47.5701159 , 24.35988296, 42.21531274, 47.27613825, 110.86526185, 70.03097584, 95.12689978, 70.91290879, 106.52986696, 91.11263692]) . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model-in-python-using-statsmodels/#solution",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model-in-python-using-statsmodels/#solution"
  },"1149": {
    "doc": "How to predict the response variable in a linear model (in R)",
    "title": "How to predict the response variable in a linear model (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model-in-r/",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model-in-r/"
  },"1150": {
    "doc": "How to predict the response variable in a linear model (in R)",
    "title": "Task",
    "content": "If we have a linear model and a value for each explanatory variable, how do we predict the corresponding value of the response variable? . Related tasks: . | How to fit a linear model to two columns of data | How to fit a multivariate linear model | . ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model-in-r/#task",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model-in-r/#task"
  },"1151": {
    "doc": "How to predict the response variable in a linear model (in R)",
    "title": "Solution",
    "content": "Let’s assume that you’ve already built a linear model. We do an example below with fake data, but you can use your own actual data. For more information on the following code, see how to fit a multivariate linear model. | 1 2 3 4 5 . | x1 &lt;- c( 2, 7, 4, 3, 11, 18, 6, 15, 9, 12) x2 &lt;- c( 4, 6, 10, 1, 18, 11, 8, 20, 16, 13) x3 &lt;- c(11, 16, 20, 6, 14, 8, 5, 23, 13, 10) y &lt;- c(24, 60, 32, 29, 90, 45, 130, 76, 100, 120) model &lt;- lm(y ~ x1 + x2 + x3) . | . Let’s say we want to estimate $y$ given that $x_1 = 5$, $x_2 = 12$, and $x_3=50$. We can use R’s predict() function as shown below. | 1 . | predict(model, newdata = data.frame(x1 = 5, x2 = 12, x3 = 50)) . | . | 1 2 . | 1 -91.71014 . | . For the given values of the explanatory variables, our predicted response variable is $-91.71014$. Note that if you want to compute the predicted values for all the data on which the model was trained, simply call predict(model) with no new data, and it defaults to using the training data. | 1 . | predict(model) . | . | 1 2 3 4 . | 1 2 3 4 5 6 7 8 47.57012 24.35988 42.21531 47.27614 110.86526 70.03098 95.12690 70.91291 9 10 106.52987 91.11264 . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model-in-r/#solution",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model-in-r/#solution"
  },"1152": {
    "doc": "How to predict the response variable in a linear model",
    "title": "How to predict the response variable in a linear model",
    "content": " ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model/",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model/"
  },"1153": {
    "doc": "How to predict the response variable in a linear model",
    "title": "Description",
    "content": "If we have a linear model and a value for each explanatory variable, how do we predict the corresponding value of the response variable? . Related tasks: . | How to fit a linear model to two columns of data | How to fit a multivariate linear model | . ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model/#description",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model/#description"
  },"1154": {
    "doc": "How to predict the response variable in a linear model",
    "title": "Using statsmodels, in Python",
    "content": "View this solution alone. Let’s assume that you’ve already built a linear model. We do an example below with fake data, but you can use your own actual data. For more information on the following code, see how to fit a multivariate linear model. | 1 2 3 4 5 6 7 8 9 10 . | import pandas as pd df = pd.DataFrame( { 'x1' : [ 2, 7, 4, 3, 11, 18, 6, 15, 9, 12], 'x2' : [ 4, 6, 10, 1, 18, 11, 8, 20, 16, 13], 'x3' : [11, 16, 20, 6, 14, 8, 5, 23, 13, 10], 'y' : [24, 60, 32, 29, 90, 45, 130, 76, 100, 120] } ) import statsmodels.api as sm model = sm.OLS( df['y'], sm.add_constant( df[['x1','x2','x3']] ) ).fit() . | . Let’s say we want to estimate $y$ given that $x_1 = 5$, $x_2 = 12$, and $x_3=50$. We can use the model’s predict() function as shown below, but we must add an entry for the constant term in the model—we can use any value, but we choose 1. | 1 . | model.predict( [ 1, 5, 12, 50 ] ) . | . | 1 . | array([-91.71014402]) . | . For the given values of the explanatory variables, our predicted response variable is $-91.71014402$. Note that if you want to compute the predicted values for all the data on which the model was trained, simply call model.predict() with no arguments, and it defaults to using the training data. | 1 . | model.predict() . | . | 1 2 3 . | array([ 47.5701159 , 24.35988296, 42.21531274, 47.27613825, 110.86526185, 70.03097584, 95.12689978, 70.91290879, 106.52986696, 91.11263692]) . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model/#using-statsmodels-in-python",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model/#using-statsmodels-in-python"
  },"1155": {
    "doc": "How to predict the response variable in a linear model",
    "title": "Solution, in R",
    "content": "View this solution alone. Let’s assume that you’ve already built a linear model. We do an example below with fake data, but you can use your own actual data. For more information on the following code, see how to fit a multivariate linear model. | 1 2 3 4 5 . | x1 &lt;- c( 2, 7, 4, 3, 11, 18, 6, 15, 9, 12) x2 &lt;- c( 4, 6, 10, 1, 18, 11, 8, 20, 16, 13) x3 &lt;- c(11, 16, 20, 6, 14, 8, 5, 23, 13, 10) y &lt;- c(24, 60, 32, 29, 90, 45, 130, 76, 100, 120) model &lt;- lm(y ~ x1 + x2 + x3) . | . Let’s say we want to estimate $y$ given that $x_1 = 5$, $x_2 = 12$, and $x_3=50$. We can use R’s predict() function as shown below. | 1 . | predict(model, newdata = data.frame(x1 = 5, x2 = 12, x3 = 50)) . | . | 1 2 . | 1 -91.71014 . | . For the given values of the explanatory variables, our predicted response variable is $-91.71014$. Note that if you want to compute the predicted values for all the data on which the model was trained, simply call predict(model) with no new data, and it defaults to using the training data. | 1 . | predict(model) . | . | 1 2 3 4 . | 1 2 3 4 5 6 7 8 47.57012 24.35988 42.21531 47.27614 110.86526 70.03098 95.12690 70.91291 9 10 106.52987 91.11264 . | . Content last modified on 07 December 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model/#solution-in-r",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model/#solution-in-r"
  },"1156": {
    "doc": "How to predict the response variable in a linear model",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | Bentley University MA252 | . ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model/#topics-that-include-this-task",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model/#topics-that-include-this-task"
  },"1157": {
    "doc": "How to predict the response variable in a linear model",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-predict-the-response-variable-in-a-linear-model/#opportunities",
    "relUrl": "/how-to-predict-the-response-variable-in-a-linear-model/#opportunities"
  },"1158": {
    "doc": "How to quickly load some sample data (in Julia)",
    "title": "How to quickly load some sample data (in Julia)",
    "content": "See all solutions. ",
    "url": "/how-to-quickly-load-some-sample-data-in-julia/",
    "relUrl": "/how-to-quickly-load-some-sample-data-in-julia/"
  },"1159": {
    "doc": "How to quickly load some sample data (in Julia)",
    "title": "Task",
    "content": "Sometimes you just need to try out a new piece of code, whether it be data manipulation, statistical computation, plotting, or whatever. And it’s handy to be able to quickly load some example data to work with. There is a lot of freely available sample data out there. What’s the easiest way to load it? . ",
    "url": "/how-to-quickly-load-some-sample-data-in-julia/#task",
    "relUrl": "/how-to-quickly-load-some-sample-data-in-julia/#task"
  },"1160": {
    "doc": "How to quickly load some sample data (in Julia)",
    "title": "Solution",
    "content": "The R programming language comes with many free datasets built in. To make these same datasets available to Julia programmers as well, you can install and import the RDatasets package. First, ensure that you have it installed, by running the Julia commands using Pkg and then Pkg.add( \"RDatasets\" ). Then you can get access to many datasets as follows: . | 1 2 3 . | using RDatasets iris = dataset( \"datasets\", \"iris\" ) first( iris, 5 ) # just show the first 5 rows . | . 5×5 DataFrame | Row | SepalLength | SepalWidth | PetalLength | PetalWidth | Species | . | | Float64 | Float64 | Float64 | Float64 | Cat… | . | 1 | 5.1 | 3.5 | 1.4 | 0.2 | setosa | . | 2 | 4.9 | 3.0 | 1.4 | 0.2 | setosa | . | 3 | 4.7 | 3.2 | 1.3 | 0.2 | setosa | . | 4 | 4.6 | 3.1 | 1.5 | 0.2 | setosa | . | 5 | 5.0 | 3.6 | 1.4 | 0.2 | setosa | . But what datasets are available? There are many! You can find a full list in the package itself. | 1 . | RDatasets.packages() . | . 34×2 DataFrame9 rows omitted | Row | Package | Title | . | | String15 | String | . | 1 | COUNT | Functions, data and code for count data. | . | 2 | Ecdat | Data sets for econometrics | . | 3 | HSAUR | A Handbook of Statistical Analyses Using R (1st Edition) | . | 4 | HistData | Data sets from the history of statistics and data visualization | . | 5 | ISLR | Data for An Introduction to Statistical Learning with Applications in R | . | 6 | KMsurv | Data sets from Klein and Moeschberger (1997), Survival Analysis | . | 7 | MASS | Support Functions and Datasets for Venables and Ripley&apos;s MASS | . | 8 | SASmixed | Data sets from &quot;SAS System for Mixed Models&quot; | . | 9 | Zelig | Everyone&apos;s Statistical Software | . | 10 | adehabitatLT | Analysis of Animal Movements | . | 11 | boot | Bootstrap Functions (Originally by Angelo Canty for S) | . | 12 | car | Companion to Applied Regression | . | 13 | cluster | Cluster Analysis Extended Rousseeuw et al. | . | &vellip; | &vellip; | &vellip; | . | 23 | plm | Linear Models for Panel Data | . | 24 | plyr | Tools for splitting, applying and combining data | . | 25 | pscl | Political Science Computational Laboratory, Stanford University | . | 26 | psych | Procedures for Psychological, Psychometric, and Personality Research | . | 27 | quantreg | Quantile Regression | . | 28 | reshape2 | Flexibly Reshape Data: A Reboot of the Reshape Package. | . | 29 | robustbase | Basic Robust Statistics | . | 30 | rpart | Recursive Partitioning and Regression Trees | . | 31 | sandwich | Robust Covariance Matrix Estimators | . | 32 | sem | Structural Equation Models | . | 33 | survival | Survival Analysis | . | 34 | vcd | Visualizing Categorical Data | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-quickly-load-some-sample-data-in-julia/#solution",
    "relUrl": "/how-to-quickly-load-some-sample-data-in-julia/#solution"
  },"1161": {
    "doc": "How to quickly load some sample data (in Python)",
    "title": "How to quickly load some sample data (in Python)",
    "content": "See all solutions. ",
    "url": "/how-to-quickly-load-some-sample-data-in-python/",
    "relUrl": "/how-to-quickly-load-some-sample-data-in-python/"
  },"1162": {
    "doc": "How to quickly load some sample data (in Python)",
    "title": "Task",
    "content": "Sometimes you just need to try out a new piece of code, whether it be data manipulation, statistical computation, plotting, or whatever. And it’s handy to be able to quickly load some example data to work with. There is a lot of freely available sample data out there. What’s the easiest way to load it? . ",
    "url": "/how-to-quickly-load-some-sample-data-in-python/#task",
    "relUrl": "/how-to-quickly-load-some-sample-data-in-python/#task"
  },"1163": {
    "doc": "How to quickly load some sample data (in Python)",
    "title": "Solution",
    "content": "The R programming language comes with many free datasets built in. To make these same datasets available to Python programmers as well, you can install and import the rdatasets package. First, ensure that you have it installed, by running pip install rdatasets or conda install rdatasets from your command line. Then you can get access to many datasets as follows: . | 1 2 3 . | from rdatasets import data df = data( 'iris' ) # Load the famous Fisher's irises dataset df.head() . | . | | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species | . | 0 | 5.1 | 3.5 | 1.4 | 0.2 | setosa | . | 1 | 4.9 | 3.0 | 1.4 | 0.2 | setosa | . | 2 | 4.7 | 3.2 | 1.3 | 0.2 | setosa | . | 3 | 4.6 | 3.1 | 1.5 | 0.2 | setosa | . | 4 | 5.0 | 3.6 | 1.4 | 0.2 | setosa | . But what datasets are available? There are many! You can find a full list in the package itself. | 1 2 . | from rdatasets import summary summary() . | . | | Package | Item | Title | Rows | Cols | n_binary | n_character | n_factor | n_logical | n_numeric | CSV | Doc | . | 0 | boot | acme | Monthly Excess Returns | 60 | 3 | 0 | 1 | 0 | 0 | 2 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 1 | boot | aids | Delay in AIDS Reporting in England and Wales | 570 | 6 | 1 | 0 | 0 | 0 | 6 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 2 | boot | aircondit | Failures of Air-conditioning Equipment | 12 | 1 | 0 | 0 | 0 | 0 | 1 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 3 | boot | aircondit7 | Failures of Air-conditioning Equipment | 24 | 1 | 0 | 0 | 0 | 0 | 1 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 4 | boot | amis | Car Speeding and Warning Signs | 8437 | 4 | 1 | 0 | 0 | 0 | 4 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . | 1340 | Zelig | tobin | Tobin's Tobit Data | 20 | 3 | 0 | 0 | 0 | 0 | 3 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 1341 | Zelig | turnout | Turnout Data Set from the National Election Su... | 2000 | 5 | 2 | 0 | 1 | 0 | 4 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 1342 | Zelig | voteincome | Sample Turnout and Demographic Data from the 2... | 1500 | 7 | 3 | 0 | 1 | 0 | 6 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 1343 | Zelig | Weimar | 1932 Weimar election data | 10 | 11 | 0 | 0 | 0 | 0 | 11 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 1344 | Zelig | Zelig.url | Table of links for Zelig | 49 | 2 | 0 | 0 | 2 | 0 | 0 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . 1345 rows × 12 columns . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-quickly-load-some-sample-data-in-python/#solution",
    "relUrl": "/how-to-quickly-load-some-sample-data-in-python/#solution"
  },"1164": {
    "doc": "How to quickly load some sample data (in R)",
    "title": "How to quickly load some sample data (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-quickly-load-some-sample-data-in-r/",
    "relUrl": "/how-to-quickly-load-some-sample-data-in-r/"
  },"1165": {
    "doc": "How to quickly load some sample data (in R)",
    "title": "Task",
    "content": "Sometimes you just need to try out a new piece of code, whether it be data manipulation, statistical computation, plotting, or whatever. And it’s handy to be able to quickly load some example data to work with. There is a lot of freely available sample data out there. What’s the easiest way to load it? . ",
    "url": "/how-to-quickly-load-some-sample-data-in-r/#task",
    "relUrl": "/how-to-quickly-load-some-sample-data-in-r/#task"
  },"1166": {
    "doc": "How to quickly load some sample data (in R)",
    "title": "Solution",
    "content": "R comes with many datasets in its datasets package. Ensure that you have it installed as follows. | 1 . | library(datasets) . | . Then you can load any one of them with the data function, as follows. | 1 2 . | data(iris) # Load the famous Fisher's irises dataset. head(iris) # It has been placed in a variable of the same name. | . | 1 2 3 4 5 6 7 . | Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa . | . To page through a list of all available datasets, just call data() with no arguments. Content last modified on 26 July 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-quickly-load-some-sample-data-in-r/#solution",
    "relUrl": "/how-to-quickly-load-some-sample-data-in-r/#solution"
  },"1167": {
    "doc": "How to quickly load some sample data",
    "title": "How to quickly load some sample data",
    "content": " ",
    "url": "/how-to-quickly-load-some-sample-data/",
    "relUrl": "/how-to-quickly-load-some-sample-data/"
  },"1168": {
    "doc": "How to quickly load some sample data",
    "title": "Description",
    "content": "Sometimes you just need to try out a new piece of code, whether it be data manipulation, statistical computation, plotting, or whatever. And it’s handy to be able to quickly load some example data to work with. There is a lot of freely available sample data out there. What’s the easiest way to load it? . ",
    "url": "/how-to-quickly-load-some-sample-data/#description",
    "relUrl": "/how-to-quickly-load-some-sample-data/#description"
  },"1169": {
    "doc": "How to quickly load some sample data",
    "title": "Solution, in Julia",
    "content": "View this solution alone. The R programming language comes with many free datasets built in. To make these same datasets available to Julia programmers as well, you can install and import the RDatasets package. First, ensure that you have it installed, by running the Julia commands using Pkg and then Pkg.add( \"RDatasets\" ). Then you can get access to many datasets as follows: . | 1 2 3 . | using RDatasets iris = dataset( \"datasets\", \"iris\" ) first( iris, 5 ) # just show the first 5 rows . | . 5×5 DataFrame | Row | SepalLength | SepalWidth | PetalLength | PetalWidth | Species | . | | Float64 | Float64 | Float64 | Float64 | Cat… | . | 1 | 5.1 | 3.5 | 1.4 | 0.2 | setosa | . | 2 | 4.9 | 3.0 | 1.4 | 0.2 | setosa | . | 3 | 4.7 | 3.2 | 1.3 | 0.2 | setosa | . | 4 | 4.6 | 3.1 | 1.5 | 0.2 | setosa | . | 5 | 5.0 | 3.6 | 1.4 | 0.2 | setosa | . But what datasets are available? There are many! You can find a full list in the package itself. | 1 . | RDatasets.packages() . | . 34×2 DataFrame9 rows omitted | Row | Package | Title | . | | String15 | String | . | 1 | COUNT | Functions, data and code for count data. | . | 2 | Ecdat | Data sets for econometrics | . | 3 | HSAUR | A Handbook of Statistical Analyses Using R (1st Edition) | . | 4 | HistData | Data sets from the history of statistics and data visualization | . | 5 | ISLR | Data for An Introduction to Statistical Learning with Applications in R | . | 6 | KMsurv | Data sets from Klein and Moeschberger (1997), Survival Analysis | . | 7 | MASS | Support Functions and Datasets for Venables and Ripley&apos;s MASS | . | 8 | SASmixed | Data sets from &quot;SAS System for Mixed Models&quot; | . | 9 | Zelig | Everyone&apos;s Statistical Software | . | 10 | adehabitatLT | Analysis of Animal Movements | . | 11 | boot | Bootstrap Functions (Originally by Angelo Canty for S) | . | 12 | car | Companion to Applied Regression | . | 13 | cluster | Cluster Analysis Extended Rousseeuw et al. | . | &vellip; | &vellip; | &vellip; | . | 23 | plm | Linear Models for Panel Data | . | 24 | plyr | Tools for splitting, applying and combining data | . | 25 | pscl | Political Science Computational Laboratory, Stanford University | . | 26 | psych | Procedures for Psychological, Psychometric, and Personality Research | . | 27 | quantreg | Quantile Regression | . | 28 | reshape2 | Flexibly Reshape Data: A Reboot of the Reshape Package. | . | 29 | robustbase | Basic Robust Statistics | . | 30 | rpart | Recursive Partitioning and Regression Trees | . | 31 | sandwich | Robust Covariance Matrix Estimators | . | 32 | sem | Structural Equation Models | . | 33 | survival | Survival Analysis | . | 34 | vcd | Visualizing Categorical Data | . Content last modified on 04 November 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-quickly-load-some-sample-data/#solution-in-julia",
    "relUrl": "/how-to-quickly-load-some-sample-data/#solution-in-julia"
  },"1170": {
    "doc": "How to quickly load some sample data",
    "title": "Solution, in Python",
    "content": "View this solution alone. The R programming language comes with many free datasets built in. To make these same datasets available to Python programmers as well, you can install and import the rdatasets package. First, ensure that you have it installed, by running pip install rdatasets or conda install rdatasets from your command line. Then you can get access to many datasets as follows: . | 1 2 3 . | from rdatasets import data df = data( 'iris' ) # Load the famous Fisher's irises dataset df.head() . | . | | Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species | . | 0 | 5.1 | 3.5 | 1.4 | 0.2 | setosa | . | 1 | 4.9 | 3.0 | 1.4 | 0.2 | setosa | . | 2 | 4.7 | 3.2 | 1.3 | 0.2 | setosa | . | 3 | 4.6 | 3.1 | 1.5 | 0.2 | setosa | . | 4 | 5.0 | 3.6 | 1.4 | 0.2 | setosa | . But what datasets are available? There are many! You can find a full list in the package itself. | 1 2 . | from rdatasets import summary summary() . | . | | Package | Item | Title | Rows | Cols | n_binary | n_character | n_factor | n_logical | n_numeric | CSV | Doc | . | 0 | boot | acme | Monthly Excess Returns | 60 | 3 | 0 | 1 | 0 | 0 | 2 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 1 | boot | aids | Delay in AIDS Reporting in England and Wales | 570 | 6 | 1 | 0 | 0 | 0 | 6 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 2 | boot | aircondit | Failures of Air-conditioning Equipment | 12 | 1 | 0 | 0 | 0 | 0 | 1 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 3 | boot | aircondit7 | Failures of Air-conditioning Equipment | 24 | 1 | 0 | 0 | 0 | 0 | 1 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 4 | boot | amis | Car Speeding and Warning Signs | 8437 | 4 | 1 | 0 | 0 | 0 | 4 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . | 1340 | Zelig | tobin | Tobin's Tobit Data | 20 | 3 | 0 | 0 | 0 | 0 | 3 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 1341 | Zelig | turnout | Turnout Data Set from the National Election Su... | 2000 | 5 | 2 | 0 | 1 | 0 | 4 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 1342 | Zelig | voteincome | Sample Turnout and Demographic Data from the 2... | 1500 | 7 | 3 | 0 | 1 | 0 | 6 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 1343 | Zelig | Weimar | 1932 Weimar election data | 10 | 11 | 0 | 0 | 0 | 0 | 11 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . | 1344 | Zelig | Zelig.url | Table of links for Zelig | 49 | 2 | 0 | 0 | 2 | 0 | 0 | https://raw.github.com/vincentarelbundock/Rdat... | https://raw.github.com/vincentarelbundock/Rdat... | . 1345 rows × 12 columns . Content last modified on 26 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-quickly-load-some-sample-data/#solution-in-python",
    "relUrl": "/how-to-quickly-load-some-sample-data/#solution-in-python"
  },"1171": {
    "doc": "How to quickly load some sample data",
    "title": "Solution, in R",
    "content": "View this solution alone. R comes with many datasets in its datasets package. Ensure that you have it installed as follows. | 1 . | library(datasets) . | . Then you can load any one of them with the data function, as follows. | 1 2 . | data(iris) # Load the famous Fisher's irises dataset. head(iris) # It has been placed in a variable of the same name. | . | 1 2 3 4 5 6 7 . | Sepal.Length Sepal.Width Petal.Length Petal.Width Species 1 5.1 3.5 1.4 0.2 setosa 2 4.9 3.0 1.4 0.2 setosa 3 4.7 3.2 1.3 0.2 setosa 4 4.6 3.1 1.5 0.2 setosa 5 5.0 3.6 1.4 0.2 setosa 6 5.4 3.9 1.7 0.4 setosa . | . To page through a list of all available datasets, just call data() with no arguments. Content last modified on 26 July 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-quickly-load-some-sample-data/#solution-in-r",
    "relUrl": "/how-to-quickly-load-some-sample-data/#solution-in-r"
  },"1172": {
    "doc": "How to quickly load some sample data",
    "title": "Topics that include this task",
    "content": ". | Bentley University GB213 | Bentley University GR521 | Bentley University MA346 | . ",
    "url": "/how-to-quickly-load-some-sample-data/#topics-that-include-this-task",
    "relUrl": "/how-to-quickly-load-some-sample-data/#topics-that-include-this-task"
  },"1173": {
    "doc": "How to quickly load some sample data",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-quickly-load-some-sample-data/#opportunities",
    "relUrl": "/how-to-quickly-load-some-sample-data/#opportunities"
  },"1174": {
    "doc": "How to solve an ordinary differential equation (in Python, using SymPy)",
    "title": "How to solve an ordinary differential equation (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-solve-an-ordinary-differential-equation-in-python-using-sympy/",
    "relUrl": "/how-to-solve-an-ordinary-differential-equation-in-python-using-sympy/"
  },"1175": {
    "doc": "How to solve an ordinary differential equation (in Python, using SymPy)",
    "title": "Task",
    "content": "Elsewhere we’ve seen how to write an ordinary differential equation. Once one is written, how can we ask software to solve it? And since ODEs often come with initial conditions that impact the solution, how can we include those as well? . ",
    "url": "/how-to-solve-an-ordinary-differential-equation-in-python-using-sympy/#task",
    "relUrl": "/how-to-solve-an-ordinary-differential-equation-in-python-using-sympy/#task"
  },"1176": {
    "doc": "How to solve an ordinary differential equation (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s re-use here the code from how to write an ordinary differential equation, to write $\\frac{dy}{dx}=y$. | 1 2 3 4 5 . | var( 'x' ) y = Function('y')(x) dydx = Derivative( y, x ) ode = dydx - y ode . | . $\\displaystyle - y{\\left(x \\right)} + \\frac{d}{d x} y{\\left(x \\right)}$ . You can solve an ODE by using the dsolve command. | 1 2 . | solution = dsolve( ode ) solution . | . $\\displaystyle y{\\left(x \\right)} = C_{1} e^{x}$ . If there are initial conditions that need to be substituted in for $x$ and $y$, it is crucial to substitute for $y$ first and then $x$. Let’s assume we have the initial condition $(3,5)$. We might proceed as follows. | 1 2 . | with_inits = solution.subs( y, 5 ).subs( x, 3 ) with_inits . | . $\\displaystyle 5 = C_{1} e^{3}$ . | 1 . | solve( with_inits ) . | . $\\displaystyle \\left[ \\frac{5}{e^{3}}\\right]$ . To substitute $C_1=\\frac{5}{e^3}$ into the solution, note that $C_1$ is written as var('C1'). | 1 . | solution.subs( var('C1'), 5/E**3 ) . | . $\\displaystyle y{\\left(x \\right)} = \\frac{5 e^{x}}{e^{3}}$ . Content last modified on 02 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-solve-an-ordinary-differential-equation-in-python-using-sympy/#solution",
    "relUrl": "/how-to-solve-an-ordinary-differential-equation-in-python-using-sympy/#solution"
  },"1177": {
    "doc": "How to solve an ordinary differential equation",
    "title": "How to solve an ordinary differential equation",
    "content": " ",
    "url": "/how-to-solve-an-ordinary-differential-equation/",
    "relUrl": "/how-to-solve-an-ordinary-differential-equation/"
  },"1178": {
    "doc": "How to solve an ordinary differential equation",
    "title": "Description",
    "content": "Elsewhere we’ve seen how to write an ordinary differential equation. Once one is written, how can we ask software to solve it? And since ODEs often come with initial conditions that impact the solution, how can we include those as well? . ",
    "url": "/how-to-solve-an-ordinary-differential-equation/#description",
    "relUrl": "/how-to-solve-an-ordinary-differential-equation/#description"
  },"1179": {
    "doc": "How to solve an ordinary differential equation",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s re-use here the code from how to write an ordinary differential equation, to write $\\frac{dy}{dx}=y$. | 1 2 3 4 5 . | var( 'x' ) y = Function('y')(x) dydx = Derivative( y, x ) ode = dydx - y ode . | . $\\displaystyle - y{\\left(x \\right)} + \\frac{d}{d x} y{\\left(x \\right)}$ . You can solve an ODE by using the dsolve command. | 1 2 . | solution = dsolve( ode ) solution . | . $\\displaystyle y{\\left(x \\right)} = C_{1} e^{x}$ . If there are initial conditions that need to be substituted in for $x$ and $y$, it is crucial to substitute for $y$ first and then $x$. Let’s assume we have the initial condition $(3,5)$. We might proceed as follows. | 1 2 . | with_inits = solution.subs( y, 5 ).subs( x, 3 ) with_inits . | . $\\displaystyle 5 = C_{1} e^{3}$ . | 1 . | solve( with_inits ) . | . $\\displaystyle \\left[ \\frac{5}{e^{3}}\\right]$ . To substitute $C_1=\\frac{5}{e^3}$ into the solution, note that $C_1$ is written as var('C1'). | 1 . | solution.subs( var('C1'), 5/E**3 ) . | . $\\displaystyle y{\\left(x \\right)} = \\frac{5 e^{x}}{e^{3}}$ . Content last modified on 02 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-solve-an-ordinary-differential-equation/#using-sympy-in-python",
    "relUrl": "/how-to-solve-an-ordinary-differential-equation/#using-sympy-in-python"
  },"1180": {
    "doc": "How to solve an ordinary differential equation",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-solve-an-ordinary-differential-equation/#topics-that-include-this-task",
    "relUrl": "/how-to-solve-an-ordinary-differential-equation/#topics-that-include-this-task"
  },"1181": {
    "doc": "How to solve an ordinary differential equation",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-solve-an-ordinary-differential-equation/#opportunities",
    "relUrl": "/how-to-solve-an-ordinary-differential-equation/#opportunities"
  },"1182": {
    "doc": "How to solve symbolic equations (in Python, using SymPy)",
    "title": "How to solve symbolic equations (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-solve-symbolic-equations-in-python-using-sympy/",
    "relUrl": "/how-to-solve-symbolic-equations-in-python-using-sympy/"
  },"1183": {
    "doc": "How to solve symbolic equations (in Python, using SymPy)",
    "title": "Task",
    "content": "Once we’ve expressed an equation or system of equations using the technique from how to write symbolic equations, we often want the software to solve the equation or system of equations for us. Related tasks: . | How to isolate one variable in an equation | . ",
    "url": "/how-to-solve-symbolic-equations-in-python-using-sympy/#task",
    "relUrl": "/how-to-solve-symbolic-equations-in-python-using-sympy/#task"
  },"1184": {
    "doc": "How to solve symbolic equations (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . If your equation has just one variable, simply call solve on it. Note that you may get a list of more than one solution. | 1 2 3 . | var( 'x' ) equation = Eq( x**2 + 3*x, -x + 9 ) solve( equation ) . | . $\\displaystyle \\left[ -2 + \\sqrt{13}, \\ - \\sqrt{13} - 2\\right]$ . Sometimes you get no solutions, which is shown as a Python empty list. | 1 . | solve( Eq( x+1, x+2 ) ) . | . $\\displaystyle \\left[ \\right]$ . Sometimes the answers include complex numbers. | 1 . | solve( Eq( x**3, -1 ) ) . | . $\\displaystyle \\left[ -1, \\ \\frac{1}{2} - \\frac{\\sqrt{3} i}{2}, \\ \\frac{1}{2} + \\frac{\\sqrt{3} i}{2}\\right]$ . To restrict the solution to the real numbers, use solveset instead, and specify the real numbers as the domain. | 1 . | solveset( Eq( x**3, -1 ), domain=S.Reals ) . | . $\\displaystyle \\left\\{-1\\right\\}$ . You can solve systems of equations by calling solve on them. | 1 2 3 4 5 6 . | var( 'x y' ) system = [ Eq( x + 2*y, 1 ), Eq( x - 9*y, 5 ) ] solve( system ) . | . $\\displaystyle \\left\\{ x : \\frac{19}{11}, \\ y : - \\frac{4}{11}\\right\\}$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-solve-symbolic-equations-in-python-using-sympy/#solution",
    "relUrl": "/how-to-solve-symbolic-equations-in-python-using-sympy/#solution"
  },"1185": {
    "doc": "How to solve symbolic equations",
    "title": "How to solve symbolic equations",
    "content": " ",
    "url": "/how-to-solve-symbolic-equations/",
    "relUrl": "/how-to-solve-symbolic-equations/"
  },"1186": {
    "doc": "How to solve symbolic equations",
    "title": "Description",
    "content": "Once we’ve expressed an equation or system of equations using the technique from how to write symbolic equations, we often want the software to solve the equation or system of equations for us. Related tasks: . | How to isolate one variable in an equation | . ",
    "url": "/how-to-solve-symbolic-equations/#description",
    "relUrl": "/how-to-solve-symbolic-equations/#description"
  },"1187": {
    "doc": "How to solve symbolic equations",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . If your equation has just one variable, simply call solve on it. Note that you may get a list of more than one solution. | 1 2 3 . | var( 'x' ) equation = Eq( x**2 + 3*x, -x + 9 ) solve( equation ) . | . $\\displaystyle \\left[ -2 + \\sqrt{13}, \\ - \\sqrt{13} - 2\\right]$ . Sometimes you get no solutions, which is shown as a Python empty list. | 1 . | solve( Eq( x+1, x+2 ) ) . | . $\\displaystyle \\left[ \\right]$ . Sometimes the answers include complex numbers. | 1 . | solve( Eq( x**3, -1 ) ) . | . $\\displaystyle \\left[ -1, \\ \\frac{1}{2} - \\frac{\\sqrt{3} i}{2}, \\ \\frac{1}{2} + \\frac{\\sqrt{3} i}{2}\\right]$ . To restrict the solution to the real numbers, use solveset instead, and specify the real numbers as the domain. | 1 . | solveset( Eq( x**3, -1 ), domain=S.Reals ) . | . $\\displaystyle \\left\\{-1\\right\\}$ . You can solve systems of equations by calling solve on them. | 1 2 3 4 5 6 . | var( 'x y' ) system = [ Eq( x + 2*y, 1 ), Eq( x - 9*y, 5 ) ] solve( system ) . | . $\\displaystyle \\left\\{ x : \\frac{19}{11}, \\ y : - \\frac{4}{11}\\right\\}$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-solve-symbolic-equations/#using-sympy-in-python",
    "relUrl": "/how-to-solve-symbolic-equations/#using-sympy-in-python"
  },"1188": {
    "doc": "How to solve symbolic equations",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-solve-symbolic-equations/#topics-that-include-this-task",
    "relUrl": "/how-to-solve-symbolic-equations/#topics-that-include-this-task"
  },"1189": {
    "doc": "How to solve symbolic equations",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-solve-symbolic-equations/#opportunities",
    "relUrl": "/how-to-solve-symbolic-equations/#opportunities"
  },"1190": {
    "doc": "How to substitute a value for a symbolic variable (in Python, using SymPy)",
    "title": "How to substitute a value for a symbolic variable (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-substitute-a-value-for-a-symbolic-variable-in-python-using-sympy/",
    "relUrl": "/how-to-substitute-a-value-for-a-symbolic-variable-in-python-using-sympy/"
  },"1191": {
    "doc": "How to substitute a value for a symbolic variable (in Python, using SymPy)",
    "title": "Task",
    "content": "If we’ve defined a symbolic variable and used it in a formula, how can we substitute a value in for it, to evaluate the formula? This is often informally called “plugging in” a value. Related tasks: . | How to create symbolic variables | . ",
    "url": "/how-to-substitute-a-value-for-a-symbolic-variable-in-python-using-sympy/#task",
    "relUrl": "/how-to-substitute-a-value-for-a-symbolic-variable-in-python-using-sympy/#task"
  },"1192": {
    "doc": "How to substitute a value for a symbolic variable (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s assume we’ve defined a variable and created a formula, as covered in how to create symbolic variables. | 1 2 3 . | var( 'x' ) formula = x**2 + x formula . | . $\\displaystyle x^{2} + x$ . We can substitute a value for $x$ using the subs function. You provide the variable and the value to substitute. | 1 . | formula.subs( x, 8 ) # computes 8**2 + 8 . | . $\\displaystyle 72$ . If you had to substitute values for multiple variables, you can use multiple subs calls or you can pass a dictionary to subs. | 1 2 3 . | var( 'y' ) formula = x/2 + y/3 formula . | . $\\displaystyle \\frac{x}{2} + \\frac{y}{3}$ . | 1 . | formula.subs( x, 10 ).subs( y, 6 ) . | . $\\displaystyle 7$ . | 1 . | formula.subs( { x: 10, y: 6 } ) . | . $\\displaystyle 7$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-substitute-a-value-for-a-symbolic-variable-in-python-using-sympy/#solution",
    "relUrl": "/how-to-substitute-a-value-for-a-symbolic-variable-in-python-using-sympy/#solution"
  },"1193": {
    "doc": "How to substitute a value for a symbolic variable",
    "title": "How to substitute a value for a symbolic variable",
    "content": " ",
    "url": "/how-to-substitute-a-value-for-a-symbolic-variable/",
    "relUrl": "/how-to-substitute-a-value-for-a-symbolic-variable/"
  },"1194": {
    "doc": "How to substitute a value for a symbolic variable",
    "title": "Description",
    "content": "If we’ve defined a symbolic variable and used it in a formula, how can we substitute a value in for it, to evaluate the formula? This is often informally called “plugging in” a value. Related tasks: . | How to create symbolic variables | . ",
    "url": "/how-to-substitute-a-value-for-a-symbolic-variable/#description",
    "relUrl": "/how-to-substitute-a-value-for-a-symbolic-variable/#description"
  },"1195": {
    "doc": "How to substitute a value for a symbolic variable",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s assume we’ve defined a variable and created a formula, as covered in how to create symbolic variables. | 1 2 3 . | var( 'x' ) formula = x**2 + x formula . | . $\\displaystyle x^{2} + x$ . We can substitute a value for $x$ using the subs function. You provide the variable and the value to substitute. | 1 . | formula.subs( x, 8 ) # computes 8**2 + 8 . | . $\\displaystyle 72$ . If you had to substitute values for multiple variables, you can use multiple subs calls or you can pass a dictionary to subs. | 1 2 3 . | var( 'y' ) formula = x/2 + y/3 formula . | . $\\displaystyle \\frac{x}{2} + \\frac{y}{3}$ . | 1 . | formula.subs( x, 10 ).subs( y, 6 ) . | . $\\displaystyle 7$ . | 1 . | formula.subs( { x: 10, y: 6 } ) . | . $\\displaystyle 7$ . Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-substitute-a-value-for-a-symbolic-variable/#using-sympy-in-python",
    "relUrl": "/how-to-substitute-a-value-for-a-symbolic-variable/#using-sympy-in-python"
  },"1196": {
    "doc": "How to substitute a value for a symbolic variable",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-substitute-a-value-for-a-symbolic-variable/#topics-that-include-this-task",
    "relUrl": "/how-to-substitute-a-value-for-a-symbolic-variable/#topics-that-include-this-task"
  },"1197": {
    "doc": "How to substitute a value for a symbolic variable",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-substitute-a-value-for-a-symbolic-variable/#opportunities",
    "relUrl": "/how-to-substitute-a-value-for-a-symbolic-variable/#opportunities"
  },"1198": {
    "doc": "How to summarize a column (in Excel)",
    "title": "How to summarize a column (in Excel)",
    "content": "See all solutions. ",
    "url": "/how-to-summarize-a-column-in-excel/",
    "relUrl": "/how-to-summarize-a-column-in-excel/"
  },"1199": {
    "doc": "How to summarize a column (in Excel)",
    "title": "Task",
    "content": "When provided with a dataset in which you want to focus on one column, how would you compute descriptive statistics for that column? . Related task: . | How to compute summary statistics | How to summarize and compare data by groups | . ",
    "url": "/how-to-summarize-a-column-in-excel/#task",
    "relUrl": "/how-to-summarize-a-column-in-excel/#task"
  },"1200": {
    "doc": "How to summarize a column (in Excel)",
    "title": "Solution",
    "content": "Let’s assume you have some data in a single column of an Excel workbook. We show the first 10 rows (out of 27) for some example data below, but we assume you are applying what we cover here to your own real data. To compute descriptive statistics, you will need the Data Analysis Toolpak. If you’ve never enabled it before, see these instructions from Microsoft on how to do so. On the Data tab, click the Data Analysis button, shown below. From the list of tools it provides, choose Descriptive Statistics, as shown below, then click OK. Highlight all the cells in your column as input (excluding the column header, if any), then check the “Summary statistics” checkbox, as shown below. Then click OK. Excel will create a new sheet that reports your column’s mean, median, variance, and more, as shown below. To get a report of the unique values in your column and the frequency of each, you can use a pivot table. Highlight your column of data, then on the Insert tab, choose Pivot Table, as shown below. Drag your column’s name from the list of pivot table fields down into both the Rows and Values areas, as shown below. From the drop-down under Values, choose “Value field settings…” and change Sum to Count, as shown below. Then click OK. Your pivot table will now contain the desired report. The first few rows with our example data look like the following. Most data points appear only once, but 6 appears twice and 34 appears three times. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-summarize-a-column-in-excel/#solution",
    "relUrl": "/how-to-summarize-a-column-in-excel/#solution"
  },"1201": {
    "doc": "How to summarize a column (in Python)",
    "title": "How to summarize a column (in Python)",
    "content": "See all solutions. ",
    "url": "/how-to-summarize-a-column-in-python/",
    "relUrl": "/how-to-summarize-a-column-in-python/"
  },"1202": {
    "doc": "How to summarize a column (in Python)",
    "title": "Task",
    "content": "When provided with a dataset in which you want to focus on one column, how would you compute descriptive statistics for that column? . Related task: . | How to compute summary statistics | How to summarize and compare data by groups | . ",
    "url": "/how-to-summarize-a-column-in-python/#task",
    "relUrl": "/how-to-summarize-a-column-in-python/#task"
  },"1203": {
    "doc": "How to summarize a column (in Python)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . Let us consider qualitative and quantitative variables separately. Consider the qualitative column “supp” in the dataset (which type of supplement the animal received). To count the distribution of each categorical value, use value_counts(): . | 1 2 . | df['supp'].value_counts() # Or use df['supp'].value_counts(normalize = True) for proportions instead. | . | 1 2 3 . | VC 30 OJ 30 Name: supp, dtype: int64 . | . The output says that there are 30 observations under each of the two levels, Orange Juice and Ascorbic Acid. If you wish to jointly summarize two categorical columns, provide both to value_counts(): . | 1 . | df[['supp','dose']].value_counts() . | . | 1 2 3 4 5 6 7 8 . | supp dose OJ 0.5 10 1.0 10 2.0 10 VC 0.5 10 1.0 10 2.0 10 dtype: int64 . | . This informs us that there are 10 observations for each of the combinations. Now consider the quantitative column len in the dataset (the length of the animal’s tooth). We can compute summary statistics for it just as we can for a whole dataframe (as we cover in how to compute summary statistics). | 1 . | df['len'].describe() # Summary statistics . | . | 1 2 3 4 5 6 7 8 9 . | count 60.000000 mean 18.813333 std 7.649315 min 4.200000 25% 13.075000 50% 19.250000 75% 25.275000 max 33.900000 Name: len, dtype: float64 . | . The individual functions for mean, standard deviation, etc. covered under “how to compute summary statistics” apply to individual columns as well. For example, we can compute quantiles: . | 1 . | df['len'].quantile([0.25,0.5,0.75]) # These chosen values give quartiles. | . | 1 2 3 4 . | 0.25 13.075 0.50 19.250 0.75 25.275 Name: len, dtype: float64 . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-summarize-a-column-in-python/#solution",
    "relUrl": "/how-to-summarize-a-column-in-python/#solution"
  },"1204": {
    "doc": "How to summarize a column (in R)",
    "title": "How to summarize a column (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-summarize-a-column-in-r/",
    "relUrl": "/how-to-summarize-a-column-in-r/"
  },"1205": {
    "doc": "How to summarize a column (in R)",
    "title": "Task",
    "content": "When provided with a dataset in which you want to focus on one column, how would you compute descriptive statistics for that column? . Related task: . | How to compute summary statistics | How to summarize and compare data by groups | . ",
    "url": "/how-to-summarize-a-column-in-r/#task",
    "relUrl": "/how-to-summarize-a-column-in-r/#task"
  },"1206": {
    "doc": "How to summarize a column (in R)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 . | df &lt;- ToothGrowth . | . Let us consider qualitative and quantitative variables separately. Consider the qualitative column “supp” in the dataset (which type of supplement the animal received). To count the distribution of each categorical value, use table(): . | 1 . | table(df$supp) # OR summary(df$supp) . | . | 1 2 . | OJ VC 30 30 . | . The output says that there are 30 observations under each of the two levels, Orange Juice and Ascorbic Acid. If you wish to jointly summarize two categorical columns, provide both to table(): . | 1 . | table(df$supp, df$dose) . | . | 1 2 3 . | 0.5 1 2 OJ 10 10 10 VC 10 10 10 . | . This informs us that there are 10 observations for each of the combinations. Note: If there are more than 2 categorical variables of interest, you can use ftable() instead. Now consider the quantitative column len in the dataset (the length of the animal’s tooth). We can compute summary statistics for it just as we can for a whole dataframe (as we cover in how to compute summary statistics). | 1 . | summary(df$len) . | . | 1 2 . | Min. 1st Qu. Median Mean 3rd Qu. Max. 4.20 13.07 19.25 18.81 25.27 33.90 . | . The individual functions for mean, standard deviation, etc. covered under “how to compute summary statistics” apply to individual columns as well. For example, we can compute quantiles: . | 1 . | quantile(df$len) # quantiles . | . | 1 2 . | 0% 25% 50% 75% 100% 4.200 13.075 19.250 25.275 33.900 . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-summarize-a-column-in-r/#solution",
    "relUrl": "/how-to-summarize-a-column-in-r/#solution"
  },"1207": {
    "doc": "How to summarize a column",
    "title": "How to summarize a column",
    "content": " ",
    "url": "/how-to-summarize-a-column/",
    "relUrl": "/how-to-summarize-a-column/"
  },"1208": {
    "doc": "How to summarize a column",
    "title": "Description",
    "content": "When provided with a dataset in which you want to focus on one column, how would you compute descriptive statistics for that column? . Related task: . | How to compute summary statistics | How to summarize and compare data by groups | . ",
    "url": "/how-to-summarize-a-column/#description",
    "relUrl": "/how-to-summarize-a-column/#description"
  },"1209": {
    "doc": "How to summarize a column",
    "title": "Solution, in Excel",
    "content": "View this solution alone. Let’s assume you have some data in a single column of an Excel workbook. We show the first 10 rows (out of 27) for some example data below, but we assume you are applying what we cover here to your own real data. To compute descriptive statistics, you will need the Data Analysis Toolpak. If you’ve never enabled it before, see these instructions from Microsoft on how to do so. On the Data tab, click the Data Analysis button, shown below. From the list of tools it provides, choose Descriptive Statistics, as shown below, then click OK. Highlight all the cells in your column as input (excluding the column header, if any), then check the “Summary statistics” checkbox, as shown below. Then click OK. Excel will create a new sheet that reports your column’s mean, median, variance, and more, as shown below. To get a report of the unique values in your column and the frequency of each, you can use a pivot table. Highlight your column of data, then on the Insert tab, choose Pivot Table, as shown below. Drag your column’s name from the list of pivot table fields down into both the Rows and Values areas, as shown below. From the drop-down under Values, choose “Value field settings…” and change Sum to Count, as shown below. Then click OK. Your pivot table will now contain the desired report. The first few rows with our example data look like the following. Most data points appear only once, but 6 appears twice and 34 appears three times. Content last modified on 21 June 2022. See a problem? Tell us or edit the source. ",
    "url": "/how-to-summarize-a-column/#solution-in-excel",
    "relUrl": "/how-to-summarize-a-column/#solution-in-excel"
  },"1210": {
    "doc": "How to summarize a column",
    "title": "Solution, in Python",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . Let us consider qualitative and quantitative variables separately. Consider the qualitative column “supp” in the dataset (which type of supplement the animal received). To count the distribution of each categorical value, use value_counts(): . | 1 2 . | df['supp'].value_counts() # Or use df['supp'].value_counts(normalize = True) for proportions instead. | . | 1 2 3 . | VC 30 OJ 30 Name: supp, dtype: int64 . | . The output says that there are 30 observations under each of the two levels, Orange Juice and Ascorbic Acid. If you wish to jointly summarize two categorical columns, provide both to value_counts(): . | 1 . | df[['supp','dose']].value_counts() . | . | 1 2 3 4 5 6 7 8 . | supp dose OJ 0.5 10 1.0 10 2.0 10 VC 0.5 10 1.0 10 2.0 10 dtype: int64 . | . This informs us that there are 10 observations for each of the combinations. Now consider the quantitative column len in the dataset (the length of the animal’s tooth). We can compute summary statistics for it just as we can for a whole dataframe (as we cover in how to compute summary statistics). | 1 . | df['len'].describe() # Summary statistics . | . | 1 2 3 4 5 6 7 8 9 . | count 60.000000 mean 18.813333 std 7.649315 min 4.200000 25% 13.075000 50% 19.250000 75% 25.275000 max 33.900000 Name: len, dtype: float64 . | . The individual functions for mean, standard deviation, etc. covered under “how to compute summary statistics” apply to individual columns as well. For example, we can compute quantiles: . | 1 . | df['len'].quantile([0.25,0.5,0.75]) # These chosen values give quartiles. | . | 1 2 3 4 . | 0.25 13.075 0.50 19.250 0.75 25.275 Name: len, dtype: float64 . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-summarize-a-column/#solution-in-python",
    "relUrl": "/how-to-summarize-a-column/#solution-in-python"
  },"1211": {
    "doc": "How to summarize a column",
    "title": "Solution, in R",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 . | df &lt;- ToothGrowth . | . Let us consider qualitative and quantitative variables separately. Consider the qualitative column “supp” in the dataset (which type of supplement the animal received). To count the distribution of each categorical value, use table(): . | 1 . | table(df$supp) # OR summary(df$supp) . | . | 1 2 . | OJ VC 30 30 . | . The output says that there are 30 observations under each of the two levels, Orange Juice and Ascorbic Acid. If you wish to jointly summarize two categorical columns, provide both to table(): . | 1 . | table(df$supp, df$dose) . | . | 1 2 3 . | 0.5 1 2 OJ 10 10 10 VC 10 10 10 . | . This informs us that there are 10 observations for each of the combinations. Note: If there are more than 2 categorical variables of interest, you can use ftable() instead. Now consider the quantitative column len in the dataset (the length of the animal’s tooth). We can compute summary statistics for it just as we can for a whole dataframe (as we cover in how to compute summary statistics). | 1 . | summary(df$len) . | . | 1 2 . | Min. 1st Qu. Median Mean 3rd Qu. Max. 4.20 13.07 19.25 18.81 25.27 33.90 . | . The individual functions for mean, standard deviation, etc. covered under “how to compute summary statistics” apply to individual columns as well. For example, we can compute quantiles: . | 1 . | quantile(df$len) # quantiles . | . | 1 2 . | 0% 25% 50% 75% 100% 4.200 13.075 19.250 25.275 33.900 . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-summarize-a-column/#solution-in-r",
    "relUrl": "/how-to-summarize-a-column/#solution-in-r"
  },"1212": {
    "doc": "How to summarize a column",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-summarize-a-column/#topics-that-include-this-task",
    "relUrl": "/how-to-summarize-a-column/#topics-that-include-this-task"
  },"1213": {
    "doc": "How to summarize a column",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-summarize-a-column/#opportunities",
    "relUrl": "/how-to-summarize-a-column/#opportunities"
  },"1214": {
    "doc": "How to summarize and compare data by groups (in Python)",
    "title": "How to summarize and compare data by groups (in Python)",
    "content": "See all solutions. ",
    "url": "/how-to-summarize-and-compare-data-by-groups-in-python/",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups-in-python/"
  },"1215": {
    "doc": "How to summarize and compare data by groups (in Python)",
    "title": "Task",
    "content": "When given a set of data that has different treatment conditions and an outcome variable, we need to perform some exploratory data analysis. How would you quantitatively compare the treatment conditions with regards to the outcome variable? . Related tasks: . | How to compute summary statistics | . ",
    "url": "/how-to-summarize-and-compare-data-by-groups-in-python/#task",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups-in-python/#task"
  },"1216": {
    "doc": "How to summarize and compare data by groups (in Python)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . To obtain the descriptive statistics of the quantitative column (len for length of teeth) based on the treatment levels (supp), we can combine the groupby and describe functions. | 1 . | df.groupby('supp')['len'].describe() . | . | | count | mean | std | min | 25% | 50% | 75% | max | . | supp | | | | | | | | | . | OJ | 30.0 | 20.663333 | 6.605561 | 8.2 | 15.525 | 22.7 | 25.725 | 30.9 | . | VC | 30.0 | 16.963333 | 8.266029 | 4.2 | 11.200 | 16.5 | 23.100 | 33.9 | . To choose which statistics you want to see, you could use the agg function and list the statistics you want. | 1 . | df.groupby('supp')['len'].agg(['min','median','mean','max','std','count']) . | . | | min | median | mean | max | std | count | . | supp | | | | | | | . | OJ | 8.2 | 22.7 | 20.663333 | 30.9 | 6.605561 | 30 | . | VC | 4.2 | 16.5 | 16.963333 | 33.9 | 8.266029 | 30 | . If your focus is on just one statistic, you can often use its name in place of agg, as shown below, using the quantile function. | 1 . | df.groupby('supp')['len'].quantile([0.25,0.5,0.75]) # Quartiles - default is median, i.e. 0.5 . | . | 1 2 3 4 5 6 7 8 . | supp OJ 0.25 15.525 0.50 22.700 0.75 25.725 VC 0.25 11.200 0.50 16.500 0.75 23.100 Name: len, dtype: float64 . | . In this example, we grouped by just one category (supp), but the groupby function accepts a list of columns if you need to create subcategories, etc. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-summarize-and-compare-data-by-groups-in-python/#solution",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups-in-python/#solution"
  },"1217": {
    "doc": "How to summarize and compare data by groups (in R)",
    "title": "How to summarize and compare data by groups (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-summarize-and-compare-data-by-groups-in-r/",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups-in-r/"
  },"1218": {
    "doc": "How to summarize and compare data by groups (in R)",
    "title": "Task",
    "content": "When given a set of data that has different treatment conditions and an outcome variable, we need to perform some exploratory data analysis. How would you quantitatively compare the treatment conditions with regards to the outcome variable? . Related tasks: . | How to compute summary statistics | . ",
    "url": "/how-to-summarize-and-compare-data-by-groups-in-r/#task",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups-in-r/#task"
  },"1219": {
    "doc": "How to summarize and compare data by groups (in R)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 . | df &lt;- ToothGrowth . | . To obtain the descriptive statistics of the quantitative column (len for length of teeth) based on the treatment levels (supp), we can use either the tapply or favstats functions. | 1 2 . | attach(df) tapply(len, supp, summary) . | . | 1 2 3 4 5 6 7 . | $OJ Min. 1st Qu. Median Mean 3rd Qu. Max. 8.20 15.53 22.70 20.66 25.73 30.90 $VC Min. 1st Qu. Median Mean 3rd Qu. Max. 4.20 11.20 16.50 16.96 23.10 33.90 . | . You can replace summary in the call to tapply with mean, median, max, min, or quantile to get just one value. An example is shown below for quantiles. | 1 . | tapply(len, supp, quantile, prob = 0.25, data=df) # 1st quartile . | . | 1 2 . | OJ VC 15.525 11.200 . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-summarize-and-compare-data-by-groups-in-r/#solution",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups-in-r/#solution"
  },"1220": {
    "doc": "How to summarize and compare data by groups",
    "title": "How to summarize and compare data by groups",
    "content": " ",
    "url": "/how-to-summarize-and-compare-data-by-groups/",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups/"
  },"1221": {
    "doc": "How to summarize and compare data by groups",
    "title": "Description",
    "content": "When given a set of data that has different treatment conditions and an outcome variable, we need to perform some exploratory data analysis. How would you quantitatively compare the treatment conditions with regards to the outcome variable? . Related tasks: . | How to compute summary statistics | . ",
    "url": "/how-to-summarize-and-compare-data-by-groups/#description",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups/#description"
  },"1222": {
    "doc": "How to summarize and compare data by groups",
    "title": "Solution, in Python",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . To obtain the descriptive statistics of the quantitative column (len for length of teeth) based on the treatment levels (supp), we can combine the groupby and describe functions. | 1 . | df.groupby('supp')['len'].describe() . | . | | count | mean | std | min | 25% | 50% | 75% | max | . | supp | | | | | | | | | . | OJ | 30.0 | 20.663333 | 6.605561 | 8.2 | 15.525 | 22.7 | 25.725 | 30.9 | . | VC | 30.0 | 16.963333 | 8.266029 | 4.2 | 11.200 | 16.5 | 23.100 | 33.9 | . To choose which statistics you want to see, you could use the agg function and list the statistics you want. | 1 . | df.groupby('supp')['len'].agg(['min','median','mean','max','std','count']) . | . | | min | median | mean | max | std | count | . | supp | | | | | | | . | OJ | 8.2 | 22.7 | 20.663333 | 30.9 | 6.605561 | 30 | . | VC | 4.2 | 16.5 | 16.963333 | 33.9 | 8.266029 | 30 | . If your focus is on just one statistic, you can often use its name in place of agg, as shown below, using the quantile function. | 1 . | df.groupby('supp')['len'].quantile([0.25,0.5,0.75]) # Quartiles - default is median, i.e. 0.5 . | . | 1 2 3 4 5 6 7 8 . | supp OJ 0.25 15.525 0.50 22.700 0.75 25.725 VC 0.25 11.200 0.50 16.500 0.75 23.100 Name: len, dtype: float64 . | . In this example, we grouped by just one category (supp), but the groupby function accepts a list of columns if you need to create subcategories, etc. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-summarize-and-compare-data-by-groups/#solution-in-python",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups/#solution-in-python"
  },"1223": {
    "doc": "How to summarize and compare data by groups",
    "title": "Solution, in R",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 . | df &lt;- ToothGrowth . | . To obtain the descriptive statistics of the quantitative column (len for length of teeth) based on the treatment levels (supp), we can use either the tapply or favstats functions. | 1 2 . | attach(df) tapply(len, supp, summary) . | . | 1 2 3 4 5 6 7 . | $OJ Min. 1st Qu. Median Mean 3rd Qu. Max. 8.20 15.53 22.70 20.66 25.73 30.90 $VC Min. 1st Qu. Median Mean 3rd Qu. Max. 4.20 11.20 16.50 16.96 23.10 33.90 . | . You can replace summary in the call to tapply with mean, median, max, min, or quantile to get just one value. An example is shown below for quantiles. | 1 . | tapply(len, supp, quantile, prob = 0.25, data=df) # 1st quartile . | . | 1 2 . | OJ VC 15.525 11.200 . | . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-summarize-and-compare-data-by-groups/#solution-in-r",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups/#solution-in-r"
  },"1224": {
    "doc": "How to summarize and compare data by groups",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-summarize-and-compare-data-by-groups/#topics-that-include-this-task",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups/#topics-that-include-this-task"
  },"1225": {
    "doc": "How to summarize and compare data by groups",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-summarize-and-compare-data-by-groups/#opportunities",
    "relUrl": "/how-to-summarize-and-compare-data-by-groups/#opportunities"
  },"1226": {
    "doc": "How to test data for normality with Pearson's chi-squared test (in R)",
    "title": "How to test data for normality with Pearson’s chi-squared test (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test-in-r/#how-to-test-data-for-normality-with-pearsons-chi-squared-test-in-r",
    "relUrl": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test-in-r/#how-to-test-data-for-normality-with-pearsons-chi-squared-test-in-r"
  },"1227": {
    "doc": "How to test data for normality with Pearson's chi-squared test (in R)",
    "title": "Task",
    "content": "We often want to know whether a set of data is normally distributed, so that we can deduce what inference tests are appropriate to conduct. If we have a set of data and want to figure out if it comes from a population that follows a normal distribution, one tool that can help is Pearson’s $\\chi^2$ test. How do we perform it? . Related tasks: . | How to create a QQ-plot | How to test data for normality with the D’Agostino-Pearson test | How to test data for normality with the Jarque-Bera test | . ",
    "url": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test-in-r/#task",
    "relUrl": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test-in-r/#task"
  },"1228": {
    "doc": "How to test data for normality with Pearson's chi-squared test (in R)",
    "title": "Solution",
    "content": "We’re going to use some fake restaurant data, but you can replace our fake data with your real data in the code below. The values in our fake data represent the amount of money that customers spent on a Sunday morning at the restaurant. | 1 2 3 4 5 6 . | # Replace your data here spending &lt;- c(34, 12, 19, 56, 54, 34, 45, 37, 13, 22, 65, 19, 16, 45, 19, 50, 36, 23, 28, 56, 40, 61, 45, 47, 37) mean(spending) sd(spending) . | . | 1 2 3 4 5 . | [1] 36.52 [1] 15.77213 . | . We will now conduct a test of the following null hypothesis: The data comes from a population that is normally distributed with mean 36.52 and standard deviation 15.77. We will use a value $\\alpha=0.05$ as our Type I error rate. The pearson.test() function in the nortest package can perform Pearson’s $\\chi^2$ test for normality. | 1 2 3 . | # install.packages(\"nortest\") # if you have not already done so library(nortest) pearson.test(spending) . | . | 1 2 3 4 . | Pearson chi-square normality test data: spending P = 3.48, p-value = 0.6264 . | . The p-value is 0.6264, which is greater than $\\alpha=0.05$, so we fail to reject our null hypothesis. We would continue to operate under our original assumption that the data come from a normally distributed population. Content last modified on 23 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test-in-r/#solution",
    "relUrl": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test-in-r/#solution"
  },"1229": {
    "doc": "How to test data for normality with Pearson's chi-squared test (in R)",
    "title": "How to test data for normality with Pearson's chi-squared test (in R)",
    "content": " ",
    "url": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test-in-r/",
    "relUrl": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test-in-r/"
  },"1230": {
    "doc": "How to test data for normality with Pearson's chi-squared test",
    "title": "How to test data for normality with Pearson’s chi-squared test",
    "content": " ",
    "url": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/#how-to-test-data-for-normality-with-pearsons-chi-squared-test",
    "relUrl": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/#how-to-test-data-for-normality-with-pearsons-chi-squared-test"
  },"1231": {
    "doc": "How to test data for normality with Pearson's chi-squared test",
    "title": "Description",
    "content": "We often want to know whether a set of data is normally distributed, so that we can deduce what inference tests are appropriate to conduct. If we have a set of data and want to figure out if it comes from a population that follows a normal distribution, one tool that can help is Pearson’s $\\chi^2$ test. How do we perform it? . Related tasks: . | How to create a QQ-plot | How to test data for normality with the D’Agostino-Pearson test | How to test data for normality with the Jarque-Bera test | . ",
    "url": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/#description",
    "relUrl": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/#description"
  },"1232": {
    "doc": "How to test data for normality with Pearson's chi-squared test",
    "title": "Solution, in R",
    "content": "View this solution alone. We’re going to use some fake restaurant data, but you can replace our fake data with your real data in the code below. The values in our fake data represent the amount of money that customers spent on a Sunday morning at the restaurant. | 1 2 3 4 5 6 . | # Replace your data here spending &lt;- c(34, 12, 19, 56, 54, 34, 45, 37, 13, 22, 65, 19, 16, 45, 19, 50, 36, 23, 28, 56, 40, 61, 45, 47, 37) mean(spending) sd(spending) . | . | 1 2 3 4 5 . | [1] 36.52 [1] 15.77213 . | . We will now conduct a test of the following null hypothesis: The data comes from a population that is normally distributed with mean 36.52 and standard deviation 15.77. We will use a value $\\alpha=0.05$ as our Type I error rate. The pearson.test() function in the nortest package can perform Pearson’s $\\chi^2$ test for normality. | 1 2 3 . | # install.packages(\"nortest\") # if you have not already done so library(nortest) pearson.test(spending) . | . | 1 2 3 4 . | Pearson chi-square normality test data: spending P = 3.48, p-value = 0.6264 . | . The p-value is 0.6264, which is greater than $\\alpha=0.05$, so we fail to reject our null hypothesis. We would continue to operate under our original assumption that the data come from a normally distributed population. Content last modified on 23 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/#solution-in-r",
    "relUrl": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/#solution-in-r"
  },"1233": {
    "doc": "How to test data for normality with Pearson's chi-squared test",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/#topics-that-include-this-task",
    "relUrl": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/#topics-that-include-this-task"
  },"1234": {
    "doc": "How to test data for normality with Pearson's chi-squared test",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Python | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/#opportunities",
    "relUrl": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/#opportunities"
  },"1235": {
    "doc": "How to test data for normality with Pearson's chi-squared test",
    "title": "How to test data for normality with Pearson's chi-squared test",
    "content": " ",
    "url": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/",
    "relUrl": "/how-to-test-data-for-normality-with-pearson-s-chi-squared-test/"
  },"1236": {
    "doc": "How to test data for normality with the D'Agostino-Pearson test (in Python, using SciPy)",
    "title": "How to test data for normality with the D’Agostino-Pearson test (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test-in-python-using-scipy/#how-to-test-data-for-normality-with-the-dagostino-pearson-test-in-python-using-scipy",
    "relUrl": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test-in-python-using-scipy/#how-to-test-data-for-normality-with-the-dagostino-pearson-test-in-python-using-scipy"
  },"1237": {
    "doc": "How to test data for normality with the D'Agostino-Pearson test (in Python, using SciPy)",
    "title": "Task",
    "content": "We often want to know whether a set of data is normally distributed, so that we can deduce what inference tests are appropriate to conduct. If we have a set of data and want to figure out if it comes from a population that follows a normal distribution, one tool that can help is the D’Agostino-Pearson test (sometimes also called the D’Agostino-Pearson omnibus test, or the D’Agostino-Pearson $k^2$ test). How do we perform it? . Related tasks: . | How to create a QQ-plot | How to test data for normality with Pearson’s chi-squared test | How to test data for normality with the Jarque-Bera test | . ",
    "url": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test-in-python-using-scipy/#task",
    "relUrl": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test-in-python-using-scipy/#task"
  },"1238": {
    "doc": "How to test data for normality with the D'Agostino-Pearson test (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’re going to use some fake restaurant data, but you can replace our fake data with your real data in the code below. The values in our fake data represent the amount of money that customers spent on a Sunday morning at the restaurant. | 1 2 3 4 5 6 7 . | import numpy as np # Replace your data here spending = [34, 12, 19, 56, 54, 34, 45, 37, 13, 22, 65, 19, 16, 45, 19, 50, 36, 23, 28, 56, 40, 61, 45, 47, 37] np.mean(spending), np.std(spending, ddof=1) . | . | 1 . | (36.52, 15.772127313713899) . | . We will now conduct a test of the following null hypothesis: The data comes from a population that is normally distributed with mean 36.52 and standard deviation 15.77. We will use a value $\\alpha=0.05$ as our Type I error rate. The normaltest() function in SciPy’s stats package can perform the D’Agostino-Pearson test for normality, which uses the skew and kurtosis of the data. | 1 2 . | from scipy import stats stats.normaltest(spending) . | . | 1 . | NormaltestResult(statistic=3.0866213696851097, pvalue=0.21367252674488552) . | . The p-value is apprximately 0.21367, which is greater than $\\alpha=0.05$, so we fail to reject our null hypothesis. We would continue to operate under our original assumption that the data come from a normally distributed population. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test-in-python-using-scipy/#solution",
    "relUrl": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test-in-python-using-scipy/#solution"
  },"1239": {
    "doc": "How to test data for normality with the D'Agostino-Pearson test (in Python, using SciPy)",
    "title": "How to test data for normality with the D'Agostino-Pearson test (in Python, using SciPy)",
    "content": " ",
    "url": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test-in-python-using-scipy/",
    "relUrl": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test-in-python-using-scipy/"
  },"1240": {
    "doc": "How to test data for normality with the D'Agostino-Pearson test",
    "title": "How to test data for normality with the D’Agostino-Pearson test",
    "content": " ",
    "url": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/#how-to-test-data-for-normality-with-the-dagostino-pearson-test",
    "relUrl": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/#how-to-test-data-for-normality-with-the-dagostino-pearson-test"
  },"1241": {
    "doc": "How to test data for normality with the D'Agostino-Pearson test",
    "title": "Description",
    "content": "We often want to know whether a set of data is normally distributed, so that we can deduce what inference tests are appropriate to conduct. If we have a set of data and want to figure out if it comes from a population that follows a normal distribution, one tool that can help is the D’Agostino-Pearson test (sometimes also called the D’Agostino-Pearson omnibus test, or the D’Agostino-Pearson $k^2$ test). How do we perform it? . Related tasks: . | How to create a QQ-plot | How to test data for normality with Pearson’s chi-squared test | How to test data for normality with the Jarque-Bera test | . ",
    "url": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/#description",
    "relUrl": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/#description"
  },"1242": {
    "doc": "How to test data for normality with the D'Agostino-Pearson test",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’re going to use some fake restaurant data, but you can replace our fake data with your real data in the code below. The values in our fake data represent the amount of money that customers spent on a Sunday morning at the restaurant. | 1 2 3 4 5 6 7 . | import numpy as np # Replace your data here spending = [34, 12, 19, 56, 54, 34, 45, 37, 13, 22, 65, 19, 16, 45, 19, 50, 36, 23, 28, 56, 40, 61, 45, 47, 37] np.mean(spending), np.std(spending, ddof=1) . | . | 1 . | (36.52, 15.772127313713899) . | . We will now conduct a test of the following null hypothesis: The data comes from a population that is normally distributed with mean 36.52 and standard deviation 15.77. We will use a value $\\alpha=0.05$ as our Type I error rate. The normaltest() function in SciPy’s stats package can perform the D’Agostino-Pearson test for normality, which uses the skew and kurtosis of the data. | 1 2 . | from scipy import stats stats.normaltest(spending) . | . | 1 . | NormaltestResult(statistic=3.0866213696851097, pvalue=0.21367252674488552) . | . The p-value is apprximately 0.21367, which is greater than $\\alpha=0.05$, so we fail to reject our null hypothesis. We would continue to operate under our original assumption that the data come from a normally distributed population. Content last modified on 30 November 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/#using-scipy-in-python",
    "relUrl": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/#using-scipy-in-python"
  },"1243": {
    "doc": "How to test data for normality with the D'Agostino-Pearson test",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/#topics-that-include-this-task",
    "relUrl": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/#topics-that-include-this-task"
  },"1244": {
    "doc": "How to test data for normality with the D'Agostino-Pearson test",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/#opportunities",
    "relUrl": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/#opportunities"
  },"1245": {
    "doc": "How to test data for normality with the D'Agostino-Pearson test",
    "title": "How to test data for normality with the D'Agostino-Pearson test",
    "content": " ",
    "url": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/",
    "relUrl": "/how-to-test-data-for-normality-with-the-d-agostino-pearson-test/"
  },"1246": {
    "doc": "How to test data for normality with the Jarque-Bera test (in Python, using SciPy)",
    "title": "How to test data for normality with the Jarque-Bera test (in Python, using SciPy)",
    "content": "See all solutions. ",
    "url": "/how-to-test-data-for-normality-with-the-jarque-bera-test-in-python-using-scipy/",
    "relUrl": "/how-to-test-data-for-normality-with-the-jarque-bera-test-in-python-using-scipy/"
  },"1247": {
    "doc": "How to test data for normality with the Jarque-Bera test (in Python, using SciPy)",
    "title": "Task",
    "content": "We often want to know whether a set of data is normally distributed, so that we can deduce what inference tests are appropriate to conduct. If we have a set of data and want to figure out if it comes from a population that follows a normal distribution, one tool that can help is the Jarque-Bera test for normality. How do we perform it? . Related tasks: . | How to create a QQ-plot | How to test data for normality with the D’Agostino-Pearson test | How to test data for normality with Pearson’s chi-squared test | . ",
    "url": "/how-to-test-data-for-normality-with-the-jarque-bera-test-in-python-using-scipy/#task",
    "relUrl": "/how-to-test-data-for-normality-with-the-jarque-bera-test-in-python-using-scipy/#task"
  },"1248": {
    "doc": "How to test data for normality with the Jarque-Bera test (in Python, using SciPy)",
    "title": "Solution",
    "content": "We’re going to use some fake restaurant data, but you can replace our fake data with your real data in the code below. The values in our fake data represent the amount of money that customers spent on a Sunday morning at the restaurant. | 1 2 3 . | # Replace your data here spending = [ 34, 12, 19, 56, 54, 34, 45, 37, 13, 22, 65, 19, 16, 45, 19, 50, 36, 23, 28, 56, 40, 61, 45, 47, 37 ] . | . If we assume that the skewness coefficient $S$ and the kurtosis coefficient $K$ are both equal to zero, then our null hypothesis is $H_0: S=K=0$, or that the sample data comes from a normal distribution. We choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. We’ll let $\\alpha$ be 0.05 here. We can use the jarque_bera() function in SciPy’s stats package to run the hypothesis test. | 1 2 . | from scipy import stats stats.jarque_bera( spending ) . | . | 1 . | Jarque_beraResult(statistic=1.3347292970972013, pvalue=0.5130588882194845) . | . Our $p$-value of about $0.5131$ is greater than $\\alpha$, so we fail to reject our null hypothesis. We would continue to operate under our original assumption that the data come from a normally distributed population. Content last modified on 23 September 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-test-data-for-normality-with-the-jarque-bera-test-in-python-using-scipy/#solution",
    "relUrl": "/how-to-test-data-for-normality-with-the-jarque-bera-test-in-python-using-scipy/#solution"
  },"1249": {
    "doc": "How to test data for normality with the Jarque-Bera test",
    "title": "How to test data for normality with the Jarque-Bera test",
    "content": " ",
    "url": "/how-to-test-data-for-normality-with-the-jarque-bera-test/",
    "relUrl": "/how-to-test-data-for-normality-with-the-jarque-bera-test/"
  },"1250": {
    "doc": "How to test data for normality with the Jarque-Bera test",
    "title": "Description",
    "content": "We often want to know whether a set of data is normally distributed, so that we can deduce what inference tests are appropriate to conduct. If we have a set of data and want to figure out if it comes from a population that follows a normal distribution, one tool that can help is the Jarque-Bera test for normality. How do we perform it? . Related tasks: . | How to create a QQ-plot | How to test data for normality with the D’Agostino-Pearson test | How to test data for normality with Pearson’s chi-squared test | . ",
    "url": "/how-to-test-data-for-normality-with-the-jarque-bera-test/#description",
    "relUrl": "/how-to-test-data-for-normality-with-the-jarque-bera-test/#description"
  },"1251": {
    "doc": "How to test data for normality with the Jarque-Bera test",
    "title": "Using SciPy, in Python",
    "content": "View this solution alone. We’re going to use some fake restaurant data, but you can replace our fake data with your real data in the code below. The values in our fake data represent the amount of money that customers spent on a Sunday morning at the restaurant. | 1 2 3 . | # Replace your data here spending = [ 34, 12, 19, 56, 54, 34, 45, 37, 13, 22, 65, 19, 16, 45, 19, 50, 36, 23, 28, 56, 40, 61, 45, 47, 37 ] . | . If we assume that the skewness coefficient $S$ and the kurtosis coefficient $K$ are both equal to zero, then our null hypothesis is $H_0: S=K=0$, or that the sample data comes from a normal distribution. We choose a value $0 \\le \\alpha \\le 1$ as our Type 1 error rate. We’ll let $\\alpha$ be 0.05 here. We can use the jarque_bera() function in SciPy’s stats package to run the hypothesis test. | 1 2 . | from scipy import stats stats.jarque_bera( spending ) . | . | 1 . | Jarque_beraResult(statistic=1.3347292970972013, pvalue=0.5130588882194845) . | . Our $p$-value of about $0.5131$ is greater than $\\alpha$, so we fail to reject our null hypothesis. We would continue to operate under our original assumption that the data come from a normally distributed population. Content last modified on 23 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-test-data-for-normality-with-the-jarque-bera-test/#using-scipy-in-python",
    "relUrl": "/how-to-test-data-for-normality-with-the-jarque-bera-test/#using-scipy-in-python"
  },"1252": {
    "doc": "How to test data for normality with the Jarque-Bera test",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-test-data-for-normality-with-the-jarque-bera-test/#topics-that-include-this-task",
    "relUrl": "/how-to-test-data-for-normality-with-the-jarque-bera-test/#topics-that-include-this-task"
  },"1253": {
    "doc": "How to test data for normality with the Jarque-Bera test",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-test-data-for-normality-with-the-jarque-bera-test/#opportunities",
    "relUrl": "/how-to-test-data-for-normality-with-the-jarque-bera-test/#opportunities"
  },"1254": {
    "doc": "How to test for a treatment effect in a single factor design (in Python, using SciPy and statsmodels)",
    "title": "How to test for a treatment effect in a single factor design (in Python, using SciPy and statsmodels)",
    "content": "See all solutions. ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-python-using-scipy-and-statsmodels/",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-python-using-scipy-and-statsmodels/"
  },"1255": {
    "doc": "How to test for a treatment effect in a single factor design (in Python, using SciPy and statsmodels)",
    "title": "Task",
    "content": "Suppose you are given a dataset that has more than one treatment level and you wish to see if there is a unit-level treatment effect. How would you check that? . ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-python-using-scipy-and-statsmodels/#task",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-python-using-scipy-and-statsmodels/#task"
  },"1256": {
    "doc": "How to test for a treatment effect in a single factor design (in Python, using SciPy and statsmodels)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . In this dataset, there are only two treatments (orange juice and ascorbic acid, in the variable supp). We can therefore perrform a two-sample $t$ test. But first we must filter the outcome variable len (tooth length) based on supp. | 1 2 3 4 5 . | subjects_receiving_oj = df[df['supp']=='OJ']['len'] subjects_receiving_vc = df[df['supp']=='VC']['len'] import scipy.stats as stats stats.ttest_ind( subjects_receiving_oj, subjects_receiving_vc, equal_var=False ) . | . | 1 . | Ttest_indResult(statistic=1.91526826869527, pvalue=0.06063450788093387) . | . At the 5% significance level, we see that the length of the tooth does not differ between the two delivery methods. We assume that the model assumptions are met, but do not check that here. If there are multiple levels (two or more), you can apply the parametric ANOVA test which in this case will provide a similar $p$ value. | 1 2 3 4 5 . | from statsmodels.formula.api import ols model = ols('len ~ supp', data = df).fit() import statsmodels.api as sm sm.stats.anova_lm(model, typ=1) . | . | | df | sum_sq | mean_sq | F | PR(&gt;F) | . | supp | 1.0 | 205.350000 | 205.350000 | 3.668253 | 0.060393 | . | Residual | 58.0 | 3246.859333 | 55.980333 | NaN | NaN | . We see the $p$ value in the final column is very similar. However, if the assumptions of ANOVA are not met, we can utilize a nonparametric approach via the Kruskal-Wallis Test. We use the filtered variables defined above and import the kruskal function from SciPy. | 1 2 . | from scipy.stats import kruskal kruskal( subjects_receiving_oj, subjects_receiving_vc ) . | . | 1 . | KruskalResult(statistic=3.4453580631407035, pvalue=0.06342967639688878) . | . Similar to the previous results, the length of the tooth does not differ between the delivery methods at the 5% significance level. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-python-using-scipy-and-statsmodels/#solution",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-python-using-scipy-and-statsmodels/#solution"
  },"1257": {
    "doc": "How to test for a treatment effect in a single factor design (in R, using perm)",
    "title": "How to test for a treatment effect in a single factor design (in R, using perm)",
    "content": "See all solutions. ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-r-using-perm/",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-r-using-perm/"
  },"1258": {
    "doc": "How to test for a treatment effect in a single factor design (in R, using perm)",
    "title": "Task",
    "content": "Suppose you are given a dataset that has more than one treatment level and you wish to see if there is a unit-level treatment effect. How would you check that? . ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-r-using-perm/#task",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-r-using-perm/#task"
  },"1259": {
    "doc": "How to test for a treatment effect in a single factor design (in R, using perm)",
    "title": "Solution",
    "content": "The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 . | df &lt;- ToothGrowth . | . In this dataset, there are only two treatments (orange juice and ascorbic acid, in the variable supp). We can therefore perrform a two-sample $t$ test. But first we must filter the outcome variable len (tooth length) based on supp. | 1 . | t.test(len ~ supp, data=df) . | . | 1 2 3 4 5 6 7 8 9 10 . | Welch Two Sample t-test data: len by supp t = 1.9153, df = 55.309, p-value = 0.06063 alternative hypothesis: true difference in means between group OJ and group VC is not equal to 0 95 percent confidence interval: -0.1710156 7.5710156 sample estimates: mean in group OJ mean in group VC 20.66333 16.96333 . | . The $p$-value is reported in the first row of numerical output as 0.06063. Because this is greater than 0.05, at a 5% significance level, we see that the length of the tooth does not differ between the two delivery methods. Since the t.test makes some assumptions, we can use the permTS function instead. It can conduct a permutation or randomization test, but it requires us to load the perm package first. | 1 2 3 . | # install.packages(\"perm\") # If you have not already installed it library(perm) permTS(len ~ supp, data=df) . | . | 1 2 3 4 5 6 7 8 . | Permutation Test using Asymptotic Approximation data: len by supp Z = 1.8734, p-value = 0.06102 alternative hypothesis: true mean supp=OJ - mean supp=VC is not equal to 0 sample estimates: mean supp=OJ - mean supp=VC 3.7 . | . The $p$-value is reported in the first row of numerical output as 0.06102. Because this is greater than 0.05, at a 5% significance level, we see that the length of the tooth does not differ between the two delivery methods. We assume that the model assumptions are met but not shown in this task. If there are multiple levels (2 or more), you can apply the parametric ANOVA test which in this case will provide a similar $p$-value. | 1 2 . | aov1 &lt;- aov(len ~ supp, data = df) summary(aov1) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) supp 1 205 205.35 3.668 0.0604 . Residuals 58 3247 55.98 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The $p$-value for supp is shown at the end of the supp row, in the Pr(&gt;F) column. Because it is 0.0604, which is greater than 0.05, at a 5% significance level, we see that the length of the tooth does not differ between the delivery methods. However, if the assumptions of ANOVA are not met, we can utilize the non parametric approach via the Kruskal-Wallis Test. | 1 . | kruskal.test(len ~ supp, data = df) . | . | 1 2 3 4 . | Kruskal-Wallis rank sum test data: len by supp Kruskal-Wallis chi-squared = 3.4454, df = 1, p-value = 0.06343 . | . The $p$-value is the last part of the output, and is 0.06343. Because it is greater than 0.05, at a 5% significance level, we see that the length of the tooth does not differ between the delivery methods. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Krtin Juneja (KJUNEJA@falcon.bentley.edu) . ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-r-using-perm/#solution",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design-in-r-using-perm/#solution"
  },"1260": {
    "doc": "How to test for a treatment effect in a single factor design",
    "title": "How to test for a treatment effect in a single factor design",
    "content": " ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/"
  },"1261": {
    "doc": "How to test for a treatment effect in a single factor design",
    "title": "Description",
    "content": "Suppose you are given a dataset that has more than one treatment level and you wish to see if there is a unit-level treatment effect. How would you check that? . ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/#description",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/#description"
  },"1262": {
    "doc": "How to test for a treatment effect in a single factor design",
    "title": "Using SciPy and statsmodels, in Python",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 2 . | from rdatasets import data df = data('ToothGrowth') . | . In this dataset, there are only two treatments (orange juice and ascorbic acid, in the variable supp). We can therefore perrform a two-sample $t$ test. But first we must filter the outcome variable len (tooth length) based on supp. | 1 2 3 4 5 . | subjects_receiving_oj = df[df['supp']=='OJ']['len'] subjects_receiving_vc = df[df['supp']=='VC']['len'] import scipy.stats as stats stats.ttest_ind( subjects_receiving_oj, subjects_receiving_vc, equal_var=False ) . | . | 1 . | Ttest_indResult(statistic=1.91526826869527, pvalue=0.06063450788093387) . | . At the 5% significance level, we see that the length of the tooth does not differ between the two delivery methods. We assume that the model assumptions are met, but do not check that here. If there are multiple levels (two or more), you can apply the parametric ANOVA test which in this case will provide a similar $p$ value. | 1 2 3 4 5 . | from statsmodels.formula.api import ols model = ols('len ~ supp', data = df).fit() import statsmodels.api as sm sm.stats.anova_lm(model, typ=1) . | . | | df | sum_sq | mean_sq | F | PR(&gt;F) | . | supp | 1.0 | 205.350000 | 205.350000 | 3.668253 | 0.060393 | . | Residual | 58.0 | 3246.859333 | 55.980333 | NaN | NaN | . We see the $p$ value in the final column is very similar. However, if the assumptions of ANOVA are not met, we can utilize a nonparametric approach via the Kruskal-Wallis Test. We use the filtered variables defined above and import the kruskal function from SciPy. | 1 2 . | from scipy.stats import kruskal kruskal( subjects_receiving_oj, subjects_receiving_vc ) . | . | 1 . | KruskalResult(statistic=3.4453580631407035, pvalue=0.06342967639688878) . | . Similar to the previous results, the length of the tooth does not differ between the delivery methods at the 5% significance level. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/#using-scipy-and-statsmodels-in-python",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/#using-scipy-and-statsmodels-in-python"
  },"1263": {
    "doc": "How to test for a treatment effect in a single factor design",
    "title": "Using perm, in R",
    "content": "View this solution alone. The solution below uses an example dataset about the teeth of 10 guinea pigs at three Vitamin C dosage levels (in mg) with two delivery methods (orange juice vs. ascorbic acid). (See how to quickly load some sample data.) . | 1 . | df &lt;- ToothGrowth . | . In this dataset, there are only two treatments (orange juice and ascorbic acid, in the variable supp). We can therefore perrform a two-sample $t$ test. But first we must filter the outcome variable len (tooth length) based on supp. | 1 . | t.test(len ~ supp, data=df) . | . | 1 2 3 4 5 6 7 8 9 10 . | Welch Two Sample t-test data: len by supp t = 1.9153, df = 55.309, p-value = 0.06063 alternative hypothesis: true difference in means between group OJ and group VC is not equal to 0 95 percent confidence interval: -0.1710156 7.5710156 sample estimates: mean in group OJ mean in group VC 20.66333 16.96333 . | . The $p$-value is reported in the first row of numerical output as 0.06063. Because this is greater than 0.05, at a 5% significance level, we see that the length of the tooth does not differ between the two delivery methods. Since the t.test makes some assumptions, we can use the permTS function instead. It can conduct a permutation or randomization test, but it requires us to load the perm package first. | 1 2 3 . | # install.packages(\"perm\") # If you have not already installed it library(perm) permTS(len ~ supp, data=df) . | . | 1 2 3 4 5 6 7 8 . | Permutation Test using Asymptotic Approximation data: len by supp Z = 1.8734, p-value = 0.06102 alternative hypothesis: true mean supp=OJ - mean supp=VC is not equal to 0 sample estimates: mean supp=OJ - mean supp=VC 3.7 . | . The $p$-value is reported in the first row of numerical output as 0.06102. Because this is greater than 0.05, at a 5% significance level, we see that the length of the tooth does not differ between the two delivery methods. We assume that the model assumptions are met but not shown in this task. If there are multiple levels (2 or more), you can apply the parametric ANOVA test which in this case will provide a similar $p$-value. | 1 2 . | aov1 &lt;- aov(len ~ supp, data = df) summary(aov1) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) supp 1 205 205.35 3.668 0.0604 . Residuals 58 3247 55.98 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The $p$-value for supp is shown at the end of the supp row, in the Pr(&gt;F) column. Because it is 0.0604, which is greater than 0.05, at a 5% significance level, we see that the length of the tooth does not differ between the delivery methods. However, if the assumptions of ANOVA are not met, we can utilize the non parametric approach via the Kruskal-Wallis Test. | 1 . | kruskal.test(len ~ supp, data = df) . | . | 1 2 3 4 . | Kruskal-Wallis rank sum test data: len by supp Kruskal-Wallis chi-squared = 3.4454, df = 1, p-value = 0.06343 . | . The $p$-value is the last part of the output, and is 0.06343. Because it is greater than 0.05, at a 5% significance level, we see that the length of the tooth does not differ between the delivery methods. Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/#using-perm-in-r",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/#using-perm-in-r"
  },"1264": {
    "doc": "How to test for a treatment effect in a single factor design",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA255 | . ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/#topics-that-include-this-task",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/#topics-that-include-this-task"
  },"1265": {
    "doc": "How to test for a treatment effect in a single factor design",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/#opportunities",
    "relUrl": "/how-to-test-for-a-treatment-effect-in-a-single-factor-design/#opportunities"
  },"1266": {
    "doc": "How to use Bonferroni's Correction method (in R)",
    "title": "How to use Bonferroni’s Correction method (in R)",
    "content": "See all solutions. ",
    "url": "/how-to-use-bonferroni-s-correction-method-in-r/#how-to-use-bonferronis-correction-method-in-r",
    "relUrl": "/how-to-use-bonferroni-s-correction-method-in-r/#how-to-use-bonferronis-correction-method-in-r"
  },"1267": {
    "doc": "How to use Bonferroni's Correction method (in R)",
    "title": "Task",
    "content": "If we run a one-way ANOVA test and find that there is a significant difference between population means, we might want to know which means are actually different from each other. One way to do so is with the Bonferroni correction. This method runs a $t$-test for each pair of categories using a conservative confidence level. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-sided hypothesis test for two sample means (which is just an ANOVA with only two samples) | How to do a Kruskal-Wallis test | . ",
    "url": "/how-to-use-bonferroni-s-correction-method-in-r/#task",
    "relUrl": "/how-to-use-bonferroni-s-correction-method-in-r/#task"
  },"1268": {
    "doc": "How to use Bonferroni's Correction method (in R)",
    "title": "Solution",
    "content": "Let’s assume that you have already done an analysis of variance (ANOVA). (See how to do a one-way analysis of variance (ANOVA) for details.) . As an example, we will use the fake data below, which looks at the number of transactions at an ice cream shop on the weekends. Let’s assume that we chose $\\alpha$ to be 0.05 in that ANOVA. | 1 2 3 4 5 6 7 8 9 . | # Store our fake data in vectors. (You can replace this with your real data.) num.transactions &lt;- c(91, 134, 98, 105, 93, 89, 145, 132, 109, 94, 105, 99, 84, 128, 120, 115, 118) days &lt;- c(\"Fri\", \"Sun\", \"Sun\", \"Sat\", \"Fri\", \"Fri\", \"Sat\", \"Sun\", \"Sun\", \"Fri\", \"Sat\", \"Sat\", \"Fri\", \"Sun\", \"Fri\", \"Sat\", \"Sun\") # Perform an ANOVA and print a summary. model &lt;- aov(num.transactions ~ days) summary(model) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) days 2 1965 982.7 4.348 0.034 * Residuals 14 3164 226.0 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The top-right value in the output is the $p$-value for the test, $0.034$. Because it is below our chosen significance level of $\\alpha=0.05$, there are significant differences between the mean number of transactions at the ice cream shop across at least two of these weekend days. But specifically which two, or is it more than two? . We’ll use the PostHocTest() function in the DescTools package, and specify that we want to use the Bonferroni method to make the confidence intervals for each pair of days. Let’s let $\\alpha$ be equal to 0.05 again, but the Bonferroni correction implies that the overall probability of a Type I Error in any of the tests below is now at most 0.05, rather than each one being 0.05 separately. | 1 2 3 4 5 . | # install.packages(\"DescTools\") # If you have not already installed it library(DescTools) # Run the test and print the confidence intervals for each pair of days PostHocTest(model, method = \"bonferroni\", conf.level = 0.95) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | Posthoc multiple comparisons of means : Bonferroni 95% family-wise confidence level $days diff lwr.ci upr.ci pval Sat-Fri 18.633333 -6.108523 43.37519 0.1798 Sun-Fri 24.666667 1.076232 48.25710 0.0392 * Sun-Sat 6.033333 -18.708523 30.77519 1.0000 --- Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 . | . In the output, R has highlighted the second row for us by placing a * after it. That is the one row where the $p$-value (in the final column) is below our chosen $\\alpha=0.05$. Therefore, the only significant difference in mean number of transactions is between Sundays and Fridays. Notice also that the confidence interval in that row (from lwr.ci to upr.ci) does not include zero. (In that particular row, the confidence interval is $(1.076232,48.25710)$.) . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. Contributed by Elizabeth Czarniak (CZARNIA_ELIZ@bentley.edu) . ",
    "url": "/how-to-use-bonferroni-s-correction-method-in-r/#solution",
    "relUrl": "/how-to-use-bonferroni-s-correction-method-in-r/#solution"
  },"1269": {
    "doc": "How to use Bonferroni's Correction method (in R)",
    "title": "How to use Bonferroni's Correction method (in R)",
    "content": " ",
    "url": "/how-to-use-bonferroni-s-correction-method-in-r/",
    "relUrl": "/how-to-use-bonferroni-s-correction-method-in-r/"
  },"1270": {
    "doc": "How to use Bonferroni's Correction method",
    "title": "How to use Bonferroni’s Correction method",
    "content": " ",
    "url": "/how-to-use-bonferroni-s-correction-method/#how-to-use-bonferronis-correction-method",
    "relUrl": "/how-to-use-bonferroni-s-correction-method/#how-to-use-bonferronis-correction-method"
  },"1271": {
    "doc": "How to use Bonferroni's Correction method",
    "title": "Description",
    "content": "If we run a one-way ANOVA test and find that there is a significant difference between population means, we might want to know which means are actually different from each other. One way to do so is with the Bonferroni correction. This method runs a $t$-test for each pair of categories using a conservative confidence level. Related tasks: . | How to do a one-way analysis of variance (ANOVA) | How to do a two-sided hypothesis test for two sample means (which is just an ANOVA with only two samples) | How to do a Kruskal-Wallis test | . ",
    "url": "/how-to-use-bonferroni-s-correction-method/#description",
    "relUrl": "/how-to-use-bonferroni-s-correction-method/#description"
  },"1272": {
    "doc": "How to use Bonferroni's Correction method",
    "title": "Solution, in R",
    "content": "View this solution alone. Let’s assume that you have already done an analysis of variance (ANOVA). (See how to do a one-way analysis of variance (ANOVA) for details.) . As an example, we will use the fake data below, which looks at the number of transactions at an ice cream shop on the weekends. Let’s assume that we chose $\\alpha$ to be 0.05 in that ANOVA. | 1 2 3 4 5 6 7 8 9 . | # Store our fake data in vectors. (You can replace this with your real data.) num.transactions &lt;- c(91, 134, 98, 105, 93, 89, 145, 132, 109, 94, 105, 99, 84, 128, 120, 115, 118) days &lt;- c(\"Fri\", \"Sun\", \"Sun\", \"Sat\", \"Fri\", \"Fri\", \"Sat\", \"Sun\", \"Sun\", \"Fri\", \"Sat\", \"Sat\", \"Fri\", \"Sun\", \"Fri\", \"Sat\", \"Sun\") # Perform an ANOVA and print a summary. model &lt;- aov(num.transactions ~ days) summary(model) . | . | 1 2 3 4 5 . | Df Sum Sq Mean Sq F value Pr(&gt;F) days 2 1965 982.7 4.348 0.034 * Residuals 14 3164 226.0 --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 . | . The top-right value in the output is the $p$-value for the test, $0.034$. Because it is below our chosen significance level of $\\alpha=0.05$, there are significant differences between the mean number of transactions at the ice cream shop across at least two of these weekend days. But specifically which two, or is it more than two? . We’ll use the PostHocTest() function in the DescTools package, and specify that we want to use the Bonferroni method to make the confidence intervals for each pair of days. Let’s let $\\alpha$ be equal to 0.05 again, but the Bonferroni correction implies that the overall probability of a Type I Error in any of the tests below is now at most 0.05, rather than each one being 0.05 separately. | 1 2 3 4 5 . | # install.packages(\"DescTools\") # If you have not already installed it library(DescTools) # Run the test and print the confidence intervals for each pair of days PostHocTest(model, method = \"bonferroni\", conf.level = 0.95) . | . | 1 2 3 4 5 6 7 8 9 10 11 . | Posthoc multiple comparisons of means : Bonferroni 95% family-wise confidence level $days diff lwr.ci upr.ci pval Sat-Fri 18.633333 -6.108523 43.37519 0.1798 Sun-Fri 24.666667 1.076232 48.25710 0.0392 * Sun-Sat 6.033333 -18.708523 30.77519 1.0000 --- Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 . | . In the output, R has highlighted the second row for us by placing a * after it. That is the one row where the $p$-value (in the final column) is below our chosen $\\alpha=0.05$. Therefore, the only significant difference in mean number of transactions is between Sundays and Fridays. Notice also that the confidence interval in that row (from lwr.ci to upr.ci) does not include zero. (In that particular row, the confidence interval is $(1.076232,48.25710)$.) . Content last modified on 24 October 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-use-bonferroni-s-correction-method/#solution-in-r",
    "relUrl": "/how-to-use-bonferroni-s-correction-method/#solution-in-r"
  },"1273": {
    "doc": "How to use Bonferroni's Correction method",
    "title": "Topics that include this task",
    "content": ". | Bentley University MA214 | . ",
    "url": "/how-to-use-bonferroni-s-correction-method/#topics-that-include-this-task",
    "relUrl": "/how-to-use-bonferroni-s-correction-method/#topics-that-include-this-task"
  },"1274": {
    "doc": "How to use Bonferroni's Correction method",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | Python | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-use-bonferroni-s-correction-method/#opportunities",
    "relUrl": "/how-to-use-bonferroni-s-correction-method/#opportunities"
  },"1275": {
    "doc": "How to use Bonferroni's Correction method",
    "title": "How to use Bonferroni's Correction method",
    "content": " ",
    "url": "/how-to-use-bonferroni-s-correction-method/",
    "relUrl": "/how-to-use-bonferroni-s-correction-method/"
  },"1276": {
    "doc": "How to write a piecewise-defined function (in Python, using SymPy)",
    "title": "How to write a piecewise-defined function (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-write-a-piecewise-defined-function-in-python-using-sympy/",
    "relUrl": "/how-to-write-a-piecewise-defined-function-in-python-using-sympy/"
  },"1277": {
    "doc": "How to write a piecewise-defined function (in Python, using SymPy)",
    "title": "Task",
    "content": "In mathematics, we use the following notation for a “piecewise-defined” function. \\[f(x) = \\begin{cases} x^2 &amp; \\text{if } x&gt;2 \\\\ 1+x &amp; \\text{if } x\\leq 2 \\end{cases}\\] This means that for all $x$ values larger than 2, $f(x)=x^2$, but for $x$ values less than or equal to 2, $f(x)=1+x$. How can we express this in mathematical software? . ",
    "url": "/how-to-write-a-piecewise-defined-function-in-python-using-sympy/#task",
    "relUrl": "/how-to-write-a-piecewise-defined-function-in-python-using-sympy/#task"
  },"1278": {
    "doc": "How to write a piecewise-defined function (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . SymPy has support for piecewise functions built in, using Piecewise. The function above would be written as follows. | 1 2 3 . | var( 'x' ) formula = Piecewise( (x**2, x&gt;2), (1+x, x&lt;=2) ) formula . | . $\\displaystyle \\begin{cases} x^{2} &amp; \\text{for}\\: x &gt; 2 \\\\x + 1 &amp; \\text{otherwise} \\end{cases}$ . We can test to be sure the function works correctly by plugging in a few $x$ values and ensuring the correct $y$ values result. Here we’re using the method from how to substitute a value for a symbolic variable. | 1 . | formula.subs(x,1), formula.subs(x,2), formula.subs(x,3) . | . $\\displaystyle \\left( 2, \\ 3, \\ 9\\right)$ . For $x=1$ we got $1+1=2$. For $x=2$ we got $2+1=3$. For $x=3$, we got $3^2=9$. Content last modified on 01 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-write-a-piecewise-defined-function-in-python-using-sympy/#solution",
    "relUrl": "/how-to-write-a-piecewise-defined-function-in-python-using-sympy/#solution"
  },"1279": {
    "doc": "How to write a piecewise-defined function",
    "title": "How to write a piecewise-defined function",
    "content": " ",
    "url": "/how-to-write-a-piecewise-defined-function/",
    "relUrl": "/how-to-write-a-piecewise-defined-function/"
  },"1280": {
    "doc": "How to write a piecewise-defined function",
    "title": "Description",
    "content": "In mathematics, we use the following notation for a “piecewise-defined” function. \\[f(x) = \\begin{cases} x^2 &amp; \\text{if } x&gt;2 \\\\ 1+x &amp; \\text{if } x\\leq 2 \\end{cases}\\] This means that for all $x$ values larger than 2, $f(x)=x^2$, but for $x$ values less than or equal to 2, $f(x)=1+x$. How can we express this in mathematical software? . ",
    "url": "/how-to-write-a-piecewise-defined-function/#description",
    "relUrl": "/how-to-write-a-piecewise-defined-function/#description"
  },"1281": {
    "doc": "How to write a piecewise-defined function",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . SymPy has support for piecewise functions built in, using Piecewise. The function above would be written as follows. | 1 2 3 . | var( 'x' ) formula = Piecewise( (x**2, x&gt;2), (1+x, x&lt;=2) ) formula . | . $\\displaystyle \\begin{cases} x^{2} &amp; \\text{for}\\: x &gt; 2 \\\\x + 1 &amp; \\text{otherwise} \\end{cases}$ . We can test to be sure the function works correctly by plugging in a few $x$ values and ensuring the correct $y$ values result. Here we’re using the method from how to substitute a value for a symbolic variable. | 1 . | formula.subs(x,1), formula.subs(x,2), formula.subs(x,3) . | . $\\displaystyle \\left( 2, \\ 3, \\ 9\\right)$ . For $x=1$ we got $1+1=2$. For $x=2$ we got $2+1=3$. For $x=3$, we got $3^2=9$. Content last modified on 01 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-write-a-piecewise-defined-function/#using-sympy-in-python",
    "relUrl": "/how-to-write-a-piecewise-defined-function/#using-sympy-in-python"
  },"1282": {
    "doc": "How to write a piecewise-defined function",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-write-a-piecewise-defined-function/#topics-that-include-this-task",
    "relUrl": "/how-to-write-a-piecewise-defined-function/#topics-that-include-this-task"
  },"1283": {
    "doc": "How to write a piecewise-defined function",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-write-a-piecewise-defined-function/#opportunities",
    "relUrl": "/how-to-write-a-piecewise-defined-function/#opportunities"
  },"1284": {
    "doc": "How to write an ordinary differential equation (in Python, using SymPy)",
    "title": "How to write an ordinary differential equation (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-write-an-ordinary-differential-equation-in-python-using-sympy/",
    "relUrl": "/how-to-write-an-ordinary-differential-equation-in-python-using-sympy/"
  },"1285": {
    "doc": "How to write an ordinary differential equation (in Python, using SymPy)",
    "title": "Task",
    "content": "Differential equations are equations that contain differentials like $dy$ and $dx$, often in the form $\\frac{dy}{dx}$. How can we write them using software? . ",
    "url": "/how-to-write-an-ordinary-differential-equation-in-python-using-sympy/#task",
    "relUrl": "/how-to-write-an-ordinary-differential-equation-in-python-using-sympy/#task"
  },"1286": {
    "doc": "How to write an ordinary differential equation (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . The following code tells SymPy that $x$ is a variable and that $y$ is a function of $x$. It then expresses $\\frac{dy}{dx}$ as the derivative of $y$ with respect to $x$. | 1 2 3 4 . | var( 'x' ) # Let x be a variable. y = Function('y')(x) # Literally, y is a function, named y, based on x. dydx = Derivative( y, x ) # How to write dy/dx. dydx # Let's see how SymPy displays dy/dx. | . $\\displaystyle \\frac{d}{d x} y{\\left(x \\right)}$ . Let’s now write a very simple differential equation, $\\frac{dy}{dx}=y$. As with how to do implicit differentiation, SymPy expects us to move everything to the left hand side of the equation. In this case, that makes the equation $\\frac{dy}{dx}-y=0$, and we will use just the left-hand side to express our ODE. | 1 2 . | ode = dydx - y ode . | . $\\displaystyle - y{\\left(x \\right)} + \\frac{d}{d x} y{\\left(x \\right)}$ . Content last modified on 02 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-write-an-ordinary-differential-equation-in-python-using-sympy/#solution",
    "relUrl": "/how-to-write-an-ordinary-differential-equation-in-python-using-sympy/#solution"
  },"1287": {
    "doc": "How to write an ordinary differential equation",
    "title": "How to write an ordinary differential equation",
    "content": " ",
    "url": "/how-to-write-an-ordinary-differential-equation/",
    "relUrl": "/how-to-write-an-ordinary-differential-equation/"
  },"1288": {
    "doc": "How to write an ordinary differential equation",
    "title": "Description",
    "content": "Differential equations are equations that contain differentials like $dy$ and $dx$, often in the form $\\frac{dy}{dx}$. How can we write them using software? . ",
    "url": "/how-to-write-an-ordinary-differential-equation/#description",
    "relUrl": "/how-to-write-an-ordinary-differential-equation/#description"
  },"1289": {
    "doc": "How to write an ordinary differential equation",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . The following code tells SymPy that $x$ is a variable and that $y$ is a function of $x$. It then expresses $\\frac{dy}{dx}$ as the derivative of $y$ with respect to $x$. | 1 2 3 4 . | var( 'x' ) # Let x be a variable. y = Function('y')(x) # Literally, y is a function, named y, based on x. dydx = Derivative( y, x ) # How to write dy/dx. dydx # Let's see how SymPy displays dy/dx. | . $\\displaystyle \\frac{d}{d x} y{\\left(x \\right)}$ . Let’s now write a very simple differential equation, $\\frac{dy}{dx}=y$. As with how to do implicit differentiation, SymPy expects us to move everything to the left hand side of the equation. In this case, that makes the equation $\\frac{dy}{dx}-y=0$, and we will use just the left-hand side to express our ODE. | 1 2 . | ode = dydx - y ode . | . $\\displaystyle - y{\\left(x \\right)} + \\frac{d}{d x} y{\\left(x \\right)}$ . Content last modified on 02 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-write-an-ordinary-differential-equation/#using-sympy-in-python",
    "relUrl": "/how-to-write-an-ordinary-differential-equation/#using-sympy-in-python"
  },"1290": {
    "doc": "How to write an ordinary differential equation",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-write-an-ordinary-differential-equation/#topics-that-include-this-task",
    "relUrl": "/how-to-write-an-ordinary-differential-equation/#topics-that-include-this-task"
  },"1291": {
    "doc": "How to write an ordinary differential equation",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-write-an-ordinary-differential-equation/#opportunities",
    "relUrl": "/how-to-write-an-ordinary-differential-equation/#opportunities"
  },"1292": {
    "doc": "How to write and evaluate definite integrals (in Python, using SymPy)",
    "title": "How to write and evaluate definite integrals (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-write-and-evaluate-definite-integrals-in-python-using-sympy/",
    "relUrl": "/how-to-write-and-evaluate-definite-integrals-in-python-using-sympy/"
  },"1293": {
    "doc": "How to write and evaluate definite integrals (in Python, using SymPy)",
    "title": "Task",
    "content": "The area under a curve can be computed using a definite integral. To compute the area above the $x$ axis and under $f(x)$, from $x=a$ to $x=b$, we write . \\[\\int_a^b f(x)\\;dx.\\] How can we write and evaluate definite integrals using software? . Related tasks: . | How to compute the derivative of a function | How to write and evaluate indefinite integrals | . ",
    "url": "/how-to-write-and-evaluate-definite-integrals-in-python-using-sympy/#task",
    "relUrl": "/how-to-write-and-evaluate-definite-integrals-in-python-using-sympy/#task"
  },"1294": {
    "doc": "How to write and evaluate definite integrals (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s compute the area under $\\sin x$ from $x=0$ to $x=\\pi$. We use the same technique as in how to write and evaluate indefinite integrals, except that we add the lower and upper bounds together with $x$, as shown below. | 1 2 3 . | var( 'x' ) formula = sin(x) Integral( formula, (x,0,pi) ) . | . $\\displaystyle \\int\\limits_{0}^{\\pi} \\sin{\\left(x \\right)}\\, dx$ . The above code just displays the definite integral. To evaluate it, use the integrate command. | 1 . | integrate( formula, (x,0,pi) ) . | . $\\displaystyle 2$ . Content last modified on 02 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-write-and-evaluate-definite-integrals-in-python-using-sympy/#solution",
    "relUrl": "/how-to-write-and-evaluate-definite-integrals-in-python-using-sympy/#solution"
  },"1295": {
    "doc": "How to write and evaluate definite integrals",
    "title": "How to write and evaluate definite integrals",
    "content": " ",
    "url": "/how-to-write-and-evaluate-definite-integrals/",
    "relUrl": "/how-to-write-and-evaluate-definite-integrals/"
  },"1296": {
    "doc": "How to write and evaluate definite integrals",
    "title": "Description",
    "content": "The area under a curve can be computed using a definite integral. To compute the area above the $x$ axis and under $f(x)$, from $x=a$ to $x=b$, we write . \\[\\int_a^b f(x)\\;dx.\\] How can we write and evaluate definite integrals using software? . Related tasks: . | How to compute the derivative of a function | How to write and evaluate indefinite integrals | . ",
    "url": "/how-to-write-and-evaluate-definite-integrals/#description",
    "relUrl": "/how-to-write-and-evaluate-definite-integrals/#description"
  },"1297": {
    "doc": "How to write and evaluate definite integrals",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s compute the area under $\\sin x$ from $x=0$ to $x=\\pi$. We use the same technique as in how to write and evaluate indefinite integrals, except that we add the lower and upper bounds together with $x$, as shown below. | 1 2 3 . | var( 'x' ) formula = sin(x) Integral( formula, (x,0,pi) ) . | . $\\displaystyle \\int\\limits_{0}^{\\pi} \\sin{\\left(x \\right)}\\, dx$ . The above code just displays the definite integral. To evaluate it, use the integrate command. | 1 . | integrate( formula, (x,0,pi) ) . | . $\\displaystyle 2$ . Content last modified on 02 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-write-and-evaluate-definite-integrals/#using-sympy-in-python",
    "relUrl": "/how-to-write-and-evaluate-definite-integrals/#using-sympy-in-python"
  },"1298": {
    "doc": "How to write and evaluate definite integrals",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-write-and-evaluate-definite-integrals/#topics-that-include-this-task",
    "relUrl": "/how-to-write-and-evaluate-definite-integrals/#topics-that-include-this-task"
  },"1299": {
    "doc": "How to write and evaluate definite integrals",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-write-and-evaluate-definite-integrals/#opportunities",
    "relUrl": "/how-to-write-and-evaluate-definite-integrals/#opportunities"
  },"1300": {
    "doc": "How to write and evaluate indefinite integrals (in Python, using SymPy)",
    "title": "How to write and evaluate indefinite integrals (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-write-and-evaluate-indefinite-integrals-in-python-using-sympy/",
    "relUrl": "/how-to-write-and-evaluate-indefinite-integrals-in-python-using-sympy/"
  },"1301": {
    "doc": "How to write and evaluate indefinite integrals (in Python, using SymPy)",
    "title": "Task",
    "content": "The antiderivative of a function is expressed using an indefinite integral, as in . \\[\\int f(x)\\;dx.\\] How can we write and evaluate indefinite integrals using software? . Related tasks: . | How to compute the derivative of a function | How to write and evaluate definite integrals | . ",
    "url": "/how-to-write-and-evaluate-indefinite-integrals-in-python-using-sympy/#task",
    "relUrl": "/how-to-write-and-evaluate-indefinite-integrals-in-python-using-sympy/#task"
  },"1302": {
    "doc": "How to write and evaluate indefinite integrals (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s choose an example formula whose antiderivative we will compute. | 1 2 3 . | var( 'x' ) formula = 3*sqrt(x) formula . | . $\\displaystyle 3 \\sqrt{x}$ . Use the Integral function to build a definite integral without evaluating it. The second parameter is the variable with respect to which you’re integrating. | 1 . | Integral( formula, x ) . | . $\\displaystyle \\int 3 \\sqrt{x}\\, dx$ . Use the integrate function to perform the integration, showing the answer. | 1 . | integrate( formula, x ) . | . $\\displaystyle 2 x^{\\frac{3}{2}}$ . | 1 . | integrate( formula, x ) + var('C') # same, but with a constant of integration . | . $\\displaystyle C + 2 x^{\\frac{3}{2}}$ . Content last modified on 02 June 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-write-and-evaluate-indefinite-integrals-in-python-using-sympy/#solution",
    "relUrl": "/how-to-write-and-evaluate-indefinite-integrals-in-python-using-sympy/#solution"
  },"1303": {
    "doc": "How to write and evaluate indefinite integrals",
    "title": "How to write and evaluate indefinite integrals",
    "content": " ",
    "url": "/how-to-write-and-evaluate-indefinite-integrals/",
    "relUrl": "/how-to-write-and-evaluate-indefinite-integrals/"
  },"1304": {
    "doc": "How to write and evaluate indefinite integrals",
    "title": "Description",
    "content": "The antiderivative of a function is expressed using an indefinite integral, as in . \\[\\int f(x)\\;dx.\\] How can we write and evaluate indefinite integrals using software? . Related tasks: . | How to compute the derivative of a function | How to write and evaluate definite integrals | . ",
    "url": "/how-to-write-and-evaluate-indefinite-integrals/#description",
    "relUrl": "/how-to-write-and-evaluate-indefinite-integrals/#description"
  },"1305": {
    "doc": "How to write and evaluate indefinite integrals",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s choose an example formula whose antiderivative we will compute. | 1 2 3 . | var( 'x' ) formula = 3*sqrt(x) formula . | . $\\displaystyle 3 \\sqrt{x}$ . Use the Integral function to build a definite integral without evaluating it. The second parameter is the variable with respect to which you’re integrating. | 1 . | Integral( formula, x ) . | . $\\displaystyle \\int 3 \\sqrt{x}\\, dx$ . Use the integrate function to perform the integration, showing the answer. | 1 . | integrate( formula, x ) . | . $\\displaystyle 2 x^{\\frac{3}{2}}$ . | 1 . | integrate( formula, x ) + var('C') # same, but with a constant of integration . | . $\\displaystyle C + 2 x^{\\frac{3}{2}}$ . Content last modified on 02 June 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-write-and-evaluate-indefinite-integrals/#using-sympy-in-python",
    "relUrl": "/how-to-write-and-evaluate-indefinite-integrals/#using-sympy-in-python"
  },"1306": {
    "doc": "How to write and evaluate indefinite integrals",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-write-and-evaluate-indefinite-integrals/#topics-that-include-this-task",
    "relUrl": "/how-to-write-and-evaluate-indefinite-integrals/#topics-that-include-this-task"
  },"1307": {
    "doc": "How to write and evaluate indefinite integrals",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-write-and-evaluate-indefinite-integrals/#opportunities",
    "relUrl": "/how-to-write-and-evaluate-indefinite-integrals/#opportunities"
  },"1308": {
    "doc": "How to write symbolic equations (in Python, using SymPy)",
    "title": "How to write symbolic equations (in Python, using SymPy)",
    "content": "See all solutions. ",
    "url": "/how-to-write-symbolic-equations-in-python-using-sympy/",
    "relUrl": "/how-to-write-symbolic-equations-in-python-using-sympy/"
  },"1309": {
    "doc": "How to write symbolic equations (in Python, using SymPy)",
    "title": "Task",
    "content": "In programming, when we write a=b, the computer interprets it as an instruction, to change the value of a to b. But in mathematics, $a=b$ is a statement that $a$ and $b$ are equal; it’s often a starting point for algebraic work. How can we write a mathematical equation using software? . Related tasks: . | How to solve symbolic equations | How to isolate one variable in an equation | . ",
    "url": "/how-to-write-symbolic-equations-in-python-using-sympy/#task",
    "relUrl": "/how-to-write-symbolic-equations-in-python-using-sympy/#task"
  },"1310": {
    "doc": "How to write symbolic equations (in Python, using SymPy)",
    "title": "Solution",
    "content": "This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s say we want to write the equation $x^2+y^2=2$. We must first define $x$ and $y$ as mathematical variables, then use SymPy’s Eq function to build an equation. This helps SymPy distinguish a mathematical equation from a Python assignment statement. | 1 2 . | var( 'x y' ) Eq( x**2 + y**2, 2 ) # Two parameters: left and right sides of equation . | . $\\displaystyle x^{2} + y^{2} = 2$ . You can make a system of equations just by placing several equations in a Python list. | 1 2 3 4 5 . | system = [ Eq( x + 2*y, 1 ), Eq( x - 9*y, 5 ) ] system . | . $\\displaystyle \\left[ x + 2 y = 1, \\ x - 9 y = 5\\right]$ . Content last modified on 10 September 2021. See a problem? Tell us or edit the source. Contributed by Nathan Carter (ncarter@bentley.edu) . ",
    "url": "/how-to-write-symbolic-equations-in-python-using-sympy/#solution",
    "relUrl": "/how-to-write-symbolic-equations-in-python-using-sympy/#solution"
  },"1311": {
    "doc": "How to write symbolic equations",
    "title": "How to write symbolic equations",
    "content": " ",
    "url": "/how-to-write-symbolic-equations/",
    "relUrl": "/how-to-write-symbolic-equations/"
  },"1312": {
    "doc": "How to write symbolic equations",
    "title": "Description",
    "content": "In programming, when we write a=b, the computer interprets it as an instruction, to change the value of a to b. But in mathematics, $a=b$ is a statement that $a$ and $b$ are equal; it’s often a starting point for algebraic work. How can we write a mathematical equation using software? . Related tasks: . | How to solve symbolic equations | How to isolate one variable in an equation | . ",
    "url": "/how-to-write-symbolic-equations/#description",
    "relUrl": "/how-to-write-symbolic-equations/#description"
  },"1313": {
    "doc": "How to write symbolic equations",
    "title": "Using SymPy, in Python",
    "content": "View this solution alone. This answer assumes you have imported SymPy as follows. | 1 2 . | from sympy import * # load all math functions init_printing( use_latex='mathjax' ) # use pretty math output . | . Let’s say we want to write the equation $x^2+y^2=2$. We must first define $x$ and $y$ as mathematical variables, then use SymPy’s Eq function to build an equation. This helps SymPy distinguish a mathematical equation from a Python assignment statement. | 1 2 . | var( 'x y' ) Eq( x**2 + y**2, 2 ) # Two parameters: left and right sides of equation . | . $\\displaystyle x^{2} + y^{2} = 2$ . You can make a system of equations just by placing several equations in a Python list. | 1 2 3 4 5 . | system = [ Eq( x + 2*y, 1 ), Eq( x - 9*y, 5 ) ] system . | . $\\displaystyle \\left[ x + 2 y = 1, \\ x - 9 y = 5\\right]$ . Content last modified on 10 September 2021. See a problem? Tell us or edit the source. ",
    "url": "/how-to-write-symbolic-equations/#using-sympy-in-python",
    "relUrl": "/how-to-write-symbolic-equations/#using-sympy-in-python"
  },"1314": {
    "doc": "How to write symbolic equations",
    "title": "Topics that include this task",
    "content": ". | Bentley University GR526 | . ",
    "url": "/how-to-write-symbolic-equations/#topics-that-include-this-task",
    "relUrl": "/how-to-write-symbolic-equations/#topics-that-include-this-task"
  },"1315": {
    "doc": "How to write symbolic equations",
    "title": "Opportunities",
    "content": "This website does not yet contain a solution for this task in any of the following software packages. | R | Excel | Julia | . If you can contribute a solution using any of these pieces of software, see our Contributing page for how to help extend this website. ",
    "url": "/how-to-write-symbolic-equations/#opportunities",
    "relUrl": "/how-to-write-symbolic-equations/#opportunities"
  },"1316": {
    "doc": "Welcome",
    "title": "Welcome to How to Data!",
    "content": "A reference for data science students . ",
    "url": "/#welcome-to-how-to-data",
    "relUrl": "/#welcome-to-how-to-data"
  },"1317": {
    "doc": "Welcome",
    "title": "What’s on the site?",
    "content": ". | Tasks: Data-related how-tos using software like Python, R, and Excel. Examples: . | How to compare two nested linear models | How to create basic plots | . | Topics: Groups of tasks organized by course of study. Examples: . | Intro statistics at Bentley University | Data Science at Bentley University | . | . ",
    "url": "/#whats-on-the-site",
    "relUrl": "/#whats-on-the-site"
  },"1318": {
    "doc": "Welcome",
    "title": "How much is here?",
    "content": "This site began at Bentley University, but accepts contributions from any school or business, and is happy to work with you to let you add content that would be useful to your students or employees. See the Contributing page for details. | Content | Quantity | . | Topics | 7 | . | Tasks | 105 | . | Solutions | 205 | . | Software packages | 4 | . ",
    "url": "/#how-much-is-here",
    "relUrl": "/#how-much-is-here"
  },"1319": {
    "doc": "Welcome",
    "title": "Welcome",
    "content": " ",
    "url": "/",
    "relUrl": "/"
  },"1320": {
    "doc": "Software package: Excel",
    "title": "Software package: Excel",
    "content": ". ",
    "url": "/software-package-excel/",
    "relUrl": "/software-package-excel/"
  },"1321": {
    "doc": "Software package: Excel",
    "title": "Solutions in Excel (6)",
    "content": "| Task | Solutions in Excel | Solutions in other software packages | . | How to compute probabilities from a distribution | solution | 3 (view) | . | How to compute summary statistics | solution | 3 (view) | . | How to do basic mathematical computations | solution | 5 (view) | . | How to generate random values from a distribution | solution | 3 (view) | . | How to plot continuous probability distributions | solution | 3 (view) | . | How to summarize a column | solution | 2 (view) | . ",
    "url": "/software-package-excel/#solutions-in-excel-6",
    "relUrl": "/software-package-excel/#solutions-in-excel-6"
  },"1322": {
    "doc": "Software package: Excel",
    "title": "Solutions needed in Excel",
    "content": "| Task | Solutions in Excel | Solutions in other software packages | . | How to add a polynomial term to a model | none yet(Want to submit one?) | 2 (view) | . | How to add a transformed term to a model | none yet(Want to submit one?) | 2 (view) | . | How to add an interaction term to a model | none yet(Want to submit one?) | 1 (view) | . | How to add details to a plot | none yet(Want to submit one?) | 2 (view) | . | How to analyze the sample means of different treatment conditions | none yet(Want to submit one?) | 2 (view) | . | How to change axes, ticks, and scale in a plot | none yet(Want to submit one?) | 1 (view) | . | How to check the assumptions of a linear model | none yet(Want to submit one?) | 2 (view) | . | How to choose the sample size in a study with two population means | none yet(Want to submit one?) | 2 (view) | . | How to compare two nested linear models | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for a mean difference (matched pairs) | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for a population mean | none yet(Want to submit one?) | 3 (view) | . | How to compute a confidence interval for a population mean using z-scores | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for a regression coefficient | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for a single population variance | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the difference between two means when both population variances are known | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the difference between two means when population variances are unknown | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the difference between two proportions | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the expected value of a response variable | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the population proportion | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the ratio of two population variances | none yet(Want to submit one?) | 2 (view) | . | How to compute adjusted R-squared | none yet(Want to submit one?) | 2 (view) | . | How to compute covariance and correlation coefficients | none yet(Want to submit one?) | 2 (view) | . | How to compute Fisher’s confidence intervals | none yet(Want to submit one?) | 1 (view) | . | How to compute R-squared for a simple linear model | none yet(Want to submit one?) | 3 (view) | . | How to compute the derivative of a function | none yet(Want to submit one?) | 2 (view) | . | How to compute the domain of a function | none yet(Want to submit one?) | 1 (view) | . | How to compute the error bounds on a Taylor approximation | none yet(Want to submit one?) | 1 (view) | . | How to compute the limit of a function | none yet(Want to submit one?) | 1 (view) | . | How to compute the power of a test comparing two population means | none yet(Want to submit one?) | 2 (view) | . | How to compute the residuals of a linear model | none yet(Want to submit one?) | 2 (view) | . | How to compute the standard error of the estimate for a model | none yet(Want to submit one?) | 2 (view) | . | How to compute the Taylor series for a function | none yet(Want to submit one?) | 1 (view) | . | How to conduct a mixed designs ANOVA | none yet(Want to submit one?) | 2 (view) | . | How to conduct a repeated measures ANOVA | none yet(Want to submit one?) | 2 (view) | . | How to convert a text column into dates | none yet(Want to submit one?) | 2 (view) | . | How to create a box (and whisker) plot | none yet(Want to submit one?) | 2 (view) | . | How to create a data frame from scratch | none yet(Want to submit one?) | 2 (view) | . | How to create a histogram | none yet(Want to submit one?) | 2 (view) | . | How to create a QQ-plot | none yet(Want to submit one?) | 3 (view) | . | How to create basic plots | none yet(Want to submit one?) | 2 (view) | . | How to create bivariate plots to compare groups | none yet(Want to submit one?) | 2 (view) | . | How to create symbolic variables | none yet(Want to submit one?) | 1 (view) | . | How to define a mathematical sequence | none yet(Want to submit one?) | 1 (view) | . | How to define a mathematical series | none yet(Want to submit one?) | 1 (view) | . | How to do a goodness of fit test for a multinomial experiment | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for a mean difference (matched pairs) | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for a population proportion | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for population variance | none yet(Want to submit one?) | 1 (view) | . | How to do a hypothesis test for the difference between means when both population variances are known | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for the difference between two proportions | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for the mean with known standard deviation | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for the ratio of two population variances | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test of a coefficient’s significance | none yet(Want to submit one?) | 1 (view) | . | How to do a Kruskal-Wallis test | none yet(Want to submit one?) | 2 (view) | . | How to do a one-sided hypothesis test for two sample means | none yet(Want to submit one?) | 2 (view) | . | How to do a one-way analysis of variance (ANOVA) | none yet(Want to submit one?) | 3 (view) | . | How to do a Spearman rank correlation test | none yet(Want to submit one?) | 2 (view) | . | How to do a test of joint significance | none yet(Want to submit one?) | 2 (view) | . | How to do a two-sided hypothesis test for a sample mean | none yet(Want to submit one?) | 3 (view) | . | How to do a two-sided hypothesis test for two sample means | none yet(Want to submit one?) | 3 (view) | . | How to do a two-way ANOVA test with interaction | none yet(Want to submit one?) | 2 (view) | . | How to do a two-way ANOVA test without interaction | none yet(Want to submit one?) | 2 (view) | . | How to do a Wilcoxon rank-sum test | none yet(Want to submit one?) | 2 (view) | . | How to do a Wilcoxon signed-rank test | none yet(Want to submit one?) | 2 (view) | . | How to do a Wilcoxon signed-rank test for matched pairs | none yet(Want to submit one?) | 2 (view) | . | How to do implicit differentiation | none yet(Want to submit one?) | 1 (view) | . | How to find critical values and p-values from the normal distribution | none yet(Want to submit one?) | 2 (view) | . | How to find critical values and p-values from the t-distribution | none yet(Want to submit one?) | 2 (view) | . | How to find the critical numbers of a function | none yet(Want to submit one?) | 1 (view) | . | How to fit a linear model to two columns of data | none yet(Want to submit one?) | 4 (view) | . | How to fit a multivariate linear model | none yet(Want to submit one?) | 2 (view) | . | How to graph a two-variable function as a surface | none yet(Want to submit one?) | 1 (view) | . | How to graph curves that are not functions | none yet(Want to submit one?) | 1 (view) | . | How to graph mathematical functions | none yet(Want to submit one?) | 3 (view) | . | How to graph mathematical sequences | none yet(Want to submit one?) | 1 (view) | . | How to isolate one variable in an equation | none yet(Want to submit one?) | 1 (view) | . | How to perform a chi-squared test on a contingency table | none yet(Want to submit one?) | 3 (view) | . | How to perform a planned comparison test | none yet(Want to submit one?) | 1 (view) | . | How to perform an analysis of covariance (ANCOVA) | none yet(Want to submit one?) | 2 (view) | . | How to perform pairwise comparisons | none yet(Want to submit one?) | 2 (view) | . | How to perform post-hoc analysis with Tukey’s HSD test | none yet(Want to submit one?) | 3 (view) | . | How to plot discrete probability distributions | none yet(Want to submit one?) | 3 (view) | . | How to plot interaction effects of treatments | none yet(Want to submit one?) | 2 (view) | . | How to predict the response variable in a linear model | none yet(Want to submit one?) | 2 (view) | . | How to quickly load some sample data | none yet(Want to submit one?) | 3 (view) | . | How to solve an ordinary differential equation | none yet(Want to submit one?) | 1 (view) | . | How to solve symbolic equations | none yet(Want to submit one?) | 1 (view) | . | How to substitute a value for a symbolic variable | none yet(Want to submit one?) | 1 (view) | . | How to summarize and compare data by groups | none yet(Want to submit one?) | 2 (view) | . | How to test data for normality with Pearson’s chi-squared test | none yet(Want to submit one?) | 1 (view) | . | How to test data for normality with the D’Agostino-Pearson test | none yet(Want to submit one?) | 1 (view) | . | How to test data for normality with the Jarque-Bera test | none yet(Want to submit one?) | 1 (view) | . | How to test for a treatment effect in a single factor design | none yet(Want to submit one?) | 2 (view) | . | How to use Bonferroni’s Correction method | none yet(Want to submit one?) | 1 (view) | . | How to write a piecewise-defined function | none yet(Want to submit one?) | 1 (view) | . | How to write an ordinary differential equation | none yet(Want to submit one?) | 1 (view) | . | How to write and evaluate definite integrals | none yet(Want to submit one?) | 1 (view) | . | How to write and evaluate indefinite integrals | none yet(Want to submit one?) | 1 (view) | . | How to write symbolic equations | none yet(Want to submit one?) | 1 (view) | . ",
    "url": "/software-package-excel/#solutions-needed-in-excel",
    "relUrl": "/software-package-excel/#solutions-needed-in-excel"
  },"1323": {
    "doc": "Software package: Julia",
    "title": "Software package: Julia",
    "content": ". ",
    "url": "/software-package-julia/",
    "relUrl": "/software-package-julia/"
  },"1324": {
    "doc": "Software package: Julia",
    "title": "Solutions in Julia (16)",
    "content": "| Task | Solutions in Julia | Solutions in other software packages | . | How to compute a confidence interval for a population mean | solution | 2 (view) | . | How to compute probabilities from a distribution | solution | 3 (view) | . | How to compute R-squared for a simple linear model | solution | 2 (view) | . | How to compute summary statistics | solution | 3 (view) | . | How to do a one-way analysis of variance (ANOVA) | solution | 2 (view) | . | How to do a two-sided hypothesis test for a sample mean | solution | 2 (view) | . | How to do a two-sided hypothesis test for two sample means | solution | 2 (view) | . | How to do basic mathematical computations | solution | 5 (view) | . | How to find critical values and p-values from the normal distribution | solution | 1 (view) | . | How to find critical values and p-values from the t-distribution | solution | 1 (view) | . | How to fit a linear model to two columns of data | solution | 3 (view) | . | How to generate random values from a distribution | solution | 3 (view) | . | How to perform a chi-squared test on a contingency table | solution | 2 (view) | . | How to plot continuous probability distributions | solution | 3 (view) | . | How to plot discrete probability distributions | solution | 2 (view) | . | How to quickly load some sample data | solution | 2 (view) | . ",
    "url": "/software-package-julia/#solutions-in-julia-16",
    "relUrl": "/software-package-julia/#solutions-in-julia-16"
  },"1325": {
    "doc": "Software package: Julia",
    "title": "Solutions needed in Julia",
    "content": "| Task | Solutions in Julia | Solutions in other software packages | . | How to add a polynomial term to a model | none yet(Want to submit one?) | 2 (view) | . | How to add a transformed term to a model | none yet(Want to submit one?) | 2 (view) | . | How to add an interaction term to a model | none yet(Want to submit one?) | 1 (view) | . | How to add details to a plot | none yet(Want to submit one?) | 2 (view) | . | How to analyze the sample means of different treatment conditions | none yet(Want to submit one?) | 2 (view) | . | How to change axes, ticks, and scale in a plot | none yet(Want to submit one?) | 1 (view) | . | How to check the assumptions of a linear model | none yet(Want to submit one?) | 2 (view) | . | How to choose the sample size in a study with two population means | none yet(Want to submit one?) | 2 (view) | . | How to compare two nested linear models | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for a mean difference (matched pairs) | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for a population mean using z-scores | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for a regression coefficient | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for a single population variance | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the difference between two means when both population variances are known | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the difference between two means when population variances are unknown | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the difference between two proportions | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the expected value of a response variable | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the population proportion | none yet(Want to submit one?) | 2 (view) | . | How to compute a confidence interval for the ratio of two population variances | none yet(Want to submit one?) | 2 (view) | . | How to compute adjusted R-squared | none yet(Want to submit one?) | 2 (view) | . | How to compute covariance and correlation coefficients | none yet(Want to submit one?) | 2 (view) | . | How to compute Fisher’s confidence intervals | none yet(Want to submit one?) | 1 (view) | . | How to compute the derivative of a function | none yet(Want to submit one?) | 2 (view) | . | How to compute the domain of a function | none yet(Want to submit one?) | 1 (view) | . | How to compute the error bounds on a Taylor approximation | none yet(Want to submit one?) | 1 (view) | . | How to compute the limit of a function | none yet(Want to submit one?) | 1 (view) | . | How to compute the power of a test comparing two population means | none yet(Want to submit one?) | 2 (view) | . | How to compute the residuals of a linear model | none yet(Want to submit one?) | 2 (view) | . | How to compute the standard error of the estimate for a model | none yet(Want to submit one?) | 2 (view) | . | How to compute the Taylor series for a function | none yet(Want to submit one?) | 1 (view) | . | How to conduct a mixed designs ANOVA | none yet(Want to submit one?) | 2 (view) | . | How to conduct a repeated measures ANOVA | none yet(Want to submit one?) | 2 (view) | . | How to convert a text column into dates | none yet(Want to submit one?) | 2 (view) | . | How to create a box (and whisker) plot | none yet(Want to submit one?) | 2 (view) | . | How to create a data frame from scratch | none yet(Want to submit one?) | 2 (view) | . | How to create a histogram | none yet(Want to submit one?) | 2 (view) | . | How to create a QQ-plot | none yet(Want to submit one?) | 3 (view) | . | How to create basic plots | none yet(Want to submit one?) | 2 (view) | . | How to create bivariate plots to compare groups | none yet(Want to submit one?) | 2 (view) | . | How to create symbolic variables | none yet(Want to submit one?) | 1 (view) | . | How to define a mathematical sequence | none yet(Want to submit one?) | 1 (view) | . | How to define a mathematical series | none yet(Want to submit one?) | 1 (view) | . | How to do a goodness of fit test for a multinomial experiment | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for a mean difference (matched pairs) | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for a population proportion | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for population variance | none yet(Want to submit one?) | 1 (view) | . | How to do a hypothesis test for the difference between means when both population variances are known | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for the difference between two proportions | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for the mean with known standard deviation | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test for the ratio of two population variances | none yet(Want to submit one?) | 2 (view) | . | How to do a hypothesis test of a coefficient’s significance | none yet(Want to submit one?) | 1 (view) | . | How to do a Kruskal-Wallis test | none yet(Want to submit one?) | 2 (view) | . | How to do a one-sided hypothesis test for two sample means | none yet(Want to submit one?) | 2 (view) | . | How to do a Spearman rank correlation test | none yet(Want to submit one?) | 2 (view) | . | How to do a test of joint significance | none yet(Want to submit one?) | 2 (view) | . | How to do a two-way ANOVA test with interaction | none yet(Want to submit one?) | 2 (view) | . | How to do a two-way ANOVA test without interaction | none yet(Want to submit one?) | 2 (view) | . | How to do a Wilcoxon rank-sum test | none yet(Want to submit one?) | 2 (view) | . | How to do a Wilcoxon signed-rank test | none yet(Want to submit one?) | 2 (view) | . | How to do a Wilcoxon signed-rank test for matched pairs | none yet(Want to submit one?) | 2 (view) | . | How to do implicit differentiation | none yet(Want to submit one?) | 1 (view) | . | How to find the critical numbers of a function | none yet(Want to submit one?) | 1 (view) | . | How to fit a multivariate linear model | none yet(Want to submit one?) | 2 (view) | . | How to graph a two-variable function as a surface | none yet(Want to submit one?) | 1 (view) | . | How to graph curves that are not functions | none yet(Want to submit one?) | 1 (view) | . | How to graph mathematical functions | none yet(Want to submit one?) | 3 (view) | . | How to graph mathematical sequences | none yet(Want to submit one?) | 1 (view) | . | How to isolate one variable in an equation | none yet(Want to submit one?) | 1 (view) | . | How to perform a planned comparison test | none yet(Want to submit one?) | 1 (view) | . | How to perform an analysis of covariance (ANCOVA) | none yet(Want to submit one?) | 2 (view) | . | How to perform pairwise comparisons | none yet(Want to submit one?) | 2 (view) | . | How to perform post-hoc analysis with Tukey’s HSD test | none yet(Want to submit one?) | 3 (view) | . | How to plot interaction effects of treatments | none yet(Want to submit one?) | 2 (view) | . | How to predict the response variable in a linear model | none yet(Want to submit one?) | 2 (view) | . | How to solve an ordinary differential equation | none yet(Want to submit one?) | 1 (view) | . | How to solve symbolic equations | none yet(Want to submit one?) | 1 (view) | . | How to substitute a value for a symbolic variable | none yet(Want to submit one?) | 1 (view) | . | How to summarize a column | none yet(Want to submit one?) | 3 (view) | . | How to summarize and compare data by groups | none yet(Want to submit one?) | 2 (view) | . | How to test data for normality with Pearson’s chi-squared test | none yet(Want to submit one?) | 1 (view) | . | How to test data for normality with the D’Agostino-Pearson test | none yet(Want to submit one?) | 1 (view) | . | How to test data for normality with the Jarque-Bera test | none yet(Want to submit one?) | 1 (view) | . | How to test for a treatment effect in a single factor design | none yet(Want to submit one?) | 2 (view) | . | How to use Bonferroni’s Correction method | none yet(Want to submit one?) | 1 (view) | . | How to write a piecewise-defined function | none yet(Want to submit one?) | 1 (view) | . | How to write an ordinary differential equation | none yet(Want to submit one?) | 1 (view) | . | How to write and evaluate definite integrals | none yet(Want to submit one?) | 1 (view) | . | How to write and evaluate indefinite integrals | none yet(Want to submit one?) | 1 (view) | . | How to write symbolic equations | none yet(Want to submit one?) | 1 (view) | . ",
    "url": "/software-package-julia/#solutions-needed-in-julia",
    "relUrl": "/software-package-julia/#solutions-needed-in-julia"
  },"1326": {
    "doc": "Software package: Python",
    "title": "Software package: Python",
    "content": ". ",
    "url": "/software-package-python/",
    "relUrl": "/software-package-python/"
  },"1327": {
    "doc": "Software package: Python",
    "title": "Solutions in Python (101)",
    "content": "| Task | Solutions in Python | Solutions in other software packages | . | How to add a polynomial term to a model | using sklearn | 1 (view) | . | How to add a transformed term to a model | using NumPy and sklearn | 1 (view) | . | How to add details to a plot | using Matplotlib | 1 (view) | . | How to analyze the sample means of different treatment conditions | using Matplotlib and Seaborn | 1 (view) | . | How to change axes, ticks, and scale in a plot | using Matplotlib | None | . | How to check the assumptions of a linear model | using NumPy, SciPy, sklearn, Matplotlib and Seaborn | 1 (view) | . | How to choose the sample size in a study with two population means | using statsmodels | 1 (view) | . | How to compare two nested linear models | using statsmodels | 1 (view) | . | How to compute a confidence interval for a mean difference (matched pairs) | using NumPy and SciPy | 1 (view) | . | How to compute a confidence interval for a population mean | using SciPy | 2 (view) | . | How to compute a confidence interval for a population mean using z-scores | using SciPy | 1 (view) | . | How to compute a confidence interval for a regression coefficient | using statsmodels | 1 (view) | . | How to compute a confidence interval for a single population variance | using SciPy | 1 (view) | . | How to compute a confidence interval for the difference between two means when both population variances are known | using NumPy and SciPy | 1 (view) | . | How to compute a confidence interval for the difference between two means when population variances are unknown | using NumPy and SciPy | 1 (view) | . | How to compute a confidence interval for the difference between two proportions | using SciPy | 1 (view) | . | How to compute a confidence interval for the expected value of a response variable | using statsmodels and sklearn | 1 (view) | . | How to compute a confidence interval for the population proportion | using SciPy | 1 (view) | . | How to compute a confidence interval for the ratio of two population variances | using SciPy | 1 (view) | . | How to compute adjusted R-squared | using statsmodels | 1 (view) | . | How to compute covariance and correlation coefficients | using pandas and NumPy | 1 (view) | . | How to compute probabilities from a distribution | using SciPy | 3 (view) | . | How to compute R-squared for a simple linear model | using SciPy | 2 (view) | . | How to compute summary statistics | using pandas and NumPy | 3 (view) | . | How to compute the derivative of a function | using SymPy | 1 (view) | . | How to compute the domain of a function | using SymPy | None | . | How to compute the error bounds on a Taylor approximation | using SymPy | None | . | How to compute the limit of a function | using SymPy | None | . | How to compute the power of a test comparing two population means | using statsmodels | 1 (view) | . | How to compute the residuals of a linear model | using statsmodels | 1 (view) | . | How to compute the standard error of the estimate for a model | using statsmodels | 1 (view) | . | How to compute the Taylor series for a function | using SymPy | None | . | How to conduct a mixed designs ANOVA | using pandas and pingouin | 1 (view) | . | How to conduct a repeated measures ANOVA | using pandas and pingouin | 1 (view) | . | How to convert a text column into dates | using pandas | 1 (view) | . | How to create a box (and whisker) plot | using Matplotlib | 1 (view) | . | How to create a data frame from scratch | solution | 1 (view) | . | How to create a histogram | using Matplotlib | 1 (view) | . | How to create a QQ-plot | using SciPy, using statsmodels | 1 (view) | . | How to create basic plots | using Matplotlib | 1 (view) | . | How to create bivariate plots to compare groups | using Matplotlib and Seaborn | 1 (view) | . | How to create symbolic variables | using SymPy | None | . | How to define a mathematical sequence | using SymPy | None | . | How to define a mathematical series | using SymPy | None | . | How to do a goodness of fit test for a multinomial experiment | using SciPy | 1 (view) | . | How to do a hypothesis test for a mean difference (matched pairs) | using SciPy | 1 (view) | . | How to do a hypothesis test for a population proportion | using SciPy | 1 (view) | . | How to do a hypothesis test for the difference between means when both population variances are known | using SciPy | 1 (view) | . | How to do a hypothesis test for the difference between two proportions | using SciPy | 1 (view) | . | How to do a hypothesis test for the mean with known standard deviation | using SciPy | 1 (view) | . | How to do a hypothesis test for the ratio of two population variances | using SciPy | 1 (view) | . | How to do a Kruskal-Wallis test | using SciPy | 1 (view) | . | How to do a one-sided hypothesis test for two sample means | using SciPy | 1 (view) | . | How to do a one-way analysis of variance (ANOVA) | using SciPy | 2 (view) | . | How to do a Spearman rank correlation test | using SciPy | 1 (view) | . | How to do a test of joint significance | using Statsmodels | 1 (view) | . | How to do a two-sided hypothesis test for a sample mean | using SciPy | 2 (view) | . | How to do a two-sided hypothesis test for two sample means | using SciPy | 2 (view) | . | How to do a two-way ANOVA test with interaction | using Statsmodels | 1 (view) | . | How to do a two-way ANOVA test without interaction | using Statsmodels | 1 (view) | . | How to do a Wilcoxon rank-sum test | using SciPy | 1 (view) | . | How to do a Wilcoxon signed-rank test | using SciPy | 1 (view) | . | How to do a Wilcoxon signed-rank test for matched pairs | using SciPy | 1 (view) | . | How to do basic mathematical computations | using NumPy, using SymPy, solution | 3 (view) | . | How to do implicit differentiation | using SymPy | None | . | How to find the critical numbers of a function | using SymPy | None | . | How to fit a linear model to two columns of data | using SciPy, using statsmodels | 2 (view) | . | How to fit a multivariate linear model | using statsmodels | 1 (view) | . | How to generate random values from a distribution | using SciPy | 3 (view) | . | How to graph a two-variable function as a surface | using SymPy | None | . | How to graph curves that are not functions | using SymPy | None | . | How to graph mathematical functions | using NumPy and Matplotlib, using SymPy | 1 (view) | . | How to graph mathematical sequences | using SymPy and Matplotlib | None | . | How to isolate one variable in an equation | using SymPy | None | . | How to perform a chi-squared test on a contingency table | using SciPy | 2 (view) | . | How to perform an analysis of covariance (ANCOVA) | using pingouin | 1 (view) | . | How to perform pairwise comparisons | using statsmodels, Matplotlib and scikit | 1 (view) | . | How to perform post-hoc analysis with Tukey’s HSD test | using statsmodels, Matplotlib and scikit | 2 (view) | . | How to plot continuous probability distributions | using SciPy | 3 (view) | . | How to plot discrete probability distributions | using SciPy | 2 (view) | . | How to plot interaction effects of treatments | using Matplotlib and Seaborn | 1 (view) | . | How to predict the response variable in a linear model | using statsmodels | 1 (view) | . | How to quickly load some sample data | solution | 2 (view) | . | How to solve an ordinary differential equation | using SymPy | None | . | How to solve symbolic equations | using SymPy | None | . | How to substitute a value for a symbolic variable | using SymPy | None | . | How to summarize a column | solution | 2 (view) | . | How to summarize and compare data by groups | solution | 1 (view) | . | How to test data for normality with the D’Agostino-Pearson test | using SciPy | None | . | How to test data for normality with the Jarque-Bera test | using SciPy | None | . | How to test for a treatment effect in a single factor design | using SciPy and statsmodels | 1 (view) | . | How to write a piecewise-defined function | using SymPy | None | . | How to write an ordinary differential equation | using SymPy | None | . | How to write and evaluate definite integrals | using SymPy | None | . | How to write and evaluate indefinite integrals | using SymPy | None | . | How to write symbolic equations | using SymPy | None | . ",
    "url": "/software-package-python/#solutions-in-python-101",
    "relUrl": "/software-package-python/#solutions-in-python-101"
  },"1328": {
    "doc": "Software package: Python",
    "title": "Solutions needed in Python",
    "content": "| Task | Solutions in Python | Solutions in other software packages | . | How to add an interaction term to a model | none yet(Want to submit one?) | 1 (view) | . | How to compute Fisher’s confidence intervals | none yet(Want to submit one?) | 1 (view) | . | How to do a hypothesis test for population variance | none yet(Want to submit one?) | 1 (view) | . | How to do a hypothesis test of a coefficient’s significance | none yet(Want to submit one?) | 1 (view) | . | How to find critical values and p-values from the normal distribution | none yet(Want to submit one?) | 2 (view) | . | How to find critical values and p-values from the t-distribution | none yet(Want to submit one?) | 2 (view) | . | How to perform a planned comparison test | none yet(Want to submit one?) | 1 (view) | . | How to test data for normality with Pearson’s chi-squared test | none yet(Want to submit one?) | 1 (view) | . | How to use Bonferroni’s Correction method | none yet(Want to submit one?) | 1 (view) | . ",
    "url": "/software-package-python/#solutions-needed-in-python",
    "relUrl": "/software-package-python/#solutions-needed-in-python"
  },"1329": {
    "doc": "Software package: R",
    "title": "Software package: R",
    "content": ". ",
    "url": "/software-package-r/",
    "relUrl": "/software-package-r/"
  },"1330": {
    "doc": "Software package: R",
    "title": "Solutions in R (82)",
    "content": "| Task | Solutions in R | Solutions in other software packages | . | How to add a polynomial term to a model | solution | 1 (view) | . | How to add a transformed term to a model | solution | 1 (view) | . | How to add an interaction term to a model | solution | None | . | How to add details to a plot | solution | 1 (view) | . | How to analyze the sample means of different treatment conditions | using gplots and emmeans | 1 (view) | . | How to check the assumptions of a linear model | solution | 1 (view) | . | How to choose the sample size in a study with two population means | solution | 1 (view) | . | How to compare two nested linear models | solution | 1 (view) | . | How to compute a confidence interval for a mean difference (matched pairs) | solution | 1 (view) | . | How to compute a confidence interval for a population mean | solution | 2 (view) | . | How to compute a confidence interval for a population mean using z-scores | solution | 1 (view) | . | How to compute a confidence interval for a regression coefficient | solution | 1 (view) | . | How to compute a confidence interval for a single population variance | solution | 1 (view) | . | How to compute a confidence interval for the difference between two means when both population variances are known | solution | 1 (view) | . | How to compute a confidence interval for the difference between two means when population variances are unknown | solution | 1 (view) | . | How to compute a confidence interval for the difference between two proportions | solution | 1 (view) | . | How to compute a confidence interval for the expected value of a response variable | solution | 1 (view) | . | How to compute a confidence interval for the population proportion | solution | 1 (view) | . | How to compute a confidence interval for the ratio of two population variances | solution | 1 (view) | . | How to compute adjusted R-squared | solution | 1 (view) | . | How to compute covariance and correlation coefficients | solution | 1 (view) | . | How to compute Fisher’s confidence intervals | solution | None | . | How to compute probabilities from a distribution | solution | 3 (view) | . | How to compute R-squared for a simple linear model | solution | 2 (view) | . | How to compute summary statistics | solution | 3 (view) | . | How to compute the derivative of a function | solution | 1 (view) | . | How to compute the power of a test comparing two population means | solution | 1 (view) | . | How to compute the residuals of a linear model | solution | 1 (view) | . | How to compute the standard error of the estimate for a model | solution | 1 (view) | . | How to conduct a mixed designs ANOVA | solution | 1 (view) | . | How to conduct a repeated measures ANOVA | using rstatix and tidyr and car | 1 (view) | . | How to convert a text column into dates | solution | 1 (view) | . | How to create a box (and whisker) plot | solution | 1 (view) | . | How to create a data frame from scratch | solution | 1 (view) | . | How to create a histogram | solution | 1 (view) | . | How to create a QQ-plot | solution | 2 (view) | . | How to create basic plots | solution | 1 (view) | . | How to create bivariate plots to compare groups | using lattice and gplots | 1 (view) | . | How to do a goodness of fit test for a multinomial experiment | solution | 1 (view) | . | How to do a hypothesis test for a mean difference (matched pairs) | solution | 1 (view) | . | How to do a hypothesis test for a population proportion | solution | 1 (view) | . | How to do a hypothesis test for population variance | solution | None | . | How to do a hypothesis test for the difference between means when both population variances are known | solution | 1 (view) | . | How to do a hypothesis test for the difference between two proportions | solution | 1 (view) | . | How to do a hypothesis test for the mean with known standard deviation | solution | 1 (view) | . | How to do a hypothesis test for the ratio of two population variances | solution | 1 (view) | . | How to do a hypothesis test of a coefficient’s significance | solution | None | . | How to do a Kruskal-Wallis test | solution | 1 (view) | . | How to do a one-sided hypothesis test for two sample means | solution | 1 (view) | . | How to do a one-way analysis of variance (ANOVA) | solution | 2 (view) | . | How to do a Spearman rank correlation test | solution | 1 (view) | . | How to do a test of joint significance | solution | 1 (view) | . | How to do a two-sided hypothesis test for a sample mean | solution | 2 (view) | . | How to do a two-sided hypothesis test for two sample means | solution | 2 (view) | . | How to do a two-way ANOVA test with interaction | solution | 1 (view) | . | How to do a two-way ANOVA test without interaction | solution | 1 (view) | . | How to do a Wilcoxon rank-sum test | solution | 1 (view) | . | How to do a Wilcoxon signed-rank test | solution | 1 (view) | . | How to do a Wilcoxon signed-rank test for matched pairs | solution | 1 (view) | . | How to do basic mathematical computations | solution | 5 (view) | . | How to find critical values and p-values from the normal distribution | solution | 1 (view) | . | How to find critical values and p-values from the t-distribution | solution | 1 (view) | . | How to fit a linear model to two columns of data | solution | 3 (view) | . | How to fit a multivariate linear model | solution | 1 (view) | . | How to generate random values from a distribution | solution | 3 (view) | . | How to graph mathematical functions | solution | 2 (view) | . | How to perform a chi-squared test on a contingency table | solution | 2 (view) | . | How to perform a planned comparison test | using gmodels | None | . | How to perform an analysis of covariance (ANCOVA) | solution | 1 (view) | . | How to perform pairwise comparisons | solution | 1 (view) | . | How to perform post-hoc analysis with Tukey’s HSD test | using agricolae, solution | 1 (view) | . | How to plot continuous probability distributions | solution | 3 (view) | . | How to plot discrete probability distributions | solution | 2 (view) | . | How to plot interaction effects of treatments | using ggpubr | 1 (view) | . | How to predict the response variable in a linear model | solution | 1 (view) | . | How to quickly load some sample data | solution | 2 (view) | . | How to summarize a column | solution | 2 (view) | . | How to summarize and compare data by groups | solution | 1 (view) | . | How to test data for normality with Pearson’s chi-squared test | solution | None | . | How to test for a treatment effect in a single factor design | using perm | 1 (view) | . | How to use Bonferroni’s Correction method | solution | None | . ",
    "url": "/software-package-r/#solutions-in-r-82",
    "relUrl": "/software-package-r/#solutions-in-r-82"
  },"1331": {
    "doc": "Software package: R",
    "title": "Solutions needed in R",
    "content": "| Task | Solutions in R | Solutions in other software packages | . | How to change axes, ticks, and scale in a plot | none yet(Want to submit one?) | 1 (view) | . | How to compute the domain of a function | none yet(Want to submit one?) | 1 (view) | . | How to compute the error bounds on a Taylor approximation | none yet(Want to submit one?) | 1 (view) | . | How to compute the limit of a function | none yet(Want to submit one?) | 1 (view) | . | How to compute the Taylor series for a function | none yet(Want to submit one?) | 1 (view) | . | How to create symbolic variables | none yet(Want to submit one?) | 1 (view) | . | How to define a mathematical sequence | none yet(Want to submit one?) | 1 (view) | . | How to define a mathematical series | none yet(Want to submit one?) | 1 (view) | . | How to do implicit differentiation | none yet(Want to submit one?) | 1 (view) | . | How to find the critical numbers of a function | none yet(Want to submit one?) | 1 (view) | . | How to graph a two-variable function as a surface | none yet(Want to submit one?) | 1 (view) | . | How to graph curves that are not functions | none yet(Want to submit one?) | 1 (view) | . | How to graph mathematical sequences | none yet(Want to submit one?) | 1 (view) | . | How to isolate one variable in an equation | none yet(Want to submit one?) | 1 (view) | . | How to solve an ordinary differential equation | none yet(Want to submit one?) | 1 (view) | . | How to solve symbolic equations | none yet(Want to submit one?) | 1 (view) | . | How to substitute a value for a symbolic variable | none yet(Want to submit one?) | 1 (view) | . | How to test data for normality with the D’Agostino-Pearson test | none yet(Want to submit one?) | 1 (view) | . | How to test data for normality with the Jarque-Bera test | none yet(Want to submit one?) | 1 (view) | . | How to write a piecewise-defined function | none yet(Want to submit one?) | 1 (view) | . | How to write an ordinary differential equation | none yet(Want to submit one?) | 1 (view) | . | How to write and evaluate definite integrals | none yet(Want to submit one?) | 1 (view) | . | How to write and evaluate indefinite integrals | none yet(Want to submit one?) | 1 (view) | . | How to write symbolic equations | none yet(Want to submit one?) | 1 (view) | . ",
    "url": "/software-package-r/#solutions-needed-in-r",
    "relUrl": "/software-package-r/#solutions-needed-in-r"
  },"1332": {
    "doc": "Software Packages",
    "title": "Software Packages",
    "content": "Here is a list of the software packages that appear in the solutions on this website. This list can include standard applications like Microsoft Excel, web-based applications like Google Sheets, or programming languages like Python and R. | Software Package | Icon | Number of solutions | Website | . | Python | | 101 | https://www.python.org/ | . | R | | 82 | https://www.r-project.org/ | . | Excel | | 6 | https://www.microsoft.com/en-us/microsoft-365/excel | . | Julia | | 16 | https://julialang.org/ | . ",
    "url": "/software/",
    "relUrl": "/software/"
  },"1333": {
    "doc": "Software Packages",
    "title": "Under Construction",
    "content": "We will add additional software packages in time. Our initial priorities are on the two programming languages used in data-related courses at Bentley University, where this website is being created (and those are Python and R). Natural next steps include languages like Julia and popular software like Excel, SPSS, etc. ",
    "url": "/software/#under-construction",
    "relUrl": "/software/#under-construction"
  },"1334": {
    "doc": "Tasks",
    "title": "Tasks",
    "content": "This database is a list of tasks that students of data science may want to know how to accomplish, all phrased as “How to” questions. The table below lists all tasks in the database. To see them categorized, check out the topics page. | Task | Solutions | . | How to add a polynomial term to a model | In Python: using sklearnIn R: solution | . | How to add a transformed term to a model | In Python: using NumPy and sklearnIn R: solution | . | How to add an interaction term to a model | In R: solution | . | How to add details to a plot | In Python: using MatplotlibIn R: solution | . | How to analyze the sample means of different treatment conditions | In Python: using Matplotlib and SeabornIn R: using gplots and emmeans | . | How to change axes, ticks, and scale in a plot | In Python: using Matplotlib | . | How to check the assumptions of a linear model | In Python: using NumPy, SciPy, sklearn, Matplotlib and SeabornIn R: solution | . | How to choose the sample size in a study with two population means | In Python: using statsmodelsIn R: solution | . | How to compare two nested linear models | In Python: using statsmodelsIn R: solution | . | How to compute a confidence interval for a mean difference (matched pairs) | In Python: using NumPy and SciPyIn R: solution | . | How to compute a confidence interval for a population mean | In Python: using SciPyIn R: solutionIn Julia: solution | . | How to compute a confidence interval for a population mean using z-scores | In Python: using SciPyIn R: solution | . | How to compute a confidence interval for a regression coefficient | In Python: using statsmodelsIn R: solution | . | How to compute a confidence interval for a single population variance | In Python: using SciPyIn R: solution | . | How to compute a confidence interval for the difference between two means when both population variances are known | In Python: using NumPy and SciPyIn R: solution | . | How to compute a confidence interval for the difference between two means when population variances are unknown | In Python: using NumPy and SciPyIn R: solution | . | How to compute a confidence interval for the difference between two proportions | In Python: using SciPyIn R: solution | . | How to compute a confidence interval for the expected value of a response variable | In Python: using statsmodels and sklearnIn R: solution | . | How to compute a confidence interval for the population proportion | In Python: using SciPyIn R: solution | . | How to compute a confidence interval for the ratio of two population variances | In Python: using SciPyIn R: solution | . | How to compute adjusted R-squared | In Python: using statsmodelsIn R: solution | . | How to compute covariance and correlation coefficients | In Python: using pandas and NumPyIn R: solution | . | How to compute Fisher’s confidence intervals | In R: solution | . | How to compute probabilities from a distribution | In Python: using SciPyIn R: solutionIn Excel: solutionIn Julia: solution | . | How to compute R-squared for a simple linear model | In Python: using SciPyIn R: solutionIn Julia: solution | . | How to compute summary statistics | In Python: using pandas and NumPyIn R: solutionIn Excel: solutionIn Julia: solution | . | How to compute the derivative of a function | In Python: using SymPyIn R: solution | . | How to compute the domain of a function | In Python: using SymPy | . | How to compute the error bounds on a Taylor approximation | In Python: using SymPy | . | How to compute the limit of a function | In Python: using SymPy | . | How to compute the power of a test comparing two population means | In Python: using statsmodelsIn R: solution | . | How to compute the residuals of a linear model | In Python: using statsmodelsIn R: solution | . | How to compute the standard error of the estimate for a model | In Python: using statsmodelsIn R: solution | . | How to compute the Taylor series for a function | In Python: using SymPy | . | How to conduct a mixed designs ANOVA | In Python: using pandas and pingouinIn R: solution | . | How to conduct a repeated measures ANOVA | In Python: using pandas and pingouinIn R: using rstatix and tidyr and car | . | How to convert a text column into dates | In Python: using pandasIn R: solution | . | How to create a box (and whisker) plot | In Python: using MatplotlibIn R: solution | . | How to create a data frame from scratch | In Python: solutionIn R: solution | . | How to create a histogram | In Python: using MatplotlibIn R: solution | . | How to create a QQ-plot | In Python: using SciPy, using statsmodelsIn R: solution | . | How to create basic plots | In Python: using MatplotlibIn R: solution | . | How to create bivariate plots to compare groups | In Python: using Matplotlib and SeabornIn R: using lattice and gplots | . | How to create symbolic variables | In Python: using SymPy | . | How to define a mathematical sequence | In Python: using SymPy | . | How to define a mathematical series | In Python: using SymPy | . | How to do a goodness of fit test for a multinomial experiment | In Python: using SciPyIn R: solution | . | How to do a hypothesis test for a mean difference (matched pairs) | In Python: using SciPyIn R: solution | . | How to do a hypothesis test for a population proportion | In Python: using SciPyIn R: solution | . | How to do a hypothesis test for population variance | In R: solution | . | How to do a hypothesis test for the difference between means when both population variances are known | In Python: using SciPyIn R: solution | . | How to do a hypothesis test for the difference between two proportions | In Python: using SciPyIn R: solution | . | How to do a hypothesis test for the mean with known standard deviation | In Python: using SciPyIn R: solution | . | How to do a hypothesis test for the ratio of two population variances | In Python: using SciPyIn R: solution | . | How to do a hypothesis test of a coefficient’s significance | In R: solution | . | How to do a Kruskal-Wallis test | In Python: using SciPyIn R: solution | . | How to do a one-sided hypothesis test for two sample means | In Python: using SciPyIn R: solution | . | How to do a one-way analysis of variance (ANOVA) | In Python: using SciPyIn R: solutionIn Julia: solution | . | How to do a Spearman rank correlation test | In Python: using SciPyIn R: solution | . | How to do a test of joint significance | In Python: using StatsmodelsIn R: solution | . | How to do a two-sided hypothesis test for a sample mean | In Python: using SciPyIn R: solutionIn Julia: solution | . | How to do a two-sided hypothesis test for two sample means | In Python: using SciPyIn R: solutionIn Julia: solution | . | How to do a two-way ANOVA test with interaction | In Python: using StatsmodelsIn R: solution | . | How to do a two-way ANOVA test without interaction | In Python: using StatsmodelsIn R: solution | . | How to do a Wilcoxon rank-sum test | In Python: using SciPyIn R: solution | . | How to do a Wilcoxon signed-rank test | In Python: using SciPyIn R: solution | . | How to do a Wilcoxon signed-rank test for matched pairs | In Python: using SciPyIn R: solution | . | How to do basic mathematical computations | In Python: using NumPy, using SymPy, solutionIn R: solutionIn Excel: solutionIn Julia: solution | . | How to do implicit differentiation | In Python: using SymPy | . | How to find critical values and p-values from the normal distribution | In R: solutionIn Julia: solution | . | How to find critical values and p-values from the t-distribution | In R: solutionIn Julia: solution | . | How to find the critical numbers of a function | In Python: using SymPy | . | How to fit a linear model to two columns of data | In Python: using SciPy, using statsmodelsIn R: solutionIn Julia: solution | . | How to fit a multivariate linear model | In Python: using statsmodelsIn R: solution | . | How to generate random values from a distribution | In Python: using SciPyIn R: solutionIn Excel: solutionIn Julia: solution | . | How to graph a two-variable function as a surface | In Python: using SymPy | . | How to graph curves that are not functions | In Python: using SymPy | . | How to graph mathematical functions | In Python: using NumPy and Matplotlib, using SymPyIn R: solution | . | How to graph mathematical sequences | In Python: using SymPy and Matplotlib | . | How to isolate one variable in an equation | In Python: using SymPy | . | How to perform a chi-squared test on a contingency table | In Python: using SciPyIn R: solutionIn Julia: solution | . | How to perform a planned comparison test | In R: using gmodels | . | How to perform an analysis of covariance (ANCOVA) | In Python: using pingouinIn R: solution | . | How to perform pairwise comparisons | In Python: using statsmodels, Matplotlib and scikitIn R: solution | . | How to perform post-hoc analysis with Tukey’s HSD test | In Python: using statsmodels, Matplotlib and scikitIn R: using agricolae, solution | . | How to plot continuous probability distributions | In Python: using SciPyIn R: solutionIn Excel: solutionIn Julia: solution | . | How to plot discrete probability distributions | In Python: using SciPyIn R: solutionIn Julia: solution | . | How to plot interaction effects of treatments | In Python: using Matplotlib and SeabornIn R: using ggpubr | . | How to predict the response variable in a linear model | In Python: using statsmodelsIn R: solution | . | How to quickly load some sample data | In Python: solutionIn R: solutionIn Julia: solution | . | How to solve an ordinary differential equation | In Python: using SymPy | . | How to solve symbolic equations | In Python: using SymPy | . | How to substitute a value for a symbolic variable | In Python: using SymPy | . | How to summarize a column | In Python: solutionIn R: solutionIn Excel: solution | . | How to summarize and compare data by groups | In Python: solutionIn R: solution | . | How to test data for normality with Pearson’s chi-squared test | In R: solution | . | How to test data for normality with the D’Agostino-Pearson test | In Python: using SciPy | . | How to test data for normality with the Jarque-Bera test | In Python: using SciPy | . | How to test for a treatment effect in a single factor design | In Python: using SciPy and statsmodelsIn R: using perm | . | How to use Bonferroni’s Correction method | In R: solution | . | How to write a piecewise-defined function | In Python: using SymPy | . | How to write an ordinary differential equation | In Python: using SymPy | . | How to write and evaluate definite integrals | In Python: using SymPy | . | How to write and evaluate indefinite integrals | In Python: using SymPy | . | How to write symbolic equations | In Python: using SymPy | . ",
    "url": "/tasks/",
    "relUrl": "/tasks/"
  },"1335": {
    "doc": "Topics",
    "title": "Topics",
    "content": " ",
    "url": "/topics/",
    "relUrl": "/topics/"
  },"1336": {
    "doc": "Topics",
    "title": "What is a “topic?”",
    "content": "Although this website is focused mostly on tasks, it can be helpful to have them organized in some way. We organize them into topics. A topic can be a course at a univeristy or other school, a textbook, a field of study, or any other category into which we can collect tasks in a way that’s helpful this site’s readers. ",
    "url": "/topics/#what-is-a-topic",
    "relUrl": "/topics/#what-is-a-topic"
  },"1337": {
    "doc": "Topics",
    "title": "All topics, in alphabetical order",
    "content": ". | Bentley University GB213 | Bentley University GR521 | Bentley University GR526 | Bentley University MA214 | Bentley University MA252 | Bentley University MA255 | Bentley University MA346 | . ",
    "url": "/topics/#all-topics-in-alphabetical-order",
    "relUrl": "/topics/#all-topics-in-alphabetical-order"
  },"1338": {
    "doc": "Topics",
    "title": "Under construction",
    "content": "There will be many more topics added to this site in time. This website has just begun! Check back later. ",
    "url": "/topics/#under-construction",
    "relUrl": "/topics/#under-construction"
  }
}
